{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "loader = TextLoader(\"file.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content=\"Python is a versatile and powerful programming language that has gained immense popularity in recent years. Known for its simplicity and readability, Python is often the first choice for beginners and experienced developers alike. Created by Guido van Rossum and first released in 1991, Python has since evolved into a robust language used in various fields such as web development, data science, artificial intelligence, and more. One of the key reasons for Python's popularity is its easy-to-understand syntax, which emphasizes readability and reduces the cost of program maintenance. Python's design philosophy emphasizes code readability with its notable use of significant whitespace. It provides constructs that enable clear programming on both small and large scales.\\n\\nPython supports multiple programming paradigms, including object-oriented, imperative, functional, and procedural programming. This versatility allows developers to choose the approach that best suits their needs, making Python suitable for a wide range of applications. Additionally, Python has a comprehensive standard library that provides support for many common tasks, such as file I/O, networking, and web development. This extensive library reduces the need for developers to write code from scratch, enabling them to focus on solving specific problems.\\n\\nAnother key feature of Python is its strong community support. The Python community is known for its inclusivity and helpfulness, with a vast number of libraries and frameworks available for almost any task imaginable. These libraries and frameworks, such as Django for web development, NumPy for scientific computing, and TensorFlow for machine learning, contribute to Python's popularity in various fields.\\n\\nPython's popularity in the field of data science and machine learning is particularly noteworthy. Its simplicity and readability make it an ideal choice for data analysis and visualization tasks. Libraries such as Pandas, Matplotlib, and Seaborn provide powerful tools for working with data, while libraries like TensorFlow and PyTorch offer state-of-the-art machine learning capabilities. Python's popularity in these fields has been further boosted by the rise of Jupyter notebooks, which allow for interactive and exploratory data analysis.\\n\\nIn addition to its use in data science and machine learning, Python is also widely used in web development. Frameworks like Django and Flask provide developers with the tools to build scalable and secure web applications. Python's simplicity and readability make it easy to develop and maintain web applications, making it a popular choice among web developers.\\n\\nPython's versatility extends beyond web development and data science. It is also used in game development, desktop applications, network programming, and more. Its ease of use and extensive library support make it a go-to language for developers working in various domains.\\n\\nIn conclusion, Python is a powerful and versatile programming language that has gained widespread popularity due to its simplicity, readability, and strong community support. Its versatility makes it suitable for a wide range of applications, from web development to data science and machine learning. Whether you're a beginner learning to code or an experienced developer working on complex projects, Python has something to offer for everyone.\", metadata={'source': 'file.txt'})]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_doc = loader.load()\n",
    "text_doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='', metadata={'source': 'python.pdf', 'page': 0}),\n",
       " Document(page_content='Learning Python', metadata={'source': 'python.pdf', 'page': 1}),\n",
       " Document(page_content='', metadata={'source': 'python.pdf', 'page': 2}),\n",
       " Document(page_content='FOURTH EDITION\\nLearning Python\\nMark Lutz\\nBeijing •Cambridge •Farnham •Köln •Sebastopol •Taipei •Tokyo', metadata={'source': 'python.pdf', 'page': 3}),\n",
       " Document(page_content='Learning Python, Fourth Edition\\nby Mark Lutz\\nCopyright © 2009 Mark Lutz. All rights reserved.\\nPrinted in the United States of America.\\nPublished by O’Reilly Media, Inc., 1005 Gravenstein Highway North, Sebastopol, CA 95472.\\nO’Reilly books may \\nbe purchased for educational, business, or sales promotional use. Online editions\\nare also available for most titles ( http://my.safaribooksonline.com). For more information, contact our\\ncorporate/institutional sales department: (800) 998-9938 or corporate@oreilly.com.\\nEditor: Julie Steele\\nProduction Editor: Sumita Mukherji\\nCopyeditor: Rachel Head\\nProduction Services: Newgen North AmericaIndexer: John Bickelhaupt\\nCover Designer: Karen Montgomery\\nInterior Designer: David Futato\\nIllustrator: Robert Romano\\nPrinting History:\\nMarch 1999: First Edition. \\nDecember 2003: Second Edition. \\nOctober 2007:\\nThird Edition. \\nSeptember 2009: Fourth Edition. \\nNutshell Handbook, the Nutshell Handbook logo, and the O’Reilly logo are registered trademarks of\\nO’Reilly Media, Inc. Learning Python , \\nthe image of a wood rat, and related trade dress are trademarks\\nof O’Reilly Media, Inc.\\nMany of the designations used by manufacturers and sellers to distinguish their products are claimed as\\ntrademarks. Where those designations appear in this book, and O’Reilly Media, Inc., was aware of a\\ntrademark claim, the designations have been printed in caps or initial caps.\\nWhile every precaution has been taken in the preparation of this book, the publisher and author assume\\nno responsibility for errors or omissions, or for damages resulting from the use of the information con-\\ntained herein.\\nISBN: 978-0-596-15806-4\\n[M]\\n1252944666', metadata={'source': 'python.pdf', 'page': 4}),\n",
       " Document(page_content='To Vera.\\nYou are my life.', metadata={'source': 'python.pdf', 'page': 5}),\n",
       " Document(page_content='', metadata={'source': 'python.pdf', 'page': 6}),\n",
       " Document(page_content='Table of Contents\\nPreface . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  xxxi\\nPart I. Getting Started \\n1. A Python Q&A Session . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  3\\nWhy Do People Use Python? 3\\nSoftware Quality 4\\nDeveloper Productivity 5\\nIs Python a “Scripting Language”? 5\\nOK, but What’s the Downside? 7\\nWho Uses Python Today? 7\\nWhat Can I Do with Python? 9\\nSystems Programming 9\\nGUIs 9\\nInternet Scripting 10\\nComponent Integration 10\\nDatabase Programming 11\\nRapid Prototyping 11\\nNumeric and Scientific Programming 11\\nGaming, Images, Serial Ports, XML, Robots, and More 12\\nHow Is Python Supported? 12\\nWhat Are Python’s Technical Strengths? 13\\nIt’s Object-Oriented 13\\nIt’s Free 13\\nIt’s Portable 14\\nIt’s Powerful 15\\nIt’s Mixable 16\\nIt’s Easy to Use 16\\nIt’s Easy to Learn 17\\nIt’s Named After Monty Python 17\\nHow Does Python Stack Up to Language X? 17\\nvii', metadata={'source': 'python.pdf', 'page': 7}),\n",
       " Document(page_content='Chapter Summary 18\\nTest Your Knowledge: Quiz 19\\nTest Your Knowledge: Answers 19\\n2. How Python Runs Programs \\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  23\\nIntroducing the Python Interpreter 23\\nProgram Execution 24\\nThe Programmer’s View 24\\nPython’s View 26\\nExecution Model Variations 29\\nPython Implementation Alternatives 29\\nExecution Optimization Tools 30\\nFrozen Binaries 32\\nOther Execution Options 33\\nFuture Possibilities? 33\\nChapter Summary 34\\nTest Your Knowledge: Quiz 34\\nTest Your Knowledge: Answers 34\\n3. How You Run Programs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  35\\nThe Interactive Prompt 35\\nRunning Code Interactively 37\\nWhy the Interactive Prompt? 38\\nUsing the Interactive Prompt 39\\nSystem Command Lines and Files 41\\nA First Script 42\\nRunning Files with Command Lines 43\\nUsing Command Lines and Files 44\\nUnix Executable Scripts (#!) 46\\nClicking File Icons 47\\nClicking Icons on Windows 47\\nThe input Trick 49\\nOther Icon-Click Limitations 50\\nModule Imports and Reloads 51\\nThe Grander Module Story: Attributes 53\\nimport and reload Usage Notes 56\\nUsing exec to Run Module Files 57\\nThe IDLE User Interface 58\\nIDLE Basics 58\\nUsing IDLE 60\\nAdvanced IDLE Tools 62\\nOther IDEs 63\\nOther Launch Options 64\\nviii | Table of Contents', metadata={'source': 'python.pdf', 'page': 8}),\n",
       " Document(page_content='Embedding Calls 64\\nFrozen Binary Executables 65\\nText Editor Launch Options 65\\nStill Other Launch Options 66\\nFuture Possibilities? 66\\nWhich Option Should I Use? 66\\nChapter Summary 68\\nTest Your Knowledge: Quiz 68\\nTest Your Knowledge: Answers 69\\nTest Your Knowledge: Part I Exercises 70\\nPart II. Types and Operations \\n4. Introducing Python Object Types . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  75\\nWhy Use Built-in Types? 76\\nPython’s Core Data Types 77\\nNumbers 78\\nStrings 80\\nSequence Operations 80\\nImmutability 82\\nType-Specific Methods 82\\nGetting Help 84\\nOther Ways to Code Strings 85\\nPattern Matching 85\\nLists 86\\nSequence Operations 86\\nType-Specific Operations 87\\nBounds Checking 87\\nNesting 88\\nComprehensions 88\\nDictionaries 90\\nMapping Operations 90\\nNesting Revisited 91\\nSorting Keys: for Loops 93\\nIteration and Optimization 94\\nMissing Keys: if Tests 95\\nTuples 96\\nWhy Tuples? 97\\nFiles 97\\nOther File-Like Tools 99\\nOther Core Types 99\\nHow to Break Your Code’s Flexibility 100\\nTable of Contents | ix', metadata={'source': 'python.pdf', 'page': 9}),\n",
       " Document(page_content='User-Defined Classes 101\\nAnd Everything Else 102\\nChapter Summary 103\\nTest Your Knowledge: Quiz 103\\nTest Your Knowledge: Answers 104\\n5. Numeric Types \\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  105\\nNumeric Type Basics 105\\nNumeric Literals 106\\nBuilt-in Numeric Tools 108\\nPython Expression Operators 108\\nNumbers in Action 113\\nVariables and Basic Expressions 113\\nNumeric Display Formats 115\\nComparisons: Normal and Chained 116\\nDivision: Classic, Floor, and True 117\\nInteger Precision 121\\nComplex Numbers 122\\nHexadecimal, Octal, and Binary Notation 122\\nBitwise Operations 124\\nOther Built-in Numeric Tools 125\\nOther Numeric Types 127\\nDecimal Type 127\\nFraction Type 129\\nSets 133\\nBooleans 139\\nNumeric Extensions 140\\nChapter Summary 141\\nTest Your Knowledge: Quiz 141\\nTest Your Knowledge: Answers 141\\n6. The Dynamic Typing Interlude . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  143\\nThe Case of the Missing Declaration Statements 143\\nVariables, Objects, and References 144\\nTypes Live with Objects, Not Variables 145\\nObjects Are Garbage-Collected 146\\nShared References 148\\nShared References and In-Place Changes 149\\nShared References and Equality 151\\nDynamic Typing Is Everywhere 152\\nChapter Summary 153\\nTest Your Knowledge: Quiz 153\\nTest Your Knowledge: Answers 154\\nx | Table of Contents', metadata={'source': 'python.pdf', 'page': 10}),\n",
       " Document(page_content='7. Strings . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  155\\nString Literals 157\\nSingle- and Double-Quoted Strings Are the Same 158\\nEscape Sequences Represent Special Bytes 158\\nRaw Strings Suppress Escapes 161\\nTriple Quotes Code Multiline Block Strings 162\\nStrings in Action 163\\nBasic Operations 164\\nIndexing and Slicing 165\\nString Conversion Tools 169\\nChanging Strings 171\\nString Methods 172\\nString Method Examples: Changing Strings 174\\nString Method Examples: Parsing Text 176\\nOther Common String Methods in Action 177\\nThe Original string Module (Gone in 3.0) 178\\nString Formatting Expressions 179\\nAdvanced String Formatting Expressions 181\\nDictionary-Based String Formatting Expressions 182\\nString Formatting Method Calls 183\\nThe Basics 184\\nAdding Keys, Attributes, and Offsets 184\\nAdding Specific Formatting 185\\nComparison to the % Formatting Expression 187\\nWhy the New Format Method? 190\\nGeneral Type Categories 193\\nTypes Share Operation Sets by Categories 194\\nMutable Types Can Be Changed In-Place 194\\nChapter Summary 195\\nTest Your Knowledge: Quiz 195\\nTest Your Knowledge: Answers 196\\n8. Lists and Dictionaries \\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  197\\nLists 197\\nLists in Action 200\\nBasic List Operations 200\\nList Iteration and Comprehensions 200\\nIndexing, Slicing, and Matrixes 201\\nChanging Lists In-Place 202\\nDictionaries 207\\nDictionaries in Action 209\\nBasic Dictionary Operations 209\\nChanging Dictionaries In-Place 210\\nTable of Contents | xi', metadata={'source': 'python.pdf', 'page': 11}),\n",
       " Document(page_content='More Dictionary Methods 211\\nA Languages Table 212\\nDictionary Usage Notes 213\\nOther Ways to Make Dictionaries 216\\nDictionary Changes in Python 3.0 217\\nChapter Summary 223\\nTest Your Knowledge: Quiz 224\\nTest Your Knowledge: Answers 224\\n9. Tuples, Files, and Everything Else \\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  225\\nTuples 225\\nTuples in Action 227\\nWhy Lists and Tuples? 229\\nFiles 229\\nOpening Files 230\\nUsing Files 231\\nFiles in Action 232\\nOther File Tools 238\\nType Categories Revisited 239\\nObject Flexibility 241\\nReferences Versus Copies 241\\nComparisons, Equality, and Truth 244\\nPython 3.0 Dictionary Comparisons 246\\nThe Meaning of True and False in Python 246\\nPython’s Type Hierarchies 248\\nType Objects 249\\nOther Types in Python 250\\nBuilt-in Type Gotchas 251\\nAssignment Creates References, Not Copies 251\\nRepetition Adds One Level Deep 252\\nBeware of Cyclic Data Structures 252\\nImmutable Types Can’t Be Changed In-Place 253\\nChapter Summary 253\\nTest Your Knowledge: Quiz 254\\nTest Your Knowledge: Answers 254\\nTest Your Knowledge: Part II Exercises 255\\nPart III. Statements and Syntax \\n10. Introducing Python Statements . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  261\\nPython Program Structure Revisited 261\\nPython’s Statements 262\\nxii | Table of Contents', metadata={'source': 'python.pdf', 'page': 12}),\n",
       " Document(page_content='A Tale of Two ifs 264\\nWhat Python Adds 264\\nWhat Python Removes 265\\nWhy Indentation Syntax? 266\\nA Few Special Cases 269\\nA Quick Example: Interactive Loops 271\\nA Simple Interactive Loop 271\\nDoing Math on User Inputs 272\\nHandling Errors by Testing Inputs 273\\nHandling Errors with try Statements 274\\nNesting Code Three Levels Deep 275\\nChapter Summary 276\\nTest Your Knowledge: Quiz 276\\nTest Your Knowledge: Answers 277\\n11. Assignments, Expressions, and Prints \\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  279\\nAssignment Statements 279\\nAssignment Statement Forms 280\\nSequence Assignments 281\\nExtended Sequence Unpacking in Python 3.0 284\\nMultiple-Target Assignments 288\\nAugmented Assignments 289\\nVariable Name Rules 292\\nExpression Statements 295\\nExpression Statements and In-Place Changes 296\\nPrint Operations 297\\nThe Python 3.0 print Function 298\\nThe Python 2.6 print Statement 300\\nPrint Stream Redirection 302\\nVersion-Neutral Printing 306\\nChapter Summary 308\\nTest Your Knowledge: Quiz 308\\nTest Your Knowledge: Answers 308\\n12. if Tests and Syntax Rules . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  311\\nif Statements 311\\nGeneral Format 311\\nBasic Examples 312\\nMultiway Branching 312\\nPython Syntax Rules 314\\nBlock Delimiters: Indentation Rules 315\\nStatement Delimiters: Lines and Continuations 317\\nA Few Special Cases 318\\nTable of Contents | xiii', metadata={'source': 'python.pdf', 'page': 13}),\n",
       " Document(page_content='Truth Tests 320\\nThe if/else Ternary Expression 321\\nChapter Summary 324\\nTest Your Knowledge: Quiz 324\\nTest Your Knowledge: Answers 324\\n13. while and for Loops \\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  327\\nwhile Loops 327\\nGeneral Format 328\\nExamples 328\\nbreak, continue, pass, and the Loop else 329\\nGeneral Loop Format 329\\npass 330\\ncontinue 331\\nbreak 331\\nLoop else 332\\nfor Loops 334\\nGeneral Format 334\\nExamples 335\\nLoop Coding Techniques 341\\nCounter Loops: while and range 342\\nNonexhaustive Traversals: range and Slices 343\\nChanging Lists: range 344\\nParallel Traversals: zip and map 345\\nGenerating Both Offsets and Items: enumerate 348\\nChapter Summary 349\\nTest Your Knowledge: Quiz 349\\nTest Your Knowledge: Answers 350\\n14. Iterations and Comprehensions, Part 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  351\\nIterators: A First Look 351\\nThe Iteration Protocol: File Iterators 352\\nManual Iteration: iter and next 354\\nOther Built-in Type Iterators 356\\nList Comprehensions: A First Look 358\\nList Comprehension Basics 359\\nUsing List Comprehensions on Files 359\\nExtended List Comprehension Syntax 361\\nOther Iteration Contexts 362\\nNew Iterables in Python 3.0 366\\nThe range Iterator 367\\nThe map, zip, and filter Iterators 368\\nMultiple Versus Single Iterators 369\\nxiv | Table of Contents', metadata={'source': 'python.pdf', 'page': 14}),\n",
       " Document(page_content='Dictionary View Iterators 370\\nOther Iterator Topics 372\\nChapter Summary 372\\nTest Your Knowledge: Quiz 372\\nTest Your Knowledge: Answers 373\\n15. The Documentation Interlude \\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 375\\nPython Documentation Sources 375\\n# Comments 376\\nThe dir Function 376\\nDocstrings: __doc__ 377\\nPyDoc: The help Function 380\\nPyDoc: HTML Reports 383\\nThe Standard Manual Set 386\\nWeb Resources 387\\nPublished Books 387\\nCommon Coding Gotchas 387\\nChapter Summary 389\\nTest Your Knowledge: Quiz 389\\nTest Your Knowledge: Answers 390\\nTest Your Knowledge: Part III Exercises 390\\nPart IV. Functions \\n16. Function Basics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  395\\nWhy Use Functions? 396\\nCoding Functions 396\\ndef Statements 398\\ndef Executes at Runtime 399\\nA First Example: Definitions and Calls 400\\nDefinition 400\\nCalls 400\\nPolymorphism in Python 401\\nA Second Example: Intersecting Sequences 402\\nDefinition 402\\nCalls 403\\nPolymorphism Revisited 403\\nLocal Variables 404\\nChapter Summary 404\\nTest Your Knowledge: Quiz 405\\nTest Your Knowledge: Answers 405\\nTable of Contents | xv', metadata={'source': 'python.pdf', 'page': 15}),\n",
       " Document(page_content='17. Scopes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  407\\nPython Scope Basics 407\\nScope Rules 408\\nName Resolution: The LEGB Rule 410\\nScope Example 411\\nThe Built-in Scope 412\\nThe global Statement 414\\nMinimize Global Variables 415\\nMinimize Cross-File Changes 416\\nOther Ways to Access Globals 418\\nScopes and Nested Functions 419\\nNested Scope Details 419\\nNested Scope Examples 419\\nThe nonlocal Statement 425\\nnonlocal Basics 425\\nnonlocal in Action 426\\nWhy nonlocal? 429\\nChapter Summary 432\\nTest Your Knowledge: Quiz 433\\nTest Your Knowledge: Answers 434\\n18. Arguments \\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  435\\nArgument-Passing Basics 435\\nArguments and Shared References 436\\nAvoiding Mutable Argument Changes 438\\nSimulating Output Parameters 439\\nSpecial Argument-Matching Modes 440\\nThe Basics 441\\nMatching Syntax 442\\nThe Gritty Details 443\\nKeyword and Default Examples 444\\nArbitrary Arguments Examples 446\\nPython 3.0 Keyword-Only Arguments 450\\nThe min Wakeup Call! 453\\nFull Credit 454\\nBonus Points 455\\nThe Punch Line... 456\\nGeneralized Set Functions 456\\nEmulating the Python 3.0 print Function 457\\nUsing Keyword-Only Arguments 459\\nChapter Summary 460\\nTest Your Knowledge: Quiz 461\\nTest Your Knowledge: Answers 462\\nxvi |\\nTable of Contents', metadata={'source': 'python.pdf', 'page': 16}),\n",
       " Document(page_content='19. Advanced Function Topics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  463\\nFunction Design Concepts 463\\nRecursive Functions 465\\nSummation with Recursion 465\\nCoding Alternatives 466\\nLoop Statements Versus Recursion 467\\nHandling Arbitrary Structures 468\\nFunction Objects: Attributes and Annotations 469\\nIndirect Function Calls 469\\nFunction Introspection 470\\nFunction Attributes 471\\nFunction Annotations in 3.0 472\\nAnonymous Functions: lambda 474\\nlambda Basics 474\\nWhy Use lambda? 475\\nHow (Not) to Obfuscate Your Python Code 477\\nNested lambdas and Scopes 478\\nMapping Functions over Sequences: map 479\\nFunctional Programming Tools: filter and reduce 481\\nChapter Summary 483\\nTest Your Knowledge: Quiz 483\\nTest Your Knowledge: Answers 483\\n20. Iterations and Comprehensions, Part 2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  485\\nList Comprehensions Revisited: Functional Tools 485\\nList Comprehensions Versus map 486\\nAdding Tests and Nested Loops: filter 487\\nList Comprehensions and Matrixes 489\\nComprehending List Comprehensions 490\\nIterators Revisited: Generators 492\\nGenerator Functions: yield Versus return 492\\nGenerator Expressions: Iterators Meet Comprehensions 497\\nGenerator Functions Versus Generator Expressions 498\\nGenerators Are Single-Iterator Objects 499\\nEmulating zip and map with Iteration Tools 500\\nValue Generation in Built-in Types and Classes 506\\n3.0 Comprehension Syntax Summary 507\\nComprehending Set and Dictionary Comprehensions 507\\nExtended Comprehension Syntax for Sets and Dictionaries 508\\nTiming Iteration Alternatives 509\\nTiming Module 509\\nTiming Script 510\\nTiming Results 511\\nTable of Contents | xvii', metadata={'source': 'python.pdf', 'page': 17}),\n",
       " Document(page_content='Timing Module Alternatives 513\\nOther Suggestions 517\\nFunction Gotchas 518\\nLocal Names Are Detected Statically 518\\nDefaults and Mutable Objects 520\\nFunctions Without returns 522\\nEnclosing Scope Loop Variables 522\\nChapter Summary 522\\nTest Your Knowledge: Quiz 523\\nTest Your Knowledge: Answers 523\\nTest Your Knowledge: Part IV Exercises 524\\nPart V. Modules \\n21. Modules: The Big Picture . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  529\\nWhy Use Modules? 529\\nPython Program Architecture 530\\nHow to Structure a Program 531\\nImports and Attributes 531\\nStandard Library Modules 533\\nHow Imports Work 533\\n1. Find It 534\\n2. Compile It (Maybe) 534\\n3. Run It 535\\nThe Module Search Path 535\\nConfiguring the Search Path 537\\nSearch Path Variations 538\\nThe sys.path List 538\\nModule File Selection 539\\nAdvanced Module Selection Concepts 540\\nChapter Summary 541\\nTest Your Knowledge: Quiz 541\\nTest Your Knowledge: Answers 542\\n22. Module Coding Basics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 543\\nModule Creation 543\\nModule Usage 544\\nThe import Statement 544\\nThe from Statement 545\\nThe from * Statement 545\\nImports Happen Only Once 546\\nimport and from Are Assignments 546\\nxviii | Table of Contents', metadata={'source': 'python.pdf', 'page': 18}),\n",
       " Document(page_content='Cross-File Name Changes 547\\nimport and from Equivalence 548\\nPotential Pitfalls of the from Statement 548\\nModule Namespaces 550\\nFiles Generate Namespaces 550\\nAttribute Name Qualification 552\\nImports Versus Scopes 552\\nNamespace Nesting 553\\nReloading Modules 554\\nreload Basics 555\\nreload Example 556\\nChapter Summary 558\\nTest Your Knowledge: Quiz 558\\nTest Your Knowledge: Answers 558\\n23. Module Packages \\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  561\\nPackage Import Basics 561\\nPackages and Search Path Settings 562\\nPackage __init__.py Files 563\\nPackage Import Example 564\\nfrom Versus import with Packages 566\\nWhy Use Package Imports? 566\\nA Tale of Three Systems 567\\nPackage Relative Imports 569\\nChanges in Python 3.0 570\\nRelative Import Basics 570\\nWhy Relative Imports? 572\\nThe Scope of Relative Imports 574\\nModule Lookup Rules Summary 575\\nRelative Imports in Action 575\\nChapter Summary 581\\nTest Your Knowledge: Quiz 582\\nTest Your Knowledge: Answers 582\\n24. Advanced Module Topics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  583\\nData Hiding in Modules 583\\nMinimizing from * Damage: _X and __all__ 584\\nEnabling Future Language Features 584\\nMixed Usage Modes: __name__ and __main__ 585\\nUnit Tests with __name__ 586\\nUsing Command-Line Arguments with __name__ 587\\nChanging the Module Search Path 590\\nThe as Extension for import and from 591\\nTable of Contents | xix', metadata={'source': 'python.pdf', 'page': 19}),\n",
       " Document(page_content='Modules Are Objects: Metaprograms 591\\nImporting Modules by Name String 594\\nTransitive Module Reloads 595\\nModule Design Concepts 598\\nModule Gotchas 599\\nStatement Order Matters in Top-Level Code 599\\nfrom Copies Names but Doesn’t Link 600\\nfrom * Can Obscure the Meaning of Variables 601\\nreload May Not Impact from Imports 601\\nreload, from, and Interactive Testing 602\\nRecursive from Imports May Not Work 603\\nChapter Summary 604\\nTest Your Knowledge: Quiz 604\\nTest Your Knowledge: Answers 605\\nTest Your Knowledge: Part V Exercises 605\\nPart VI. Classes and OOP \\n25. OOP: The Big Picture . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 611\\nWhy Use Classes? 612\\nOOP from 30,000 Feet 613\\nAttribute Inheritance Search 613\\nClasses and Instances 615\\nClass Method Calls 616\\nCoding Class Trees 616\\nOOP Is About Code Reuse 619\\nChapter Summary 622\\nTest Your Knowledge: Quiz 622\\nTest Your Knowledge: Answers 622\\n26. Class Coding Basics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  625\\nClasses Generate Multiple Instance Objects 625\\nClass Objects Provide Default Behavior 626\\nInstance Objects Are Concrete Items 626\\nA First Example 627\\nClasses Are Customized by Inheritance 629\\nA Second Example 630\\nClasses Are Attributes in Modules 631\\nClasses Can Intercept Python Operators 633\\nA Third Example 634\\nWhy Use Operator Overloading? 636\\nThe World’s Simplest Python Class 636\\nxx | Table of Contents', metadata={'source': 'python.pdf', 'page': 20}),\n",
       " Document(page_content='Classes Versus Dictionaries 639\\nChapter Summary 641\\nTest Your Knowledge: Quiz 641\\nTest Your Knowledge: Answers 641\\n27. A More Realistic Example \\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 643\\nStep 1: Making Instances 644\\nCoding Constructors 644\\nTesting As You Go 645\\nUsing Code Two Ways 646\\nStep 2: Adding Behavior Methods 648\\nCoding Methods 649\\nStep 3: Operator Overloading 651\\nProviding Print Displays 652\\nStep 4: Customizing Behavior by Subclassing 653\\nCoding Subclasses 653\\nAugmenting Methods: The Bad Way 654\\nAugmenting Methods: The Good Way 654\\nPolymorphism in Action 656\\nInherit, Customize, and Extend 657\\nOOP: The Big Idea 658\\nStep 5: Customizing Constructors, Too 658\\nOOP Is Simpler Than You May Think 660\\nOther Ways to Combine Classes 660\\nStep 6: Using Introspection Tools 663\\nSpecial Class Attributes 664\\nA Generic Display Tool 665\\nInstance Versus Class Attributes 666\\nName Considerations in Tool Classes 667\\nOur Classes’ Final Form 668\\nStep 7 (Final): Storing Objects in a Database 669\\nPickles and Shelves 670\\nStoring Objects on a Shelve Database 671\\nExploring Shelves Interactively 672\\nUpdating Objects on a Shelve 674\\nFuture Directions 675\\nChapter Summary 677\\nTest Your Knowledge: Quiz 677\\nTest Your Knowledge: Answers 678\\n28. Class Coding Details . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  681\\nThe class Statement 681\\nGeneral Form 681\\nTable of Contents | xxi', metadata={'source': 'python.pdf', 'page': 21}),\n",
       " Document(page_content='Example 682\\nMethods 684\\nMethod Example 685\\nCalling Superclass Constructors 686\\nOther Method Call Possibilities 686\\nInheritance 687\\nAttribute Tree Construction 687\\nSpecializing Inherited Methods 687\\nClass Interface Techniques 689\\nAbstract Superclasses 690\\nPython 2.6 and 3.0 Abstract Superclasses 692\\nNamespaces: The Whole Story 693\\nSimple Names: Global Unless Assigned 693\\nAttribute Names: Object Namespaces 693\\nThe “Zen” of Python Namespaces: Assignments Classify Names 694\\nNamespace Dictionaries 696\\nNamespace Links 699\\nDocumentation Strings Revisited 701\\nClasses Versus Modules 703\\nChapter Summary 703\\nTest Your Knowledge: Quiz 703\\nTest Your Knowledge: Answers 704\\n29.\\nOperator Overloading . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  705\\nThe Basics 705\\nConstructors and Expressions: __init__ and __sub__ 706\\nCommon Operator Overloading Methods 706\\nIndexing and Slicing: __getitem__ and __setitem__ 708\\nIntercepting Slices 708\\nIndex Iteration: __getitem__ 710\\nIterator Objects: __iter__ and __next__ 711\\nUser-Defined Iterators 712\\nMultiple Iterators on One Object 714\\nMembership: __contains__, __iter__, and __getitem__ 716\\nAttribute Reference: __getattr__ and __setattr__ 718\\nOther Attribute Management Tools 719\\nEmulating Privacy for Instance Attributes: Part 1 720\\nString Representation: __repr__ and __str__ 721\\nRight-Side and In-Place Addition: __radd__ and __iadd__ 723\\nIn-Place Addition 725\\nCall Expressions: __call__ 725\\nFunction Interfaces and Callback-Based Code 727\\nComparisons: __lt__, __gt__, and Others 728\\nxxii | Table of Contents', metadata={'source': 'python.pdf', 'page': 22}),\n",
       " Document(page_content='The 2.6 __cmp__ Method (Removed in 3.0) 729\\nBoolean Tests: __bool__ and __len__ 730\\nObject Destruction: __del__ 732\\nChapter Summary 733\\nTest Your Knowledge: Quiz 734\\nTest Your Knowledge: Answers 734\\n30. Designing with Classes \\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 737\\nPython and OOP 737\\nOverloading by Call Signatures (or Not) 738\\nOOP and Inheritance: “Is-a” Relationships 739\\nOOP and Composition: “Has-a” Relationships 740\\nStream Processors Revisited 742\\nOOP and Delegation: “Wrapper” Objects 745\\nPseudoprivate Class Attributes 747\\nName Mangling Overview 748\\nWhy Use Pseudoprivate Attributes? 748\\nMethods Are Objects: Bound or Unbound 750\\nUnbound Methods are Functions in 3.0 752\\nBound Methods and Other Callable Objects 754\\nMultiple Inheritance: “Mix-in” Classes 756\\nCoding Mix-in Display Classes 757\\nClasses Are Objects: Generic Object Factories 768\\nWhy Factories? 769\\nOther Design-Related Topics 770\\nChapter Summary 770\\nTest Your Knowledge: Quiz 770\\nTest Your Knowledge: Answers 771\\n31. Advanced Class Topics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  773\\nExtending Built-in Types 773\\nExtending Types by Embedding 774\\nExtending Types by Subclassing 775\\nThe “New-Style” Class Model 777\\nNew-Style Class Changes 778\\nType Model Changes 779\\nDiamond Inheritance Change 783\\nNew-Style Class Extensions 788\\nInstance Slots 788\\nClass Properties 792\\n__getattribute__ and Descriptors 794\\nMetaclasses 794\\nStatic and Class Methods 795\\nTable of Contents | xxiii', metadata={'source': 'python.pdf', 'page': 23}),\n",
       " Document(page_content='Why the Special Methods? 795\\nStatic Methods in 2.6 and 3.0 796\\nStatic Method Alternatives 798\\nUsing Static and Class Methods 799\\nCounting Instances with Static Methods 800\\nCounting Instances with Class Methods 802\\nDecorators and Metaclasses: Part 1 804\\nFunction Decorator Basics 804\\nA First Function Decorator Example 805\\nClass Decorators and Metaclasses 807\\nFor More Details 808\\nClass Gotchas 808\\nChanging Class Attributes Can Have Side Effects 808\\nChanging Mutable Class Attributes Can Have Side Effects, Too 810\\nMultiple Inheritance: Order Matters 811\\nMethods, Classes, and Nested Scopes 812\\nDelegation-Based Classes in 3.0: __getattr__ and built-ins 814\\n“Overwrapping-itis” 814\\nChapter Summary 815\\nTest Your Knowledge: Quiz 815\\nTest Your Knowledge: Answers 815\\nTest Your Knowledge: Part VI Exercises 816\\nPart VII. \\nExceptions and Tools \\n32. Exception Basics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  825\\nWhy Use Exceptions? 825\\nException Roles 826\\nExceptions: The Short Story 827\\nDefault Exception Handler 827\\nCatching Exceptions 828\\nRaising Exceptions 829\\nUser-Defined Exceptions 830\\nTermination Actions 830\\nChapter Summary 833\\nTest Your Knowledge: Quiz 833\\nTest Your Knowledge: Answers 833\\n33. Exception Coding Details . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  835\\nThe try/except/else Statement 835\\ntry Statement Clauses 837\\nThe try else Clause 839\\nxxiv | Table of Contents', metadata={'source': 'python.pdf', 'page': 24}),\n",
       " Document(page_content='Example: Default Behavior 840\\nExample: Catching Built-in Exceptions 841\\nThe try/finally Statement 842\\nExample: Coding Termination Actions with try/finally 843\\nUnified try/except/finally 844\\nUnified try Statement Syntax 845\\nCombining finally and except by Nesting 845\\nUnified try Example 846\\nThe raise Statement 848\\nPropagating Exceptions with raise 849\\nPython 3.0 Exception Chaining: raise from 849\\nThe assert Statement 850\\nExample: Trapping Constraints (but Not Errors!) 851\\nwith/as Context Managers 851\\nBasic Usage 852\\nThe Context Management Protocol 853\\nChapter Summary 855\\nTest Your Knowledge: Quiz 856\\nTest Your Knowledge: Answers 856\\n34. Exception Objects \\n. .. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  857\\nExceptions: Back to the Future 858\\nString Exceptions Are Right Out! 858\\nClass-Based Exceptions 859\\nCoding Exceptions Classes 859\\nWhy Exception Hierarchies? 861\\nBuilt-in Exception Classes 864\\nBuilt-in Exception Categories 865\\nDefault Printing and State 866\\nCustom Print Displays 867\\nCustom Data and Behavior 868\\nProviding Exception Details 868\\nProviding Exception Methods 869\\nChapter Summary 870\\nTest Your Knowledge: Quiz 871\\nTest Your Knowledge: Answers 871\\n35. Designing with Exceptions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  873\\nNesting Exception Handlers 873\\nExample: Control-Flow Nesting 875\\nExample: Syntactic Nesting 875\\nException Idioms 877\\nExceptions Aren’t Always Errors 877\\nTable of Contents | xxv', metadata={'source': 'python.pdf', 'page': 25}),\n",
       " Document(page_content='Functions Can Signal Conditions with raise 878\\nClosing Files and Server Connections 878\\nDebugging with Outer try Statements 879\\nRunning In-Process Tests 880\\nMore on sys.exc_info 881\\nException Design Tips and Gotchas 882\\nWhat Should Be Wrapped 882\\nCatching Too Much: Avoid Empty except and Exception 883\\nCatching Too Little: Use Class-Based Categories 885\\nCore Language Summary 885\\nThe Python Toolset 886\\nDevelopment Tools for Larger Projects 887\\nChapter Summary 890\\nTest Your Knowledge: Quiz 891\\nTest Your Knowledge: Answers 891\\nTest Your Knowledge: Part VII Exercises 891\\nPart VIII. Advanced Topics \\n36. Unicode and Byte Strings . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 895\\nString Changes in 3.0 896\\nString Basics 897\\nCharacter Encoding Schemes 897\\nPython’s String Types 899\\nText and Binary Files 900\\nPython 3.0 Strings in Action 902\\nLiterals and Basic Properties 902\\nConversions 903\\nCoding Unicode Strings 904\\nCoding ASCII Text 905\\nCoding Non-ASCII Text 905\\nEncoding and Decoding Non-ASCII text 906\\nOther Unicode Coding Techniques 907\\nConverting Encodings 909\\nCoding Unicode Strings in Python 2.6 910\\nSource File Character Set Encoding Declarations 912\\nUsing 3.0 Bytes Objects 913\\nMethod Calls 913\\nSequence Operations 914\\nOther Ways to Make bytes Objects 915\\nMixing String Types 916\\nUsing 3.0 (and 2.6) bytearray Objects 917\\nxxvi | Table of Contents', metadata={'source': 'python.pdf', 'page': 26}),\n",
       " Document(page_content='Using Text and Binary Files 920\\nText File Basics 920\\nText and Binary Modes in 3.0 921\\nType and Content Mismatches 923\\nUsing Unicode Files 924\\nReading and Writing Unicode in 3.0 924\\nHandling the BOM in 3.0 926\\nUnicode Files in 2.6 928\\nOther String Tool Changes in 3.0 929\\nThe re Pattern Matching Module 929\\nThe struct Binary Data Module 930\\nThe pickle Object Serialization Module 932\\nXML Parsing Tools 934\\nChapter Summary 937\\nTest Your Knowledge: Quiz 937\\nTest Your Knowledge: Answers 937\\n37. Managed Attributes \\n. .. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  941\\nWhy Manage Attributes? 941\\nInserting Code to Run on Attribute Access 942\\nProperties 943\\nThe Basics 943\\nA First Example 944\\nComputed Attributes 945\\nCoding Properties with Decorators 946\\nDescriptors 947\\nThe Basics 948\\nA First Example 950\\nComputed Attributes 952\\nUsing State Information in Descriptors 953\\nHow Properties and Descriptors Relate 955\\n__getattr__ and __getattribute__ 956\\nThe Basics 957\\nA First Example 959\\nComputed Attributes 961\\n__getattr__ and __getattribute__ Compared 962\\nManagement Techniques Compared 963\\nIntercepting Built-in Operation Attributes 966\\nDelegation-Based Managers Revisited 970\\nExample: Attribute Validations 973\\nUsing Properties to Validate 973\\nUsing Descriptors to Validate 975\\nUsing __getattr__ to Validate 977\\nTable of Contents | xxvii', metadata={'source': 'python.pdf', 'page': 27}),\n",
       " Document(page_content='Using __getattribute__ to Validate 978\\nChapter Summary 979\\nTest Your Knowledge: Quiz 980\\nTest Your Knowledge: Answers 980\\n38. Decorators \\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  983\\nWhat’s a Decorator? 983\\nManaging Calls and Instances 984\\nManaging Functions and Classes 984\\nUsing and Defining Decorators 984\\nWhy Decorators? 985\\nThe Basics 986\\nFunction Decorators 986\\nClass Decorators 990\\nDecorator Nesting 993\\nDecorator Arguments 994\\nDecorators Manage Functions and Classes, Too 995\\nCoding Function Decorators 996\\nTracing Calls 996\\nState Information Retention Options 997\\nClass Blunders I: Decorating Class Methods 1001\\nTiming Calls 1006\\nAdding Decorator Arguments 1008\\nCoding Class Decorators 1011\\nSingleton Classes 1011\\nTracing Object Interfaces 1013\\nClass Blunders II: Retaining Multiple Instances 1016\\nDecorators Versus Manager Functions 1018\\nWhy Decorators? (Revisited) 1019\\nManaging Functions and Classes Directly 1021\\nExample: “Private” and “Public” Attributes 1023\\nImplementing Private Attributes 1023\\nImplementation Details I 1025\\nGeneralizing for Public Declarations, Too 1026\\nImplementation Details II 1029\\nOpen Issues 1030\\nPython Isn’t About Control 1034\\nExample: Validating Function Arguments 1034\\nThe Goal 1034\\nA Basic Range-Testing Decorator for Positional Arguments 1035\\nGeneralizing for Keywords and Defaults, Too 1037\\nImplementation Details 1040\\nOpen Issues 1042\\nxxviii |\\nTable of Contents', metadata={'source': 'python.pdf', 'page': 28}),\n",
       " Document(page_content='Decorator Arguments Versus Function Annotations 1043\\nOther Applications: Type Testing (If You Insist!) 1045\\nChapter Summary 1046\\nTest Your Knowledge: Quiz 1047\\nTest Your Knowledge: Answers 1047\\n39. Metaclasses \\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  1051\\nTo Metaclass or Not to Metaclass 1052\\nIncreasing Levels of Magic 1052\\nThe Downside of “Helper” Functions 1054\\nMetaclasses Versus Class Decorators: Round 1 1056\\nThe Metaclass Model 1058\\nClasses Are Instances of type 1058\\nMetaclasses Are Subclasses of Type 1061\\nClass Statement Protocol 1061\\nDeclaring Metaclasses 1062\\nCoding Metaclasses 1063\\nA Basic Metaclass 1064\\nCustomizing Construction and Initialization 1065\\nOther Metaclass Coding Techniques 1065\\nInstances Versus Inheritance 1068\\nExample: Adding Methods to Classes 1070\\nManual Augmentation 1070\\nMetaclass-Based Augmentation 1071\\nMetaclasses Versus Class Decorators: Round 2 1073\\nExample: Applying Decorators to Methods 1076\\nTracing with Decoration Manually 1076\\nTracing with Metaclasses and Decorators 1077\\nApplying Any Decorator to Methods 1079\\nMetaclasses Versus Class Decorators: Round 3 1080\\nChapter Summary 1084\\nTest Your Knowledge: Quiz 1084\\nTest Your Knowledge: Answers 1085\\nPart IX. Appendixes \\nA. Installation and Configuration . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  1089\\nB. Solutions to End-of-Part Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  1101\\nIndex . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  1139\\nTable of Contents | xxix', metadata={'source': 'python.pdf', 'page': 29}),\n",
       " Document(page_content='', metadata={'source': 'python.pdf', 'page': 30}),\n",
       " Document(page_content='Preface\\nThis book provides an introduction to the Python programming language. Python is a\\npopular open source \\nprogramming language used for both standalone programs and\\nscripting applications in a wide variety of domains. It is free, portable, powerful, and\\nremarkably easy and fun to use. Programmers from every corner of the software in-\\ndustry have found Python’s focus on developer productivity and software quality to be\\na strategic advantage in projects both large and small.\\nWhether you are new to programming or are a professional developer, this book’s goal\\nis to bring you quickly up to speed on the fundamentals of the core Python language.\\nAfter reading this book, you will know enough about Python to apply it in whatever\\napplication domains you choose to explore.\\nBy design, this book is a tutorial that focuses on the core Python language  itself, rather\\nthan specific applications of it. As such, it’s intended to serve as the first in a two-volume\\nset:\\n•Learning Python, this book, teaches Python itself.\\n•Programming Python , among others, shows what you can do with Python after\\nyou’ve learned it.\\nThat is, applications-focused books such as Programming Python pick up where this\\nbook leaves off, exploring Python’s role in common domains such as the Web, graphical\\nuser interfaces (GUIs), and databases. In addition, the book Python Pocket Reference\\nprovides additional reference materials not included here, and it is designed to sup-\\nplement this book.\\nBecause of this book’s foundations focus, though, it is able to present Python funda-\\nmentals with more depth than many programmers see when first learning the language.\\nAnd because it’s based upon a three-day Python training class with quizzes and exer-\\ncises throughout, this book serves as a self-paced introduction to the language.\\nxxxi', metadata={'source': 'python.pdf', 'page': 31}),\n",
       " Document(page_content='About This Fourth Edition\\nThis fourth edition of this book has changed in three ways. This edition:\\n• Covers both Python 3.0 and \\nPython 2.6—it emphasizes 3.0, but notes differences\\nin 2.6\\n• Includes a set of new chapters mainly targeted at advanced core-language topics\\n• Reorganizes some existing material and expands it with new examples for clarity\\nAs I write this edition in 2009, Python comes in two flavors—version 3.0 is an emerging\\nand incompatible mutation of the language, and 2.6 retains backward compatibility\\nwith the vast body of existing Python code. Although Python 3 is viewed as the future\\nof Python, Python 2 is still widely used and will be supported in parallel with Python\\n3 for years to come. While 3.0 is largely the same language, it runs almost no code\\nwritten for prior releases (the mutation of print from statement to function alone,\\naesthetically sound as it may be, breaks nearly every Python program ever written).\\nThis split presents a bit of a dilemma for both programmers and book authors. While\\nit would be easier for a book to pretend that Python 2 never existed and cover 3 only,\\nthis would not address the needs of the large Python user base that exists today. A vast\\namount of existing code was written for Python 2, and it won’t be going away any time\\nsoon. And while newcomers to the language can focus on Python 3, anyone who must\\nuse code written in the past needs to keep one foot in the Python 2 world today. Since\\nit may be years before all third-party libraries and extensions are ported to Python 3,\\nthis fork might not be entirely temporary.\\nCoverage for Both 3.0 and 2.6\\nTo address this dichotomy and to meet the needs of all potential readers, this edition\\nof this book has been updated to cover both Python 3.0 and Python 2.6 (and later\\nreleases in the 3.X and 2.X lines). It’s intended for programmers using Python 2, pro-\\ngrammers using Python 3, and programmers stuck somewhere between the two.\\nThat is, you can use this book to learn either Python line. Although the focus here is\\non 3.0 primarily, 2.6 differences and tools are also noted along the way for programmers\\nusing older code. While the two versions are largely the same, they diverge in some\\nimportant ways, and I’ll point these out along the way.\\nFor instance, I’ll use 3.0 print calls in most examples, but will describe the 2.6 print\\nstatement, too, so you can make sense of earlier code. I’ll also freely introduce new\\nfeatures, such as the nonlocal statement in 3.0 and the string format method in 2.6 and\\n3.0, and will point out when such extensions are not present in older Pythons.\\nIf you are learning Python for the first time and don’t need to use any legacy code, I\\nencourage you to begin with Python 3.0; it cleans up some longstanding warts in the\\nlanguage, while retaining all the original core ideas and adding some nice new tools.\\nxxxii | Preface', metadata={'source': 'python.pdf', 'page': 32}),\n",
       " Document(page_content='Many popular Python libraries and tools will likely be available for Python 3.0 by the\\ntime you read \\nthese words, especially given the file I/O performance improvements\\nexpected in the upcoming 3.1 release. If you are using a system based on Python 2.X,\\nhowever, you’ll find that this book addresses your concerns, too, and will help you\\nmigrate to 3.0 in the future.\\nBy proxy, this edition addresses other Python version 2 and 3 releases as well, though\\nsome older version 2.X code may not be able to run all the examples here. Although\\nclass decorators are available in both Python 2.6 and 3.0, for example, you cannot use\\nthem in an older Python 2.X that did not yet have this feature. See Tables P-1 and P-2\\nlater in this Preface for summaries of 2.6 and 3.0 changes.\\nShortly before going to press, this book was also augmented with notes\\nabout prominent extensions \\nin the upcoming Python 3.1 release—\\ncomma separators and automatic field numbering in string format\\nmethod calls, multiple context manager syntax in with statements, new\\nmethods for numbers, and so on. Because Python 3.1 was targeted pri-\\nmarily at optimization, this book applies directly to this new release as\\nwell. In fact, because Python 3.1 supersedes 3.0, and because the latest\\nPython is usually the best Python to fetch and use anyhow, in this book\\nthe term “Python 3.0” generally refers to the language variations intro-\\nduced by Python 3.0 but that are present in the entire 3.X line.\\nNew Chapters\\nAlthough the main purpose of this edition is to update the examples and material from\\nthe preceding edition for 3.0 and 2.6, I’ve also added five new chapters to address new\\ntopics and add context:\\n•Chapter 27 is a new class tutorial, using a more realistic example to explore the\\nbasics of Python object-oriented programming (OOP).\\n•Chapter 36  provides details on Unicode and byte strings and outlines string and\\nfile differences between 3.0 and 2.6.\\n•Chapter 37  collects managed attribute tools such as properties and provides new\\ncoverage of descriptors.\\n•Chapter 38  presents function and class decorators and works through compre-\\nhensive examples.\\n•Chapter 39  covers metaclasses and compares and contrasts them with decorators.\\nThe first of these chapters provides a gradual, step-by-step tutorial for using classes and\\nOOP in Python. It’s based upon a live demonstration I have been using in recent years\\nin the training classes I teach, but has been honed here for use in a book. The chapter\\nis designed to show OOP in a more realistic context than earlier examples and to\\nPreface | xxxiii', metadata={'source': 'python.pdf', 'page': 33}),\n",
       " Document(page_content='illustrate how class concepts come together into larger, working programs. I hope it\\nworks as well here as it has in live classes.\\nThe last \\nfour of these new chapters are collected in a new final part of the book, “Ad-\\nvanced Topics.” Although these are technically core language topics, not every Python\\nprogrammer needs to delve into the details of Unicode text or metaclasses. Because of\\nthis, these four chapters have been separated out into this new part, and are officially\\noptional reading. The details of Unicode and binary data strings, for example, have been\\nmoved to this final part because most programmers use simple ASCII strings and don’t\\nneed to know about these topics. Similarly, decorators and metaclasses are specialist\\ntopics that are usually of more interest to API builders than application programmers.\\nIf you do use such tools, though, or use code that does, these new advanced topic\\nchapters should help you master the basics. In addition, these chapters’ examples in-\\nclude case studies that tie core language concepts together, and they are more sub-\\nstantial than those in most of the rest of the book. Because this new part is optional\\nreading, it has end-of-chapter quizzes but no end-of-part exercises.\\nChanges to Existing Material\\nIn addition, some material from the prior edition has been reorganized, or supplemen-\\nted with new examples . Multiple inheritance, for instance, gets a new case study ex-\\nample that lists class trees in Chapter 30 ; new examples for generators that manually\\nimplement map and zip are provided in Chapter 20 ; static and class methods are illus-\\ntrated by new code in Chapter 31; package relative imports are captured in action in\\nChapter 23 ; and the __contains__, __bool__, and __index__ operator overloading meth-\\nods are illustrated by example now as well in Chapter 29, along with the new\\noverloading protocols for slicing and comparison.\\nThis edition also incorporates some reorganization for clarity. For instance, to accom-\\nmodate new material and topics, and to avoid chapter topic overload, five prior chapters\\nhave been split into two each here. The result is new standalone chapters on operator\\noverloading, scopes and arguments, exception statement details, and comprehension\\nand iteration topics. Some reordering has been done within the existing chapters as\\nwell, to improve topic flow.\\nThis edition also tries to minimize forward references with some reordering, though\\nPython 3.0’s changes make this impossible in some cases: to understand printing and\\nthe string format method, you now must know keyword arguments for functions; to\\nunderstand dictionary key lists and key tests, you must now know iteration; to use\\nexec to run code, you need to be able to use file objects; and so on. A linear reading\\nstill probably makes the most sense, but some topics may require nonlinear jumps and\\nrandom lookups.\\nAll told, there have been hundreds of changes in this edition. The next section’s tables\\nalone document 27 additions and 57 changes in Python. In fact, it’s fair to say that this\\nxxxiv | Preface', metadata={'source': 'python.pdf', 'page': 34}),\n",
       " Document(page_content=\"edition is somewhat more advanced, because Python is somewhat more advanced. As\\nfor Python 3.0 \\nitself, though, you’re probably better off discovering most of this book’s\\nchanges for yourself, rather than reading about them further in this Preface.\\nSpecific Language Extensions in 2.6 and 3.0\\nIn general, Python 3.0 is a cleaner language, but it is also in some ways a more sophis-\\nticated language. In fact, some of its changes seem to assume you must already know\\nPython in order to learn Python! The prior section outlined some of the more prominent\\ncircular knowledge dependencies in 3.0; as a random example, the rationale for wrap-\\nping dictionary views in a list call is incredibly subtle and requires substantial fore-\\nknowledge. Besides teaching Python fundamentals, this book serves to help bridge this\\nknowledge gap.\\nTable P-1  lists the most prominent new language features covered in this edition, along\\nwith the primary chapters in which they appear.\\nTable P-1. Extensions in Python 2.6 and 3.0\\nExtension Covered in chapter(s)\\nThe print function in 3.0 11\\nThe nonlocal x,y statement in 3.0 17\\nThe str.format method in 2.6 and 3.0 7\\nString types in 3.0: str for Unicode text, bytes for binary data 7, 36\\nText and binary file distinctions in 3.0 9, 36\\nClass decorators in 2.6 and 3.0: @private('age') 31, 38\\nNew iterators in 3.0: range, map, zip 14, 20\\nDictionary views in 3.0: D.keys, D.values, D.items 8, 14\\nDivision operators in 3.0: remainders, / and // 5\\nSet literals in 3.0: {a, b, c} 5\\nSet comprehensions in 3.0: {x**2 for x in seq} 4, 5, 14, 20\\nDictionary comprehensions in 3.0: {x: x**2 for x in seq} 4, 8, 14, 20\\nBinary digit-string support in 2.6 and 3.0: 0b0101, bin(I) 5\\nThe fraction number type in 2.6 and 3.0: Fraction(1, 3) 5\\nFunction annotations in 3.0: def f(a:99, b:str)->int 19\\nKeyword-only arguments in 3.0: def f(a, *b, c, **d) 18, 20\\nExtended sequence unpacking in 3.0: a, *b = seq 11, 13\\nRelative import syntax for packages enabled in 3.0: from . 23\\nContext managers enabled in 2.6 and 3.0: with/as 33, 35\\nException syntax changes in 3.0: raise, except/as, superclass 33, 34\\nPreface | xxxv\", metadata={'source': 'python.pdf', 'page': 35}),\n",
       " Document(page_content='Extension Covered in chapter(s)\\nException chaining in 3.0: raise e2 from e1 33\\nReserved word changes in 2.6 and 3.0 11\\nNew-style class cutover in 3.0 31\\nProperty decorators in 2.6 and 3.0: @property 37\\nDescriptor use in 2.6 and 3.0 31, 38\\nMetaclass use in 2.6 and 3.0 31, 39\\nAbstract base classes support in 2.6 and 3.0 28\\nSpecific Language Removals in 3.0\\nIn addition to extensions, \\na number of language tools have been removed in 3.0 in an\\neffort to clean up its design. Table P-2  summarizes the changes that impact this book,\\ncovered in various chapters of this edition. Many of the removals listed in Table P-2\\nhave direct replacements, some of which are also available in 2.6 to support future\\nmigration to 3.0.\\nTable P-2. Removals in Python 3.0 that impact this book\\nRemoved Replacement Covered in chapter(s)\\nreload(M) imp.reload(M) (or exec) 3, 22\\napply(f, ps, ks) f(*ps, **ks) 18\\n`X` repr(X) 5\\nX <> Y X != Y 5\\nlong int 5\\n9999L 9999 5\\nD.has_key(K) K in D (or D.get(key) != None) 8\\nraw_input input 3, 10\\nold input eval(input()) 3\\nxrange range 14\\nfile open (and io module classes) 9\\nX.next X.__next__, called by next(X) 14, 20, 29\\nX.__getslice__ X.__getitem__ passed a slice object 7, 29\\nX.__setslice__ X.__setitem__ passed a slice object 7, 29\\nreduce functools.reduce (or loop code) 14, 19\\nexecfile(filename) exec(open(filename).read()) 3\\nexec open(filename) exec(open(filename).read()) 3\\n0777 0o777 5\\nprint x, y print(x, y) 11\\nxxxvi | Preface', metadata={'source': 'python.pdf', 'page': 36}),\n",
       " Document(page_content=\"Removed Replacement Covered in chapter(s)\\nprint >> F, x, y print(x, y, file=F) 11\\nprint x, y, print(x, y, end=' ') 11\\nu'ccc' 'ccc' 7, 36\\n'bbb' for byte strings b'bbb' 7, 9, 36\\nraise E, V raise E(V) 32, 33, 34\\nexcept E, X: except E as X: 32, 33, 34\\ndef f((a, b)): def f(x): (a, b) = x 11, 18, 20\\nfile.xreadlines for line in file: (or X=iter(file)) 13, 14\\nD.keys(), etc. as lists list(D.keys()) (dictionary views) 8, 14\\nmap(), range(), etc. as lists list(map()), list(range()) (built-ins) 14\\nmap(None, ...) zip (or manual code to pad results) 13, 20\\nX=D.keys(); X.sort() sorted(D) (or list(D.keys())) 4, 8, 14\\ncmp(x, y) (x > y) - (x < y) 29\\nX.__cmp__(y) __lt__, __gt__, __eq__, etc. 29\\nX.__nonzero__ X.__bool__ 29\\nX.__hex__, X.__oct__ X._index__ 29\\nSort comparison functions Use key=transform or reverse=True 8\\nDictionary <, >, <=, >= Compare sorted(D.items()) (or loop code) 8, 9\\ntypes.ListType list (types is for nonbuilt-in names only) 9\\n__metaclass__ = M class C(metaclass=M): 28, 31, 39\\n__builtin__ builtins (renamed) 17\\nTkinter tkinter (renamed) 18, 19, 24, 29, 30\\nsys.exc_type, exc_value sys.exc_info()[0], [1] 34, 35\\nfunction.func_code function.__code__ 19, 38\\n__getattr__ run by built-ins Redefine __X__ methods in wrapper classes 30, 37, 38\\n-t, –tt command-line switches Inconsistent tabs/spaces use is always an error 10, 12\\nfrom ... *, within a function May only appear at the top level of a file 22\\nimport mod, in same package from . import mod, package-relative form 23\\nclass MyException: class MyException(Exception): 34\\nexceptions module Built-in scope, library manual 34\\nthread, Queue modules _thread, queue (both renamed) 17\\nanydbm module dbm (renamed) 27\\ncPickle module _pickle (renamed, used automatically) 9\\nos.popen2/3/4 subprocess.Popen (os.popen retained) 14\\nString-based exceptions Class-based exceptions (also required in 2.6) 32, 33, 34\\nPreface | xxxvii\", metadata={'source': 'python.pdf', 'page': 37}),\n",
       " Document(page_content='Removed Replacement Covered in chapter(s)\\nString module functions String object methods 7\\nUnbound methods Functions (staticmethod to call via instance) 30, 31\\nMixed type comparisons, sorts Nonnumeric mixed type comparisons are errors 5, 9\\nThere are additional changes in Python 3.0 that are not listed in this table, simply\\nbecause they don’t \\naffect this book. Changes in the standard library, for instance, might\\nhave a larger impact on applications-focused books like Programming Python  than they\\ndo here; although most standard library functionality is still present, Python 3.0 takes\\nfurther liberties with renaming modules, grouping them into packages, and so on. For\\na more comprehensive list of changes in 3.0, see the “What’s New in Python 3.0”\\ndocument in Python’s standard manual set.\\nIf you are migrating from Python 2.X to Python 3.X, be sure to also see the 2to3 auto-\\nmatic code conversion script that is available with Python 3.0. It can’t translate every-\\nthing, but it does a reasonable job of converting the majority of 2.X code to run under\\n3.X. As I write this, a new 3to2 back-conversion project is also underway to translate\\nPython 3.X code to run in 2.X environments. Either tool may prove useful if you must\\nmaintain code for both Python lines; see the Web for details.\\nBecause this fourth edition is mostly a fairly straightforward update for 3.0 with a\\nhandful of new chapters, and because it’s only been two years since the prior edition\\nwas published, the rest of this Preface is taken from the prior edition with only minor\\nupdating.\\nAbout The Third Edition\\nIn the four years between the publication of the second and third editions of this book\\nthere were substantial changes in Python itself, and in the topics I presented in Python\\ntraining sessions. The third edition reflected these changes, and also incorporated a\\nhandful of structural changes.\\nThe Third Edition’s Python Language Changes\\nOn the language front, the third edition was thoroughly updated to reflect Python 2.5\\nand all changes to the language since the publication of the second edition in late 2003.\\n(The second edition was based largely on Python 2.2, with some 2.3 features grafted\\non at the end of the project.) In addition, discussions of anticipated changes in the\\nupcoming Python 3.0 release were incorporated where appropriate. Here are some of\\nthe major language topics for which new or expanded coverage was provided (chapter\\nnumbers here have been updated to reflect the fourth edition):\\nxxxviii | Preface', metadata={'source': 'python.pdf', 'page': 38}),\n",
       " Document(page_content='• The new B if A else C conditional expression (Chapter 19)\\n•with/as context managers (Chapter 33)\\n•try/except/finally unification (Chapter 33)\\n• Relative import syntax (Chapter 23\\n)\\n• Generator expressions (Chapter 20)\\n• New generator function features (Chapter 20)\\n• Function decorators (Chapter 31)\\n• The set object type (Chapter 5)\\n• New built-in functions: sorted, sum, any, all, enumerate (Chapters 13 and 14)\\n• The decimal fixed-precision object type (Chapter 5)\\n• Files, list comprehensions, and iterators (Chapters 14 and 20)\\n• New development tools: Eclipse, distutils, unittest and doctest, IDLE enhance-\\nments, Shedskin, and so on (Chapters 2 and 35)\\nSmaller language changes (for instance, the widespread use of True and False; the new\\nsys.exc_info for fetching exception details; and the demise of string-based exceptions,\\nstring methods, and the apply and reduce built-ins) are discussed throughout the book.\\nThe third edition also expanded coverage of some of the features that were new in the\\nsecond edition, including three-limit slices and the arbitrary arguments call syntax that\\nsubsumed apply.\\nThe Third Edition’s Python Training Changes\\nBesides such language changes, the third edition was augmented with new topics and\\nexamples presented in my Python training sessions. Changes included (chapter num-\\nbers again updated to reflect those in the fourth edition):\\n• A new chapter introducing built-in types (Chapter 4)\\n• A new chapter introducing statement syntax (Chapter 10)\\n• A new full chapter on dynamic typing, with enhanced coverage (Chapter 6)\\n• An expanded OOP introduction (Chapter 25)\\n• New examples for files, scopes, statement nesting, classes, exceptions, and more\\nMany additions and changes were made with Python beginners in mind, and some\\ntopics were moved to appear at the places where they proved simplest to digest in\\ntraining classes. List comprehensions and iterators, for example, now make their initial\\nappearance in conjunction with the for loop statement, instead of later with functional\\ntools.\\nPreface | xxxix', metadata={'source': 'python.pdf', 'page': 39}),\n",
       " Document(page_content='Coverage of many original core language topics also was substantially expanded in the\\nthird edition, with \\nnew discussions and examples added. Because this text has become\\nsomething of a de facto standard resource for learning the core Python language, the\\npresentation was made more complete and augmented with new use cases throughout.\\nIn addition, a new set of Python tips and tricks, gleaned from 10 years of teaching classes\\nand 15 years of using Python for real work, was incorporated, and the exercises were\\nupdated and expanded to reflect current Python best practices, new language features,\\nand common beginners’ mistakes witnessed firsthand in classes. Overall, the core lan-\\nguage coverage was expanded.\\nThe Third Edition’s Structural Changes\\nBecause the material was more complete, it was split into bite-sized chunks. The core\\nlanguage material was organized into many multichapter parts to make it easier to\\ntackle. Types and statements, for instance, are now two top-level parts, with one chap-\\nter for each major type and statement topic. Exercises and “gotchas” (common mis-\\ntakes) were also moved from chapter ends to part ends, appearing at the end of the last\\nchapter in each part.\\nIn the third edition, I also augmented the end-of-part exercises with end-of-chapter\\nsummaries and end-of-chapter quizzes to help you review chapters as you complete\\nthem. Each chapter concludes with a set of questions to help you review and test your\\nunderstanding of the chapter’s material. Unlike the end-of-part exercises, whose solu-\\ntions are presented in Appendix B , the solutions to the end-of-chapter quizzes appear\\nimmediately after the questions; I encourage you to look at the solutions even if you’re\\nsure you’ve answered the questions correctly because the answers are a sort of review\\nin themselves.\\nDespite all the new topics, the book is still oriented toward Python newcomers and is\\ndesigned to be a first Python text for programmers. Because it is largely based on time-\\ntested training experience and materials, it can still serve as a self-paced introductory\\nPython class.\\nThe Third Edition’s Scope Changes\\nAs of its third edition, this book is intended as a tutorial on the core Python language,\\nand nothing else. It’s about learning the language in an in-depth fashion, before ap-\\nplying it in application-level programming. The presentation here is bottom-up and\\ngradual, but it provides a complete look at the entire language, in isolation from its\\napplication roles.\\nFor some, “learning Python” involves spending an hour or two going through a tutorial\\non the Web. This works for already advanced programmers, up to a point; Python is,\\nafter all, relatively simple in comparison to other languages. The problem with this fast-\\ntrack approach is that its practitioners eventually stumble onto unusual cases and get\\nxl | Preface', metadata={'source': 'python.pdf', 'page': 40}),\n",
       " Document(page_content='stuck—variables change out from under them, mutable default arguments mutate in-\\nexplicably, and so on. The goal here is instead to provide a solid grounding in Python\\nfundamentals, so that even the unusual cases will make sense when they crop up.\\nThis scope is \\ndeliberate. By restricting our gaze to language fundamentals, we can in-\\nvestigate them here in more satisfying depth. Other texts, described ahead, pick up\\nwhere this book leaves off and provide a more complete look at application-level topics\\nand additional reference materials. The purpose of the book you are reading now is\\nsolely to teach Python itself so that you can apply it to whatever domain you happen\\nto work in.\\nAbout This Book\\nThis section underscores some important points about this book in general, regardless\\nof its edition number. No book addresses every possible audience, so it’s important to\\nunderstand a book’s goals up front.\\nThis Book’s Prerequisites\\nThere are no absolute prerequisites to speak of, really. Both true beginners and crusty\\nprogramming veterans have used this book successfully. If you are motivated to learn\\nPython, this text will probably work for you. In general, though, I have found that any\\nexposure to programming or scripting before this book can be helpful, even if not\\nrequired for every reader.\\nThis book is designed to be an introductory-level Python text for programmers.* It may\\nnot be an ideal text for someone who has never touched a computer before (for instance,\\nwe’re not going to spend any time exploring what a computer is), but I haven’t made\\nmany assumptions about your programming background or education.\\nOn the other hand, I won’t insult readers by assuming they are “dummies,” either,\\nwhatever that means—it’s easy to do useful things in Python, and this book will show\\nyou how. The text occasionally contrasts Python with languages such as C, C++, Java,\\nand Pascal, but you can safely ignore these comparisons if you haven’t used such lan-\\nguages in the past.\\nThis Book’s Scope and Other Books\\nAlthough this book covers all the essentials of the Python language, I’ve kept its scope\\nnarrow in the interests of speed and size. To keep things simple, this book focuses on\\ncore concepts, uses small and self-contained examples to illustrate points, and\\n* And by “programmers,” I mean anyone who has written a single line of code in any programming or scripting\\nlanguage in \\nthe past. If this doesn’t include you, you will probably find this book useful anyhow, but be aware\\nthat it will spend more time teaching Python than programming fundamentals.\\nPreface | xli', metadata={'source': 'python.pdf', 'page': 41}),\n",
       " Document(page_content='sometimes omits the small details that are readily available in reference manuals. Be-\\ncause of \\nthat, this book is probably best described as an introduction and a stepping-\\nstone to more advanced and complete texts.\\nFor example, we won’t talk much about Python/C integration—a complex topic that\\nis nevertheless central to many Python-based systems. We also won’t talk much about\\nPython’s history or development processes. And popular Python applications such as\\nGUIs, system tools, and network scripting get only a short glance, if they are mentioned\\nat all. Naturally, this scope misses some of the big picture.\\nBy and large, Python is about raising the quality bar a few notches in the scripting world.\\nSome of its ideas require more context than can be provided here, and I’d be remiss if\\nI didn’t recommend further study after you finish this book. I hope that most readers\\nof this book will eventually go on to gain a more complete understanding of application-\\nlevel programming from other texts.\\nBecause of its beginner’s focus, Learning Python is designed to be naturally comple-\\nmented by O’Reilly’s other Python books. For instance, Programming Python, another\\nbook I authored, provides larger and more complete examples, along with tutorials on\\napplication programming techniques, and was explicitly designed to be a follow-up\\ntext to the one you are reading now. Roughly, the current editions of Learning\\nPython and Programming Python reflect the two halves of their author’s training\\nmaterials—the core language, and application programming. In addition, O’Reilly’s\\nPython Pocket Reference  serves as a quick reference supplement for looking up some\\nof the finer details skipped here.\\nOther follow-up books can also provide references, additional examples, or details\\nabout using Python in specific domains such as the Web and GUIs. For instance,\\nO’Reilly’s Python in a Nutshell  and Sams’s Python Essential Reference  serve as useful\\nreferences, and O’Reilly’s Python Cookbook  offers a library of self-contained examples\\nfor people already familiar with application programming techniques. Because reading\\nbooks is such a subjective experience, I encourage you to browse on your own to find\\nadvanced texts that suit your needs. Regardless of which books you choose, though,\\nkeep in mind that the rest of the Python story requires studying examples that are more\\nrealistic than there is space for here.\\nHaving said that, I think you’ll find this book to be a good first text on Python, despite\\nits limited scope (and perhaps because of it). You’ll learn everything you need to get\\nstarted writing useful standalone Python programs and scripts. By the time you’ve fin-\\nished this book, you will have learned not only the language itself, but also how to apply\\nit well to your day-to-day tasks. And you’ll be equipped to tackle more advanced topics\\nand examples as they come your way.\\nxlii | Preface', metadata={'source': 'python.pdf', 'page': 42}),\n",
       " Document(page_content='This Book’s Style and Structure\\nThis book is \\nbased on training materials developed for a three-day hands-on Python\\ncourse. You’ll find quizzes at the end of each chapter, and exercises at the end of the\\nlast chapter of each part. Solutions to chapter quizzes appear in the chapters themselves,\\nand solutions to part exercises show up in Appendix B. The quizzes are designed to\\nreview material, while the exercises are designed to get you coding right away and are\\nusually one of the highlights of the course.\\nI strongly recommend working through the quizzes and exercises along the way, not\\nonly to gain Python programming experience, but also because some of the exercises\\nraise issues not covered elsewhere in the book. The solutions in the chapters and in\\nAppendix B should help you if you get stuck (and you are encouraged to peek at the\\nanswers as much and as often as you like).\\nThe overall structure of this book is also derived from class materials. Because this text\\nis designed to introduce language basics quickly, I’ve organized the presentation by\\nmajor language features, not examples. We’ll take a bottom-up approach here: from\\nbuilt-in object types, to statements, to program units, and so on. Each chapter is fairly\\nself-contained, but later chapters draw upon ideas introduced in earlier ones (e.g., by\\nthe time we get to classes, I’ll assume you know how to write functions), so a linear\\nreading makes the most sense for most readers.\\nIn general terms, this book presents the Python language in a linear fashion. It is or-\\nganized with one part per major language feature—types, functions, and so forth—and\\nmost of the examples are small and self-contained (some might also call the examples\\nin this text artificial, but they illustrate the points it aims to make). More specifically,\\nhere is what you will find:\\nPart I, Getting Started\\nWe begin with a general overview of Python that answers commonly asked initial\\nquestions—why people use the language, what it’s useful for, and so on. The first\\nchapter introduces the major ideas underlying the technology to give you some\\nbackground context. Then the technical material of the book begins, as we explore\\nthe ways that both we and Python run programs. The goal of this part of the book\\nis to give you just enough information to be able to follow along with later examples\\nand exercises.\\nPart II, Types and Operations\\nNext, we begin our tour of the Python language, studying Python’s major built-in\\nobject types in depth: numbers, lists, dictionaries, and so on. You can get a lot done\\nin Python with these tools alone. This is the most substantial part of the book\\nbecause we lay groundwork here for later chapters. We’ll also look at dynamic\\ntyping and its references—keys to using Python well—in this part.\\nPreface | xliii', metadata={'source': 'python.pdf', 'page': 43}),\n",
       " Document(page_content='Part III, Statements and Syntax\\nThe next part \\nmoves on to introduce Python’s statements—the code you type to\\ncreate and process objects in Python. It also presents Python’s general syntax\\nmodel. Although this part focuses on syntax, it also introduces some related tools,\\nsuch as the PyDoc system, and explores coding alternatives.\\nPart IV, Functions\\nThis part begins \\nour look at Python’s higher-level program structure tools. Func-\\ntions turn out to be a simple way to package code for reuse and avoid code redun-\\ndancy. In this part, we will explore Python’s scoping rules, argument-passing\\ntechniques, and more.\\nPart V, Modules\\nPython modules let you organize statements and functions into larger components,\\nand this part illustrates how to create, use, and reload modules. We’ll also look at\\nsome more advanced topics here, such as module packages, module reloading, and\\nthe __name__ variable.\\nPart VI, Classes and OOP\\nHere, we explore Python’s object-oriented programming tool, the class—an op-\\ntional but powerful way to structure code for customization and reuse. As you’ll\\nsee, classes mostly reuse ideas we will have covered by this point in the book, and\\nOOP in Python is mostly about looking up names in linked objects. As you’ll also\\nsee, OOP is optional in Python, but it can shave development time substantially,\\nespecially for long-term strategic project development.\\nPart VII, Exceptions and Tools\\nWe conclude the language fundamentals coverage in this text with a look at Py-\\nthon’s exception handling model and statements, plus a brief overview of devel-\\nopment tools that will become more useful when you start writing larger programs\\n(debugging and testing tools, for instance). Although exceptions are a fairly light-\\nweight tool, this part appears after the discussion of classes because exceptions\\nshould now all be classes.\\nPart VIII, Advanced Topics (new in the fourth edition)\\nIn the final part, we explore some advanced topics. Here, we study Unicode and\\nbyte strings, managed attribute tools like properties and descriptors, function and\\nclass decorators, and metaclasses. These chapters are all optional reading, because\\nnot all programmers need to understand the subjects they address. On the other\\nhand, readers who must process internationalized text or binary data, or are re-\\nsponsible for developing APIs for other programmers to use, should find something\\nof interest in this part.\\nPart IX, Appendixes\\nThe book wraps up with a pair of appendixes that give platform-specific tips for\\nusing Python on various computers ( Appendix A ) and provide solutions to the end-\\nof-part exercises ( Appendix B ). Solutions to end-of-chapter quizzes appear in the\\nchapters themselves.\\nxliv | Preface', metadata={'source': 'python.pdf', 'page': 44}),\n",
       " Document(page_content='Note that the index and table of contents can be used to hunt for details, but there are\\nno reference appendixes \\nin this book (this book is a tutorial, not a reference). As men-\\ntioned earlier, you can consult Python Pocket Reference , as well as other books, and the\\nfree Python reference manuals maintained at http://www.python.org for syntax and\\nbuilt-in tool details.\\nBook Updates\\nImprovements happen (and so do mis ^H^H^H typos). Updates, supplements, and cor-\\nrections for this book will be maintained (or referenced) on the Web at one of the\\nfollowing sites:\\nhttp://www.oreilly.com/catalog/9780596158064 (O’Reilly’s web page for the book)\\nhttp://www.rmi.net/~lutz (the author’s site)\\nhttp://www.rmi.net/~lutz/about-lp.html (the author’s web page for the book)\\nThe last of these three URLs points to a web page for this book where I will post updates,\\nbut be sure \\nto search the Web if this link becomes invalid. If I could become more\\nclairvoyant, I would, but the Web changes faster than printed books.\\nAbout the Programs in This Book\\nThis fourth edition of this book, and all the program examples in it, is based on Python\\nversion 3.0. In addition, most of its examples run under Python 2.6, as described in the\\ntext, and notes for Python 2.6 readers are mixed in along the way.\\nBecause this text focuses on the core language, however, you can be fairly sure that\\nmost of what it has to say won’t change very much in future releases of Python. Most\\nof this book applies to earlier Python versions, too, except when it does not; naturally,\\nif you try using extensions added after the release you’ve got, all bets are off.\\nAs a rule of thumb, the latest Python is the best Python. Because this book focuses on\\nthe core language, most of it also applies to Jython, the Java-based Python language\\nimplementation, as well as other Python implementations described in Chapter 2.\\nSource code for the book’s examples, as well as exercise solutions, can be fetched from\\nthe book’s website at http://www.oreilly.com/catalog/9780596158064/. So, how do you\\nrun the examples? We’ll study startup details in Chapter 3, so please stay tuned for\\ninformation on this front.\\nUsing Code Examples\\nThis book is here to help you get your job done. In general, you may use the code in\\nthis book in your programs and documentation. You do not need to contact us for\\npermission unless you’re reproducing a significant portion of the code. For example,\\nPreface | xlv', metadata={'source': 'python.pdf', 'page': 45}),\n",
       " Document(page_content='writing a program that uses several chunks of code from this book does not require\\npermission. Selling or \\ndistributing a CD-ROM of examples from O’Reilly books does\\nrequire permission. Answering a question by citing this book and quoting example\\ncode does not require permission. Incorporating a significant amount of example code\\nfrom this book into your product’s documentation does require permission.\\nWe appreciate, but do not require, attribution. An attribution usually includes the title,\\nauthor, publisher, and ISBN. For example: “ Learning Python, Fourth Edition, by Mark\\nLutz. Copyright 2009 Mark Lutz, 978-0-596-15806-4.”\\nIf you feel your use of code examples falls outside fair use or the permission given above,\\nfeel free to contact us at permissions@oreilly.com.\\nFont Conventions\\nThis book uses the following typographical conventions:\\nItalic\\nUsed for email addresses, URLs, filenames, pathnames, and emphasizing new\\nterms when they are first introduced\\nConstant width\\nUsed for the contents of files and the output from commands, and to designate\\nmodules, methods, statements, and commands\\nConstant width bold\\nUsed in code sections to show commands or text that would be typed by the user,\\nand, occasionally, to highlight portions of code\\nConstant width italic\\nUsed for replaceables and some comments in code sections\\n<Constant width>\\nIndicates a syntactic unit that should be replaced with real code\\nIndicates a tip, suggestion, or general note relating to the nearby text.\\nIndicates a warning or caution relating to the nearby text.\\nxlvi | Preface', metadata={'source': 'python.pdf', 'page': 46}),\n",
       " Document(page_content='Notes specific to this book: In this book’s examples, the % character at\\nthe start of a system command line stands for the system’s prompt,\\nwhatever that may be on your machine (e.g., C:\\\\Python30> in a DOS\\nwindow). Don’t type the % character (or the system prompt it sometimes\\nstands for) yourself.\\nSimilarly, in interpreter interaction listings, do not type the >>>\\nand ... characters shown at the start of lines—these are prompts that\\nPython displays. Type just the text after these prompts. To help you\\nremember this, user inputs are shown in bold font in this book.\\nAlso, you normally don’t need to type text that starts with a # in listings;\\nas you’ll learn, these are comments, not executable code.\\nSafari® Books Online\\nSafari Books Online is an on-demand digital library that lets you easily\\nsearch over 7,500 \\ntechnology and creative reference books and videos to\\nfind the answers you need quickly.\\nWith a subscription, you can read any page and watch any video from our library online.\\nRead books on your cell phone and mobile devices. Access new titles before they are\\navailable for print, and get exclusive access to manuscripts in development and post\\nfeedback for the authors. Copy and paste code samples, organize your favorites, down-\\nload chapters, bookmark key sections, create notes, print out pages, and benefit from\\ntons of other time-saving features.\\nO’Reilly Media has uploaded this book to the Safari Books Online service. To have full\\ndigital access to this book and others on similar topics from O’Reilly and other pub-\\nlishers, sign up for free at http://my.safaribooksonline.com.\\nHow to Contact Us\\nPlease address comments and questions concerning this book to the publisher:\\nO’Reilly Media, Inc.\\n1005 Gravenstein Highway North\\nSebastopol, CA 95472\\n800-998-9938 (in the United States or Canada)\\n707-829-0515 (international or local)\\n707-829-0104 (fax)\\nWe will also maintain a web page for this book, where we list errata, examples, and\\nany additional information. You can access this page at:\\nhttp://www.oreilly.com/catalog/9780596158064/\\nPreface | xlvii', metadata={'source': 'python.pdf', 'page': 47}),\n",
       " Document(page_content='To comment or ask technical questions about this book, send email to:\\nbookquestions@oreilly.com\\nFor more information about our books, conferences, Resource Centers, and the\\nO’Reilly Network, see our website at:\\nhttp://www.oreilly.com\\nFor book updates, be sure to also see the other links mentioned earlier in this Preface.\\nAcknowledgments\\nAs I write \\nthis fourth edition of this book in 2009, I can’t help but be in a sort of “mission\\naccomplished” state of mind. I have now been using and promoting Python for 17 years,\\nand have been teaching it for 12 years. Despite the passage of time and events, I am still\\nconstantly amazed at how successful Python has been over the years. It has grown in\\nways that most of us could not possibly have imagined in 1992. So, at the risk of\\nsounding like a hopelessly self-absorbed author, you’ll have to pardon a few words of\\nreminiscing, congratulations, and thanks here.\\nIt’s been the proverbial long and winding road. Looking back today, when I first dis-\\ncovered Python in 1992, I had no idea what an impact it would have on the next 17\\nyears of my life. Two years after writing the first edition of Programming Python  in\\n1995, I began traveling around the country and the world teaching Python to beginners\\nand experts. Since finishing the first edition of Learning Python  in 1999, I’ve been an\\nindependent Python trainer and writer, thanks largely to Python’s exponential growth\\nin popularity.\\nAs I write these words in mid-2009, I have written 12 Python books (4 editions of 3).\\nI have also been teaching Python for more than a decade; have taught some 225 Python\\ntraining sessions in the U.S., Europe, Canada, and Mexico; and have met over 3,000\\nstudents along the way. Besides racking up frequent flyer miles, these classes helped\\nme refine this text as well as my other Python books. Over the years, teaching honed\\nthe books, and vice versa. In fact, the book you’re reading is derived almost entirely\\nfrom my classes.\\nBecause of this, I’d like to thank all the students who have participated in my courses\\nduring the last 12 years. Along with changes in Python itself, your feedback played a\\nhuge role in shaping this text. (There’s nothing quite as instructive as watching 3,000\\nstudents repeat the same beginner’s mistakes!) This edition owes its changes primarily\\nto classes held after 2003, though every class held since 1997 has in some way helped\\nrefine this book. I’d especially like to single out clients who hosted classes in Dublin,\\nMexico City, Barcelona, London, Edmonton, and Puerto Rico; better perks would be\\nhard to imagine.\\nI’d also like to express my gratitude to everyone who played a part in producing this\\nbook. To the editors who worked on this project: Julie Steele on this edition, Tatiana\\nxlviii | Preface', metadata={'source': 'python.pdf', 'page': 48}),\n",
       " Document(page_content='Apandi on the prior edition, and many others on earlier editions. To Doug Hellmann\\nand Jesse Noller \\nfor taking part in the technical review of this book. And to O’Reilly\\nfor giving me a chance to work on those 12 book projects—it’s been net fun (and only\\nfeels a little like the movie Groundhog Day).\\nI want to thank my original coauthor David Ascher as well for his work on the first two\\neditions of this book. David contributed the “Outer Layers” part in prior editions,\\nwhich we unfortunately had to trim to make room for new core language materials in\\nthe third edition. To compensate, I added a handful of more advanced programs as a\\nself-study final exercise in the third edition, and added both new advanced examples\\nand a new complete part for advanced topics in the fourth edition. Also see the prior\\nnotes in this Preface about follow-up application-level texts you may want to consult\\nonce you’ve learned the fundamentals here.\\nFor creating such an enjoyable and useful language, I owe additional thanks to Guido\\nvan Rossum and the rest of the Python community. Like most open source systems,\\nPython is the product of many heroic efforts. After 17 years of programming Python, I\\nstill find it to be seriously fun. It’s been my privilege to watch Python grow from a new\\nkid on the scripting languages block to a widely used tool, deployed in some fashion\\nby almost every organization writing software. That has been an exciting endeavor to\\nbe a part of, and I’d like to thank and congratulate the entire Python community for a\\njob well done.\\nI also want to thank my original editor at O’Reilly, the late Frank Willison. This book\\nwas largely Frank’s idea, and it reflects the contagious vision he had. In looking back,\\nFrank had a profound impact on both my own career and that of Python itself. It is not\\nan exaggeration to say that Frank was responsible for much of the fun and success of\\nPython when it was new. We still miss him.\\nFinally, a few personal notes of thanks. To OQO for the best toys so far (while they\\nlasted). To the late Carl Sagan for inspiring an 18-year-old kid from Wisconsin. To my\\nMom, for courage. And to all the large corporations I’ve come across over the years,\\nfor reminding me how lucky I have been to be self-employed for the last decade!\\nTo my children, Mike, Sammy, and Roxy, for whatever futures you will choose to make.\\nYou were children when I began with Python, and you seem to have somehow grown\\nup along the way; I’m proud of you. Life may compel us down paths all our own, but\\nthere will always be a path home.\\nAnd most of all, to Vera, my best friend, my girlfriend, and my wife. The best day of\\nmy life was the day I finally found you. I don’t know what the next 50 years hold, but\\nI do know that I want to spend all of them holding you.\\n—Mark Lutz\\nSarasota, Florida\\nJuly 2009\\nPreface | xlix', metadata={'source': 'python.pdf', 'page': 49}),\n",
       " Document(page_content='', metadata={'source': 'python.pdf', 'page': 50}),\n",
       " Document(page_content='PART I\\nGetting Started', metadata={'source': 'python.pdf', 'page': 51}),\n",
       " Document(page_content='', metadata={'source': 'python.pdf', 'page': 52}),\n",
       " Document(page_content='CHAPTER 1\\nA Python Q&A Session\\nIf you’ve bought this book, you may already know what Python is and why it’s an\\nimportant tool to \\nlearn. If you don’t, you probably won’t be sold on Python until you’ve\\nlearned the language by reading the rest of this book and have done a project or two.\\nBut before we jump into details, the first few pages of this book will briefly introduce\\nsome of the main reasons behind Python’s popularity. To begin sculpting a definition\\nof Python, this chapter takes the form of a question-and-answer session, which poses\\nsome of the most common questions asked by beginners.\\nWhy Do People Use Python?\\nBecause there are many programming languages available today, this is the usual first\\nquestion of newcomers. Given that there are roughly 1 million Python users out there\\nat the moment, there really is no way to answer this question with complete accuracy;\\nthe choice of development tools is sometimes based on unique constraints or personal\\npreference.\\nBut after teaching Python to roughly 225 groups and over 3,000 students during the\\nlast 12 years, some common themes have emerged. The primary factors cited by Python\\nusers seem to be these:\\nSoftware quality\\nFor many, Python’s focus on readability, coherence, and software quality in general\\nsets it apart from other tools in the scripting world. Python code is designed to be\\nreadable, and hence reusable and maintainable—much more so than traditional\\nscripting languages. The uniformity of Python code makes it easy to understand,\\neven if you did not write it. In addition, Python has deep support for more advanced\\nsoftware reuse mechanisms, such as object-oriented programming (OOP).\\nDeveloper productivity\\nPython boosts developer productivity many times beyond compiled or statically\\ntyped languages such as C, C++, and Java. Python code is typically one-third to\\none-fifth the size of equivalent C++ or Java code. That means there is less to type,\\n3', metadata={'source': 'python.pdf', 'page': 53}),\n",
       " Document(page_content='less to debug, and less to maintain after the fact. Python programs also run imme-\\ndiately, without the \\nlengthy compile and link steps required by some other tools,\\nfurther boosting programmer speed.\\nProgram portability\\nMost Python programs run unchanged on all major computer platforms. Porting\\nPython code between Linux and Windows, for example, is usually just a matter of\\ncopying a script’s code between machines. Moreover, Python offers multiple op-\\ntions for coding portable graphical user interfaces, database access programs, web-\\nbased systems, and more. Even operating system interfaces, including program\\nlaunches and directory processing, are as portable in Python as they can possibly\\nbe.\\nSupport libraries\\nPython comes with a large collection of prebuilt and portable functionality, known\\nas the standard library. This library supports an array of application-level pro-\\ngramming tasks, from text pattern matching to network scripting. In addition,\\nPython can be extended with both homegrown libraries and a vast collection of\\nthird-party application support software. Python’s third-party domain offers tools\\nfor website construction, numeric programming, serial port access, game devel-\\nopment, and much more. The NumPy extension, for instance, has been described\\nas a free and more powerful equivalent to the Matlab numeric programming\\nsystem.\\nComponent integration\\nPython scripts can easily communicate with other parts of an application, using a\\nvariety of integration mechanisms. Such integrations allow Python to be used as a\\nproduct customization and extension tool. Today, Python code can invoke C and\\nC++ libraries, can be called from C and C++ programs, can integrate with Java\\nand .NET components, can communicate over frameworks such as COM, can\\ninterface with devices over serial ports, and can interact over networks with inter-\\nfaces like SOAP, XML-RPC, and CORBA. It is not a standalone tool.\\nEnjoyment\\nBecause of Python’s ease of use and built-in toolset, it can make the act of pro-\\ngramming more pleasure than chore. Although this may be an intangible benefit,\\nits effect on productivity is an important asset.\\nOf these factors, the first two (quality and productivity) are probably the most com-\\npelling benefits to most Python users.\\nSoftware Quality\\nBy design, Python implements a deliberately simple and readable syntax and a highly\\ncoherent programming model. As a slogan at a recent Python conference attests, the\\nnet result is that Python seems to “fit your brain”—that is, features of the language\\ninteract in consistent and limited ways and follow naturally from a small set of core\\n4 | Chapter 1: \\u2002A Python Q&A Session', metadata={'source': 'python.pdf', 'page': 54}),\n",
       " Document(page_content='concepts. This makes the language easier to learn, understand, and remember. In prac-\\ntice, Python programmers \\ndo not need to constantly refer to manuals when reading or\\nwriting code; it’s a consistently designed system that many find yields surprisingly\\nregular-looking code.\\nBy philosophy, Python adopts a somewhat minimalist approach. This means that al-\\nthough there are usually multiple ways to accomplish a coding task, there is usually\\njust one obvious way, a few less obvious alternatives, and a small set of coherent in-\\nteractions everywhere in the language. Moreover, Python doesn’t make arbitrary deci-\\nsions for you; when interactions are ambiguous, explicit intervention is preferred over\\n“magic.” In the Python way of thinking, explicit is better than implicit, and simple is\\nbetter than complex.*\\nBeyond such design themes, Python includes tools such as modules and OOP that\\nnaturally promote code reusability. And because Python is focused on quality, so too,\\nnaturally, are Python programmers.\\nDeveloper Productivity\\nDuring the great Internet boom of the mid-to-late 1990s, it was difficult to find enough\\nprogrammers to implement software projects; developers were asked to implement\\nsystems as fast as the Internet evolved. Today, in an era of layoffs and economic reces-\\nsion, the picture has shifted. Programming staffs are often now asked to accomplish\\nthe same tasks with even fewer people.\\nIn both of these scenarios, Python has shined as a tool that allows programmers to get\\nmore done with less effort. It is deliberately optimized for speed of development —its\\nsimple syntax, dynamic typing, lack of compile steps, and built-in toolset allow pro-\\ngrammers to develop programs in a fraction of the time needed when using some other\\ntools. The net effect is that Python typically boosts developer productivity many times\\nbeyond the levels supported by traditional languages. That’s good news in both boom\\nand bust times, and everywhere the software industry goes in between.\\nIs Python a “Scripting Language”?\\nPython is a general-purpose programming language that is often applied in scripting\\nroles. It is commonly defined as an object-oriented scripting language—a definition that\\nblends support for OOP with an overall orientation toward scripting roles. In fact,\\npeople often use the word “script” instead of “program” to describe a Python code file.\\nIn this book, the terms “script” and “program” are used interchangeably, with a slight\\n* For a more complete look at the Python philosophy, type the command import this at any Python interactive\\nprompt (you’ll see how in Chapter 2). This invokes an “Easter egg” hidden in Python—a collection of design\\nprinciples underlying Python. The acronym EIBTI is now fashionable jargon for the “explicit is better than\\nimplicit” rule.\\nIs Python a “Scripting Language”? | 5', metadata={'source': 'python.pdf', 'page': 55}),\n",
       " Document(page_content='preference for “script” to describe a simpler top-level file and “program” to refer to a\\nmore sophisticated multifile application.\\nBecause the term \\n“scripting language” has so many different meanings to different\\nobservers, some would prefer that it not be applied to Python at all. In fact, people tend\\nto make three very different associations, some of which are more useful than others,\\nwhen they hear Python labeled as such:\\nShell tools\\nSometimes when people hear Python described as a scripting language, they think\\nit means that Python is a tool for coding operating-system-oriented scripts. Such\\nprograms are often launched from console command lines and perform tasks such\\nas processing text files and launching other programs.\\nPython programs can and do serve such roles, but this is just one of dozens of\\ncommon Python application domains. It is not just a better shell-script language.\\nControl language\\nTo others, scripting refers to a “glue” layer used to control and direct (i.e., script)\\nother application components. Python programs are indeed often deployed in the\\ncontext of larger applications. For instance, to test hardware devices, Python pro-\\ngrams may call out to components that give low-level access to a device. Similarly,\\nprograms may run bits of Python code at strategic points to support end-user\\nproduct customization without the need to ship and recompile the entire system’s\\nsource code.\\nPython’s simplicity makes it a naturally flexible control tool. Technically, though,\\nthis is also just a common Python role; many (perhaps most) Python programmers\\ncode standalone scripts without ever using or knowing about any integrated com-\\nponents. It is not just a control language.\\nEase of use\\nProbably the best way to think of the term “scripting language” is that it refers to\\na simple language used for quickly coding tasks. This is especially true when the\\nterm is applied to Python, which allows much faster program development than\\ncompiled languages like C++. Its rapid development cycle fosters an exploratory,\\nincremental mode of programming that has to be experienced to be appreciated.\\nDon’t be fooled, though—Python is not just for simple tasks. Rather, it makes tasks\\nsimple by its ease of use and flexibility. Python has a simple feature set, but it allows\\nprograms to scale up in sophistication as needed. Because of that, it is commonly\\nused for quick tactical tasks and longer-term strategic development.\\nSo, is Python a scripting language or not? It depends on whom you ask. In general, the\\nterm “scripting” is probably best used to describe the rapid and flexible mode of de-\\nvelopment that Python supports, rather than a particular application domain.\\n6 | Chapter 1: \\u2002A Python Q&A Session', metadata={'source': 'python.pdf', 'page': 56}),\n",
       " Document(page_content='OK, but What’s the Downside?\\nAfter using it \\nfor 17 years and teaching it for 12, the only downside to Python I’ve found\\nis that, as currently implemented, its execution speed may not always be as fast as that\\nof compiled languages such as C and C++.\\nWe’ll talk about implementation concepts in detail later in this book. In short, the\\nstandard implementations of Python today compile (i.e., translate) source code state-\\nments to an intermediate format known as byte code  and then interpret the byte code.\\nByte code provides portability, as it is a platform-independent format. However, be-\\ncause Python is not compiled all the way down to binary machine code (e.g., instruc-\\ntions for an Intel chip), some programs will run more slowly in Python than in a fully\\ncompiled language like C.\\nWhether you will ever care about the execution speed difference depends on what kinds\\nof programs you write. Python has been optimized numerous times, and Python code\\nruns fast enough by itself in most application domains. Furthermore, whenever you do\\nsomething “real” in a Python script, like processing a file or constructing a graphical\\nuser interface (GUI), your program will actually run at C speed, since such tasks are\\nimmediately dispatched to compiled C code inside the Python interpreter. More fun-\\ndamentally, Python’s speed-of-development gain is often far more important than any\\nspeed-of-execution loss, especially given modern computer speeds.\\nEven at today’s CPU speeds, though, there still are some domains that do require op-\\ntimal execution speeds. Numeric programming and animation, for example, often need\\nat least their core number-crunching components to run at C speed (or better). If you\\nwork in such a domain, you can still use Python—simply split off the parts of the\\napplication that require optimal speed into compiled extensions , and link those into\\nyour system for use in Python scripts.\\nWe won’t talk about extensions much in this text, but this is really just an instance of\\nthe Python-as-control-language role we discussed earlier. A prime example of this dual\\nlanguage strategy is the NumPy numeric programming extension for Python; by com-\\nbining compiled and optimized numeric extension libraries with the Python language,\\nNumPy turns Python into a numeric programming tool that is efficient and easy to use.\\nYou may never need to code such extensions in your own Python work, but they provide\\na powerful optimization mechanism if you ever do.\\nWho Uses Python Today?\\nAt this writing, the best estimate anyone can seem to make of the size of the Python\\nuser base is that there are roughly 1 million Python users around the world today (plus\\nor minus a few). This estimate is based on various statistics, like download rates and\\ndeveloper surveys. Because Python is open source, a more exact count is difficult—\\nthere are no license registrations to tally. Moreover, Python is automatically included\\nWho Uses Python Today? | 7', metadata={'source': 'python.pdf', 'page': 57}),\n",
       " Document(page_content='with Linux distributions, Macintosh computers, and some products and hardware,\\nfurther clouding the user-base picture.\\nIn general, though, \\nPython enjoys a large user base and a very active developer com-\\nmunity. Because Python has been around for some 19 years and has been widely used,\\nit is also very stable and robust. Besides being employed by individual users, Python is\\nalso being applied in real revenue-generating products by real companies. For instance:\\n• Google makes extensive use of Python in its web search systems, and employs\\nPython’s creator.\\n• The YouTube video sharing service is largely written in Python.\\n• The popular BitTorrent peer-to-peer file sharing system is a Python program.\\n• Google’s popular App Engine web development framework uses Python as its ap-\\nplication language.\\n• EVE Online, a Massively Multiplayer Online Game (MMOG), makes extensive use\\nof Python.\\n• Maya, a powerful integrated 3D modeling and animation system, provides a\\nPython scripting API.\\n• Intel, Cisco, Hewlett-Packard, Seagate, Qualcomm, and IBM use Python for hard-\\nware testing.\\n• Industrial Light & Magic, Pixar, and others use Python in the production of ani-\\nmated movies.\\n• JPMorgan Chase, UBS, Getco, and Citadel apply Python for financial market\\nforecasting.\\n• NASA, Los Alamos, Fermilab, JPL, and others use Python for scientific program-\\nming tasks.\\n• iRobot uses Python to develop commercial robotic devices.\\n• ESRI uses Python as an end-user customization tool for its popular GIS mapping\\nproducts.\\n• The NSA uses Python for cryptography and intelligence analysis.\\n• The IronPort email server product uses more than 1 million lines of Python code\\nto do its job.\\n• The One Laptop Per Child (OLPC) project builds its user interface and activity\\nmodel in Python.\\nAnd so on. Probably the only common thread amongst the companies using Python\\ntoday is that Python is used all over the map, in terms of application domains. Its\\ngeneral-purpose nature makes it applicable to almost all fields, not just one. In fact, it’s\\nsafe to say that virtually every substantial organization writing software is using Python,\\nwhether for short-term tactical tasks, such as testing and administration, or for long-\\nterm strategic product development. Python has proven to work well in both modes.\\n8 | Chapter 1: \\u2002A Python Q&A Session', metadata={'source': 'python.pdf', 'page': 58}),\n",
       " Document(page_content='For more details on companies using Python today, see Python’s website at http://www\\n.python.org.\\nWhat Can I Do with Python?\\nIn addition to \\nbeing a well-designed programming language, Python is useful for ac-\\ncomplishing real-world tasks—the sorts of things developers do day in and day out.\\nIt’s commonly used in a variety of domains, as a tool for scripting other components\\nand implementing standalone programs. In fact, as a general-purpose language,\\nPython’s roles are virtually unlimited: you can use it for everything from website de-\\nvelopment and gaming to robotics and spacecraft control.\\nHowever, the most common Python roles currently seem to fall into a few broad cat-\\negories. The next few sections describe some of Python’s most common applications\\ntoday, as well as tools used in each domain. We won’t be able to explore the tools\\nmentioned here in any depth—if you are interested in any of these topics, see the Python\\nwebsite or other resources for more details.\\nSystems Programming\\nPython’s built-in interfaces to operating-system services make it ideal for writing port-\\nable, maintainable system-administration tools and utilities (sometimes called shell\\ntools). Python programs can search files and directory trees, launch other programs, do\\nparallel processing with processes and threads, and so on.\\nPython’s standard library comes with POSIX bindings and support for all the usual OS\\ntools: environment variables, files, sockets, pipes, processes, multiple threads, regular\\nexpression pattern matching, command-line arguments, standard stream interfaces,\\nshell-command launchers, filename expansion, and more. In addition, the bulk of Py-\\nthon’s system interfaces are designed to be portable; for example, a script that copies\\ndirectory trees typically runs unchanged on all major Python platforms. The Stackless\\nPython system, used by EVE Online, also offers advanced solutions to multiprocessing\\nrequirements.\\nGUIs\\nPython’s simplicity and rapid turnaround also make it a good match for graphical user\\ninterface programming. Python comes with a standard object-oriented interface to the\\nTk GUI API called tkinter ( Tkinter in 2.6) that allows Python programs to implement\\nportable GUIs with a native look and feel. Python/tkinter GUIs run unchanged on\\nMicrosoft Windows, X Windows (on Unix and Linux), and the Mac OS (both Classic\\nand OS X). A free extension package, PMW, adds advanced widgets to the tkinter\\ntoolkit. In addition, the wxPython GUI API, based on a C++ library, offers an alternative\\ntoolkit for constructing portable GUIs in Python.\\nWhat Can I Do with Python? | 9', metadata={'source': 'python.pdf', 'page': 59}),\n",
       " Document(page_content='Higher-level toolkits such as PythonCard and Dabo are built on top of base APIs such\\nas wxPython and \\ntkinter. With the proper library, you can also use GUI support in\\nother toolkits in Python, such as Qt with PyQt, GTK with PyGTK, MFC with\\nPyWin32, .NET with IronPython, and Swing with Jython (the Java version of Python,\\ndescribed in Chapter 2) or JPype. For applications that run in web browsers or have\\nsimple interface requirements, both Jython and Python web frameworks and server-\\nside CGI scripts, described in the next section, provide additional user interface\\noptions.\\nInternet Scripting\\nPython comes with standard Internet modules that allow Python programs to perform\\na wide variety of networking tasks, in client and server modes. Scripts can communicate\\nover sockets; extract form information sent to server-side CGI scripts; transfer files by\\nFTP; parse, generate, and analyze XML files; send, receive, compose, and parse email;\\nfetch web pages by URLs; parse the HTML and XML of fetched web pages; commu-\\nnicate over XML-RPC, SOAP, and Telnet; and more. Python’s libraries make these\\ntasks remarkably simple.\\nIn addition, a large collection of third-party tools are available on the Web for doing\\nInternet programming in Python. For instance, the HTMLGen system generates HTML\\nfiles from Python class-based descriptions, the mod_python package runs Python effi-\\nciently within the Apache web server and supports server-side templating with its Py-\\nthon Server Pages, and the Jython system provides for seamless Python/Java integration\\nand supports coding of server-side applets that run on clients.\\nIn addition, full-blown web development framework packages for Python, such as\\nDjango, TurboGears, web2py, Pylons, Zope, and WebWare, support quick construction\\nof full-featured and production-quality websites with Python. Many of these include\\nfeatures such as object-relational mappers, a Model/View/Controller architecture,\\nserver-side scripting and templating, and AJAX support, to provide complete and\\nenterprise-level web development solutions.\\nComponent Integration\\nWe discussed the component integration role earlier when describing Python as a con-\\ntrol language. Python’s ability to be extended by and embedded in C and C++ systems\\nmakes it useful as a flexible glue language for scripting the behavior of other systems\\nand components. For instance, integrating a C library into Python enables Python to\\ntest and launch the library’s components, and embedding Python in a product enables\\nonsite customizations to be coded without having to recompile the entire product (or\\nship its source code at all).\\n10 | Chapter 1: \\u2002A Python Q&A Session', metadata={'source': 'python.pdf', 'page': 60}),\n",
       " Document(page_content='Tools such as the SWIG and SIP code generators can automate much of the work\\nneeded to link compiled components into Python for use in scripts, and the Cython\\nsystem allows coders to mix Python and C-like code. Larger frameworks, such as Py-\\nthon’s COM support on Windows, the Jython Java-based implementation, the Iron-\\nPython .NET-based implementation, and various CORBA toolkits for Python, provide\\nalternative ways to script components. On Windows, for example, Python scripts can\\nuse frameworks to script Word and Excel.\\nDatabase Programming\\nFor traditional database demands, there are Python interfaces to all commonly used\\nrelational database systems—Sybase, Oracle, Informix, ODBC, MySQL, PostgreSQL,\\nSQLite, and more. The Python world has also defined a portable database API  for ac-\\ncessing SQL database systems from Python scripts, which looks the same on a variety\\nof underlying database systems. For instance, because the vendor interfaces implement\\nthe portable API, a script written to work with the free MySQL system will work largely\\nunchanged on other systems (such as Oracle); all you have to do is replace the under-\\nlying vendor interface.\\nPython’s standard pickle module provides a simple object persistence system—it allows\\nprograms to easily save and restore entire Python objects to files and file-like objects.\\nOn the Web, you’ll also find a third-party open source system named ZODB that pro-\\nvides a complete object-oriented database system for Python scripts, and others (such\\nas SQLObject and SQLAlchemy) that map relational tables onto Python’s class model.\\nFurthermore, as of Python 2.5, the in-process SQLite embedded SQL database engine\\nis a standard part of Python itself.\\nRapid Prototyping\\nTo Python programs, components written in Python and C look the same. Because of\\nthis, it’s possible to prototype systems in Python initially, and then move selected com-\\nponents to a compiled language such as C or C++ for delivery. Unlike some prototyping\\ntools, Python doesn’t require a complete rewrite once the prototype has solidified. Parts\\nof the system that don’t require the efficiency of a language such as C++ can remain\\ncoded in Python for ease of maintenance and use.\\nNumeric and Scientific Programming\\nThe NumPy numeric programming extension for Python mentioned earlier includes\\nsuch advanced tools as an array object, interfaces to standard mathematical libraries,\\nand much more. By integrating Python with numeric routines coded in a compiled\\nlanguage for speed, NumPy turns Python into a sophisticated yet easy-to-use numeric\\nprogramming tool that can often replace existing code written in traditional compiled\\nlanguages such as FORTRAN or C++. Additional numeric tools for Python support\\nWhat Can I Do with Python? | 11', metadata={'source': 'python.pdf', 'page': 61}),\n",
       " Document(page_content='animation, 3D visualization, parallel processing, and so on. The popular SciPy and \\nScientificPython extensions, for example, provide additional libraries of scientific pro-\\ngramming tools and use NumPy code.\\nGaming, Images, Serial Ports, XML, Robots, and More\\nPython \\nis commonly applied in more domains than can be mentioned here. For exam-\\nple, you can do:\\n• Game programming and multimedia in Python with the pygame system\\n• Serial port communication on Windows, Linux, and more with the PySerial\\nextension\\n• Image processing with PIL, PyOpenGL, Blender, Maya, and others\\n• Robot control programming with the PyRo toolkit\\n• XML parsing with the xml library package, the xmlrpclib module, and third-party\\nextensions\\n• Artificial intelligence programming with neural network simulators and expert\\nsystem shells\\n• Natural language analysis with the NLTK package\\nYou can even play solitaire with the PySol program. You’ll find support for many such\\nfields at the PyPI websites, and via web searches (search Google or http://www.python\\n.org for links).\\nMany of these specific domains are largely just instances of Python’s component inte-\\ngration role in action again. Adding it as a frontend to libraries of components written\\nin a compiled language such as C makes Python useful for scripting in a wide variety\\nof domains. As a general-purpose language that supports integration, Python is widely \\napplicable.\\nHow Is Python Supported?\\nAs a popular open source system, Python enjoys a large and active development com-\\nmunity that responds to issues and develops enhancements with a speed that many\\ncommercial software developers would find remarkable (if not downright shocking).\\nPython developers coordinate work online with a source-control system. Changes fol-\\nlow a formal PEP (Python Enhancement Proposal) protocol and must be accompanied\\nby extensions to Python’s extensive regression testing system. In fact, modifying\\nPython today is roughly as involved as changing commercial software—a far cry from\\nPython’s early days, when an email to its creator would suffice, but a good thing given\\nits current large user base.\\n12 | Chapter 1: \\u2002A Python Q&A Session', metadata={'source': 'python.pdf', 'page': 62}),\n",
       " Document(page_content='The PSF (Python Software Foundation), a formal nonprofit group, organizes confer-\\nences and \\ndeals with intellectual property issues. Numerous Python conferences are\\nheld around the world; O’Reilly’s OSCON and the PSF’s PyCon are the largest. The\\nformer of these addresses multiple open source projects, and the latter is a Python-only\\nevent that has experienced strong growth in recent years. Attendance at PyCon 2008\\nnearly doubled from the prior year, growing from 586 attendees in 2007 to over 1,000\\nin 2008. This was on the heels of a 40% attendance increase in 2007, from 410 in 2006.\\nPyCon 2009 had 943 attendees, a slight decrease from 2008, but a still very strong\\nshowing during a global recession.\\nWhat Are Python’s Technical Strengths?\\nNaturally, this is a developer’s question. If you don’t already have a programming\\nbackground, the language in the next few sections may be a bit baffling—don’t worry,\\nwe’ll explore all of these terms in more detail as we proceed through this book. For\\ndevelopers, though, here is a quick introduction to some of Python’s top technical\\nfeatures.\\nIt’s Object-Oriented\\nPython is an object-oriented language, from the ground up. Its class model supports\\nadvanced notions such as polymorphism, operator overloading, and multiple inheri-\\ntance; yet, in the context of Python’s simple syntax and typing, OOP is remarkably easy\\nto apply. In fact, if you don’t understand these terms, you’ll find they are much easier\\nto learn with Python than with just about any other OOP language available.\\nBesides serving as a powerful code structuring and reuse device, Python’s OOP nature\\nmakes it ideal as a scripting tool for object-oriented systems languages such as C++\\nand Java. For example, with the appropriate glue code, Python programs can subclass\\n(specialize) classes implemented in C++, Java, and C#.\\nOf equal significance, OOP is an option in Python; you can go far without having to\\nbecome an object guru all at once. Much like C++, Python supports both procedural\\nand object-oriented programming modes. Its object-oriented tools can be applied if\\nand when constraints allow. This is especially useful in tactical development modes,\\nwhich preclude design phases.\\nIt’s Free\\nPython is completely free to use and distribute. As with other open source software,\\nsuch as Tcl, Perl, Linux, and Apache, you can fetch the entire Python system’s source\\ncode for free on the Internet. There are no restrictions on copying it, embedding it in\\nyour systems, or shipping it with your products. In fact, you can even sell Python’s\\nsource code, if you are so inclined.\\nWhat Are Python’s Technical Strengths? | 13', metadata={'source': 'python.pdf', 'page': 63}),\n",
       " Document(page_content='But don’t get the wrong idea: “free” doesn’t mean “unsupported.” On the contrary,\\nthe Python online \\ncommunity responds to user queries with a speed that most com-\\nmercial software help desks would do well to try to emulate. Moreover, because Python\\ncomes with complete source code, it empowers developers, leading to the creation of\\na large team of implementation experts. Although studying or changing a programming\\nlanguage’s implementation isn’t everyone’s idea of fun, it’s comforting to know that\\nyou can do so if you need to. You’re not dependent on the whims of a commercial\\nvendor; the ultimate documentation source is at your disposal.\\nAs mentioned earlier, Python development is performed by a community that largely\\ncoordinates its efforts over the Internet. It consists of Python’s creator— Guido van\\nRossum, the officially anointed Benevolent Dictator for Life (BDFL) of Python—plus a\\nsupporting cast of thousands. Language changes must follow a formal enhancement\\nprocedure and be scrutinized by both other developers and the BDFL. Happily, this\\ntends to make Python more conservative with changes than some other languages.\\nIt’s Portable\\nThe standard implementation of Python is written in portable ANSI C, and it compiles\\nand runs on virtually every major platform currently in use. For example, Python pro-\\ngrams run today on everything from PDAs to supercomputers. As a partial list, Python\\nis available on:\\n• Linux and Unix systems\\n• Microsoft Windows and DOS (all modern flavors)\\n• Mac OS (both OS X and Classic)\\n• BeOS, OS/2, VMS, and QNX\\n• Real-time systems such as VxWorks\\n• Cray supercomputers and IBM mainframes\\n• PDAs running Palm OS, PocketPC, and Linux\\n• Cell phones running Symbian OS and Windows Mobile\\n• Gaming consoles and iPods\\n• And more\\nLike the language interpreter itself, the standard library modules that ship with Python\\nare implemented to be as portable across platform boundaries as possible. Further,\\nPython programs are automatically compiled to portable byte code, which runs the\\nsame on any platform with a compatible version of Python installed (more on this in\\nthe next chapter).\\n14 | Chapter 1: \\u2002A Python Q&A Session', metadata={'source': 'python.pdf', 'page': 64}),\n",
       " Document(page_content='What that means is that Python programs using the core language and standard libraries\\nrun the same \\non Linux, Windows, and most other systems with a Python interpreter.\\nMost Python ports also contain platform-specific extensions (e.g., COM support on\\nWindows), but the core Python language and libraries work the same everywhere. As\\nmentioned earlier, Python also includes an interface to the Tk GUI toolkit called tkinter\\n(Tkinter in 2.6), which allows Python programs to implement full-featured graphical\\nuser interfaces that run on all major GUI platforms without program changes.\\nIt’s Powerful\\nFrom a features perspective, Python is something of a hybrid. Its toolset places it be-\\ntween traditional scripting languages (such as Tcl, Scheme, and Perl) and systems de-\\nvelopment languages (such as C, C++, and Java). Python provides all the simplicity\\nand ease of use of a scripting language, along with more advanced software-engineering\\ntools typically found in compiled languages. Unlike some scripting languages, this\\ncombination makes Python useful for large-scale development projects. As a preview,\\nhere are some of the main things you’ll find in Python’s toolbox:\\nDynamic typing\\nPython keeps track of the kinds of objects your program uses when it runs; it\\ndoesn’t require complicated type and size declarations in your code. In fact, as\\nyou’ll see in Chapter 6, there is no such thing as a type or variable declaration\\nanywhere in Python. Because Python code does not constrain data types, it is also\\nusually automatically applicable to a whole range of objects.\\nAutomatic memory management\\nPython automatically allocates objects and reclaims (“garbage collects”) them\\nwhen they are no longer used, and most can grow and shrink on demand. As you’ll\\nlearn, Python keeps track of low-level memory details so you don’t have to.\\nProgramming-in-the-large support\\nFor building larger systems, Python includes tools such as modules, classes, and\\nexceptions. These tools allow you to organize systems into components, use OOP\\nto reuse and customize code, and handle events and errors gracefully.\\nBuilt-in object types\\nPython provides commonly used data structures such as lists, dictionaries, and\\nstrings as intrinsic parts of the language; as you’ll see, they’re both flexible and easy\\nto use. For instance, built-in objects can grow and shrink on demand, can be\\narbitrarily nested to represent complex information, and more.\\nBuilt-in tools\\nTo process all those object types, Python comes with powerful and standard op-\\nerations, including concatenation (joining collections), slicing (extracting sec-\\ntions), sorting, mapping, and more.\\nWhat Are Python’s Technical Strengths? | 15', metadata={'source': 'python.pdf', 'page': 65}),\n",
       " Document(page_content='Library utilities\\nFor more specific \\ntasks, Python also comes with a large collection of precoded\\nlibrary tools that support everything from regular expression matching to net-\\nworking. Once you learn the language itself, Python’s library tools are where much\\nof the application-level action occurs.\\nThird-party utilities\\nBecause Python is open source, developers are encouraged to contribute precoded\\ntools that support tasks beyond those supported by its built-ins; on the Web, you’ll\\nfind free support for COM, imaging, CORBA ORBs, XML, database access, and\\nmuch more.\\nDespite the array of tools in Python, it retains a remarkably simple syntax and design.\\nThe result is a powerful programming tool with all the usability of a scripting language.\\nIt’s Mixable\\nPython programs can easily be “glued” to components written in other languages in a\\nvariety of ways. For example, Python’s C API lets C programs call and be called by\\nPython programs flexibly. That means you can add functionality to the Python system\\nas needed, and use Python programs within other environments or systems.\\nMixing Python with libraries coded in languages such as C or C++, for instance, makes\\nit an easy-to-use frontend language and customization tool. As mentioned earlier, this\\nalso makes Python good at rapid prototyping; systems may be implemented in Python\\nfirst, to leverage its speed of development, and later moved to C for delivery, one piece\\nat a time, according to performance demands.\\nIt’s Easy to Use\\nTo run a Python program, you simply type it and run it. There are no intermediate\\ncompile and link steps, like there are for languages such as C or C++. Python executes\\nprograms immediately, which makes for an interactive programming experience and\\nrapid turnaround after program changes—in many cases, you can witness the effect of\\na program change as fast as you can type it.\\nOf course, development cycle turnaround is only one aspect of Python’s ease of use. It\\nalso provides a deliberately simple syntax and powerful built-in tools. In fact, some\\nhave gone so far as to call Python “executable pseudocode.” Because it eliminates much\\nof the complexity in other tools, Python programs are simpler, smaller, and more flex-\\nible than equivalent programs in languages like C, C++, and Java.\\n16 | Chapter 1: \\u2002A Python Q&A Session', metadata={'source': 'python.pdf', 'page': 66}),\n",
       " Document(page_content='It’s Easy to Learn\\nThis brings us \\nto a key point of this book: compared to other programming languages,\\nthe core Python language is remarkably easy to learn. In fact, you can expect to be\\ncoding significant Python programs in a matter of days (or perhaps in just hours, if\\nyou’re already an experienced programmer). That’s good news for professional devel-\\nopers seeking to learn the language to use on the job, as well as for end users of systems\\nthat expose a Python layer for customization or control.\\nToday, many systems rely on the fact that end users can quickly learn enough Python\\nto tailor their Python customizations’ code onsite, with little or no support. Although\\nPython does have advanced programming tools, its core language will still seem simple\\nto beginners and gurus alike.\\nIt’s Named After Monty Python\\nOK, this isn’t quite a technical strength, but it does seem to be a surprisingly well-kept\\nsecret that I wish to expose up front. Despite all the reptile icons in the Python world,\\nthe truth is that Python creator Guido van Rossum named it after the BBC comedy\\nseries Monty Python’s Flying Circus . He is a big fan of Monty Python, as are many\\nsoftware developers (indeed, there seems to almost be a symmetry between the two\\nfields).\\nThis legacy inevitably adds a humorous quality to Python code examples. For instance,\\nthe traditional “foo” and “bar” for generic variable names become “spam” and “eggs”\\nin the Python world. The occasional “Brian,” “ni,” and “shrubbery” likewise owe their\\nappearances to this namesake. It even impacts the Python community at large: talks at\\nPython conferences are regularly billed as “The Spanish Inquisition.”\\nAll of this is, of course, very funny if you are familiar with the show, but less so other-\\nwise. You don’t need to be familiar with the series to make sense of examples that\\nborrow references to Monty Python (including many you will see in this book), but at\\nleast you now know their root.\\nHow Does Python Stack Up to Language X?\\nFinally, to place it in the context of what you may already know, people sometimes\\ncompare Python to languages such as Perl, Tcl, and Java. We talked about performance\\nearlier, so here we’ll focus on functionality. While other languages are also useful tools\\nto know and use, many people find that Python:\\nHow Does Python Stack Up to Language X? | 17', metadata={'source': 'python.pdf', 'page': 67}),\n",
       " Document(page_content='• Is more powerful than Tcl. Python’s support for “programming in the large” makes\\nit applicable to the development of larger systems.\\n• Has \\na cleaner syntax and simpler design than Perl, which makes it more readable\\nand maintainable and helps reduce program bugs.\\n• Is simpler and easier to use than Java. Python is a scripting language, but Java\\ninherits much of the complexity and syntax of systems languages such as C++.\\n• Is simpler and easier to use than C++, but it doesn’t often compete with C++; as\\na scripting language, Python typically serves different roles.\\n• Is both more powerful and more cross-platform than Visual Basic. Its open source\\nnature also means it is not controlled by a single company.\\n• Is more readable and general-purpose than PHP. Python is sometimes used to\\nconstruct websites, but it’s also widely used in nearly every other computer do-\\nmain, from robotics to movie animation.\\n• Is more mature and has a more readable syntax than Ruby. Unlike Ruby and Java,\\nOOP is an option in Python—Python does not impose OOP on users or projects\\nto which it may not apply.\\n• Has the dynamic flavor of languages like SmallTalk and Lisp, but also has a simple,\\ntraditional syntax accessible to developers as well as end users of customizable\\nsystems.\\nEspecially for programs that do more than scan text files, and that might have to be\\nread in the future by others (or by you!), many people find that Python fits the bill better\\nthan any other scripting or programming language available today. Furthermore, unless\\nyour application requires peak performance, Python is often a viable alternative to\\nsystems development languages such as C, C++, and Java: Python code will be much\\nless difficult to write, debug, and maintain.\\nOf course, your author has been a card-carrying Python evangelist since 1992, so take\\nthese comments as you may. They do, however, reflect the common experience of many\\ndevelopers who have taken time to explore what Python has to offer.\\nChapter Summary\\nAnd that concludes the hype portion of this book. In this chapter, we’ve explored some\\nof the reasons that people pick Python for their programming tasks. We’ve also seen\\nhow it is applied and looked at a representative sample of who is using it today. My\\ngoal is to teach Python, though, not to sell it. The best way to judge a language is to\\nsee it in action, so the rest of this book focuses entirely on the language details we’ve\\nglossed over here.\\nThe next two chapters begin our technical introduction to the language. In them, we’ll\\nexplore ways to run Python programs, peek at Python’s byte code execution model,\\nand introduce the basics of module files for saving code. The goal will be to give you\\n18 | Chapter 1: \\u2002A Python Q&A Session', metadata={'source': 'python.pdf', 'page': 68}),\n",
       " Document(page_content='just enough information to run the examples and exercises in the rest of the book. You\\nwon’t really start \\nprogramming per se until Chapter 4, but make sure you have a handle\\non the startup details before moving on.\\nTest Your Knowledge: Quiz\\nIn this edition \\nof the book, we will be closing each chapter with a quick pop quiz about\\nthe material presented therein to help you review the key concepts. The answers for\\nthese quizzes appear immediately after the questions, and you are encouraged to read\\nthe answers once you’ve taken a crack at the questions yourself. In addition to these\\nend-of-chapter quizzes, you’ll find lab exercises at the end of each part of the book,\\ndesigned to help you start coding Python on your own. For now, here’s your first test.\\nGood luck!\\n1. What are the six main reasons that people choose to use Python?\\n2. Name four notable companies or organizations using Python today.\\n3. Why might you not want to use Python in an application?\\n4. What can you do with Python?\\n5. What’s the significance of the Python import this statement?\\n6. Why does “spam” show up in so many Python examples in books and on the Web?\\n7. What is your favorite color?\\nTest Your Knowledge: Answers\\nHow did you do? Here are the answers I came up with, though there may be multiple\\nsolutions to some quiz questions. Again, even if you’re sure you got a question right, I\\nencourage you to look at these answers for additional context. See the chapter’s text\\nfor more details if any of these responses don’t make sense to you.\\n1. Software quality, developer productivity, program portability, support libraries,\\ncomponent integration, and simple enjoyment. Of these, the quality and produc-\\ntivity themes seem to be the main reasons that people choose to use Python.\\n2. Google, Industrial Light & Magic, EVE Online, Jet Propulsion Labs, Maya, ESRI,\\nand many more. Almost every organization doing software development uses Py-\\nthon in some fashion, whether for long-term strategic product development or for\\nshort-term tactical tasks such as testing and system administration.\\n3. Python’s downside is performance: it won’t run as quickly as fully compiled\\nlanguages like C and C++. On the other hand, it’s quick enough for most appli-\\ncations, and typical Python code runs at close to C speed anyhow because it invokes\\nTest Your Knowledge: Answers | 19', metadata={'source': 'python.pdf', 'page': 69}),\n",
       " Document(page_content='linked-in C code in the interpreter. If speed is critical, compiled extensions are\\navailable for number-crunching parts of an application.\\n4. You \\ncan use Python for nearly anything you can do with a computer, from website\\ndevelopment and gaming to robotics and spacecraft control.\\n5.import this  triggers an Easter egg inside Python that displays some of the design\\nphilosophies underlying the language. You’ll learn how to run this statement in\\nthe next chapter.\\n6. “Spam” is a reference from a famous Monty Python skit in which people trying to\\norder food in a cafeteria are drowned out by a chorus of Vikings singing about\\nspam. Oh, and it’s also a common variable name in Python scripts....\\n7. Blue. No, yellow!\\nPython Is Engineering, Not Art\\nWhen Python first emerged \\non the software scene in the early 1990s, it spawned what\\nis now something of a classic conflict between its proponents and those of another\\npopular scripting language, Perl. Personally, I think the debate is tired and unwarranted\\ntoday—developers are smart enough to draw their own conclusions. Still, this is one\\nof the most common topics I’m asked about on the training road, so it seems fitting to\\nsay a few words about it here.\\nThe short story is this: you can do everything in Python that you can in Perl, but you can\\nread your code after you do it . That’s it—their domains largely overlap, but Python is\\nmore focused on producing readable code. For many, the enhanced readability of Py-\\nthon translates to better code reusability and maintainability, making Python a better\\nchoice for programs that will not be written once and thrown away. Perl code is easy\\nto write, but difficult to read. Given that most software has a lifespan much longer than\\nits initial creation, many see Python as a more effective tool.\\nThe somewhat longer story reflects the backgrounds of the designers of the two lan-\\nguages and underscores some of the main reasons people choose to use Python. Py-\\nthon’s creator is a mathematician by training; as such, he produced a language with a\\nhigh degree of uniformity—its syntax and toolset are remarkably coherent. Moreover,\\nlike math, Python’s design is orthogonal—most of the language follows from a small\\nset of core concepts. For instance, once one grasps Python’s flavor of polymorphism,\\nthe rest is largely just details.\\nBy contrast, the creator of the Perl language is a linguist, and its design reflects this\\nheritage. There are many ways to accomplish the same tasks in Perl, and language\\nconstructs interact in context-sensitive and sometimes quite subtle ways—much like\\nnatural language. As the well-known Perl motto states, “There’s more than one way to\\ndo it.” Given this design, both the Perl language and its user community have histori-\\ncally encouraged freedom of expression when writing code. One person’s Perl code can\\nbe radically different from another’s. In fact, writing unique, tricky code is often a\\nsource of pride among Perl users.\\n20 | Chapter 1: \\u2002A Python Q&A Session', metadata={'source': 'python.pdf', 'page': 70}),\n",
       " Document(page_content='But as anyone who has done any substantial code maintenance should be able to attest,\\nfreedom of expression \\nis great for art, but lousy for engineering . In engineering, we need\\na minimal feature set and predictability. In engineering, freedom of expression can lead\\nto maintenance nightmares. As more than one Perl user has confided to me, the result\\nof too much freedom is often code that is much easier to rewrite from scratch than to\\nmodify.\\nConsider this: when people create a painting or a sculpture, they do so for themselves\\nfor purely aesthetic purposes. The possibility of someone else having to change that\\npainting or sculpture later does not enter into it. This is a critical difference between\\nart and engineering. When people write software, they are not writing it for themselves.\\nIn fact, they are not even writing primarily for the computer. Rather, good programmers\\nknow that code is written for the next human being who has to read it in order to\\nmaintain or reuse it. If that person cannot understand the code, it’s all but useless in a\\nrealistic development scenario.\\nThis is where many people find that Python most clearly differentiates itself from\\nscripting languages like Perl. Because Python’s syntax model almost forces users to\\nwrite readable code, Python programs lend themselves more directly to the full software\\ndevelopment cycle. And because Python emphasizes ideas such as limited interactions,\\ncode uniformity and regularity, and feature consistency, it more directly fosters code\\nthat can be used long after it is first written.\\nIn the long run, Python’s focus on code quality in itself boosts programmer produc-\\ntivity, as well as programmer satisfaction. Python programmers can be creative, too, of\\ncourse, and as we’ll see, the language does offer multiple solutions for some tasks. At\\nits core, though, Python encourages good engineering in ways that other scripting lan-\\nguages often do not.\\nAt least, that’s the common consensus among many people who have adopted Python.\\nYou should always judge such claims for yourself, of course, by learning what Python\\nhas to offer. To help you get started, let’s move on to the next chapter.\\nTest Your Knowledge: Answers | 21', metadata={'source': 'python.pdf', 'page': 71}),\n",
       " Document(page_content='', metadata={'source': 'python.pdf', 'page': 72}),\n",
       " Document(page_content='CHAPTER 2\\nHow Python Runs Programs\\nThis chapter and the next take a quick look at program execution—how you launch\\ncode, and how \\nPython runs it. In this chapter, we’ll study the Python interpreter.\\nChapter 3 will then show you how to get your own programs up and running.\\nStartup details are inherently platform-specific, and some of the material in these two\\nchapters may not apply to the platform you work on, so you should feel free to skip\\nparts not relevant to your intended use. Likewise, more advanced readers who have\\nused similar tools in the past and prefer to get to the meat of the language quickly may\\nwant to file some of this chapter away as “for future reference.” For the rest of you, let’s\\nlearn how to run some code.\\nIntroducing the Python Interpreter\\nSo far, I’ve mostly been talking about Python as a programming language. But, as cur-\\nrently implemented, it’s also a software package called an interpreter. An interpreter is\\na kind of program that executes other programs. When you write a Python program,\\nthe Python interpreter reads your program and carries out the instructions it contains.\\nIn effect, the interpreter is a layer of software logic between your code and the computer\\nhardware on your machine.\\nWhen the Python package is installed on your machine, it generates a number of com-\\nponents—minimally, an interpreter and a support library. Depending on how you use\\nit, the Python interpreter may take the form of an executable program, or a set of\\nlibraries linked into another program. Depending on which flavor of Python you run,\\nthe interpreter itself may be implemented as a C program, a set of Java classes, or\\nsomething else. Whatever form it takes, the Python code you write must always be run\\nby this interpreter. And to enable that, you must install a Python interpreter on your\\ncomputer.\\nPython installation details vary by platform and are covered in more depth in Appen-\\ndix A. In short:\\n23', metadata={'source': 'python.pdf', 'page': 73}),\n",
       " Document(page_content=\"• Windows users fetch and run a self-installing executable file that puts Python on\\ntheir machines. Simply double-click and say Yes or Next at all prompts.\\n• Linux and Mac OS X users probably already have a usable Python preinstalled on\\ntheir computers—it’s a standard component on these platforms today.\\n• Some Linux and Mac OS X users (and most Unix users) compile Python from its\\nfull source code distribution package.\\n• Linux users can also find RPM files, and Mac OS X users can find various Mac-\\nspecific installation packages.\\n• Other platforms have installation techniques relevant to those platforms. For\\ninstance, Python is available on cell phones, game consoles, and iPods, but instal-\\nlation details vary widely.\\nPython itself may be fetched from the downloads page on the website, http://www\\n.python.org. It may also be found through various other distribution channels. Keep in\\nmind that you should always check to see whether Python is already present before\\ninstalling it. If you’re working on Windows, you’ll usually find Python in the Start\\nmenu, as captured in Figure 2-1  (these menu options are discussed in the next chapter).\\nOn Unix and Linux, Python probably lives in your /usr directory tree.\\nBecause installation details are so platform-specific, we’ll finesse the rest of this story\\nhere. For more details on the installation process, consult Appendix A. For the purposes\\nof this chapter and the next, I’ll assume that you’ve got Python ready to go.\\nProgram Execution\\nWhat it means to write and run a Python script depends on whether you look at these\\ntasks as a programmer, or as a Python interpreter. Both views offer important perspec-\\ntives on Python programming.\\nThe Programmer’s View\\nIn its simplest form, a Python program is just a text file containing Python statements.\\nFor example, the following file, named script0.py, is one of the simplest Python scripts\\nI could dream up, but it passes for a fully functional Python program:\\nprint('hello world')\\nprint(2 ** 100)\\nThis file contains two Python print statements, which simply print a string (the text in\\nquotes) and a numeric expression result (2 to the power 100) to the output stream.\\nDon’t worry about the syntax of this code yet—for this chapter, we’re interested only\\nin getting it to run. I’ll explain the print statement, and why you can raise 2 to the\\npower 100 in Python without overflowing, in the next parts of this book.\\n24 | Chapter 2: \\u2002How Python Runs Programs\", metadata={'source': 'python.pdf', 'page': 74}),\n",
       " Document(page_content='You can create such a file of statements with any text editor you like. By convention,\\nPython program files \\nare given names that end in .py; technically, this naming scheme\\nis required only for files that are “imported,” as shown later in this book, but most\\nPython files have .py names for consistency.\\nAfter you’ve typed these statements into a text file, you must tell Python to execute the\\nfile—which simply means to run all the statements in the file from top to bottom, one\\nafter another. As you’ll see in the next chapter, you can launch Python program files\\nFigure 2-1. When installed on Windows, this is how Python shows up in your Start button menu. This\\ncan vary a \\nbit from release to release, but IDLE starts a development GUI, and Python starts a simple\\ninteractive session. Also here are the standard manuals and the PyDoc documentation engine (Module\\nDocs).\\nProgram Execution | 25', metadata={'source': 'python.pdf', 'page': 75}),\n",
       " Document(page_content='by shell command lines, by clicking their icons, from within IDEs, and with other\\nstandard techniques. If \\nall goes well, when you execute the file, you’ll see the results of\\nthe two print statements show up somewhere on your computer—by default, usually\\nin the same window you were in when you ran the program:\\nhello world\\n1267650600228229401496703205376\\nFor example, here’s what happened when I ran this script from a DOS command line\\non a Windows laptop (typically called a Command Prompt window, found in the Ac-\\ncessories program menu), to make sure it didn’t have any silly typos:\\nC:\\\\temp> python script0.py\\nhello world\\n1267650600228229401496703205376\\nWe’ve just run a Python script that prints a string and a number. We probably won’t\\nwin any programming awards with this code, but it’s enough to capture the basics of\\nprogram execution.\\nPython’s View\\nThe brief description in the prior section is fairly standard for scripting languages, and\\nit’s usually all that most Python programmers need to know. You type code into text\\nfiles, and you run those files through the interpreter. Under the hood, though, a bit\\nmore happens when you tell Python to “go.” Although knowledge of Python internals\\nis not strictly required for Python programming, a basic understanding of the runtime\\nstructure of Python can help you grasp the bigger picture of program execution.\\nWhen you instruct Python to run your script, there are a few steps that Python carries\\nout before your code actually starts crunching away. Specifically, it’s first compiled to\\nsomething called “byte code” and then routed to something called a “virtual machine.”\\nByte code compilation\\nInternally, and almost completely hidden from you, when you execute a program\\nPython first compiles your source code  (the statements in your file) into a format known\\nas byte code. Compilation is simply a translation step, and byte code is a lower-level,\\nplatform-independent representation of your source code. Roughly, Python translates\\neach of your source statements into a group of byte code instructions by decomposing\\nthem into individual steps. This byte code translation is performed to speed\\nexecution—byte code can be run much more quickly than the original source code\\nstatements in your text file.\\nYou’ll notice that the prior paragraph said that this is almost completely hidden from\\nyou. If the Python process has write access on your machine, it will store the byte code\\nof your programs in files that end with a .pyc extension (“.pyc” means compiled “.py”\\nsource). You will see these files show up on your computer after you’ve run a few\\n26 | Chapter 2: \\u2002How Python Runs Programs', metadata={'source': 'python.pdf', 'page': 76}),\n",
       " Document(page_content='programs alongside the corresponding source code files (that is, in the same\\ndirectories).\\nPython saves byte \\ncode like this as a startup speed optimization. The next time you run\\nyour program, Python will load the .pyc files and skip the compilation step, as long as\\nyou haven’t changed your source code since the byte code was last saved. Python au-\\ntomatically checks the timestamps of source and byte code files to know when it must\\nrecompile—if you resave your source code, byte code is automatically re-created the\\nnext time your program is run.\\nIf Python cannot write the byte code files to your machine, your program still works—\\nthe byte code is generated in memory and simply discarded on program exit.* However,\\nbecause .pyc files speed startup time, you’ll want to make sure they are written for larger\\nprograms. Byte code files are also one way to ship Python programs—Python is happy\\nto run a program if all it can find are .pyc files, even if the original .py source files are\\nabsent. (See “Frozen Binaries” on page 32 for another shipping option.)\\nThe Python Virtual Machine (PVM)\\nOnce your program has been compiled to byte code (or the byte code has been loaded\\nfrom existing .pyc files), it is shipped off for execution to something generally known\\nas the Python Virtual Machine (PVM, for the more acronym-inclined among you). The\\nPVM sounds more impressive than it is; really, it’s not a separate program, and it need\\nnot be installed by itself. In fact, the PVM is just a big loop that iterates through your\\nbyte code instructions, one by one, to carry out their operations. The PVM is the run-\\ntime engine of Python; it’s always present as part of the Python system, and it’s the\\ncomponent that truly runs your scripts. Technically, it’s just the last step of what is\\ncalled the “Python interpreter.”\\nFigure 2-2 illustrates the runtime structure described here. Keep in mind that all of this\\ncomplexity is deliberately hidden from Python programmers. Byte code compilation is\\nautomatic, and the PVM is just part of the Python system that you have installed on\\nyour machine. Again, programmers simply code and run files of statements.\\nPerformance implications\\nReaders with a background in fully compiled languages such as C and C++ might notice\\na few differences in the Python model. For one thing, there is usually no build or “make”\\nstep in Python work: code runs immediately after it is written. For another, Python byte\\ncode is not binary machine code (e.g., instructions for an Intel chip). Byte code is a\\nPython-specific representation.\\n* And, strictly speaking, byte code is saved only for files that are imported, not for the top-level file of a program.\\nWe’ll explore imports in Chapter 3 , and again in Part V . Byte \\ncode is also never saved for code typed at the\\ninteractive prompt, which is described in Chapter 3.\\nProgram Execution | 27', metadata={'source': 'python.pdf', 'page': 77}),\n",
       " Document(page_content='This is why some Python code may not run as fast as C or C++ code, as described in\\nChapter 1 —the \\nPVM loop, not the CPU chip, still must interpret the byte code, and\\nbyte code instructions require more work than CPU instructions. On the other hand,\\nunlike in classic interpreters, there is still an internal compile step—Python does not\\nneed to reanalyze and reparse each source statement repeatedly. The net effect is that\\npure Python code runs at speeds somewhere between those of a traditional compiled\\nlanguage and a traditional interpreted language. See Chapter 1 for more on Python\\nperformance tradeoffs.\\nDevelopment implications\\nAnother ramification of Python’s execution model is that there is really no distinction\\nbetween the development and execution environments. That is, the systems that com-\\npile and execute your source code are really one and the same. This similarity may have\\na bit more significance to readers with a background in traditional compiled languages,\\nbut in Python, the compiler is always present at runtime and is part of the system that\\nruns programs.\\nThis makes for a much more rapid development cycle. There is no need to precompile\\nand link before execution may begin; simply type and run the code. This also adds a\\nmuch more dynamic flavor to the language—it is possible, and often very convenient,\\nfor Python programs to construct and execute other Python programs at runtime. The\\neval and exec built-ins, for instance, accept and run strings containing Python program\\ncode. This structure is also why Python lends itself to product customization—because\\nPython code can be changed on the fly, users can modify the Python parts of a system\\nonsite without needing to have or compile the entire system’s code.\\nAt a more fundamental level, keep in mind that all we really have in Python is runtime—\\nthere is no initial compile-time phase at all, and everything happens as the program is\\nrunning. This even includes operations such as the creation of functions and classes\\nand the linkage of modules. Such events occur before execution in more static lan-\\nguages, but happen as programs execute in Python. As we’ll see, the net effect makes\\nfor a much more dynamic programming experience than that to which some readers\\nmay be accustomed.\\nFigure 2-2. Python’s traditional runtime execution model: source code you type is translated to byte\\ncode, which is \\nthen run by the Python Virtual Machine. Your code is automatically compiled, but then\\nit is interpreted.\\n28 | Chapter 2: \\u2002How Python Runs Programs', metadata={'source': 'python.pdf', 'page': 78}),\n",
       " Document(page_content='Execution Model Variations\\nBefore moving on, \\nI should point out that the internal execution flow described in the\\nprior section reflects the standard implementation of Python today but is not really a\\nrequirement of the Python language itself. Because of that, the execution model is prone\\nto changing with time. In fact, there are already a few systems that modify the picture\\nin Figure 2-2  somewhat. Let’s take a few moments to explore the most prominent of\\nthese variations.\\nPython Implementation Alternatives\\nReally, as this book is being written, there are three primary implementations of the\\nPython language— CPython, Jython, and IronPython—along with a handful of secon-\\ndary implementations such as Stackless Python . In brief, CPython is the standard im-\\nplementation; all the others have very specific purposes and roles. All implement the\\nsame Python language but execute programs in different ways.\\nCPython\\nThe original, and standard, implementation of Python is usually called CPython, when\\nyou want to contrast it with the other two. Its name comes from the fact that it is coded\\nin portable ANSI C language code. This is the Python that you fetch from http://www\\n.python.org, get with the ActivePython distribution, and have automatically on most\\nLinux and Mac OS X machines. If you’ve found a preinstalled version of Python on\\nyour machine, it’s probably CPython, unless your company is using Python in very\\nspecialized ways.\\nUnless you want to script Java or .NET applications with Python, you probably want\\nto use the standard CPython system. Because it is the reference implementation of the\\nlanguage, it tends to run the fastest, be the most complete, and be more robust than\\nthe alternative systems. Figure 2-2 reflects CPython’s runtime architecture.\\nJython\\nThe Jython system (originally known as JPython) is an alternative implementation of\\nthe Python language, targeted for integration with the Java programming language.\\nJython consists of Java classes that compile Python source code to Java byte code and\\nthen route the resulting byte code to the Java Virtual Machine (JVM). Programmers\\nstill code Python statements in .py text files as usual; the Jython system essentially just\\nreplaces the rightmost two bubbles in Figure 2-2 with Java-based equivalents.\\nJython’s goal is to allow Python code to script Java applications, much as CPython\\nallows Python to script C and C++ components. Its integration with Java is remarkably\\nseamless. Because Python code is translated to Java byte code, it looks and feels like a\\ntrue Java program at runtime. Jython scripts can serve as web applets and servlets, build\\nJava-based GUIs, and so on. Moreover, Jython includes integration support that allows\\nExecution Model Variations | 29', metadata={'source': 'python.pdf', 'page': 79}),\n",
       " Document(page_content='Python code to import and use Java classes as though they were coded in Python.\\nBecause Jython is \\nslower and less robust than CPython, though, it is usually seen as a\\ntool of interest primarily to Java developers looking for a scripting language to be a\\nfrontend to Java code.\\nIronPython\\nA third implementation of Python, and newer than both CPython and Jython,\\nIronPython is designed to allow Python programs to integrate with applications coded\\nto work with Microsoft’s .NET Framework for Windows, as well as the Mono open\\nsource equivalent for Linux. .NET and its C# programming language runtime system\\nare designed to be a language-neutral object communication layer, in the spirit of Mi-\\ncrosoft’s earlier COM model. IronPython allows Python programs to act as both client\\nand server components, accessible from other .NET languages.\\nBy implementation, IronPython is very much like Jython (and, in fact, was developed\\nby the same creator)—it replaces the last two bubbles in Figure 2-2 with equivalents\\nfor execution in the .NET environment. Also, like Jython, IronPython has a special\\nfocus—it is primarily of interest to developers integrating Python with .NET compo-\\nnents. Because it is being developed by Microsoft, though, IronPython might also be\\nable to leverage some important optimization tools for better performance.\\nIronPython’s scope is still evolving as I write this; for more details, consult the Python\\nonline resources or search the Web.†\\nExecution Optimization Tools\\nCPython, Jython, and IronPython all implement the Python language in similar ways:\\nby compiling source code to byte code and executing the byte code on an appropriate\\nvirtual machine. Still other systems, including the Psyco just-in-time compiler and the\\nShedskin C++ translator, instead attempt to optimize the basic execution model. These\\nsystems are not required knowledge at this point in your Python career, but a quick\\nlook at their place in the execution model might help demystify the model in general.\\nThe Psyco just-in-time compiler\\nThe Psyco system is not another Python implementation, but rather a component that\\nextends the byte code execution model to make programs run faster. In terms of\\nFigure 2-2, Psyco is an enhancement to the PVM that collects and uses type information\\nwhile the program runs to translate portions of the program’s byte code all the way\\ndown to real binary machine code for faster execution. Psyco accomplishes this\\n† Jython and IronPython are completely independent implementations of Python that compile Python source\\nfor different \\nruntime architectures. It is also possible to access Java and .NET software from standard CPython\\nprograms: JPype and Python for .NET systems, for example, allow CPython code to call out to Java and .NET\\ncomponents.\\n30 | Chapter 2: \\u2002How Python Runs Programs', metadata={'source': 'python.pdf', 'page': 80}),\n",
       " Document(page_content='translation without requiring changes to the code or a separate compilation step during\\ndevelopment.\\nRoughly, while \\nyour program runs, Psyco collects information about the kinds of ob-\\njects being passed around; that information can be used to generate highly efficient\\nmachine code tailored for those object types. Once generated, the machine code then\\nreplaces the corresponding part of the original byte code to speed your program’s over-\\nall execution. The net effect is that, with Psyco, your program becomes much quicker\\nover time and as it is running. In ideal cases, some Python code may become as fast as\\ncompiled C code under Psyco.\\nBecause this translation from byte code happens at program runtime, Psyco is generally\\nknown as a just-in-time (JIT) compiler. Psyco is actually a bit different from the JIT\\ncompilers some readers may have seen for the Java language, though. Really, Psyco is\\na specializing JIT compiler—it generates machine code tailored to the data types that\\nyour program actually uses. For example, if a part of your program uses different data\\ntypes at different times, Psyco may generate a different version of machine code to\\nsupport each different type combination.\\nPsyco has been shown to speed Python code dramatically. According to its web page,\\nPsyco provides “2x to 100x speed-ups, typically 4x, with an unmodified Python inter-\\npreter and unmodified source code, just a dynamically loadable C extension module.”\\nOf equal significance, the largest speedups are realized for algorithmic code written in\\npure Python—exactly the sort of code you might normally migrate to C to optimize.\\nWith Psyco, such migrations become even less important.\\nPsyco is not yet a standard part of Python; you will have to fetch and install it separately.\\nIt is also still something of a research project, so you’ll have to track its evolution online.\\nIn fact, at this writing, although Psyco can still be fetched and installed by itself, it\\nappears that much of the system may eventually be absorbed into the newer “PyPy”\\nproject—an attempt to reimplement Python’s PVM in Python code, to better support\\noptimizations like Psyco.\\nPerhaps the largest downside of Psyco is that it currently only generates machine code\\nfor Intel x86 architecture chips, though this includes Windows and Linux boxes and\\nrecent Macs. For more details on the Psyco extension, and other JIT efforts that may\\narise, consult http://www.python.org; you can also check out Psyco’s home page, which\\ncurrently resides at http://psyco.sourceforge.net.\\nThe Shedskin C++ translator\\nShedskin is an emerging system that takes a different approach to Python program\\nexecution—it attempts to translate Python source code to C++ code, which your com-\\nputer’s C++ compiler then compiles to machine code. As such, it represents a platform-\\nneutral approach to running Python code. Shedskin is still somewhat experimental as\\nI write these words, and it limits Python programs to an implicit statically typed con-\\nstraint that is technically not normal Python, so we won’t go into further detail here.\\nExecution Model Variations | 31', metadata={'source': 'python.pdf', 'page': 81}),\n",
       " Document(page_content='Initial results, though, show that it has the potential to outperform both standard Py-\\nthon and the \\nPsyco extension in terms of execution speed, and it is a promising project.\\nSearch the Web for details on the project’s current status.\\nFrozen Binaries\\nSometimes when people ask for a “real” Python compiler, what they’re really seeking\\nis simply a way to generate standalone binary executables from their Python programs.\\nThis is more a packaging and shipping idea than an execution-flow concept, but it’s\\nsomewhat related. With the help of third-party tools that you can fetch off the Web, it\\nis possible to turn your Python programs into true executables, known as frozen bi-\\nnaries in the Python world.\\nFrozen binaries bundle together the byte code of your program files, along with the\\nPVM (interpreter) and any Python support files your program needs, into a single\\npackage. There are some variations on this theme, but the end result can be a single\\nbinary executable program (e.g., an .exe file on Windows) that can easily be shipped\\nto customers. In Figure 2-2 , it is as though the byte code and PVM are merged into a\\nsingle component—a frozen binary file.\\nToday, three primary systems are capable of generating frozen binaries: py2exe (for\\nWindows), PyInstaller (which is similar to py2exe but also works on Linux and Unix\\nand is capable of generating self-installing binaries), and freeze (the original). You may\\nhave to fetch these tools separately from Python itself, but they are available free of\\ncharge. They are also constantly evolving, so consult http://www.python.org or your\\nfavorite web search engine for more on these tools. To give you an idea of the scope of\\nthese systems, py2exe can freeze standalone programs that use the tkinter, PMW,\\nwxPython, and PyGTK GUI libraries; programs that use the pygame game program-\\nming toolkit; win32com client programs; and more.\\nFrozen binaries are not the same as the output of a true compiler—they run byte code\\nthrough a virtual machine. Hence, apart from a possible startup improvement, frozen\\nbinaries run at the same speed as the original source files. Frozen binaries are not small\\n(they contain a PVM), but by current standards they are not unusually large either.\\nBecause Python is embedded in the frozen binary, though, it does not have to be in-\\nstalled on the receiving end to run your program. Moreover, because your code is em-\\nbedded in the frozen binary, it is more effectively hidden from recipients.\\nThis single file-packaging scheme is especially appealing to developers of commercial\\nsoftware. For instance, a Python-coded user interface program based on the tkinter\\ntoolkit can be frozen into an executable file and shipped as a self-contained program\\non a CD or on the Web. End users do not need to install (or even have to know about)\\nPython to run the shipped program.\\n32 | Chapter 2: \\u2002How Python Runs Programs', metadata={'source': 'python.pdf', 'page': 82}),\n",
       " Document(page_content='Other Execution Options\\nStill other schemes for running Python programs have more focused goals:\\n• The Stackless Python  system \\nis a standard CPython implementation variant that\\ndoes not save state on the C language call stack. This makes Python more easy to\\nport to small stack architectures, provides efficient multiprocessing options, and\\nfosters novel programming structures such as coroutines.\\n• The Cython system (based on work done by the Pyrex project) is a hybrid language\\nthat combines Python code with the ability to call C functions and use C type\\ndeclarations for variables, parameters, and class attributes. Cython code can be\\ncompiled to C code that uses the Python/C API, which may then be compiled\\ncompletely. Though not completely compatible with standard Python, Cython can\\nbe useful both for wrapping external C libraries and for coding efficient C exten-\\nsions for Python.\\nFor more details on these systems, search the Web for recent links.\\nFuture Possibilities?\\nFinally, note that the runtime execution model sketched here is really an artifact of the\\ncurrent implementation of Python, not of the language itself. For instance, it’s not\\nimpossible that a full, traditional compiler for translating Python source code to ma-\\nchine code may appear during the shelf life of this book (although one has not in nearly\\ntwo decades!). New byte code formats and implementation variants may also be adop-\\nted in the future. For instance:\\n• The Parrot project aims to provide a common byte code format, virtual machine,\\nand optimization techniques for a variety of programming languages (see http://\\nwww.python.org). Python’s own PVM runs Python code more efficiently than Par-\\nrot, but it’s unclear how Parrot will evolve.\\n• The PyPy project is an attempt to reimplement the PVM in Python itself to enable\\nnew implementation techniques. Its goal is to produce a fast and flexible imple-\\nmentation of Python.\\n• The Google-sponsored Unladen Swallow  project aims to make standard Python\\nfaster by a factor of at least 5, and fast enough to replace the C language in many\\ncontexts. It is an optimization branch of CPython, intended to be fully compatible\\nand significantly faster. This project also hopes to remove the Python multithread-\\ning Global Interpreter Lock (GIL), which prevents pure Python threads from truly\\noverlapping in time. This is currently an emerging project being developed as open\\nsource by Google engineers; it is initially targeting Python 2.6, though 3.0 may\\nacquire its changes too. Search Google for up-to-date details.\\nAlthough such future implementation schemes may alter the runtime structure of Py-\\nthon somewhat, it seems likely that the byte code compiler will still be the standard for\\nExecution Model Variations | 33', metadata={'source': 'python.pdf', 'page': 83}),\n",
       " Document(page_content='some time to come. The portability and runtime flexibility of byte code are important\\nfeatures of many \\nPython systems. Moreover, adding type constraint declarations to\\nsupport static compilation would break the flexibility, conciseness, simplicity, and\\noverall spirit of Python coding. Due to Python’s highly dynamic nature, any future\\nimplementation will likely retain many artifacts of the current PVM.\\nChapter Summary\\nThis chapter introduced the execution model of Python (how Python runs your pro-\\ngrams) and explored some common variations on that model (just-in-time compilers\\nand the like). Although you don’t really need to come to grips with Python internals to\\nwrite Python scripts, a passing acquaintance with this chapter’s topics will help you\\ntruly understand how your programs run once you start coding them. In the next\\nchapter, you’ll start actually running some code of your own. First, though, here’s the\\nusual chapter quiz.\\nTest Your Knowledge: Quiz\\n1. What is the Python interpreter?\\n2. What is source code?\\n3.\\nWhat is byte code?\\n4. What is the PVM?\\n5. Name two variations on Python’s standard execution model.\\n6. How are CPython, Jython, and IronPython different?\\nTest Your Knowledge: Answers\\n1. The Python interpreter is a program that runs the Python programs you write.\\n2. Source code is the statements you write for your program—it consists of text in\\ntext files that normally end with a .py extension.\\n3. Byte code is the lower-level form of your program after Python compiles it. Python\\nautomatically stores byte code in files with a .pyc extension.\\n4. The PVM is the Python Virtual Machine—the runtime engine of Python that in-\\nterprets your compiled byte code.\\n5. Psyco, Shedskin, and frozen binaries are all variations on the execution model.\\n6. CPython is the standard implementation of the language. Jython and IronPython\\nimplement Python programs for use in Java and .NET environments, respectively;\\nthey are alternative compilers for Python.\\n34 | Chapter 2: \\u2002How Python Runs Programs', metadata={'source': 'python.pdf', 'page': 84}),\n",
       " Document(page_content='CHAPTER 3\\nHow You Run Programs\\nOK, it’s time to start running some code. Now that you have a handle on program\\nexecution, you’re finally \\nready to start some real Python programming. At this point,\\nI’ll assume that you have Python installed on your computer; if not, see the prior chapter\\nand Appendix A for installation and configuration hints.\\nThere are a variety of ways to tell Python to execute the code you type. This chapter\\ndiscusses all the program launching techniques in common use today. Along the way,\\nyou’ll learn how to type code interactively and how to save it in files to be run with\\nsystem command lines, icon clicks, module imports and reloads, exec calls, menu op-\\ntions in GUIs such as IDLE, and more.\\nIf you just want to find out how to run a Python program quickly, you may be tempted\\nto read the parts of this chapter that pertain only to your platform and move on to\\nChapter 4. But don’t skip the material on module imports, as that’s essential to un-\\nderstanding Python’s program architecture. I also encourage you to at least skim the\\nsections on IDLE and other IDEs, so you’ll know what tools are available for when you\\nstart developing more sophisticated Python programs.\\nThe Interactive Prompt\\nPerhaps the simplest way to run Python programs is to type them at Python’s interactive \\ncommand line, sometimes called the interactive prompt . There are a variety of ways to\\nstart this command line: in an IDE, from a system console, and so on. Assuming the\\ninterpreter is installed as an executable program on your system, the most platform-\\nneutral way to start an interactive interpreter session is usually just to type python at\\nyour operating system’s prompt, without any arguments. For example:\\n35', metadata={'source': 'python.pdf', 'page': 85}),\n",
       " Document(page_content='% python\\nPython 3.0.1 (r301:69561, Feb 13 2009, 20:04:18) [MSC v.1500 32 bit (Intel)] ...\\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\\n>>>\\nTyping the word \\n“python” at your system shell prompt like this begins an interactive\\nPython session; the “%” character at the start of this listing stands for a generic system\\nprompt in this book—it’s not input that you type yourself. The notion of a system shell\\nprompt is generic, but exactly how you access it varies by platform:\\n• On Windows, you can type python in a DOS console window (a.k.a. the Command\\nPrompt, usually found in the Accessories section of the Start →Programs menu) or\\nin the Start→Run... dialog box.\\n• On Unix, Linux, and Mac OS X, you might type this command in a shell or terminal\\nwindow (e.g., in an xterm or console running a shell such as ksh or csh).\\n• Other systems may use similar or platform-specific devices. On handheld devices,\\nfor example, you generally click the Python icon in the home or application window\\nto launch an interactive session.\\nIf you have not set your shell’s PATH environment variable to include Python’s install\\ndirectory, you may need to replace the word “python” with the full path to the Python\\nexecutable on your machine. On Unix, Linux, and similar, /usr/local/bin/python\\nor /usr/bin/python will often suffice. On Windows, try typing C:\\\\Python30\\\\python (for\\nversion 3.0):\\nC:\\\\misc> c:\\\\python30\\\\python\\nPython 3.0.1 (r301:69561, Feb 13 2009, 20:04:18) [MSC v.1500 32 bit (Intel)] ...\\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\\n>>>\\nAlternatively, you can run a change-directory command to go to Python’s install di-\\nrectory before typing “python”—try the cd c:\\\\python30 command on Windows, for\\nexample:\\nC:\\\\misc> cd C:\\\\Python30\\nC:\\\\Python30> python\\nPython 3.0.1 (r301:69561, Feb 13 2009, 20:04:18) [MSC v.1500 32 bit (Intel)] ...\\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\\n>>>\\nOn Windows, besides typing python in a shell window, you can also begin similar\\ninteractive sessions by starting IDLE’s main window (discussed later) or by selecting\\nthe “Python (command line)” menu option from the Start button menu for Python, as\\nshown in Figure 2-1  back in Chapter 2 . Both spawn a Python interactive prompt with\\nequivalent functionality; typing a shell command isn’t necessary.\\n36 | Chapter 3: \\u2002How You Run Programs', metadata={'source': 'python.pdf', 'page': 86}),\n",
       " Document(page_content=\"Running Code Interactively\\nHowever it’s started, \\nthe Python interactive session begins by printing two lines of\\ninformational text (which I’ll omit from most of this book’s examples to save space),\\nthen prompts for input with >>> when it’s waiting for you to type a new Python state-\\nment or expression. When working interactively, the results of your code are displayed\\nafter the >>> lines after you press the Enter key.\\nFor instance, here are the results of two Python print statements ( print is really a\\nfunction call in Python 3.0, but not in 2.6, so the parentheses here are required in 3.0\\nonly):\\n% python\\n>>> print('Hello world!')\\nHello world!\\n>>> print(2 ** 8)\\n256\\nAgain, you don’t need to worry about the details of the print statements shown here\\nyet; we’ll start digging into syntax in the next chapter. In short, they print a Python\\nstring and an integer, as shown by the output lines that appear after each >>> input line\\n(2 ** 8 means 2 raised to the power 8 in Python).\\nWhen coding interactively like this, you can type as many Python commands as you\\nlike; each is run immediately after it’s entered. Moreover, because the interactive ses-\\nsion automatically prints the results of expressions you type, you don’t usually need to\\nsay “print” explicitly at this prompt:\\n>>> lumberjack = 'okay'\\n>>> lumberjack\\n'okay'\\n>>> 2 ** 8\\n256\\n>>>                        <== Use Ctrl-D (on Unix) or Ctrl-Z (on Windows) to exit\\n%\\nHere, the fist line saves a value by assigning it to a variable, and the last two lines typed\\nare expressions ( lumberjack and 2 ** 8)—their results are displayed automatically. To\\nexit an interactive session like this one and return to your system shell prompt, type\\nCtrl-D on Unix-like machines; on MS-DOS and Windows systems, type Ctrl-Z to exit.\\nIn the IDLE GUI discussed later, either type Ctrl-D or simply close the window.\\nNow, we didn’t do much in this session’s code—just typed some Python print and\\nassignment statements, along with a few expressions, which we’ll study in detail later.\\nThe main thing to notice is that the interpreter executes the code entered on each line\\nimmediately, when the Enter key is pressed.\\nThe Interactive Prompt | 37\", metadata={'source': 'python.pdf', 'page': 87}),\n",
       " Document(page_content=\"For example, when we typed the first print statement at the >>> prompt, the output (a\\nPython string) was echoed back right away. There was no need to create a source-code\\nfile, and no need to run the code through a compiler and linker first, as you’d normally\\ndo when using a language such as C or C++. As you’ll see in later chapters, you can\\nalso run multiline statements at the interactive prompt; such a statement runs imme-\\ndiately after you’ve entered all of its lines and pressed Enter twice to add a blank line.\\nWhy the Interactive Prompt?\\nThe interactive prompt runs code and echoes results as you go, but it doesn’t save your\\ncode in a file. Although this means you won’t do the bulk of your coding in interactive\\nsessions, the interactive prompt turns out to be a great place to both experiment with\\nthe language and test program files on the fly.\\nExperimenting\\nBecause code is executed immediately, the interactive prompt is a perfect place to ex-\\nperiment with the language and will be used often in this book to demonstrate smaller\\nexamples. In fact, this is the first rule of thumb to remember: if you’re ever in doubt\\nabout how a piece of Python code works, fire up the interactive command line and try\\nit out to see what happens.\\nFor instance, suppose you’re reading a Python program’s code and you come across\\nan expression like 'Spam!' * 8 whose meaning you don’t understand. At this point,\\nyou can spend 10 minutes wading through manuals and books to try to figure out what\\nthe code does, or you can simply run it interactively:\\n>>> 'Spam!' * 8                                  <== Learning by trying\\n'Spam!Spam!Spam!Spam!Spam!Spam!Spam!Spam!'\\nThe immediate feedback you receive at the interactive prompt is often the quickest way\\nto deduce what a piece of code does. Here, it’s clear that it does string repetition: in\\nPython * means multiply for numbers, but repeat for strings—it’s like concatenating a\\nstring to itself repeatedly (more on strings in Chapter 4).\\nChances are good that you won’t break anything by experimenting this way—at least,\\nnot yet. To do real damage, like deleting files and running shell commands, you must\\nreally try, by importing modules explicitly (you also need to know more about Python’s\\nsystem interfaces in general before you will become that dangerous!). Straight Python\\ncode is almost always safe to run.\\nFor instance, watch what happens when you make a mistake at the interactive prompt:\\n38 | Chapter 3: \\u2002How You Run Programs\", metadata={'source': 'python.pdf', 'page': 88}),\n",
       " Document(page_content='>>> X                                            <== Making mistakes\\nTraceback (most recent call last):\\n  File \"<stdin>\", line 1, in <module>\\nNameError: name \\'X\\' is not defined\\nIn Python, using \\na variable before it has been assigned a value is always an error (oth-\\nerwise, if names were filled in with defaults, some errors might go undetected). We’ll\\nlearn more about that later; the important point here is that you don’t crash Python or\\nyour computer when you make a mistake this way. Instead, you get a meaningful error\\nmessage pointing out the mistake and the line of code that made it, and you can con-\\ntinue on in your session or script. In fact, once you get comfortable with Python, its\\nerror messages may often provide as much debugging support as you’ll need (you’ll\\nread more on debugging in the sidebar “Debugging Python Code” on page 67).\\nTesting\\nBesides serving as a tool for experimenting while you’re learning the language, the\\ninteractive interpreter is also an ideal place to test code you’ve written in files. You can\\nimport your module files interactively and run tests on the tools they define by typing\\ncalls at the interactive prompt.\\nFor instance, of the following tests a function in a precoded module that ships with\\nPython in its standard library (it prints the name of the directory you’re currently\\nworking in), but you can do the same once you start writing module files of your own:\\n>>> import os\\n>>> os.getcwd()                                  <== Testing on the fly\\n\\'c:\\\\\\\\Python30\\'\\nMore generally, the interactive prompt is a place to test program components, regard-\\nless of their source—you can import and test functions and classes in your Python files,\\ntype calls to linked-in C functions, exercise Java classes under Jython, and more. Partly\\nbecause of its interactive nature, Python supports an experimental and exploratory\\nprogramming style you’ll find convenient when getting started.\\nUsing the Interactive Prompt\\nAlthough the interactive prompt is simple to use, there are a few tips that beginners\\nshould keep in mind. I’m including lists of common mistakes like this in this chapter\\nfor reference, but they might also spare you from a few headaches if you read them up\\nfront:\\n•Type Python commands only . First of all, remember that you can only type Py-\\nthon code at the Python prompt, not system commands. There are ways to run\\nsystem commands from within Python code (e.g., with os.system), but they are\\nnot as direct as simply typing the commands themselves.\\nThe Interactive Prompt | 39', metadata={'source': 'python.pdf', 'page': 89}),\n",
       " Document(page_content='•print statements are required only in files . Because the interactive interpreter\\nautomatically prints the results of expressions, you do not need to type complete\\nprint statements interactively. This is a nice feature, but it tends to confuse users\\nwhen they move on to writing code in files: within a code file, you must use\\nprint statements to see your output because expression results are not automati-\\ncally echoed. Remember, you must say print in files, but not interactively.\\n•Don’t indent at the interactive prompt (yet) . When typing Python programs,\\neither interactively or into a text file, be sure to start all your unnested statements\\nin column 1 (that is, all the way to the left). If you don’t, Python may print a\\n“SyntaxError” message, because blank space to the left of your code is taken to be\\nindentation that groups nested statements. Until Chapter 10, all statements you\\nwrite will be unnested, so this includes everything for now. This seems to be a\\nrecurring confusion in introductory Python classes. Remember, a leading space\\ngenerates an error message.\\n•Watch out for prompt changes for compound statements . We won’t meet\\ncompound (multiline) statements until Chapter 4, and not in earnest until Chap-\\nter 10 , but as a preview, you should know that when typing lines 2 and beyond of\\na compound statement interactively, the prompt may change. In the simple shell\\nwindow interface, the interactive prompt changes to ... instead of >>> for lines 2\\nand beyond; in the IDLE interface, lines after the first are automatically indented.\\nYou’ll see why this matters in Chapter 10 . For now, if you happen to come across\\na ... prompt or a blank line when entering your code, it probably means that you’ve\\nsomehow confused interactive Python into thinking you’re typing a multiline\\nstatement. Try hitting the Enter key or a Ctrl-C combination to get back to the\\nmain prompt. The >>> and ... prompt strings can also be changed (they are avail-\\nable in the built-in module sys), but I’ll assume they have not been in the book’s\\nexample listings.\\n•Terminate compound statements at the interactive prompt with a blank\\nline. At the interactive prompt, inserting a blank line (by hitting the Enter key at\\nthe start of a line) is necessary to tell interactive Python that you’re done typing the\\nmultiline statement. That is, you must press Enter twice to make a compound\\nstatement run. By contrast, blank lines are not required in files and are simply\\nignored if present. If you don’t press Enter twice at the end of a compound state-\\nment when working interactively, you’ll appear to be stuck in a limbo state, because\\nthe interactive interpreter will do nothing at all—it’s waiting for you to press Enter\\nagain!\\n•The interactive prompt runs one statement at a time. At the interactive prompt,\\nyou must run one statement to completion before typing another. This is natural\\nfor simple statements, because pressing the Enter key runs the statement entered.\\nFor compound statements, though, remember that you must submit a blank line\\nto terminate the statement and make it run before you can type the next statement.\\n40 | Chapter 3: \\u2002How You Run Programs', metadata={'source': 'python.pdf', 'page': 90}),\n",
       " Document(page_content='Entering multiline statements\\nAt the risk \\nof repeating myself, I received emails from readers who’d gotten burned by\\nthe last two points as I was updating this chapter, so it probably merits emphasis. I’ll\\nintroduce multiline (a.k.a. compound) statements in the next chapter, and we’ll explore\\ntheir syntax more formally later in this book. Because their behavior differs slightly in\\nfiles and at the interactive prompt, though, two cautions are in order here.\\nFirst, be sure to terminate multiline compound statements like for loops and if tests\\nat the interactive prompt with a blank line. You must press the Enter key twice, to ter-\\nminate the whole multiline statement and then make it run. For example (pun not\\nintended...):\\n>>> for x in \\'spam\\':\\n...     print(x)              <== Press Enter twice here to make this loop run\\n...\\nYou don’t need the blank line after compound statements in a script file, though; this\\nis required only at the interactive prompt. In a file, blank lines are not required and are\\nsimply ignored when present; at the interactive prompt, they terminate multiline\\nstatements.\\nAlso bear in mind that the interactive prompt runs just one statement at a time: you\\nmust press Enter twice to run a loop or other multiline statement before you can type\\nthe next statement:\\n>>> for x in \\'spam\\':\\n...     print(x)              <== Need to press Enter twice before a new statement\\n... print(\\'done\\')\\n  File \"<stdin>\", line 3\\n    print(\\'done\\')\\n        ^\\nSyntaxError: invalid syntax\\nThis means you can’t cut and paste multiple lines of code into the interactive prompt,\\nunless the code includes blank lines after each compound statement. Such code is better\\nrun in a file—the next section’s topic.\\nSystem Command Lines and Files\\nAlthough the interactive prompt is great for experimenting and testing, it has one big\\ndisadvantage: programs you type there go away as soon as the Python interpreter ex-\\necutes them. Because the code you type interactively is never stored in a file, you can’t\\nrun it again without retyping it from scratch. Cut-and-paste and command recall can\\nhelp some here, but not much, especially when you start writing larger programs. To\\ncut and paste code from an interactive session, you would have to edit out Python\\nprompts, program outputs, and so on—not exactly a modern software development\\nmethodology!\\nSystem Command Lines and Files | 41', metadata={'source': 'python.pdf', 'page': 91}),\n",
       " Document(page_content=\"To save programs permanently, you need to write your code in files, which are usually\\nknown as modules. Modules are simply text files containing Python statements. Once\\ncoded, you can \\nask the Python interpreter to execute the statements in such a file any\\nnumber of times, and in a variety of ways—by system command lines, by file icon clicks,\\nby options in the IDLE user interface, and more. Regardless of how it is run, Python\\nexecutes all the code in a module file from top to bottom each time you run the file.\\nTerminology in this domain can vary somewhat. For instance, module files are often\\nreferred to as programs in Python—that is, a program is considered to be a series of\\nprecoded statements stored in a file for repeated execution. Module files that are run\\ndirectly are also sometimes called scripts—an informal term usually meaning a top-level\\nprogram file. Some reserve the term “module” for a file imported from another file.\\n(More on the meaning of “top-level” and imports in a few moments.)\\nWhatever you call them, the next few sections explore ways to run code typed into\\nmodule files. In this section, you’ll learn how to run files in the most basic way: by\\nlisting their names in a python command line entered at your computer’s system\\nprompt. Though it might seem primitive to some, for many programmers a system shell\\ncommand-line window, together with a text editor window, constitutes as much of an\\nintegrated development environment as they will ever need.\\nA First Script\\nLet’s get started. Open your favorite text editor (e.g., vi, Notepad, or the IDLE editor),\\nand type the following statements into a new text file named script1.py:\\n# A first Python script\\nimport sys                  # Load a library module\\nprint(sys.platform)\\nprint(2 ** 100)             # Raise 2 to a power\\nx = 'Spam!'\\nprint(x * 8)                # String repetition\\nThis file is our first official Python script (not counting the two-liner in Chapter 2). You\\nshouldn’t worry too much about this file’s code, but as a brief description, this file:\\n• Imports a Python module (libraries of additional tools), to fetch the name of the\\nplatform\\n• Runs three print function calls, to display the script’s results\\n• Uses a variable named x, created when it’s assigned, to hold onto a string object\\n• Applies various object operations that we’ll begin studying in the next chapter\\nThe sys.platform here is just a string that identifies the kind of computer you’re work-\\ning on; it lives in a standard Python module called sys, which you must import to load\\n(again, more on imports later).\\n42 | Chapter 3: \\u2002How You Run Programs\", metadata={'source': 'python.pdf', 'page': 92}),\n",
       " Document(page_content='For color, I’ve also added some formal Python comments here—the text after the #\\ncharacters. Comments can show up on lines by themselves, or to the right of code on\\na line. The text after a # is simply ignored as a human-readable comment and is not\\nconsidered part of the statement’s syntax. If you’re copying this code, you can ignore\\nthe comments as well. In this book, we usually use a different formatting style to make\\ncomments more visually distinctive, but they’ll appear as normal text in your code.\\nAgain, don’t focus on the syntax of the code in this file for now; we’ll learn about all\\nof it later. The main point to notice is that you’ve typed this code into a file, rather than\\nat the interactive prompt. In the process, you’ve coded a fully functional Python script.\\nNotice that the module file is called script1.py. As for all top-level files, it could also be\\ncalled simply script, but files of code you want to import into a client have to end with\\na .py suffix. We’ll study imports later in this chapter. Because you may want to import\\nthem in the future, it’s a good idea to use .py suffixes for most Python files that you\\ncode. Also, some text editors detect Python files by their .py suffix; if the suffix is not\\npresent, you may not get features like syntax colorization and automatic indentation.\\nRunning Files with Command Lines\\nOnce you’ve saved this text file, you can ask Python to run it by listing its full filename\\nas the first argument to a python command, typed at the system shell prompt:\\n% python script1.py\\nwin32\\n1267650600228229401496703205376\\nSpam!Spam!Spam!Spam!Spam!Spam!Spam!Spam!\\nAgain, you can type such a system shell command in whatever your system provides\\nfor command-line entry—a Windows Command Prompt window, an xterm window,\\nor similar. Remember to replace “python” with a full directory path, as before, if your\\nPATH setting is not configured.\\nIf all works as planned, this shell command makes Python run the code in this file line\\nby line, and you will see the output of the script’s three print statements—the name\\nof the underlying platform, 2 raised to the power 100, and the result of the same string\\nrepetition expression we saw earlier (again, more on the last two of these in Chapter 4).\\nIf all didn’t work as planned, you’ll get an error message—make sure you’ve entered\\nthe code in your file exactly as shown, and try again. We’ll talk about debugging options\\nin the sidebar “Debugging Python Code” on page 67, but at this point in the book\\nyour best bet is probably rote imitation.\\nBecause this scheme uses shell command lines to start Python programs, all the usual\\nshell syntax applies. For instance, you can route the output of a Python script to a file\\nto save it for later use or inspection by using special shell syntax:\\n% python script1.py > saveit.txt\\nSystem Command Lines and Files | 43', metadata={'source': 'python.pdf', 'page': 93}),\n",
       " Document(page_content='In this case, the three output lines shown in the prior run are stored in the file\\nsaveit.txt instead of \\nbeing printed. This is generally known as stream redirection; it\\nworks for input and output text and is available on Windows and Unix-like systems.\\nIt also has little to do with Python (Python simply supports it), so we will skip further\\ndetails on shell redirection syntax here.\\nIf you are working on a Windows platform, this example works the same, but the system\\nprompt is normally different:\\nC:\\\\Python30> python script1.py\\nwin32\\n1267650600228229401496703205376\\nSpam!Spam!Spam!Spam!Spam!Spam!Spam!Spam!\\nAs usual, be \\nsure to type the full path to Python if you haven’t set your PATH environment\\nvariable to include this path or run a change-directory command to go to the path:\\nD:\\\\temp> C:\\\\python30\\\\python script1.py\\nwin32\\n1267650600228229401496703205376\\nSpam!Spam!Spam!Spam!Spam!Spam!Spam!Spam!\\nOn all recent versions of Windows, you can also type just the name of your script, and\\nomit the name of Python itself. Because newer Windows systems use the Windows\\nRegistry to find a program with which to run a file, you don’t need to name “python”\\non the command line explicitly to run a .py file. The prior command, for example, could\\nbe simplified to this on most Windows machines:\\nD:\\\\temp> script1.py\\nFinally, remember to give the full path to your script file if it lives in a different directory\\nfrom the one in which you are working. For example, the following system command\\nline, run from D:\\\\other, assumes Python is in your system path but runs a file located\\nelsewhere:\\nD:\\\\other> python c:\\\\code\\\\otherscript.py\\nIf your PATH doesn’t include Python’s directory, and neither Python nor your script file\\nis in the directory you’re working in, use full paths for both:\\nD:\\\\other> C:\\\\Python30\\\\python c:\\\\code\\\\otherscript.py\\nUsing Command Lines and Files\\nRunning program files from system command lines is also a fairly straightforward\\nlaunch option, especially if you are familiar with command lines in general from prior\\nwork. For newcomers, though, here are a few pointers about common beginner traps\\nthat might help you avoid some frustration:\\n44 | Chapter 3: \\u2002How You Run Programs', metadata={'source': 'python.pdf', 'page': 94}),\n",
       " Document(page_content='•Beware of automatic extensions on Windows. If you use the Notepad program\\nto code \\nprogram files on Windows, be careful to pick the type All Files when it\\ncomes time to save your file, and give the file a .py suffix explicitly. Otherwise,\\nNotepad will save your file with a .txt extension (e.g., as script1.py.txt), making it\\ndifficult to run in some launching schemes.\\nWorse, Windows hides file extensions by default, so unless you have changed your\\nview options you may not even notice that you’ve coded a text file and not a Python\\nfile. The file’s icon may give this away—if it doesn’t have a snake on it, you may\\nhave trouble. Uncolored code in IDLE and files that open to edit instead of run\\nwhen clicked are other symptoms of this problem.\\nMicrosoft Word similarly adds a .doc extension by default; much worse, it adds\\nformatting characters that are not legal Python syntax. As a rule of thumb, always\\npick All Files when saving under Windows, or use a more programmer-friendly\\ntext editor such as IDLE. IDLE does not even add a .py suffix automatically—a\\nfeature programmers tend to like, but users do not.\\n•Use file extensions and directory paths at system prompts, but not for im-\\nports. Don’t forget to type the full name of your file in system command lines—\\nthat is, use python script1.py  rather than python script1 . By contrast, Python’s \\nimport statements, which we’ll meet later in this chapter, omit both the .py file\\nsuffix and the directory path (e.g., import script1). This may seem trivial, but\\nconfusing these two is a common mistake.\\nAt the system prompt, you are in a system shell, not Python, so Python’s module\\nfile search rules do not apply. Because of that, you must include both the .py ex-\\ntension and, if necessary, the full directory path leading to the file you wish to run.\\nFor instance, to run a file that resides in a different directory from the one in\\nwhich you are working, you would typically list its full path (e.g.,\\npython d:\\\\tests\\\\spam.py). Within Python code, however, you can just say\\nimport spam and rely on the Python module search path to locate your file, as\\ndescribed later.\\n•Use print statements in files. Yes, we’ve already been over this, but it is such a\\ncommon mistake that it’s worth repeating at least once here. Unlike in interactive\\ncoding, you generally must use print statements to see output from program files.\\nIf you don’t see any output, make sure you’ve said “print” in your file. Again,\\nthough, print statements are not required in an interactive session, since Python\\nautomatically echoes expression results; prints don’t hurt here, but are superfluous\\nextra typing.\\nSystem Command Lines and Files | 45', metadata={'source': 'python.pdf', 'page': 95}),\n",
       " Document(page_content=\"Unix Executable Scripts (#!)\\nIf you are \\ngoing to use Python on a Unix, Linux, or Unix-like system, you can also turn\\nfiles of Python code into executable programs, much as you would for programs coded\\nin a shell language such as csh or ksh. Such files are usually called executable scripts .\\nIn simple terms, Unix-style executable scripts are just normal text files containing Py-\\nthon statements, but with two special properties:\\n•Their first line is special . Scripts usually start with a line that begins with the\\ncharacters #! (often called “hash bang”), followed by the path to the Python in-\\nterpreter on your machine.\\n•They usually have executable privileges . Script files are usually marked as ex-\\necutable to tell the operating system that they may be run as top-level programs.\\nOn Unix systems, a command such as chmod +x file.py usually does the trick.\\nLet’s look at an example for Unix-like systems. Use your text editor again to create a\\nfile of Python code called brian:\\n#!/usr/local/bin/python\\nprint('The Bright Side ' + 'of Life...')        # + means concatenate for strings\\nThe special line at the top of the file tells the system where the Python interpreter lives.\\nTechnically, the first line is a Python comment. As mentioned earlier, all comments in\\nPython programs start with a # and span to the end of the line; they are a place to insert\\nextra information for human readers of your code. But when a comment such as the\\nfirst line in this file appears, it’s special because the operating system uses it to find an\\ninterpreter for running the program code in the rest of the file.\\nAlso, note that this file is called simply brian, without the .py suffix used for the module\\nfile earlier. Adding a .py to the name wouldn’t hurt (and might help you remember that\\nthis is a Python program file), but because you don’t plan on letting other modules\\nimport the code in this file, the name of the file is irrelevant. If you give the file executable\\nprivileges with a chmod +x brian shell command, you can run it from the operating\\nsystem shell as though it were a binary program:\\n% brian\\nThe Bright Side of Life...\\nA note for Windows users: the method described here is a Unix trick, and it may not\\nwork on your platform. Not to worry; just use the basic command-line technique ex-\\nplored earlier. List the file’s name on an explicit python command line:*\\n* As we discussed when exploring command lines, modern Windows versions also let you type just the name\\nof a .py \\nfile at the system command line—they use the Registry to determine that the file should be opened\\nwith Python (e.g., typing brian.py is equivalent to typing python brian.py). This command-line mode is\\nsimilar in spirit to the Unix #!, though it is system-wide on Windows, not per-file. Note that some\\nprograms may actually interpret and use a first #! line on Windows much like on Unix, but the DOS system\\nshell on Windows simply ignores it.\\n46 | Chapter 3: \\u2002How You Run Programs\", metadata={'source': 'python.pdf', 'page': 96}),\n",
       " Document(page_content='C:\\\\misc> python brian\\nThe Bright Side of Life...\\nIn this case, \\nyou don’t need the special #! comment at the top (although Python just\\nignores it if it’s present), and the file doesn’t need to be given executable privileges. In\\nfact, if you want to run files portably between Unix and Microsoft Windows, your life\\nwill probably be simpler if you always use the basic command-line approach, not Unix-\\nstyle scripts, to launch programs.\\nThe Unix env Lookup Trick\\nOn some Unix \\nsystems, you can avoid hardcoding the path to the Python interpreter\\nby writing the special first-line comment like this:\\n#!/usr/bin/env python\\n...script goes here...\\nWhen coded this way, the env program locates the Python interpreter according to your\\nsystem search path settings (i.e., in most Unix shells, by looking in all the directories\\nlisted in the PATH environment variable). This scheme can be more portable, as you\\ndon’t need to hardcode a Python install path in the first line of all your scripts.\\nProvided you have access to env everywhere, your scripts will run no matter where\\nPython lives on your system—you need only change the PATH environment variable\\nsettings across platforms, not in the first line in all your scripts. Of course, this assumes\\nthat env lives in the same place everywhere (on some machines, it may be\\nin /sbin, /bin, or elsewhere); if not, all portability bets are off!\\nClicking File Icons\\nOn Windows, the \\nRegistry makes opening files with icon clicks easy. Python automat-\\nically registers itself to be the program that opens Python program files when they are\\nclicked. Because of that, it is possible to launch the Python programs you write by\\nsimply clicking (or double-clicking) on their file icons with your mouse cursor.\\nOn non-Windows systems, you will probably be able to perform a similar trick, but\\nthe icons, file explorer, navigation schemes, and more may differ slightly. On some\\nUnix systems, for instance, you may need to register the .py extension with your file\\nexplorer GUI, make your script executable using the #! trick discussed in the previous\\nsection, or associate the file MIME type with an application or command by editing\\nfiles, installing programs, or using other tools. See your file explorer’s documentation\\nfor more details if clicks do not work correctly right off the bat.\\nClicking Icons on Windows\\nTo illustrate, let’s keep using the script we wrote earlier, script1.py, repeated here to\\nminimize page flipping:\\nClicking File Icons | 47', metadata={'source': 'python.pdf', 'page': 97}),\n",
       " Document(page_content=\"# A first Python script\\nimport sys                  # Load a library module\\nprint(sys.platform)\\nprint(2 ** 100)             # Raise 2 to a power\\nx = 'Spam!'\\nprint(x * 8)                # String repetition\\nAs we’ve seen, you can always run this file from a system command line:\\nC:\\\\misc> c:\\\\python30\\\\python script1.py\\nwin32\\n1267650600228229401496703205376\\nHowever, icon clicks \\nallow you to run the file without any typing at all. If you find this\\nfile’s icon—for instance, by selecting Computer (or My Computer in XP) in your Start\\nmenu and working your way down on the C drive on Windows—you will get the file\\nexplorer picture captured in Figure 3-1 (Windows Vista is being used here). Python\\nsource files show up with white backgrounds on Windows, and byte code files show\\nup with black backgrounds. You will normally want to click (or otherwise run) the\\nsource code file, in order to pick up your most recent changes. To launch the file here,\\nsimply click on the icon for script1.py.\\nFigure 3-1. On Windows, Python program files show up as icons in file explorer windows and can\\nautomatically be run \\nwith a double-click of the mouse (though you might not see printed output or\\nerror messages this way).\\n48 | Chapter 3: \\u2002How You Run Programs\", metadata={'source': 'python.pdf', 'page': 98}),\n",
       " Document(page_content=\"The input Trick\\nUnfortunately, on Windows, the \\nresult of clicking on a file icon may not be incredibly\\nsatisfying. In fact, as it is, this example script generates a perplexing “flash” when\\nclicked—not exactly the sort of feedback that budding Python programmers usually\\nhope for! This is not a bug, but has to do with the way the Windows version of Python\\nhandles printed output.\\nBy default, Python generates a pop-up black DOS console window to serve as a clicked\\nfile’s input and output. If a script just prints and exits, well, it just prints and exits—\\nthe console window appears, and text is printed there, but the console window closes\\nand disappears on program exit. Unless you are very fast, or your machine is very slow,\\nyou won’t get to see your output at all. Although this is normal behavior, it’s probably\\nnot what you had in mind.\\nLuckily, it’s easy to work around this. If you need your script’s output to stick around\\nwhen you launch it with an icon click, simply put a call to the built-in input function\\nat the very bottom of the script (raw_input in 2.6: see the note ahead). For example:\\n# A first Python script\\nimport sys                  # Load a library module\\nprint(sys.platform)\\nprint(2 ** 100)             # Raise 2 to a power\\nx = 'Spam!'\\nprint(x * 8)                # String repetition\\ninput()                     # <== ADDED\\nIn general, input reads the next line of standard input, waiting if there is none yet\\navailable. The net effect in this context will be to pause the script, thereby keeping the\\noutput window shown in Figure 3-2 open until you press the Enter key.\\nFigure 3-2. When you click a program’s icon on Windows, you will be able to see its printed output\\nif you include an input call at the very end of the script. But you only need to do so in this context!\\nClicking File Icons | 49\", metadata={'source': 'python.pdf', 'page': 99}),\n",
       " Document(page_content=\"Now that I’ve shown you this trick, keep in mind that it is usually only required for\\nWindows, and then \\nonly if your script prints text and exits and only if you will launch\\nthe script by clicking its file icon. You should add this call to the bottom of your top-\\nlevel files if and only if all of these three conditions apply. There is no reason to add\\nthis call in any other contexts (unless you’re unreasonably fond of pressing your com-\\nputer’s Enter key!).† That may sound obvious, but it’s another common mistake in live\\nclasses.\\nBefore we move ahead, note that the input call applied here is the input counterpart of\\nusing the print statement for outputs. It is the simplest way to read user input, and it\\nis more general than this example implies. For instance, input:\\n• Optionally accepts a string that will be printed as a prompt (e.g., input('Press\\nEnter to exit'))\\n• Returns to your script a line of text read as a string (e.g., nextinput = input())\\n• Supports input stream redirections at the system shell level (e.g., python spam.py\\n< input.txt), just as the print statement does for output\\nWe’ll use input in more advanced ways later in this text; for instance, Chapter 10  will\\napply it in an interactive loop.\\nVersion skew note : If you are working in Python 2.6 or earlier, use \\nraw_input() instead of input() in this code. The former was renamed to\\nthe latter in Python 3.0. Technically, 2.6 has an input too, but it also\\nevaluates strings as though they are program code typed into a script,\\nand so will not work in this context (an empty string is an error). Python\\n3.0’s input (and 2.6’s raw_input) simply returns the entered text as a\\nstring, unevaluated. To simulate 2.6’s input in 3.0, use eval(input()).\\nOther Icon-Click Limitations\\nEven with the input trick, clicking file icons is not without its perils. You also may not\\nget to see Python error messages. If your script generates an error, the error message\\ntext is written to the pop-up console window—which then immediately disappears!\\nWorse, adding an input call to your file will not help this time because your script will\\nlikely abort long before it reaches this call. In other words, you won’t be able to tell\\nwhat went wrong.\\n† It is also possible to completely suppress the pop-up DOS console window for clicked files on Windows.\\nFiles whose \\nnames end in a .pyw extension will display only windows constructed by your script, not the\\ndefault DOS console window. .pyw files are simply .py source files that have this special operational behavior\\non Windows. They are mostly used for Python-coded user interfaces that build windows of their own, often\\nin conjunction with various techniques for saving printed output and errors to files.\\n50 | Chapter 3: \\u2002How You Run Programs\", metadata={'source': 'python.pdf', 'page': 100}),\n",
       " Document(page_content='Because of these limitations, it is probably best to view icon clicks as a way to launch\\nprograms after they \\nhave been debugged or have been instrumented to write their out-\\nput to a file. Especially when starting out, use other techniques—such as system\\ncommand lines and IDLE (discussed further in the section “The IDLE User Inter-\\nface” on page 58)—so that you can see generated error messages and view your\\nnormal output without resorting to coding tricks. When we discuss exceptions later in\\nthis book, you’ll also learn that it is possible to intercept and recover from errors so\\nthat they do not terminate your programs. Watch for the discussion of the try statement\\nlater in this book for an alternative way to keep the console window from closing on\\nerrors.\\nModule Imports and Reloads\\nSo far, I’ve been talking about “importing modules” without really explaining what this\\nterm means. We’ll study modules and larger program architecture in depth in Part V ,\\nbut because imports are also a way to launch programs, this section will introduce\\nenough module basics to get you started.\\nIn simple terms, every file of Python source code whose name ends in a .py extension\\nis a module. Other files can access the items a module defines by importing that module;\\nimport operations essentially load another file and grant access to that file’s contents.\\nThe contents of a module are made available to the outside world through its attributes\\n(a term I’ll define in the next section).\\nThis module-based services model turns out to be the core idea behind program ar-\\nchitecture in Python. Larger programs usually take the form of multiple module files,\\nwhich import tools from other module files. One of the modules is designated as the\\nmain or top-level file, and this is the one launched to start the entire program.\\nWe’ll delve into such architectural issues in more detail later in this book. This chapter\\nis mostly interested in the fact that import operations run the code in a file that is being\\nloaded as a final step. Because of this, importing a file is yet another way to launch it.\\nFor instance, if you start an interactive session (from a system command line, from the\\nStart menu, from IDLE, or otherwise), you can run the script1.py file you created earlier\\nwith a simple import (be sure to delete the input line you added in the prior section\\nfirst, or you’ll need to press Enter for no reason):\\nC:\\\\misc> c:\\\\python30\\\\python\\n>>> import script1\\nwin32\\n1267650600228229401496703205376\\nSpam!Spam!Spam!Spam!Spam!Spam!Spam!Spam!\\nModule Imports and Reloads | 51', metadata={'source': 'python.pdf', 'page': 101}),\n",
       " Document(page_content=\"This works, but only once per session (really, process) by default. After the first import,\\nlater imports do \\nnothing, even if you change and save the module’s source file again in\\nanother window:\\n>>> import script1\\n>>> import script1\\nThis is by design; imports are too expensive an operation to repeat more than once per\\nfile, per program run. As you’ll learn in Chapter 21, imports must find files, compile\\nthem to byte code, and run the code.\\nIf you really want to force Python to run the file again in the same session without\\nstopping and restarting the session, you need to instead call the reload function avail-\\nable in the imp standard library module (this function is also a simple built-in in Python\\n2.6, but not in 3.0):\\n>>> from imp import reload           # Must load from module in 3.0\\n>>> reload(script1)\\nwin32\\n65536\\nSpam!Spam!Spam!Spam!Spam!Spam!Spam!Spam!\\n<module 'script1' from 'script1.py'>\\n>>>\\nThe from statement here simply copies a name out of a module (more on this soon).\\nThe reload function itself loads and runs the current version of your file’s code, picking\\nup changes if you’ve changed and saved it in another window.\\nThis allows you to edit and pick up new code on the fly within the current Python\\ninteractive session. In this session, for example, the second print statement in\\nscript1.py was changed in another window to print 2 ** 16 between the time of the\\nfirst import and the reload call.\\nThe reload function expects the name of an already loaded module object, so you have\\nto have successfully imported a module once before you reload it. Notice that reload\\nalso expects parentheses around the module object name, whereas import does not.\\nreload is a function that is called, and import is a statement.\\nThat’s why you must pass the module name to reload as an argument in parentheses,\\nand that’s why you get back an extra output line when reloading. The last output line\\nis just the display representation of the reload call’s return value, a Python module\\nobject. We’ll learn more about using functions in general in Chapter 16.\\n52 | Chapter 3: \\u2002How You Run Programs\", metadata={'source': 'python.pdf', 'page': 102}),\n",
       " Document(page_content='Version skew note : Python 3.0 moved the reload built-in function to the\\nimp standard library module. It still reloads files as before, but you must\\nimport it in order to use it. In 3.0, run an import imp and use\\nimp.reload(M), or run a from imp import reload and use reload(M), as\\nshown here. We’ll discuss import and from statements in the next sec-\\ntion, and more formally later in this book.\\nIf you are working in Python 2.6 (or 2.X in general), reload is available\\nas a built-in function, so no import is required. In Python 2.6, reload is\\navailable in both forms—built-in and module function—to aid the tran-\\nsition to 3.0. In other words, reloading is still available in 3.0, but an\\nextra line of code is required to fetch the reload call.\\nThe move in 3.0 was likely motivated in part by some well-known issues\\ninvolving reload and from statements that we’ll encounter in the next\\nsection. In short, names loaded with a from are not directly updated by\\na reload, but names accessed with an import statement are. If your\\nnames don’t seem to change after a reload, try using import and\\nmodule.attribute name references instead.\\nThe Grander Module Story: Attributes\\nImports and reloads provide a natural program launch option because import opera-\\ntions execute files as a last step. In the broader scheme of things, though, modules serve\\nthe role of libraries of tools, as you’ll learn in Part V . More generally, a module is mostly\\njust a package of variable names, known as a namespace. The names within that package\\nare called attributes—an attribute is simply a variable name that is attached to a specific\\nobject (like a module).\\nIn typical use, importers gain access to all the names assigned at the top level of a\\nmodule’s file. These names are usually assigned to tools exported by the module—\\nfunctions, classes, variables, and so on—that are intended to be used in other files and\\nother programs. Externally, a module file’s names can be fetched with two Python\\nstatements, import and from, as well as the reload call.\\nTo illustrate, use a text editor to create a one-line Python module file called myfile.py \\nwith the following contents:\\ntitle = \"The Meaning of Life\"\\nThis may be one of the world’s simplest Python modules (it contains a single assignment\\nstatement), but it’s enough to illustrate the point. When this file is imported, its code\\nis run to generate the module’s attribute. The assignment statement creates a module\\nattribute named title.\\nModule Imports and Reloads | 53', metadata={'source': 'python.pdf', 'page': 103}),\n",
       " Document(page_content=\"You can access this module’s title attribute in other components in two different ways.\\nFirst, you can load the module as a whole with an import statement, and then qualify\\nthe module name with the attribute name to fetch it:\\n% python                           # Start Python\\n>>> import myfile                  # Run file; load module as a whole\\n>>> print(myfile.title)            # Use its attribute names: '.' to qualify\\nThe Meaning of Life\\nIn general, the dot expression syntax object.attribute lets you fetch any attribute\\nattached to any object, and this is a very common operation in Python code. Here,\\nwe’ve used it to access the string variable title inside the module myfile—in other\\nwords, myfile.title.\\nAlternatively, you can fetch (really, copy) names out of a module with from statements:\\n% python                           # Start Python\\n>>> from myfile import title       # Run file; copy its names\\n>>> print(title)                   # Use name directly: no need to qualify\\nThe Meaning of Life\\nAs you’ll see in more detail later, from is just like an import, with an extra assignment\\nto names in the importing component. Technically, from copies a module’s attributes,\\nsuch that they become simple variables in the recipient—thus, you can simply refer to\\nthe imported string this time as title (a variable) instead of myfile.title (an attribute\\nreference).‡\\nWhether you use import or from to invoke an import operation, the statements in the\\nmodule file myfile.py are executed, and the importing component (here, the interactive\\nprompt) gains access to names assigned at the top level of the file. There’s only one\\nsuch name in this simple example—the variable title, assigned to a string—but the\\nconcept will be more useful when you start defining objects such as functions and\\nclasses in your modules: such objects become reusable software components that can\\nbe accessed by name from one or more client modules.\\nIn practice, module files usually define more than one name to be used in and outside\\nthe files. Here’s an example that defines three:\\na = 'dead'                      # Define three attributes\\nb = 'parrot'                    # Exported to other files\\nc = 'sketch'\\nprint(a, b, c)                  # Also used in this file\\nThis file, threenames.py, assigns three variables, and so generates three attributes for\\nthe outside world. It also uses its own three variables in a print statement, as we see\\nwhen we run this as a top-level file:\\n‡ Notice that import and from both list the name of the module file as simply myfile without its .py suffix. As\\nyou’ll learn in Part V, when Python looks for the actual file, it knows to include the suffix in its search\\nprocedure. Again, you must include the .py suffix in system shell command lines, but not in import statements.\\n54 | Chapter 3: \\u2002How You Run Programs\", metadata={'source': 'python.pdf', 'page': 104}),\n",
       " Document(page_content=\"% python threenames.py\\ndead parrot sketch\\nAll of this \\nfile’s code runs as usual the first time it is imported elsewhere (by either an\\nimport or from). Clients of this file that use import get a module with attributes, while\\nclients that use from get copies of the file’s names:\\n% python\\n>>> import threenames                    # Grab the whole module\\ndead parrot sketch\\n>>>\\n>>> threenames.b, threenames.c\\n('parrot', 'sketch')\\n>>>\\n>>> from threenames import a, b, c       # Copy multiple names\\n>>> b, c\\n('parrot', 'sketch')\\nThe results here are printed in parentheses because they are really tuples (a kind of\\nobject covered in the next part of this book); you can safely ignore them for now.\\nOnce you start coding modules with multiple names like this, the built-in dir function\\nstarts to come in handy—you can use it to fetch a list of the names available inside a\\nmodule. The following returns a Python list of strings (we’ll start studying lists in the\\nnext chapter):\\n>>> dir(threenames)\\n['__builtins__', '__doc__', '__file__', '__name__', '__package__', 'a', 'b', 'c']\\nI ran this on Python 3.0 and 2.6; older Pythons may return fewer names. When the\\ndir function is called with the name of an imported module passed in parentheses like\\nthis, it returns all the attributes inside that module. Some of the names it returns are\\nnames you get “for free”: names with leading and trailing double underscores are built-\\nin names that are always predefined by Python and that have special meaning to the\\ninterpreter. The variables our code defined by assignment— a, b, and c—show up last\\nin the dir result.\\nModules and namespaces\\nModule imports are a way to run files of code, but, as we’ll discuss later in the book,\\nmodules are also the largest program structure in Python programs.\\nIn general, Python programs are composed of multiple module files, linked together by\\nimport statements. Each module file is a self-contained package of variables—that is,\\na namespace. One module file cannot see the names defined in another file unless it\\nexplicitly imports that other file, so modules serve to minimize name collisions in your\\ncode—because each file is a self-contained namespace, the names in one file cannot\\nclash with those in another, even if they are spelled the same way.\\nModule Imports and Reloads | 55\", metadata={'source': 'python.pdf', 'page': 105}),\n",
       " Document(page_content='In fact, as you’ll see, modules are one of a handful of ways that Python goes to great\\nlengths to package \\nyour variables into compartments to avoid name clashes. We’ll\\ndiscuss modules and other namespace constructs (including classes and function\\nscopes) further later in the book. For now, modules will come in handy as a way to run\\nyour code many times without having to retype it.\\nimport versus from : I should point out that the from statement in a sense\\ndefeats the namespace partitioning purpose of modules—because the\\nfrom copies variables from one file to another, it can cause same-named\\nvariables in the importing file to be overwritten (and won’t warn you if\\nit does). This essentially collapses namespaces together, at least in terms\\nof the copied variables.\\nBecause of this, some recommend using import instead of from. I won’t\\ngo that far, though; not only does from involve less typing, but its pur-\\nported problem is rarely an issue in practice. Besides, this is something\\nyou control by listing the variables you want in the from; as long as you\\nunderstand that they’ll be assigned values, this is no more dangerous\\nthan coding assignment statements—another feature you’ll probably\\nwant to use!\\nimport and reload Usage Notes\\nFor some reason, once people find out about running files using import and reload,\\nmany tend to focus on this alone and forget about other launch options that always\\nrun the current version of the code (e.g., icon clicks, IDLE menu options, and system\\ncommand lines). This approach can quickly lead to confusion, though—you need to\\nremember when you’ve imported to know if you can reload, you need to remember to\\nuse parentheses when you call reload (only), and you need to remember to use\\nreload in the first place to get the current version of your code to run. Moreover, reloads\\naren’t transitive—reloading a module reloads that module only, not any modules it\\nmay import—so you sometimes have to reload multiple files.\\nBecause of these complications (and others we’ll explore later, including the reload/\\nfrom issue mentioned in a prior note in this chapter), it’s generally a good idea to avoid\\nthe temptation to launch by imports and reloads for now. The IDLE Run →Run Module\\nmenu option described in the next section, for example, provides a simpler and less\\nerror-prone way to run your files, and always runs the current version of your code.\\nSystem shell command lines offer similar benefits. You don’t need to use reload if you\\nuse these techniques.\\nIn addition, you may run into trouble if you use modules in unusual ways at this point\\nin the book. For instance, if you want to import a module file that is stored in a directory\\nother than the one you’re working in, you’ll have to skip ahead to Chapter 21  and learn\\nabout the module search path.\\n56 | Chapter 3: \\u2002How You Run Programs', metadata={'source': 'python.pdf', 'page': 106}),\n",
       " Document(page_content=\"For now, if you must import, try to keep all your files in the directory you are working\\nin to avoid complications.§\\nThat said, imports \\nand reloads have proven to be a popular testing technique in Python\\nclasses, and you may prefer using this approach too. As usual, though, if you find\\nyourself running into a wall, stop running into a wall!\\nUsing exec to Run Module Files\\nIn fact, there are more ways to run code stored in module files than have yet been\\nexposed here. For instance, the exec(open('module.py').read()) built-in function call\\nis another way to launch files from the interactive prompt without having to import\\nand later reload. Each exec runs the current version of the file, without requiring later\\nreloads (script1.py is as we left it after a reload in the prior section):\\nC:\\\\misc> c:\\\\python30\\\\python\\n>>> exec(open('script1.py').read())\\nwin32\\n65536\\nSpam!Spam!Spam!Spam!Spam!Spam!Spam!Spam!\\n...change script1.py in a text edit window...\\n>>> exec(open('script1.py').read())\\nwin32\\n4294967296\\nSpam!Spam!Spam!Spam!Spam!Spam!Spam!Spam!\\nThe exec call has an effect similar to an import, but it doesn’t technically import the\\nmodule—by default, each time you call exec this way it runs the file anew, as though\\nyou had pasted it in at the place where exec is called. Because of that, exec does not\\nrequire module reloads after file changes—it skips the normal module import logic.\\nOn the downside, because it works as if pasting code into the place where it is called,\\nexec, like the from statement mentioned earlier, has the potential to silently overwrite\\nvariables you may currently be using. For example, our script1.py assigns to a variable\\nnamed x. If that name is also being used in the place where exec is called, the name’s\\nvalue is replaced:\\n>>> x = 999\\n>>> exec(open('script1.py').read())     # Code run in this namespace by default\\n...same outout...\\n>>> x                                   # Its assignments can overwrite names here\\n'Spam!'\\n§ If you’re burning with curiosity, the short story is that Python searches for imported modules in every directory\\nlisted in sys.path\\n—a Python list of directory name strings in the sys module, which is initialized from a\\nPYTHONPATH environment variable, plus a set of standard directories. If you want to import from a directory\\nother than the one you are working in, that directory must generally be listed in your PYTHONPATH setting. For\\nmore details, see Chapter 21.\\nUsing exec to Run Module Files | 57\", metadata={'source': 'python.pdf', 'page': 107}),\n",
       " Document(page_content=\"By contrast, the basic import statement runs the file only once per process, and it makes\\nthe file a separate module namespace so that its assignments will not change variables\\nin your scope. The price you pay for the namespace partitioning of modules is the need\\nto reload after changes.\\nVersion skew note : Python 2.6 also includes an execfile('module.py')\\nbuilt-in function, in addition to allowing the form\\nexec(open('module.py')), which both automatically read the file’s\\ncontent. Both of these are equivalent to the\\nexec(open('module.py').read()) form, which is more complex but\\nruns in both 2.6 and 3.0.\\nUnfortunately, neither of these two simpler 2.6 forms is available in 3.0,\\nwhich means you must understand both files and their read methods to\\nfully understand this technique today (alas, this seems to be a case of\\naesthetics trouncing practicality in 3.0). In fact, the exec form in 3.0\\ninvolves so much typing that the best advice may simply be not to do\\nit—it’s usually best to launch files by typing system shell command lines\\nor by using the IDLE menu options described in the next section. For\\nmore on the 3.0 exec form, see Chapter 9.\\nThe IDLE User Interface\\nSo far, we’ve seen how to run Python code with the interactive prompt, system com-\\nmand lines, icon clicks, and module imports and exec calls. If you’re looking for some-\\nthing a bit more visual, IDLE provides a graphical user interface for doing Python\\ndevelopment, and it’s a standard and free part of the Python system. It is usually referred\\nto as an integrated development environment (IDE), because it binds together various\\ndevelopment tasks into a single view.‖\\nIn short, IDLE is a GUI that lets you edit, run, browse, and debug Python programs,\\nall from a single interface. Moreover, because IDLE is a Python program that uses the\\ntkinter GUI toolkit (known as Tkinter in 2.6), it runs portably on most Python plat-\\nforms, including Microsoft Windows, X Windows (for Linux, Unix, and Unix-like\\nplatforms), and the Mac OS (both Classic and OS X). For many, IDLE represents an\\neasy-to-use alternative to typing command lines, and a less problem-prone alternative\\nto clicking on icons.\\nIDLE Basics\\nLet’s jump right into an example. IDLE is easy to start under Windows—it has an entry\\nin the Start button menu for Python (see Figure 2-1 , shown previously), and it can also\\nbe selected by right-clicking on a Python program icon. On some Unix-like systems,\\n‖IDLE is officially a corruption of IDE, but it’s really named in honor of Monty Python member Eric Idle.\\n58 | Chapter 3: \\u2002How You Run Programs\", metadata={'source': 'python.pdf', 'page': 108}),\n",
       " Document(page_content='you may need to launch IDLE’s top-level script from a command line, or by clicking\\non the icon \\nfor the idle.pyw or idle.py file located in the idlelib subdirectory of Python’s\\nLib directory. On Windows, IDLE is a Python script that currently lives in C:\\\\Py-\\nthon30\\\\Lib\\\\idlelib (or C:Python26\\\\Lib\\\\idlelib in Python 2.6).#\\nFigure 3-3 shows the scene after starting IDLE on Windows. The Python shell window\\nthat opens initially is the main window, which runs an interactive session (notice the\\n>>> prompt). This works like all interactive sessions—code you type here is run im-\\nmediately after you type it—and serves as a testing tool.\\nFigure 3-3. The main Python shell window of the IDLE development GUI, shown here running on\\nWindows. Use the \\nFile menu to begin (New Window) or change (Open...) a source file; use the text\\nedit window’s Run menu to run the code in that window (Run Module).\\n#IDLE is a Python program that uses the standard library’s tkinter GUI toolkit (a.k.a. Tkinter in Python 2.6)\\nto build the \\nIDLE GUI. This makes IDLE portable, but it also means that you’ll need to have tkinter support\\nin your Python to use IDLE. The Windows version of Python has this by default, but some Linux and Unix\\nusers may need to install the appropriate tkinter support (a yum tkinter command may suffice on some Linux\\ndistributions, but see the installation hints in Appendix A  for details). Mac OS X may have everything you\\nneed preinstalled, too; look for an idle command or script on your machine.\\nThe IDLE User Interface | 59', metadata={'source': 'python.pdf', 'page': 109}),\n",
       " Document(page_content='IDLE uses familiar menus with keyboard shortcuts for most of its operations. To make\\n(or edit) a \\nsource code file under IDLE, open a text edit window: in the main window,\\nselect the File pull-down menu, and pick New Window (or Open... to open a text edit\\nwindow displaying an existing file for editing).\\nAlthough it may not show up fully in this book’s graphics, IDLE uses syntax-directed\\ncolorization for the code typed in both the main window and all text edit windows—\\nkeywords are one color, literals are another, and so on. This helps give you a better\\npicture of the components in your code (and can even help you spot mistakes—\\nrun-on strings are all one color, for example).\\nTo run a file of code that you are editing in IDLE, select the file’s text edit window,\\nopen that window’s Run pull-down menu, and choose the Run Module option listed\\nthere (or use the equivalent keyboard shortcut, given in the menu). Python will let you\\nknow that you need to save your file first if you’ve changed it since it was opened or\\nlast saved and forgot to save your changes—a common mistake when you’re knee deep\\nin coding.\\nWhen run this way, the output of your script and any error messages it may generate\\nshow up back in the main interactive window (the Python shell window). In Fig-\\nure 3-3 , for example, the three lines after the “RESTART” line near the middle of the\\nwindow reflect an execution of our script1.py file opened in a separate edit window.\\nThe “RESTART” message tells us that the user-code process was restarted to run the\\nedited script and serves to separate script output (it does not appear if IDLE is started\\nwithout a user-code subprocess—more on this mode in a moment).\\nIDLE hint of the day: If you want to repeat prior commands in IDLE’s\\nmain interactive window, you can use the Alt-P key combination to\\nscroll backward through the command history, and Alt-N to scroll for-\\nward (on some Macs, try Ctrl-P and Ctrl-N instead). Your prior com-\\nmands will be recalled and displayed, and may be edited and rerun. You\\ncan also recall commands by positioning the cursor on them, or use\\ncut-and-paste operations, but these techniques tend to involve more\\nwork. Outside IDLE, you may be able to recall commands in an inter-\\nactive session with the arrow keys on Windows.\\nUsing IDLE\\nIDLE is free, easy to use, portable, and automatically available on most platforms. I\\ngenerally recommend it to Python newcomers because it sugarcoats some of the details\\nand does not assume prior experience with system command lines. However, it is\\nsomewhat limited compared to more advanced commercial IDEs. To help you avoid\\nsome common pitfalls, here is a list of issues that IDLE beginners should bear in mind:\\n•You must add “.py” explicitly when saving your files. I mentioned this when\\ntalking about files in general, but it’s a common IDLE stumbling block, especially\\n60 | Chapter 3: \\u2002How You Run Programs', metadata={'source': 'python.pdf', 'page': 110}),\n",
       " Document(page_content='for Windows users. IDLE does not automatically add a .py extension to filenames\\nwhen files are saved. Be careful to type the .py extension yourself when saving a\\nfile for the first time. If you don’t, while you will be able to run your file from IDLE\\n(and system command lines), you will not be able to import it either interactively\\nor from other modules.\\n•Run scripts by selecting Run →Run Module in text edit windows, not by in-\\nteractive imports and reloads . Earlier in this chapter, we saw that it’s possible\\nto run a file by importing it interactively. However, this scheme can grow complex\\nbecause it requires you to manually reload files after changes. By contrast, using\\nthe Run→Run Module menu option in IDLE always runs the most current version\\nof your file, just like running it using a system shell command line. IDLE also\\nprompts you to save your file first, if needed (another common mistake outside\\nIDLE).\\n•You need to reload only modules being tested interactively . Like system shell\\ncommand lines, IDLE’s Run →Run Module menu option always runs the current\\nversion of both the top-level file and any modules it imports. Because of this,\\nRun→Run Module eliminates common confusions surrounding imports. You only\\nneed to reload modules that you are importing and testing interactively in IDLE.\\nIf you choose to use the import and reload technique instead of Run →Run Module,\\nremember that you can use the Alt-P/Alt-N key combinations to recall prior\\ncommands.\\n•You can customize IDLE. To change the text fonts and colors in IDLE, select the\\nConfigure option in the Options menu of any IDLE window. You can also cus-\\ntomize key combination actions, indentation settings, and more; see IDLE’s Help\\npull-down menu for more hints.\\n•There is currently no clear-screen option in IDLE . This seems to be a frequent\\nrequest (perhaps because it’s an option available in similar IDEs), and it might be\\nadded eventually. Today, though, there is no way to clear the interactive window’s\\ntext. If you want the window’s text to go away, you can either press and hold the\\nEnter key, or type a Python loop to print a series of blank lines (nobody really uses\\nthe latter technique, of course, but it sounds more high-tech than pressing the Enter\\nkey!).\\n•tkinter GUI and threaded programs may not work well with IDLE . Because\\nIDLE is a Python/tkinter program, it can hang if you use it to run certain types of\\nadvanced Python/tkinter programs. This has become less of an issue in more recent\\nversions of IDLE that run user code in one process and the IDLE GUI itself in\\nanother, but some programs (especially those that use multithreading) might still\\nhang the GUI. Your code may not exhibit such problems, but as a rule of thumb,\\nit’s always safe to use IDLE to edit GUI programs but launch them using other\\noptions, such as icon clicks or system command lines. When in doubt, if your code\\nfails in IDLE, try it outside the GUI.\\nThe IDLE User Interface | 61', metadata={'source': 'python.pdf', 'page': 111}),\n",
       " Document(page_content='•If connection errors arise, try starting IDLE in single-process mode . Because\\nIDLE requires \\ncommunication between its separate user and GUI processes, it can\\nsometimes have trouble starting up on certain platforms (notably, it fails to start\\noccasionally on some Windows machines, due to firewall software that blocks\\nconnections). If you run into such connection errors, it’s always possible to start\\nIDLE with a system command line that forces it to run in single-process mode\\nwithout a user-code subprocess and therefore avoids communication issues: its\\n-n command-line flag forces this mode. On Windows, for example, start a Com-\\nmand Prompt window and run the system command line idle.py -n  from within\\nthe directory C:\\\\Python30\\\\Lib\\\\idlelib (cd there first if needed).\\n•Beware of some IDLE usability features . IDLE does much to make life easier\\nfor beginners, but some of its tricks won’t apply outside the IDLE GUI. For in-\\nstance, IDLE runs your scripts in its own interactive namespace, so variables in\\nyour code show up automatically in the IDLE interactive session—you don’t al-\\nways need to run import commands to access names at the top level of files you’ve\\nalready run. This can be handy, but it can also be confusing, because outside the\\nIDLE environment names must always be imported from files to be used.\\nIDLE also automatically changes both to the directory of a file just run and adds\\nits directory to the module import search path—a handy feature that allows you\\nto import files there without search path settings, but also something that won’t\\nwork the same when you run files outside IDLE. It’s OK to use such features, but\\ndon’t forget that they are IDLE behavior, not Python behavior.\\nAdvanced IDLE Tools\\nBesides the basic edit and run functions, IDLE provides more advanced features, in-\\ncluding a point-and-click program debugger and an object browser. The IDLE debugger\\nis enabled via the Debug menu and the object browser via the File menu. The browser\\nallows you to navigate through the module search path to files and objects in files;\\nclicking on a file or object opens the corresponding source in a text edit window.\\nIDLE debugging is initiated by selecting the Debug →Debugger menu option in the main\\nwindow and then starting your script by selecting the Run →Run Module option in the\\ntext edit window; once the debugger is enabled, you can set breakpoints in your code\\nthat stop its execution by right-clicking on lines in the text edit windows, show variable\\nvalues, and so on. You can also watch program execution when debugging—the current\\nline of code is noted as you step through your code.\\nFor simpler debugging operations, you can also right-click with your mouse on the text\\nof an error message to quickly jump to the line of code where the error occurred—a\\ntrick that makes it simple and fast to repair and run again. In addition, IDLE’s text\\neditor offers a large collection of programmer-friendly tools, including automatic in-\\ndentation, advanced text and file search operations, and more. Because IDLE uses\\n62 | Chapter 3: \\u2002How You Run Programs', metadata={'source': 'python.pdf', 'page': 112}),\n",
       " Document(page_content='intuitive GUI interactions, you should experiment with the system live to get a feel for\\nits other tools.\\nOther IDEs\\nBecause IDLE \\nis free, portable, and a standard part of Python, it’s a nice first develop-\\nment tool to become familiar with if you want to use an IDE at all. Again, I recommend\\nthat you use IDLE for this book’s exercises if you’re just starting out, unless you are\\nalready familiar with and prefer a command-line-based development mode. There are,\\nhowever, a handful of alternative IDEs for Python developers, some of which are sub-\\nstantially more powerful and robust than IDLE. Here are some of the most commonly\\nused IDEs:\\nEclipse and PyDev\\nEclipse is an advanced open source IDE GUI. Originally developed as a Java IDE,\\nEclipse also supports Python development when you install the PyDev (or a similar)\\nplug-in. Eclipse is a popular and powerful option for Python development, and it\\ngoes well beyond IDLE’s feature set. It includes support for code completion, syn-\\ntax highlighting, syntax analysis, refactoring, debugging, and more. Its downsides\\nare that it is a large system to install and may require shareware extensions for some\\nfeatures (this may vary over time). Still, when you are ready to graduate from IDLE,\\nthe Eclipse/PyDev combination is worth your attention.\\nKomodo\\nA full-featured development environment GUI for Python (and other languages),\\nKomodo includes standard syntax-coloring, text-editing, debugging, and other\\nfeatures. In addition, Komodo offers many advanced features that IDLE does not,\\nincluding project files, source-control integration, regular-expression debugging,\\nand a drag-and-drop GUI builder that generates Python/tkinter code to implement\\nthe GUIs you design interactively. At this writing, Komodo is not free; it is available\\nat http://www.activestate.com.\\nNetBeans IDE for Python\\nNetBeans is a powerful open-source development environment GUI with support\\nfor many advanced features for Python developers: code completion, automatic\\nindentation and code colorization, editor hints, code folding, refactoring, debug-\\nging, code coverage and testing, projects, and more. It may be used to develop both\\nCPython and Jython code. Like Eclipse, NetBeans requires installation steps be-\\nyond those of the included IDLE GUI, but it is seen by many as more than worth\\nthe effort. Search the Web for the latest information and links.\\nPythonWin\\nPythonWin is a free Windows-only IDE for Python that ships as part of Active-\\nState’s ActivePython distribution (and may also be fetched separately from http://\\nwww.python.org resources). It is roughly like IDLE, with a handful of useful\\nWindows-specific extensions added; for example, PythonWin has support for\\nOther IDEs | 63', metadata={'source': 'python.pdf', 'page': 113}),\n",
       " Document(page_content='COM objects. Today, IDLE is probably more advanced than PythonWin (for in-\\nstance, IDLE’s dual-process \\narchitecture often prevents it from hanging). However,\\nPythonWin still offers tools for Windows developers that IDLE does not. See http:\\n//www.activestate.com for more information.\\nOthers\\nThere are roughly half a dozen other widely used IDEs that I’m aware of (including\\nthe commercial Wing IDE  and PythonCard) but do not have space to do justice to\\nhere, and more will probably appear over time. In fact, almost every programmer-\\nfriendly text editor has some sort of support for Python development these days,\\nwhether it be preinstalled or fetched separately. Emacs and Vim, for instance, have\\nsubstantial Python support.\\nI won’t try to document all such options here; for more information, see the re-\\nsources available at http://www.python.org or search the Web for “Python IDE.”\\nYou might also try running a web search for “Python editors”—today, this leads\\nyou to a wiki page that maintains information about many IDE and text-editor\\noptions for Python programming.\\nOther Launch Options\\nAt this point, we’ve seen how to run code typed interactively, and how to launch code\\nsaved in files in a variety of ways—system command lines, imports and execs, GUIs\\nlike IDLE, and more. That covers most of the cases you’ll see in this book. There are\\nadditional ways to run Python code, though, most of which have special or narrow\\nroles. The next few sections take a quick look at some of these.\\nEmbedding Calls\\nIn some specialized domains, Python code may be run automatically by an enclosing\\nsystem. In such cases, we say that the Python programs are embedded in (i.e., run by)\\nanother program. The Python code itself may be entered into a text file, stored in a\\ndatabase, fetched from an HTML page, parsed from an XML document, and so on.\\nBut from an operational perspective, another system—not you—may tell Python to\\nrun the code you’ve created.\\nSuch an embedded execution mode is commonly used to support end-user customi-\\nzation—a game program, for instance, might allow for play modifications by running\\nuser-accessible embedded Python code at strategic points in time. Users can modify\\nthis type of system by providing or changing Python code. Because Python code is\\ninterpreted, there is no need to recompile the entire system to incorporate the change\\n(see Chapter 2 for more on how Python code is run).\\n64 | Chapter 3: \\u2002How You Run Programs', metadata={'source': 'python.pdf', 'page': 114}),\n",
       " Document(page_content='In this mode, the enclosing system that runs your code might be written in C, C++, or\\neven Java when \\nthe Jython system is used. As an example, it’s possible to create and\\nrun strings of Python code from a C program by calling functions in the Python runtime\\nAPI (a set of services exported by the libraries created when Python is compiled on your\\nmachine):\\n#include <Python.h>\\n...\\nPy_Initialize();                                     // This is C, not Python\\nPyRun_SimpleString(\"x = \\'brave \\' + \\'sir robin\\'\");    // But it runs Python code\\nIn this C code snippet, a program coded in the C language embeds the Python inter-\\npreter by linking in its libraries, and passes it a Python assignment statement string to\\nrun. C programs may also gain access to Python modules and objects and process or\\nexecute them using other Python API tools.\\nThis book isn’t about Python/C integration, but you should be aware that, depending\\non how your organization plans to use Python, you may or may not be the one who\\nactually starts the Python programs you create. Regardless, you can usually still use the\\ninteractive and file-based launching techniques described here to test code in isolation\\nfrom those enclosing systems that may eventually use it.*\\nFrozen Binary Executables\\nFrozen binary executables, described in Chapter 2, are packages that combine your\\nprogram’s byte code and the Python interpreter into a single executable program. This\\napproach enables Python programs to be launched in the same ways that you would\\nlaunch any other executable program (icon clicks, command lines, etc.). While this\\noption works well for delivery of products, it is not really intended for use during pro-\\ngram development; you normally freeze just before shipping (after development is\\nfinished). See the prior chapter for more on this option.\\nText Editor Launch Options\\nAs mentioned previously, although they’re not full-blown IDE GUIs, most program-\\nmer-friendly text editors have support for editing, and possibly running, Python\\nprograms. Such support may be built in or fetchable on the Web. For instance, if you\\nare familiar with the Emacs text editor, you can do all your Python editing and launch-\\ning from inside that text editor. See the text editor resources page at http://www.python\\n.org/editors for more details, or search the Web for the phrase “Python editors.”\\n* See Programming Python  (O’Reilly) for more details on embedding Python in C/C++. The embedding API\\ncan call Python functions directly, load modules, and more. Also, note that the Jython system allows Java\\nprograms to invoke Python code using a Java-based API (a Python interpreter class).\\nOther Launch Options | 65', metadata={'source': 'python.pdf', 'page': 115}),\n",
       " Document(page_content='Still Other Launch Options\\nDepending on your \\nplatform, there may be additional ways that you can start Python\\nprograms. For instance, on some Macintosh systems you may be able to drag Python\\nprogram file icons onto the Python interpreter icon to make them execute, and on\\nWindows you can always start Python scripts with the Run... option in the Start menu.\\nAdditionally, the Python standard library has utilities that allow Python programs to\\nbe started by other Python programs in separate processes (e.g., os.popen, os.system),\\nand Python scripts might also be spawned in larger contexts like the Web (for instance,\\na web page might invoke a script on a server); however, these are beyond the scope of\\nthe present chapter.\\nFuture Possibilities?\\nThis chapter reflects current practice, but much of the material is both platform- and\\ntime-specific. Indeed, many of the execution and launch details presented arose during\\nthe shelf life of this book’s various editions. As with program execution options, it’s\\nnot impossible that new program launch options may arise over time.\\nNew operating systems, and new versions of existing systems, may also provide exe-\\ncution techniques beyond those outlined here. In general, because Python keeps pace\\nwith such changes, you should be able to launch Python programs in whatever way\\nmakes sense for the machines you use, both now and in the future—be that by drawing\\non tablet PCs or PDAs, grabbing icons in a virtual reality, or shouting a script’s name\\nover your coworkers’ conversations.\\nImplementation changes may also impact launch schemes somewhat (e.g., a full com-\\npiler could produce normal executables that are launched much like frozen binaries\\ntoday). If I knew what the future truly held, though, I would probably be talking to a\\nstockbroker instead of writing these words!\\nWhich Option Should I Use?\\nWith all these options, one question naturally arises: which one is best for me? In\\ngeneral, you should give the IDLE interface a try if you are just getting started with\\nPython. It provides a user-friendly GUI environment and hides some of the underlying\\nconfiguration details. It also comes with a platform-neutral text editor for coding your\\nscripts, and it’s a standard and free part of the Python system.\\nIf, on the other hand, you are an experienced programmer, you might be more com-\\nfortable with simply the text editor of your choice in one window, and another window\\nfor launching the programs you edit via system command lines and icon clicks (in fact,\\nthis is how I develop Python programs, but I have a Unix-biased past). Because the\\nchoice of development environments is very subjective, I can’t offer much more in the\\n66 | Chapter 3: \\u2002How You Run Programs', metadata={'source': 'python.pdf', 'page': 116}),\n",
       " Document(page_content='way of universal guidelines; in general, whatever environment you like to use will be\\nthe best for you to use.\\nDebugging Python Code\\nNaturally, none of \\nmy readers or students ever have bugs in their code ( insert smiley\\nhere), but for less fortunate friends of yours who may, here’s a quick look at the strat-\\negies commonly used by real-world Python programmers to debug code:\\n•Do nothing . By this, I don’t mean that Python programmers don’t debug their\\ncode—but when you make a mistake in a Python program, you get a very useful\\nand readable error message (you’ll get to see some soon, if you haven’t already).\\nIf you already know Python, and especially for your own code, this is often\\nenough—read the error message, and go fix the tagged line and file. For many, this\\nis debugging in Python. It may not always be ideal for larger system you didn’t\\nwrite, though.\\n•Insert print statements. Probably the main way that Python programmers debug\\ntheir code (and the way that I debug Python code) is to insert print statements and\\nrun again. Because Python runs immediately after changes, this is usually the\\nquickest way to get more information than error messages provide. The print\\nstatements don’t have to be sophisticated—a simple “I am here” or display of\\nvariable values is usually enough to provide the context you need. Just remember\\nto delete or comment out (i.e., add a # before) the debugging prints before you\\nship your code!\\n•Use IDE GUI debuggers . For larger systems you didn’t write, and for beginners\\nwho want to trace code in more detail, most Python development GUIs have some\\nsort of point-and-click debugging support. IDLE has a debugger too, but it doesn’t\\nappear to be used very often in practice—perhaps because it has no command line,\\nor perhaps because adding print statements is usually quicker than setting up a\\nGUI debugging session. To learn more, see IDLE’s Help, or simply try it on your\\nown; its basic interface is described in the section “Advanced IDLE\\nTools” on page 62. Other IDEs, such as Eclipse, NetBeans, Komodo, and Wing\\nIDE, offer advanced point-and-click debuggers as well; see their documentation if\\nyou use them.\\n•Use the pdb command-line debugger . For ultimate control, Python comes with\\na source-code debugger named pdb, available as a module in Python’s standard\\nlibrary. In pdb, you type commands to step line by line, display variables, set and\\nclear breakpoints, continue to a breakpoint or error, and so on. pdb can be\\nlaunched interactively by importing it, or as a top-level script. Either way, because\\nyou can type commands to control the session, it provides a powerful debugging\\ntool. pdb also includes a postmortem function you can run after an exception\\noccurs, to get information from the time of the error. See the Python library manual\\nand Chapter 35 for more details on pdb.\\n•Other options. For more specific debugging requirements, you can find additional\\ntools in the open source domain, including support for multithreaded programs,\\nembedded code, and process attachment. The Winpdb system, for example, is a\\nWhich Option Should I Use? | 67', metadata={'source': 'python.pdf', 'page': 117}),\n",
       " Document(page_content='standalone debugger with advanced debugging support and cross-platform GUI\\nand console interfaces.\\nThese options will \\nbecome more important as we start writing larger scripts. Prob-\\nably the best news on the debugging front, though, is that errors are detected and\\nreported in Python, rather than passing silently or crashing the system altogether.\\nIn fact, errors themselves are a well-defined mechanism known as exceptions,\\nwhich you can catch and process (more on exceptions in Part VII ). Making mis-\\ntakes is never fun, of course, but speaking as someone who recalls when debugging\\nmeant getting out a hex calculator and poring over piles of memory dump print-\\nouts, Python’s debugging support makes errors much less painful than they might\\notherwise be.\\nChapter Summary\\nIn this chapter, \\nwe’ve looked at common ways to launch Python programs: by running\\ncode typed interactively, and by running code stored in files with system command\\nlines, file-icon clicks, module imports, exec calls, and IDE GUIs such as IDLE. We’ve\\ncovered a lot of pragmatic startup territory here. This chapter’s goal was to equip you\\nwith enough information to enable you to start writing some code, which you’ll do in\\nthe next part of the book. There, we will start exploring the Python language itself,\\nbeginning with its core data types.\\nFirst, though, take the usual chapter quiz to exercise what you’ve learned here. Because\\nthis is the last chapter in this part of the book, it’s followed with a set of more complete\\nexercises that test your mastery of this entire part’s topics. For help with the latter set\\nof problems, or just for a refresher, be sure to turn to Appendix B after you’ve given\\nthe exercises a try.\\nTest Your Knowledge: Quiz\\n1. How can you start an interactive interpreter session?\\n2.Where do you type a system command line to launch a script file?\\n3.\\nName four or more ways to run the code saved in a script file.\\n4. Name two pitfalls related to clicking file icons on Windows.\\n5. Why might you need to reload a module?\\n6. How do you run a script from within IDLE?\\n7. Name two pitfalls related to using IDLE.\\n8. What is a namespace, and how does it relate to module files?\\n68 | Chapter 3: \\u2002How You Run Programs', metadata={'source': 'python.pdf', 'page': 118}),\n",
       " Document(page_content='Test Your Knowledge: Answers\\n1. You can start \\nan interactive session on Windows by clicking your Start button,\\npicking the All Programs option, clicking the Python entry, and selecting the “Py-\\nthon (command line)” menu option. You can also achieve the same effect on Win-\\ndows and other platforms by typing python as a system command line in your\\nsystem’s console window (a Command Prompt window on Windows). Another\\nalternative is to launch IDLE, as its main Python shell window is an interactive\\nsession. If you have not set your system’s PATH variable to find Python, you may\\nneed to cd to where Python is installed, or type its full directory path instead of just\\npython (e.g., C:\\\\Python30\\\\python on Windows).\\n2. You type system command lines in whatever your platform provides as a system\\nconsole: a Command Prompt window on Windows; an xterm or terminal window\\non Unix, Linux, and Mac OS X; and so on.\\n3. Code in a script (really, module) file can be run with system command lines, file\\nicon clicks, imports and reloads, the exec built-in function, and IDE GUI selections\\nsuch as IDLE’s Run→Run Module menu option. On Unix, they can also be run as\\nexecutables with the #! trick, and some platforms support more specialized launch-\\ning techniques (e.g., drag-and-drop). In addition, some text editors have unique\\nways to run Python code, some Python programs are provided as standalone “fro-\\nzen binary” executables, and some systems use Python code in embedded mode,\\nwhere it is run automatically by an enclosing program written in a language like\\nC, C++, or Java. The latter technique is usually done to provide a user customi-\\nzation layer.\\n4. Scripts that print and then exit cause the output file to disappear immediately,\\nbefore you can view the output (which is why the input trick comes in handy);\\nerror messages generated by your script also appear in an output window that\\ncloses before you can examine its contents (which is one reason that system com-\\nmand lines and IDEs such as IDLE are better for most development).\\n5. Python only imports (loads) a module once per process, by default, so if you’ve\\nchanged its source code and want to run the new version without stopping and\\nrestarting Python, you’ll have to reload it. You must import a module at least once\\nbefore you can reload it. Running files of code from a system shell command line,\\nvia an icon click, or via an IDE such as IDLE generally makes this a nonissue, as\\nthose launch schemes usually run the current version of the source code file each\\ntime.\\n6. Within the text edit window of the file you wish to run, select the window’s\\nRun→Run Module menu option. This runs the window’s source code as a top-level\\nscript file and displays its output back in the interactive Python shell window.\\n7. IDLE can still be hung by some types of programs—especially GUI programs that\\nperform multithreading (an advanced technique beyond this book’s scope). Also,\\nIDLE has some usability features that can burn you once you leave the IDLE GUI:\\nTest Your Knowledge: Answers | 69', metadata={'source': 'python.pdf', 'page': 119}),\n",
       " Document(page_content='a script’s variables are automatically imported to the interactive scope in IDLE, for\\ninstance, but not by Python in general.\\n8. A namespace is \\njust a package of variables (i.e., names). It takes the form of an\\nobject with attributes in Python. Each module file is automatically a namespace—\\nthat is, a package of variables reflecting the assignments made at the top level of\\nthe file. Namespaces help avoid name collisions in Python programs: because each\\nmodule file is a self-contained namespace, files must explicitly import other files\\nin order to use their names.\\nTest Your Knowledge: Part I Exercises\\nIt’s time to start doing a little coding on your own. This first exercise session is fairly\\nsimple, but a few of these questions hint at topics to come in later chapters. Be sure to\\ncheck “Part I, Getting Started” on page 1101 in the solutions appendix ( Appendix B )\\nfor the answers; the exercises and their solutions sometimes contain supplemental in-\\nformation not discussed in the main text, so you should take a peek at the solutions\\neven if you manage to answer all the questions on your own.\\n1.Interaction. Using a system command line, IDLE, or another method, start the\\nPython interactive command line ( >>> prompt), and type the expression \"Hello\\nWorld!\" (including the quotes). The string should be echoed back to you. The\\npurpose of this exercise is to get your environment configured to run Python. In\\nsome scenarios, you may need to first run a cd shell command, type the full path\\nto the Python executable, or add its path to your PATH environment variable. If\\ndesired, you can set PATH in your .cshrc or .kshrc file to make Python permanently\\navailable on Unix systems; on Windows, use a setup.bat, autoexec.bat, or the en-\\nvironment variable GUI. See Appendix A for help with environment variable\\nsettings.\\n2.Programs. With the text editor of your choice, write a simple module file containing\\nthe single statement print(\\'Hello module world!\\') and store it as module1.py.\\nNow, run this file by using any launch option you like: running it in IDLE, clicking\\non its file icon, passing it to the Python interpreter on the system shell’s command\\nline (e.g., python module1.py ), built-in exec calls, imports and reloads, and so on.\\nIn fact, experiment by running your file with as many of the launch techniques\\ndiscussed in this chapter as you can. Which technique seems easiest? (There is no\\nright answer to this, of course.)\\n3.Modules. Start the Python interactive command line ( >>> prompt) and import the\\nmodule you wrote in exercise 2. Try moving the file to a different directory and\\nimporting it again from its original directory (i.e., run Python in the original di-\\nrectory when you import). What happens? (Hint: is there still a module1.pyc byte\\ncode file in the original directory?)\\n70 | Chapter 3: \\u2002How You Run Programs', metadata={'source': 'python.pdf', 'page': 120}),\n",
       " Document(page_content='4.Scripts. If your platform supports it, add the #! line to the top of your\\nmodule1.py module file, give the file executable privileges, and run it directly as an\\nexecutable. What does the first line need to contain? #! usually only has meaning\\non Unix, Linux, and Unix-like platforms such as Mac OS X; if you’re working on\\nWindows, instead try running your file by listing just its name in a DOS console\\nwindow without the word “python” before it (this works on recent versions of\\nWindows), or via the Start→Run... dialog box.\\n5.Errors and debugging . Experiment with typing mathematical expressions and as-\\nsignments at the Python interactive command line. Along the way, type the ex-\\npressions 2 ** 500 and 1 / 0, and reference an undefined variable name as we did\\nin this chapter. What happens?\\nYou may not know it yet, but when you make a mistake, you’re doing exception\\nprocessing (a topic we’ll explore in depth in Part VII). As you’ll learn there, you\\nare technically triggering what’s known as the default exception handler—logic that\\nprints a standard error message. If you do not catch an error, the default handler\\ndoes and prints the standard error message in response.\\nExceptions are also bound up with the notion of debugging in Python. When you’re\\nfirst starting out, Python’s default error messages on exceptions will probably pro-\\nvide as much error-handling support as you need—they give the cause of the error,\\nas well as showing the lines in your code that were active when the error occurred.\\nFor more about debugging, see the sidebar “Debugging Python Code”\\non page 67.\\n6.Breaks and cycles. At the Python command line, type:\\nL = [1, 2]              # Make a 2-item list\\nL.append(L)             # Append L as a single item to itself\\nL                       # Print L\\nWhat happens? In all recent versions of Python, you’ll see a strange output that\\nwe’ll describe in the solutions appendix, and which will make more sense when\\nwe study references in the next part of the book. If you’re using a Python version\\nolder than 1.5.1, a Ctrl-C key combination will probably help on most platforms.\\nWhy do you think your version of Python responds the way it does for this code?\\nIf you do have a Python older than Release 1.5.1 (a hopefully rare\\nscenario today!), make \\nsure your machine can stop a program with\\na Ctrl-C key combination of some sort before running this test, or\\nyou may be waiting a long time.\\n7.Documentation. Spend at least 17 minutes browsing the Python library and lan-\\nguage manuals before moving on to get a feel for the available tools in the standard\\nlibrary and the structure of the documentation set. It takes at least this long to\\nbecome familiar with the locations of major topics in the manual set; once you’ve\\ndone this, it’s easy to find what you need. You can find this manual via the Python\\nTest Your Knowledge: Part I Exercises | 71', metadata={'source': 'python.pdf', 'page': 121}),\n",
       " Document(page_content='Start button entry on Windows, in the Python Docs option on the Help pull-down\\nmenu in IDLE, \\nor online at http://www.python.org/doc. I’ll also have a few more\\nwords to say about the manuals and other documentation sources available (in-\\ncluding PyDoc and the help function) in Chapter 15 . If you still have time, go\\nexplore the Python website, as well as its PyPy third-party extension repository.\\nEspecially check out the Python.org documentation and search pages; they can be\\ncrucial resources.\\n72 | Chapter 3: \\u2002How You Run Programs', metadata={'source': 'python.pdf', 'page': 122}),\n",
       " Document(page_content='PART II\\nTypes and Operations', metadata={'source': 'python.pdf', 'page': 123}),\n",
       " Document(page_content='', metadata={'source': 'python.pdf', 'page': 124}),\n",
       " Document(page_content='CHAPTER 4\\nIntroducing Python Object Types\\nThis chapter begins our tour of the Python language. In an informal sense, in Python,\\nwe do things \\nwith stuff. “Things” take the form of operations like addition and con-\\ncatenation, and “stuff” refers to the objects on which we perform those operations. In\\nthis part of the book, our focus is on that stuff, and the things our programs can do\\nwith it.\\nSomewhat more formally, in Python, data takes the form of objects—either built-in\\nobjects that Python provides, or objects we create using Python or external language\\ntools such as C extension libraries. Although we’ll firm up this definition later, objects\\nare essentially just pieces of memory, with values and sets of associated operations.\\nBecause objects are the most fundamental notion in Python programming, we’ll start\\nthis chapter with a survey of Python’s built-in object types.\\nBy way of introduction, however, let’s first establish a clear picture of how this chapter\\nfits into the overall Python picture. From a more concrete perspective, Python programs\\ncan be decomposed into modules, statements, expressions, and objects, as follows:\\n1. Programs are composed of modules.\\n2. Modules contain statements.\\n3. Statements contain expressions.\\n4.Expressions create and process objects.\\nThe discussion of modules in Chapter 3  introduced the highest level of this hierarchy.\\nThis part’s chapters begin at the bottom, exploring both built-in objects and the ex-\\npressions you can code to use them.\\n75', metadata={'source': 'python.pdf', 'page': 125}),\n",
       " Document(page_content='Why Use Built-in Types?\\nIf you’ve used \\nlower-level languages such as C or C++, you know that much of your\\nwork centers on implementing objects—also known as data structures —to represent\\nthe components in your application’s domain. You need to lay out memory structures,\\nmanage memory allocation, implement search and access routines, and so on. These\\nchores are about as tedious (and error-prone) as they sound, and they usually distract\\nfrom your program’s real goals.\\nIn typical Python programs, most of this grunt work goes away. Because Python pro-\\nvides powerful object types as an intrinsic part of the language, there’s usually no need\\nto code object implementations before you start solving problems. In fact, unless you\\nhave a need for special processing that built-in types don’t provide, you’re almost al-\\nways better off using a built-in object instead of implementing your own. Here are some\\nreasons why:\\n•Built-in objects make programs easy to write . For simple tasks, built-in types\\nare often all you need to represent the structure of problem domains. Because you\\nget powerful tools such as collections (lists) and search tables (dictionaries) for free,\\nyou can use them immediately. You can get a lot of work done with Python’s built-\\nin object types alone.\\n•Built-in objects are components of extensions . For more complex tasks, you\\nmay need to provide your own objects using Python classes or C language inter-\\nfaces. But as you’ll see in later parts of this book, objects implemented manually\\nare often built on top of built-in types such as lists and dictio naries. For instance,\\na stack data structure may be implemented as a class that manages or customizes\\na built-in list.\\n•Built-in objects are often more efficient than custom data structures . Py-\\nthon’s built-in types employ already optimized data structure algorithms that are\\nimplemented in C for speed. Although you can write similar object types on your\\nown, you’ll usually be hard-pressed to get the level of performance built-in object\\ntypes provide.\\n•Built-in objects are a standard part of the language . In some ways, Python\\nborrows both from languages that rely on built-in tools (e.g., LISP) and languages\\nthat rely on the programmer to provide tool implementations or frameworks of\\ntheir own (e.g., C++). Although you can implement unique object types in Python,\\nyou don’t need to do so just to get started. Moreover, because Python’s built-ins\\nare standard, they’re always the same; proprietary frameworks, on the other hand,\\ntend to differ from site to site.\\nIn other words, not only do built-in object types make programming easier, but they’re\\nalso more powerful and efficient than most of what can be created from scratch. Re-\\ngardless of whether you implement new object types, built-in objects form the core of\\nevery Python program.\\n76 | Chapter 4: \\u2002Introducing Python Object Types', metadata={'source': 'python.pdf', 'page': 126}),\n",
       " Document(page_content='Python’s Core Data Types\\nTable 4-1  previews Python’s \\nbuilt-in object types and some of the syntax used to code\\ntheir literals—that is, the expressions that generate these objects.* Some of these types\\nwill probably seem familiar if you’ve used other languages; for instance, numbers and\\nstrings represent numeric and textual values, respectively, and files provide an interface\\nfor processing files stored on your computer.\\nTable 4-1. Built-in objects preview\\nObject type Example literals/creation\\nNumbers 1234, 3.1415, 3+4j, Decimal, Fraction\\nStrings \\'spam\\', \"guido\\'s\", b\\'a\\\\x01c\\'\\nLists [1, [2, \\'three\\'], 4]\\nDictionaries {\\'food\\': \\'spam\\', \\'taste\\': \\'yum\\'}\\nTuples (1, \\'spam\\', 4, \\'U\\')\\nFiles myfile = open(\\'eggs\\', \\'r\\')\\nSets set(\\'abc\\'), {\\'a\\', \\'b\\', \\'c\\'}\\nOther core types Booleans, types, None\\nProgram unit types Functions, modules, classes (Part IV, Part V, Part VI)\\nImplementation-related types Compiled code, stack tracebacks (Part IV, Part VII)\\nTable 4-1  isn’t really complete, because everything we process in Python programs is a\\nkind of object. For instance, when we perform text pattern matching in Python, we\\ncreate pattern objects, and when we perform network scripting, we use socket objects.\\nThese other kinds of objects are generally created by importing and using modules and\\nhave behavior all their own.\\nAs we’ll see in later parts of the book, program units  such as functions, modules, and\\nclasses are objects in Python too—they are created with statements and expressions\\nsuch as def, class, import, and lambda and may be passed around scripts freely, stored\\nwithin other objects, and so on. Python also provides a set of implementation-related\\ntypes such as compiled code objects, which are generally of interest to tool builders\\nmore than application developers; these are also discussed in later parts of this text.\\nWe usually call the other object types in Table 4-1  core data types, though, because\\nthey are effectively built into the Python language—that is, there is specific expression\\nsyntax for generating most of them. For instance, when you run the following code:\\n>>> \\'spam\\'\\n* In this book, the term literal simply means an expression whose syntax generates an object—sometimes also\\ncalled a constant. Note that the term “constant” does not imply objects or variables that can never be changed\\n(i.e., this term is unrelated to C++’s const or Python’s “immutable”—a topic explored in the section\\n“Immutability” on page 82).\\nWhy Use Built-in Types? | 77', metadata={'source': 'python.pdf', 'page': 127}),\n",
       " Document(page_content='you are, technically speaking, running a literal expression that generates and returns a\\nnew string object. \\nThere is specific Python language syntax to make this object. Simi-\\nlarly, an expression wrapped in square brackets makes a list, one in curly braces makes\\na dictionary, and so on. Even though, as we’ll see, there are no type declarations in\\nPython, the syntax of the expressions you run determines the types of objects you create\\nand use. In fact, object-generation expressions like those in Table 4-1 are generally\\nwhere types originate in the Python language.\\nJust as importantly, once you create an object, you bind its operation set for all time—\\nyou can perform only string operations on a string and list operations on a list. As you’ll\\nlearn, Python is dynamically typed (it keeps track of types for you automatically instead\\nof requiring declaration code), but it is also strongly typed (you can perform on an object\\nonly operations that are valid for its type).\\nFunctionally, the object types in Table 4-1 are more general and powerful than what\\nyou may be accustomed to. For instance, you’ll find that lists and dictionaries alone\\nare powerful data representation tools that obviate most of the work you do to support\\ncollections and searching in lower-level languages. In short, lists provide ordered col-\\nlections of other objects, while dictionaries store objects by key; both lists and dic-\\ntionaries may be nested, can grow and shrink on demand, and may contain objects of\\nany type.\\nWe’ll study each of the object types in Table 4-1 in detail in upcoming chapters. Before\\ndigging into the details, though, let’s begin by taking a quick look at Python’s core\\nobjects in action. The rest of this chapter provides a preview of the operations we’ll\\nexplore in more depth in the chapters that follow. Don’t expect to find the full story\\nhere—the goal of this chapter is just to whet your appetite and introduce some key\\nideas. Still, the best way to get started is to get started, so let’s jump right into some\\nreal code.\\nNumbers\\nIf you’ve done any programming or scripting in the past, some of the object types in\\nTable 4-1  will probably seem familiar. Even if you haven’t, numbers are fairly straight-\\nforward. Python’s core objects set includes the usual suspects: integers (numbers with-\\nout a fractional part), floating-point numbers (roughly, numbers with a decimal point\\nin them), and more exotic numeric types (complex numbers with imaginary parts,\\nfixed-precision decimals, rational fractions with numerator and denominator, and full-\\nfeatured sets).\\nAlthough it offers some fancier options, Python’s basic number types are, well, basic.\\nNumbers in Python support the normal mathematical operations. For instance, the\\nplus sign ( +) performs addition, a star ( *) is used for multiplication, and two stars ( **)\\nare used for exponentiation:\\n78 | Chapter 4: \\u2002Introducing Python Object Types', metadata={'source': 'python.pdf', 'page': 128}),\n",
       " Document(page_content='>>> 123 + 222                    # Integer addition\\n345\\n>>> 1.5 * 4                      # Floating-point multiplication\\n6.0\\n>>> 2 ** 100                     # 2 to the power 100\\n1267650600228229401496703205376\\nNotice the last \\nresult here: Python 3.0’s integer type automatically provides extra pre-\\ncision for large numbers like this when needed (in 2.6, a separate long integer type\\nhandles numbers too large for the normal integer type in similar ways). You can, for\\ninstance, compute 2 to the power 1,000,000 as an integer in Python, but you probably\\nshouldn’t try to print the result—with more than 300,000 digits, you may be waiting\\nawhile!\\n>>> len(str(2 ** 1000000))       # How many digits in a really BIG number?\\n301030\\nOnce you start experimenting with floating-point numbers, you’re likely to stumble\\nacross something that may look a bit odd on first glance:\\n>>> 3.1415 * 2                   # repr: as code\\n6.2830000000000004\\n>>> print(3.1415 * 2)            # str: user-friendly\\n6.283\\nThe first result isn’t a bug; it’s a display issue. It turns out that there are two ways to\\nprint every object: with full precision (as in the first result shown here), and in a user-\\nfriendly form (as in the second). Formally, the first form is known as an object’s as-\\ncode repr, and the second is its user-friendly str. The difference can matter when we\\nstep up to using classes; for now, if something looks odd, try showing it with a print\\nbuilt-in call statement.\\nBesides expressions, there are a handful of useful numeric modules that ship with\\nPython—modules are just packages of additional tools that we import to use:\\n>>> import math\\n>>> math.pi\\n3.1415926535897931\\n>>> math.sqrt(85)\\n9.2195444572928871\\nThe math module contains more advanced numeric tools as functions, while the\\nrandom module performs random number generation and random selections (here, from\\na Python list, introduced later in this chapter):\\n>>> import random\\n>>> random.random()\\n0.59268735266273953\\n>>> random.choice([1, 2, 3, 4])\\n1\\nPython also includes more exotic numeric objects—such as complex, fixed-precision,\\nand rational numbers, as well as sets and Booleans—and the third-party open source\\nNumbers | 79', metadata={'source': 'python.pdf', 'page': 129}),\n",
       " Document(page_content=\"extension domain has even more (e.g., matrixes and vectors). We’ll defer discussion of\\nthese types until later in the book.\\nSo far, we’ve \\nbeen using Python much like a simple calculator; to do better justice to\\nits built-in types, let’s move on to explore strings.\\nStrings\\nStrings are used to record textual information as well as arbitrary collections of bytes.\\nThey are our first example of what we call a sequence in Python—that is, a positionally\\nordered collection of other objects. Sequences maintain a left-to-right order among the\\nitems they contain: their items are stored and fetched by their relative position. Strictly\\nspeaking, strings are sequences of one-character strings; other types of sequences in-\\nclude lists and tuples, covered later.\\nSequence Operations\\nAs sequences, strings support operations that assume a positional ordering among\\nitems. For example, if we have a four-character string, we can verify its length with the\\nbuilt-in len function and fetch its components with indexing expressions:\\n>>> S = 'Spam'\\n>>> len(S)               # Length\\n4\\n>>> S[0]                 # The first item in S, indexing by zero-based position\\n'S'\\n>>> S[1]                 # The second item from the left\\n'p'\\nIn Python, indexes are coded as offsets from the front, and so start from 0: the first item\\nis at index 0, the second is at index 1, and so on.\\nNotice how we assign the string to a variable named S here. We’ll go into detail on how\\nthis works later (especially in Chapter 6 ), but Python variables never need to be declared\\nahead of time. A variable is created when you assign it a value, may be assigned any\\ntype of object, and is replaced with its value when it shows up in an expression. It must\\nalso have been previously assigned by the time you use its value. For the purposes of\\nthis chapter, it’s enough to know that we need to assign an object to a variable in order\\nto save it for later use.\\nIn Python, we can also index backward, from the end—positive indexes count from\\nthe left, and negative indexes count back from the right:\\n>>> S[-1]                # The last item from the end in S\\n'm'\\n>>> S[-2]                # The second to last item from the end\\n'a'\\n80 | Chapter 4: \\u2002Introducing Python Object Types\", metadata={'source': 'python.pdf', 'page': 130}),\n",
       " Document(page_content=\"Formally, a negative index is simply added to the string’s size, so the following two\\noperations are equivalent \\n(though the first is easier to code and less easy to get wrong):\\n>>> S[-1]                # The last item in S\\n'm'\\n>>> S[len(S)-1]          # Negative indexing, the hard way\\n'm'\\nNotice that we can use an arbitrary expression in the square brackets, not just a hard-\\ncoded number literal—anywhere that Python expects a value, we can use a literal, a\\nvariable, or any expression. Python’s syntax is completely general this way.\\nIn addition to simple positional indexing, sequences also support a more general form\\nof indexing known as slicing, which is a way to extract an entire section (slice) in a single\\nstep. For example:\\n>>> S                     # A 4-character string\\n'Spam'\\n>>> S[1:3]                # Slice of S from offsets 1 through 2 (not 3)\\n'pa'\\nProbably the easiest way to think of slices is that they are a way to extract an entire\\ncolumn from a string in a single step. Their general form, X[I:J], means “give me ev-\\nerything in X from offset I up to but not including offset J.” The result is returned in a\\nnew object. The second of the preceding operations, for instance, gives us all the char-\\nacters in string S from offsets 1 through 2 (that is, 3 – 1) as a new string. The effect is\\nto slice or “parse out” the two characters in the middle.\\nIn a slice, the left bound defaults to zero, and the right bound defaults to the length of\\nthe sequence being sliced. This leads to some common usage variations:\\n>>> S[1:]                 # Everything past the first (1:len(S))\\n'pam'\\n>>> S                     # S itself hasn't changed\\n'Spam'\\n>>> S[0:3]                # Everything but the last\\n'Spa'\\n>>> S[:3]                 # Same as S[0:3]\\n'Spa'\\n>>> S[:-1]                # Everything but the last again, but simpler (0:-1)\\n'Spa'\\n>>> S[:]                  # All of S as a top-level copy (0:len(S))\\n'Spam'\\nNote how negative offsets can be used to give bounds for slices, too, and how the last\\noperation effectively copies the entire string. As you’ll learn later, there is no reason to\\ncopy a string, but this form can be useful for sequences like lists.\\nFinally, as sequences, strings also support concatenation with the plus sign (joining two\\nstrings into a new string) and repetition (making a new string by repeating another):\\n>>> S\\nSpam'\\n>>> S + 'xyz'             # Concatenation\\nStrings | 81\", metadata={'source': 'python.pdf', 'page': 131}),\n",
       " Document(page_content=\"'Spamxyz'\\n>>> S                     # S is unchanged\\n'Spam'\\n>>> S * 8                 # Repetition\\n'SpamSpamSpamSpamSpamSpamSpamSpam'\\nNotice that the \\nplus sign ( +) means different things for different objects: addition for\\nnumbers, and concatenation for strings. This is a general property of Python that we’ll\\ncall polymorphism later in the book—in sum, the meaning of an operation depends on\\nthe objects being operated on. As you’ll see when we study dynamic typing, this poly-\\nmorphism property accounts for much of the conciseness and flexibility of Python code.\\nBecause types aren’t constrained, a Python-coded operation can normally work on\\nmany different types of objects automatically, as long as they support a compatible\\ninterface (like the + operation here). This turns out to be a huge idea in Python; you’ll\\nlearn more about it later on our tour.\\nImmutability\\nNotice that in the prior examples, we were not changing the original string with any of\\nthe operations we ran on it. Every string operation is defined to produce a new string\\nas its result, because strings are immutable in Python—they cannot be changed in-place\\nafter they are created. For example, you can’t change a string by assigning to one of its\\npositions, but you can always build a new one and assign it to the same name. Because\\nPython cleans up old objects as you go (as you’ll see later), this isn’t as inefficient as it\\nmay sound:\\n>>> S\\n'Spam'\\n>>> S[0] = 'z'             # Immutable objects cannot be changed\\n...error text omitted...\\nTypeError: 'str' object does not support item assignment\\n>>> S = 'z' + S[1:]        # But we can run expressions to make new objects\\n>>> S\\n'zpam'\\nEvery object in Python is classified as either immutable (unchangeable) or not. In terms\\nof the core types, numbers, strings, and tuples are immutable; lists and dictionaries are\\nnot (they can be changed in-place freely). Among other things, immutability can be\\nused to guarantee that an object remains constant throughout your program.\\nType-Specific Methods\\nEvery string operation we’ve studied so far is really a sequence operation—that is, these\\noperations will work on other sequences in Python as well, including lists and tuples.\\nIn addition to generic sequence operations, though, strings also have operations all\\ntheir own, available as methods—functions attached to the object, which are triggered\\nwith a call expression.\\n82 | Chapter 4: \\u2002Introducing Python Object Types\", metadata={'source': 'python.pdf', 'page': 132}),\n",
       " Document(page_content=\"For example, the string find method is the basic substring search operation (it returns\\nthe offset of the passed-in substring, or −1 if it is not present), and the string replace\\nmethod performs global searches and replacements:\\n>>> S.find('pa')            # Find the offset of a substring\\n1\\n>>> S\\n'Spam'\\n>>> S.replace('pa', 'XYZ')  # Replace occurrences of a substring with another\\n'SXYZm'\\n>>> S\\n'Spam'\\nAgain, despite the names of these string methods, we are not changing the original\\nstrings here, but creating new strings as the results—because strings are immutable,\\nwe have to do it this way. String methods are the first line of text-processing tools in\\nPython. Other methods split a string into substrings on a delimiter (handy as a simple\\nform of parsing), perform case conversions, test the content of the string (digits, letters,\\nand so on), and strip whitespace characters off the ends of the string:\\n>>> line = 'aaa,bbb,ccccc,dd'\\n>>> line.split(',')          # Split on a delimiter into a list of substrings\\n['aaa', 'bbb', 'ccccc', 'dd']\\n>>> S = 'spam'\\n>>> S.upper()                # Upper- and lowercase conversions\\n'SPAM'\\n>>> S.isalpha()              # Content tests: isalpha, isdigit, etc.\\nTrue\\n>>> line = 'aaa,bbb,ccccc,dd\\\\n'\\n>>> line = line.rstrip()     # Remove whitespace characters on the right side\\n>>> line\\n'aaa,bbb,ccccc,dd'\\nStrings also support an advanced substitution operation known as formatting, available\\nas both an expression (the original) and a string method call (new in 2.6 and 3.0):\\n>>> '%s, eggs, and %s' % ('spam', 'SPAM!')          # Formatting expression (all)\\n'spam, eggs, and SPAM!'\\n>>> '{0}, eggs, and {1}'.format('spam', 'SPAM!')    # Formatting method (2.6, 3.0)\\n'spam, eggs, and SPAM!'\\nOne note here: although sequence operations are generic, methods are not—although\\nsome types share some method names, string method operations generally work only\\non strings, and nothing else. As a rule of thumb, Python’s toolset is layered: generic\\noperations that span multiple types show up as built-in functions or expressions (e.g.,\\nlen(X), X[0]), but type-specific operations are method calls (e.g., aString.upper()).\\nFinding the tools you need among all these categories will become more natural as you\\nuse Python more, but the next section gives a few tips you can use right now.\\nStrings | 83\", metadata={'source': 'python.pdf', 'page': 133}),\n",
       " Document(page_content=\"Getting Help\\nThe methods introduced \\nin the prior section are a representative, but small, sample of\\nwhat is available for string objects. In general, this book is not exhaustive in its look at\\nobject methods. For more details, you can always call the built-in dir function, which\\nreturns a list of all the attributes available for a given object. Because methods are\\nfunction attributes, they will show up in this list. Assuming S is still the string, here are\\nits attributes on Python 3.0 (Python 2.6 varies slightly):\\n>>> dir(S)\\n['__add__', '__class__', '__contains__', '__delattr__', '__doc__', '__eq__',\\n'__format__', '__ge__', '__getattribute__', '__getitem__', '__getnewargs__',\\n'__gt__', '__hash__', '__init__', '__iter__', '__le__', '__len__', '__lt__',\\n'__mod__', '__mul__', '__ne__', '__new__', '__reduce__', '__reduce_ex__',\\n'__repr__', '__rmod__', '__rmul__', '__setattr__', '__sizeof__', '__str__',\\n'__subclasshook__', '_formatter_field_name_split', '_formatter_parser',\\n'capitalize', 'center', 'count', 'encode', 'endswith', 'expandtabs', 'find',\\n'format', 'index', 'isalnum','isalpha', 'isdecimal', 'isdigit', 'isidentifier',\\n'islower', 'isnumeric', 'isprintable', 'isspace', 'istitle', 'isupper', 'join',\\n'ljust', 'lower', 'lstrip', 'maketrans', 'partition', 'replace', 'rfind',\\n'rindex', 'rjust', 'rpartition', 'rsplit', 'rstrip', 'split', 'splitlines',\\n'startswith', 'strip', 'swapcase', 'title', 'translate', 'upper', 'zfill']\\nYou probably won’t care about the names with underscores in this list until later in the\\nbook, when we study operator overloading in classes—they represent the implemen-\\ntation of the string object and are available to support customization. In general, leading\\nand trailing double underscores is the naming pattern Python uses for implementation\\ndetails. The names without the underscores in this list are the callable methods on string\\nobjects.\\nThe dir function simply gives the methods’ names. To ask what they do, you can pass\\nthem to the help function:\\n>>> help(S.replace)\\nHelp on built-in function replace:\\nreplace(...)\\n    S.replace (old, new[, count]) -> str\\n    Return a copy of S with all occurrences of substring\\n    old replaced by new.  If the optional argument count is\\n    given, only the first count occurrences are replaced.\\nhelp is one of a handful of interfaces to a system of code that ships with Python known\\nas PyDoc—a tool for extracting documentation from objects. Later in the book, you’ll\\nsee that PyDoc can also render its reports in HTML format.\\nYou can also ask for help on an entire string (e.g., help(S)), but you may get more help\\nthan you want to see—i.e., information about every string method. It’s generally better\\nto ask about a specific method.\\n84 | Chapter 4: \\u2002Introducing Python Object Types\", metadata={'source': 'python.pdf', 'page': 134}),\n",
       " Document(page_content='For more details, you can also consult Python’s standard library reference manual or\\ncommercially published reference \\nbooks, but dir and help are the first line of docu-\\nmentation in Python.\\nOther Ways to Code Strings\\nSo far, we’ve looked at the string object’s sequence operations and type-specific meth-\\nods. Python also provides a variety of ways for us to code strings, which we’ll explore\\nin greater depth later. For instance, special characters can be represented as backslash\\nescape sequences:\\n>>> S = \\'A\\\\nB\\\\tC\\'            # \\\\n is end-of-line, \\\\t is tab\\n>>> len(S)                   # Each stands for just one character\\n5\\n>>> ord(\\'\\\\n\\')                # \\\\n is a byte with the binary value 10 in ASCII\\n10\\n>>> S = \\'A\\\\0B\\\\0C\\'            # \\\\0, a binary zero byte, does not terminate string\\n>>> len(S)\\n5\\nPython allows strings to be enclosed in single or double quote characters (they mean\\nthe same thing). It also allows multiline string literals enclosed in triple quotes (single\\nor double)—when this form is used, all the lines are concatenated together, and end-\\nof-line characters are added where line breaks appear. This is a minor syntactic con-\\nvenience, but it’s useful for embedding things like HTML and XML code in a Python\\nscript:\\n>>> msg = \"\"\" aaaaaaaaaaaaa\\nbbb\\'\\'\\'bbbbbbbbbb\"\"bbbbbbb\\'bbbb\\ncccccccccccccc\"\"\"\\n>>> msg\\n\\'\\\\naaaaaaaaaaaaa\\\\nbbb\\\\\\'\\\\\\'\\\\\\'bbbbbbbbbb\"\"bbbbbbb\\\\\\'bbbb\\\\ncccccccccccccc\\'\\nPython also supports a raw string literal that turns off the backslash escape mechanism\\n(such string literals start with the letter r), as well as Unicode string support that sup-\\nports internationalization. In 3.0, the basic str string type handles Unicode too (which\\nmakes sense, given that ASCII text is a simple kind of Unicode), and a bytes type\\nrepresents raw byte strings; in 2.6, Unicode is a separate type, and str handles both 8-\\nbit strings and binary data. Files are also changed in 3.0 to return and accept str for\\ntext and bytes for binary data. We’ll meet all these special string forms in later chapters.\\nPattern Matching\\nOne point worth noting before we move on is that none of the string object’s methods\\nsupport pattern-based text processing. Text pattern matching is an advanced tool out-\\nside this book’s scope, but readers with backgrounds in other scripting languages may\\nbe interested to know that to do pattern matching in Python, we import a module called \\nStrings | 85', metadata={'source': 'python.pdf', 'page': 135}),\n",
       " Document(page_content=\"re. This module has analogous calls for searching, splitting, and replacement, but be-\\ncause we can use patterns to specify substrings, we can be much more general:\\n>>> import re\\n>>> \\nmatch = re.match('Hello[ \\\\t]*(.*)world', 'Hello    Python world')\\n>>> match.group(1)\\n'Python '\\nThis example searches for a substring that begins with the word “Hello,” followed by\\nzero or more tabs or spaces, followed by arbitrary characters to be saved as a matched\\ngroup, terminated by the word “world.” If such a substring is found, portions of the\\nsubstring matched by parts of the pattern enclosed in parentheses are available as\\ngroups. The following pattern, for example, picks out three groups separated by\\nslashes:\\n>>> match = re.match('/(.*)/(.*)/(.*)', '/usr/home/lumberjack')\\n>>> match.groups()\\n('usr', 'home', 'lumberjack')\\nPattern matching is a fairly advanced text-processing tool by itself, but there is also\\nsupport in Python for even more advanced language processing, including natural lan-\\nguage processing. I’ve already said enough about strings for this tutorial, though, so\\nlet’s move on to the next type.\\nLists\\nThe Python list object is the most general sequence provided by the language. Lists are\\npositionally ordered collections of arbitrarily typed objects, and they have no fixed size.\\nThey are also mutable—unlike strings, lists can be modified in-place by assignment to\\noffsets as well as a variety of list method calls.\\nSequence Operations\\nBecause they are sequences, lists support all the sequence operations we discussed for\\nstrings; the only difference is that the results are usually lists instead of strings. For\\ninstance, given a three-item list:\\n>>> L = [123, 'spam', 1.23]          # A list of three different-type objects\\n>>> len(L)                           # Number of items in the list\\n3\\nwe can index, slice, and so on, just as for strings:\\n>>> L[0]                             # Indexing by position\\n123\\n>>> L[:-1]                           # Slicing a list returns a new list\\n[123, 'spam']\\n>>> L + [4, 5, 6]                    # Concatenation makes a new list too\\n[123, 'spam', 1.23, 4, 5, 6]\\n86 | Chapter 4: \\u2002Introducing Python Object Types\", metadata={'source': 'python.pdf', 'page': 136}),\n",
       " Document(page_content='>>> L                                # We\\'re not changing the original list\\n[123, \\'spam\\', 1.23]\\nType-Specific Operations\\nPython’s lists are \\nrelated to arrays in other languages, but they tend to be more powerful.\\nFor one thing, they have no fixed type constraint—the list we just looked at, for ex-\\nample, contains three objects of completely different types (an integer, a string, and a\\nfloating-point number). Further, lists have no fixed size. That is, they can grow and\\nshrink on demand, in response to list-specific operations:\\n>>> L.append(\\'NI\\')                  # Growing: add object at end of list\\n>>> L\\n[123, \\'spam\\', 1.23, \\'NI\\']\\n>>> L.pop(2)                        # Shrinking: delete an item in the middle\\n1.23\\n>>> L                               # \"del L[2]\" deletes from a list too\\n[123, \\'spam\\', \\'NI\\']\\nHere, the list append method expands the list’s size and inserts an item at the end; the \\npop method (or an equivalent del statement) then removes an item at a given offset,\\ncausing the list to shrink. Other list methods insert an item at an arbitrary position\\n(insert), remove a given item by value (remove), and so on. Because lists are mutable,\\nmost list methods also change the list object in-place, instead of creating a new one:\\n>>> M = [\\'bb\\', \\'aa\\', \\'cc\\']\\n>>> M.sort()\\n>>> M\\n[\\'aa\\', \\'bb\\', \\'cc\\']\\n>>> M.reverse()\\n>>> M\\n[\\'cc\\', \\'bb\\', \\'aa\\']\\nThe list sort method here, for example, orders the list in ascending fashion by default,\\nand reverse reverses it—in both cases, the methods modify the list directly.\\nBounds Checking\\nAlthough lists have no fixed size, Python still doesn’t allow us to reference items that\\nare not present. Indexing off the end of a list is always a mistake, but so is assigning off\\nthe end:\\n>>> L\\n[123, \\'spam\\', \\'NI\\']\\n>>> L[99]\\n...error text omitted...\\nIndexError: list index out of range\\nLists | 87', metadata={'source': 'python.pdf', 'page': 137}),\n",
       " Document(page_content='>>> L[99] = 1\\n...error text omitted...\\nIndexError: list assignment index out of range\\nThis is intentional, \\nas it’s usually an error to try to assign off the end of a list (and a\\nparticularly nasty one in the C language, which doesn’t do as much error checking as\\nPython). Rather than silently growing the list in response, Python reports an error. To\\ngrow a list, we call list methods such as append instead.\\nNesting\\nOne nice feature of Python’s core data types is that they support arbitrary nesting—we\\ncan nest them in any combination, and as deeply as we like (for example, we can have\\na list that contains a dictionary, which contains another list, and so on). One immediate\\napplication of this feature is to represent matrixes, or “multidimensional arrays” in\\nPython. A list with nested lists will do the job for basic applications:\\n>>> M = [[1, 2, 3],               # A 3 × 3 matrix, as nested lists\\n         [4, 5, 6],               # Code can span lines if bracketed\\n         [7, 8, 9]]\\n>>> M\\n[[1, 2, 3], [4, 5, 6], [7, 8, 9]]\\nHere, we’ve coded a list that contains three other lists. The effect is to represent a\\n3 × 3 matrix of numbers. Such a structure can be accessed in a variety of ways:\\n>>> M[1]                          # Get row 2\\n[4, 5, 6]\\n>>> M[1][2]                       # Get row 2, then get item 3 within the row\\n6\\nThe first operation here fetches the entire second row, and the second grabs the third\\nitem within that row. Stringing together index operations takes us deeper and deeper\\ninto our nested-object structure.†\\nComprehensions\\nIn addition to sequence operations and list methods, Python includes a more advanced\\noperation known as a list comprehension expression , which turns out to be a powerful\\nway to process structures like our matrix. Suppose, for instance, that we need to extract\\nthe second column of our sample matrix. It’s easy to grab rows by simple indexing\\n† This matrix structure works for small-scale tasks, but for more serious number crunching you will probably\\nwant to \\nuse one of the numeric extensions to Python, such as the open source NumPy system. Such tools can\\nstore and process large matrixes much more efficiently than our nested list structure. NumPy has been said\\nto turn Python into the equivalent of a free and more powerful version of the Matlab system, and organizations\\nsuch as NASA, Los Alamos, and JPMorgan Chase use this tool for scientific and financial tasks. Search the\\nWeb for more details.\\n88 | Chapter 4: \\u2002Introducing Python Object Types', metadata={'source': 'python.pdf', 'page': 138}),\n",
       " Document(page_content=\"because the matrix is stored by rows, but it’s almost as easy to get a column with a list\\ncomprehension:\\n>>> col2 = [row[1] for row in M]             # Collect the items in column 2\\n>>> col2\\n[2, 5, 8]\\n>>> M                                        # The matrix is unchanged\\n[[1, 2, 3], [4, 5, 6], [7, 8, 9]]\\nList comprehensions derive \\nfrom set notation; they are a way to build a new list by\\nrunning an expression on each item in a sequence, one at a time, from left to right. List\\ncomprehensions are coded in square brackets (to tip you off to the fact that they make\\na list) and are composed of an expression and a looping construct that share a variable\\nname (row, here). The preceding list comprehension means basically what it says: “Give\\nme row[1] for each row in matrix M, in a new list.” The result is a new list containing\\ncolumn 2 of the matrix.\\nList comprehensions can be more complex in practice:\\n>>> [row[1] + 1 for row in M]                 # Add 1 to each item in column 2\\n[3, 6, 9]\\n>>> [row[1] for row in M if row[1] % 2 == 0]  # Filter out odd items\\n[2, 8]\\nThe first operation here, for instance, adds 1 to each item as it is collected, and the\\nsecond uses an if clause to filter odd numbers out of the result using the % modulus\\nexpression (remainder of division). List comprehensions make new lists of results, but\\nthey can be used to iterate over any iterable object. Here, for instance, we use list com-\\nprehensions to step over a hardcoded list of coordinates and a string:\\n>>> diag = [M[i][i] for i in [0, 1, 2]]      # Collect a diagonal from matrix\\n>>> diag\\n[1, 5, 9]\\n>>> doubles = [c * 2 for c in 'spam']        # Repeat characters in a string\\n>>> doubles\\n['ss', 'pp', 'aa', 'mm']\\nList comprehensions, and relatives like the map and filter built-in functions, are a bit\\ntoo involved for me to say more about them here. The main point of this brief intro-\\nduction is to illustrate that Python includes both simple and advanced tools in its ar-\\nsenal. List comprehensions are an optional feature, but they tend to be handy in practice\\nand often provide a substantial processing speed advantage. They also work on any\\ntype that is a sequence in Python, as well as some types that are not. You’ll hear much\\nmore about them later in this book.\\nAs a preview, though, you’ll find that in recent Pythons, comprehension syntax in\\nparentheses can also be used to create generators that produce results on demand (the\\nsum built-in, for instance, sums items in a sequence):\\nLists | 89\", metadata={'source': 'python.pdf', 'page': 139}),\n",
       " Document(page_content=\">>> G = (sum(row) for row in M)              # Create a generator of row sums\\n>>> next(G)\\n6\\n>>> next(G)                                  # Run the iteration protocol\\n15\\nThe map built-in can \\ndo similar work, by generating the results of running items through\\na function. Wrapping it in list forces it to return all its values in Python 3.0:\\n>>> list(map(sum, M))                        # Map sum over items in M\\n[6, 15, 24]\\nIn Python 3.0, comprehension syntax can also be used to create sets and dictionaries:\\n>>> {sum(row) for row in M}                  # Create a set of row sums\\n{24, 6, 15}\\n>>> {i : sum(M[i]) for i in range(3)}        # Creates key/value table of row sums\\n{0: 6, 1: 15, 2: 24}\\nIn fact, lists, sets, and dictionaries can all be built with comprehensions in 3.0:\\n>>> [ord(x) for x in 'spaam']                # List of character ordinals\\n[115, 112, 97, 97, 109]\\n>>> {ord(x) for x in 'spaam'}                # Sets remove duplicates\\n{112, 97, 115, 109}\\n>>> {x: ord(x) for x in 'spaam'}             # Dictionary keys are unique\\n{'a': 97, 'p': 112, 's': 115, 'm': 109}\\nTo understand objects like generators, sets, and dictionaries, though, we must move \\nahead.\\nDictionaries\\nPython dictionaries are something completely different (Monty Python reference\\nintended)—they are not sequences at all, but are instead known as mappings. Mappings\\nare also collections of other objects, but they store objects by key instead of by relative\\nposition. In fact, mappings don’t maintain any reliable left-to-right order; they simply\\nmap keys to associated values. Dictionaries, the only mapping type in Python’s core\\nobjects set, are also mutable: they may be changed in-place and can grow and shrink\\non demand, like lists.\\nMapping Operations\\nWhen written as literals, dictionaries are coded in curly braces and consist of a series\\nof “key: value” pairs. Dictionaries are useful anytime we need to associate a set of values\\nwith keys—to describe the properties of something, for instance. As an example, con-\\nsider the following three-item dictionary (with keys “food,” “quantity,” and “color”):\\n>>> D = {'food': 'Spam', 'quantity': 4, 'color': 'pink'}\\n90 | Chapter 4: \\u2002Introducing Python Object Types\", metadata={'source': 'python.pdf', 'page': 140}),\n",
       " Document(page_content=\"We can index this dictionary by key to fetch and change the keys’ associated values.\\nThe dictionary index \\noperation uses the same syntax as that used for sequences, but\\nthe item in the square brackets is a key, not a relative position:\\n>>> D['food']              # Fetch value of key 'food'\\n'Spam'\\n>>> D['quantity'] += 1     # Add 1 to 'quantity' value\\n>>> D\\n{'food': 'Spam', 'color': 'pink', 'quantity': 5}\\nAlthough the curly-braces literal form does see use, it is perhaps more common to see\\ndictionaries built up in different ways. The following code, for example, starts with an\\nempty dictionary and fills it out one key at a time. Unlike out-of-bounds assignments\\nin lists, which are forbidden, assignments to new dictionary keys create those keys:\\n>>> D = {}\\n>>> D['name'] = 'Bob'      # Create keys by assignment\\n>>> D['job']  = 'dev'\\n>>> D['age']  = 40\\n>>> D\\n{'age': 40, 'job': 'dev', 'name': 'Bob'}\\n>>> print(D['name'])\\nBob\\nHere, we’re effectively using dictionary keys as field names in a record that describes\\nsomeone. In other applications, dictionaries can also be used to replace searching\\noperations—indexing a dictionary by key is often the fastest way to code a search in\\nPython.\\nNesting Revisited\\nIn the prior example, we used a dictionary to describe a hypothetical person, with three\\nkeys. Suppose, though, that the information is more complex. Perhaps we need to\\nrecord a first name and a last name, along with multiple job titles. This leads to another\\napplication of Python’s object nesting in action. The following dictionary, coded all at\\nonce as a literal, captures more structured information:\\n>>> rec = {'name': {'first': 'Bob', 'last': 'Smith'},\\n           'job':  ['dev', 'mgr'],\\n           'age':  40.5}\\nHere, we again have a three-key dictionary at the top (keys “name,” “job,” and “age”),\\nbut the values have become more complex: a nested dictionary for the name to support\\nmultiple parts, and a nested list for the job to support multiple roles and future expan-\\nsion. We can access the components of this structure much as we did for our matrix\\nearlier, but this time some of our indexes are dictionary keys, not list offsets:\\nDictionaries | 91\", metadata={'source': 'python.pdf', 'page': 141}),\n",
       " Document(page_content=\">>> rec['name']                         # 'name' is a nested dictionary\\n{'last': 'Smith', 'first': 'Bob'}\\n>>> rec['name']['last']                 # Index the nested dictionary\\n'Smith'\\n>>> rec['job']                          # 'job' is a nested list\\n['dev', 'mgr']\\n>>> rec['job'][-1]                      # Index the nested list\\n'mgr'\\n>>> rec['job'].append('janitor')        # Expand Bob's job description in-place\\n>>> rec\\n{'age': 40.5, 'job': ['dev', 'mgr', 'janitor'], 'name': {'last': 'Smith',\\n'first': 'Bob'}}\\nNotice how the \\nlast operation here expands the nested job list—because the job list is\\na separate piece of memory from the dictionary that contains it, it can grow and shrink\\nfreely (object memory layout will be discussed further later in this book).\\nThe real reason for showing you this example is to demonstrate the flexibility of Py-\\nthon’s core data types. As you can see, nesting allows us to build up complex infor-\\nmation structures directly and easily. Building a similar structure in a low-level language\\nlike C would be tedious and require much more code: we would have to lay out and\\ndeclare structures and arrays, fill out values, link everything together, and so on. In\\nPython, this is all automatic—running the expression creates the entire nested object\\nstructure for us. In fact, this is one of the main benefits of scripting languages like\\nPython.\\nJust as importantly, in a lower-level language we would have to be careful to clean up\\nall of the object’s space when we no longer need it. In Python, when we lose the last\\nreference to the object—by assigning its variable to something else, for example—all\\nof the memory space occupied by that object’s structure is automatically cleaned up\\nfor us:\\n>>> rec = 0                             # Now the object's space is reclaimed\\nTechnically speaking, Python has a feature known as garbage collection  that cleans up\\nunused memory as your program runs and frees you from having to manage such details\\nin your code. In Python, the space is reclaimed immediately, as soon as the last reference\\nto an object is removed. We’ll study how this works later in this book; for now, it’s\\nenough to know that you can use objects freely, without worrying about creating their\\nspace or cleaning up as you go.‡\\n‡ Keep in mind that the rec record we just created really could be a database record, when we employ Python’s\\nobject persistence  system—an easy way to store native Python objects in files or access-by-key databases. We\\nwon’t go into details here, but watch for discussion of Python’s pickle and shelve modules later in this book.\\n92 | Chapter 4: \\u2002Introducing Python Object Types\", metadata={'source': 'python.pdf', 'page': 142}),\n",
       " Document(page_content='Sorting Keys: for Loops\\nAs mappings, as we’ve already seen, dictionaries only support accessing items by key.\\nHowever, they also support type-specific operations with method calls that are useful\\nin a variety of common use cases.\\nAs mentioned \\nearlier, because dictionaries are not sequences, they don’t maintain any\\ndependable left-to-right order. This means that if we make a dictionary and print it\\nback, its keys may come back in a different order than that in which we typed them:\\n>>> D = {\\'a\\': 1, \\'b\\': 2, \\'c\\': 3}\\n>>> D\\n{\\'a\\': 1, \\'c\\': 3, \\'b\\': 2}\\nWhat do we do, though, if we do need to impose an ordering on a dictionary’s items?\\nOne common solution is to grab a list of keys with the dictionary keys method, sort\\nthat with the list sort method, and then step through the result with a Python for loop\\n(be sure to press the Enter key twice after coding the for loop below—as explained in\\nChapter 3, an empty line means “go” at the interactive prompt, and the prompt changes\\nto “...” on some interfaces):\\n>>> Ks = list(D.keys())                # Unordered keys list\\n>>> Ks                                 # A list in 2.6, \"view\" in 3.0: use list()\\n[\\'a\\', \\'c\\', \\'b\\']\\n>>> Ks.sort()                          # Sorted keys list\\n>>> Ks\\n[\\'a\\', \\'b\\', \\'c\\']\\n>>> for key in Ks:                     # Iterate though sorted keys\\n        print(key, \\'=>\\', D[key])       # <== press Enter twice here\\na => 1\\nb => 2\\nc => 3\\nThis is a three-step process, although, as we’ll see in later chapters, in recent versions\\nof Python it can be done in one step with the newer sorted built-in function. The\\nsorted call returns the result and sorts a variety of object types, in this case sorting\\ndictionary keys automatically:\\n>>> D\\n{\\'a\\': 1, \\'c\\': 3, \\'b\\': 2}\\n>>> for key in sorted(D):\\n        print(key, \\'=>\\', D[key])\\na => 1\\nb => 2\\nc => 3\\nBesides showcasing dictionaries, this use case serves to introduce the Python for loop.\\nThe for loop is a simple and efficient way to step through all the items in a sequence\\nDictionaries | 93', metadata={'source': 'python.pdf', 'page': 143}),\n",
       " Document(page_content=\"and run a block of code for each item in turn. A user-defined loop variable ( key, here)\\nis used to reference the current item each time through. The net effect in our example\\nis to print the unordered dictionary’s keys and values, in sorted-key order.\\nThe for loop, and \\nits more general cousin the while loop, are the main ways we code\\nrepetitive tasks as statements in our scripts. Really, though, the for loop (like its relative\\nthe list comprehension, which we met earlier) is a sequence operation. It works on any\\nobject that is a sequence and, like the list comprehension, even on some things that are\\nnot. Here, for example, it is stepping across the characters in a string, printing the\\nuppercase version of each as it goes:\\n>>> for c in 'spam':\\n        print(c.upper())\\nS\\nP\\nA\\nM\\nPython’s while loop is a more general sort of looping tool, not limited to stepping across\\nsequences:\\n>>> x = 4\\n>>> while x > 0:\\n        print('spam!' * x)\\n        x -= 1\\nspam!spam!spam!spam!\\nspam!spam!spam!\\nspam!spam!\\nspam!\\nWe’ll discuss looping statements, syntax, and tools in depth later in the book.\\nIteration and Optimization\\nIf the last section’s for loop looks like the list comprehension expression introduced\\nearlier, it should: both are really general iteration tools. In fact, both will work on any\\nobject that follows the iteration protocol —a pervasive idea in Python that essentially\\nmeans a physically stored sequence in memory, or an object that generates one item at\\na time in the context of an iteration operation. An object falls into the latter category\\nif it responds to the iter built-in with an object that advances in response to next. The\\ngenerator comprehension expression we saw earlier is such an object.\\nI’ll have more to say about the iteration protocol later in this book. For now, keep in\\nmind that every Python tool that scans an object from left to right uses the iteration\\nprotocol. This is why the sorted call used in the prior section works on the dictionary\\ndirectly—we don’t have to call the keys method to get a sequence because dictionaries\\nare iterable objects, with a next that returns successive keys.\\n94 | Chapter 4: \\u2002Introducing Python Object Types\", metadata={'source': 'python.pdf', 'page': 144}),\n",
       " Document(page_content=\"This also means that any list comprehension expression, such as this one, which com-\\nputes the squares of a list of numbers:\\n>>> squares = [x ** 2 for x in [1, 2, 3, 4, 5]]\\n>>> squares\\n[1, 4, 9, 16, 25]\\ncan always be \\ncoded as an equivalent for loop that builds the result list manually by\\nappending as it goes:\\n>>> squares = []\\n>>> for x in [1, 2, 3, 4, 5]:          # This is what a list comprehension does\\n        squares.append(x ** 2)         # Both run the iteration protocol internally\\n>>> squares\\n[1, 4, 9, 16, 25]\\nThe list comprehension, though, and related functional programming tools like map\\nand filter, will generally run faster than a for loop today (perhaps even twice as fast)—\\na property that could matter in your programs for large data sets. Having said that,\\nthough, I should point out that performance measures are tricky business in Python\\nbecause it optimizes so much, and performance can vary from release to release.\\nA major rule of thumb in Python is to code for simplicity and readability first and worry\\nabout performance later, after your program is working, and after you’ve proved that\\nthere is a genuine performance concern. More often than not, your code will be quick\\nenough as it is. If you do need to tweak code for performance, though, Python includes\\ntools to help you out, including the time and timeit modules and the profile module.\\nYou’ll find more on these later in this book, and in the Python manuals.\\nMissing Keys: if Tests\\nOne other note about dictionaries before we move on. Although we can assign to a new\\nkey to expand a dictionary, fetching a nonexistent key is still a mistake:\\n>>> D\\n{'a': 1, 'c': 3, 'b': 2}\\n>>> D['e'] = 99                      # Assigning new keys grows dictionaries\\n>>> D\\n{'a': 1, 'c': 3, 'b': 2, 'e': 99}\\n>>> D['f']                           # Referencing a nonexistent key is an error\\n...error text omitted...\\nKeyError: 'f'\\nThis is what we want—it’s usually a programming error to fetch something that isn’t\\nreally there. But in some generic programs, we can’t always know what keys will be\\npresent when we write our code. How do we handle such cases and avoid errors? One\\ntrick is to test ahead of time. The dictionary in membership expression allows us to\\nDictionaries | 95\", metadata={'source': 'python.pdf', 'page': 145}),\n",
       " Document(page_content=\"query the existence of a key and branch on the result with a Python if statement (as\\nwith the \\nfor, be sure to press Enter twice to run the if interactively here):\\n>>> 'f' in D\\nFalse\\n>>> if not 'f' in D:\\n       print('missing')\\nmissing\\nI’ll have much more to say about the if statement and statement syntax in general later\\nin this book, but the form we’re using here is straightforward: it consists of the word\\nif, followed by an expression that is interpreted as a true or false result, followed by a\\nblock of code to run if the test is true. In its full form, the if statement can also have\\nan else clause for a default case, and one or more elif (else if) clauses for other tests.\\nIt’s the main selection tool in Python, and it’s the way we code logic in our scripts.\\nStill, there are other ways to create dictionaries and avoid accessing nonexistent keys:\\nthe get method (a conditional index with a default); the Python 2.X has_key method\\n(which is no longer available in 3.0); the try statement (a tool we’ll first meet in Chap-\\nter 10 that catches and recovers from exceptions altogether); and the if/else expression\\n(essentially, an if statement squeezed onto a single line). Here are a few examples:\\n>>> value = D.get('x', 0)                      # Index but with a default\\n>>> value\\n0\\n>>> value = D['x'] if 'x' in D else 0          # if/else expression form\\n>>> value\\n0\\nWe’ll save the details on such alternatives until a later chapter. For now, let’s move on\\nto tuples.\\nTuples\\nThe tuple object (pronounced “toople” or “tuhple,” depending on who you ask) is\\nroughly like a list that cannot be changed—tuples are sequences, like lists, but they are\\nimmutable, like strings. Syntactically, they are coded in parentheses instead of square\\nbrackets, and they support arbitrary types, arbitrary nesting, and the usual sequence\\noperations:\\n>>> T = (1, 2, 3, 4)            # A 4-item tuple\\n>>> len(T)                      # Length\\n4\\n>> T + (5, 6)                   # Concatenation\\n(1, 2, 3, 4, 5, 6)\\n>>> T[0]                        # Indexing, slicing, and more\\n1\\n96 | Chapter 4: \\u2002Introducing Python Object Types\", metadata={'source': 'python.pdf', 'page': 146}),\n",
       " Document(page_content=\"Tuples also have two type-specific callable methods in Python 3.0, but not nearly as\\nmany as lists:\\n>>> T.index(4)                  # Tuple methods: 4 appears at offset 3\\n3\\n>>> T.count(4)                  # 4 appears once\\n1\\nThe primary distinction \\nfor tuples is that they cannot be changed once created. That\\nis, they are immutable sequences:\\n>>> T[0] = 2                    # Tuples are immutable\\n...error text omitted...\\nTypeError: 'tuple' object does not support item assignment\\nLike lists and dictionaries, tuples support mixed types and nesting, but they don’t grow\\nand shrink because they are immutable:\\n>>> T = ('spam', 3.0, [11, 22, 33])\\n>>> T[1]\\n3.0\\n>>> T[2][1]\\n22\\n>>> T.append(4)\\nAttributeError: 'tuple' object has no attribute 'append'\\nWhy Tuples?\\nSo, why have a type that is like a list, but supports fewer operations? Frankly, tuples\\nare not generally used as often as lists in practice, but their immutability is the whole\\npoint. If you pass a collection of objects around your program as a list, it can be changed\\nanywhere; if you use a tuple, it cannot. That is, tuples provide a sort of integrity con-\\nstraint that is convenient in programs larger than those we’ll write here. We’ll talk more\\nabout tuples later in the book. For now, though, let’s jump ahead to our last major core\\ntype: the file.\\nFiles\\nFile objects are Python code’s main interface to external files on your computer. Files\\nare a core type, but they’re something of an oddball—there is no specific literal syntax\\nfor creating them. Rather, to create a file object, you call the built-in open function,\\npassing in an external filename and a processing mode as strings. For example, to create\\na text output file, you would pass in its name and the 'w' processing mode string to\\nwrite data:\\n>>> f = open('data.txt', 'w')      # Make a new file in output mode\\n>>> f.write('Hello\\\\n')             # Write strings of bytes to it\\n6\\n>>> f.write('world\\\\n')             # Returns number of bytes written in Python 3.0\\n6\\n>>> f.close()                      # Close to flush output buffers to disk\\nFiles | 97\", metadata={'source': 'python.pdf', 'page': 147}),\n",
       " Document(page_content=\"This creates a file in the current directory and writes text to it (the filename can be a\\nfull directory path \\nif you need to access a file elsewhere on your computer). To read\\nback what you just wrote, reopen the file in 'r' processing mode, for reading text\\ninput—this is the default if you omit the mode in the call. Then read the file’s content\\ninto a string, and display it. A file’s contents are always a string in your script, regardless\\nof the type of data the file contains:\\n>>> f = open('data.txt')           # 'r' is the default processing mode\\n>>> text = f.read()                # Read entire file into a string\\n>>> text\\n'Hello\\\\nworld\\\\n'\\n>>> print(text)                    # print interprets control characters\\nHello\\nworld\\n>>> text.split()                   # File content is always a string\\n['Hello', 'world']\\nOther file object methods support additional features we don’t have time to cover here.\\nFor instance, file objects provide more ways of reading and writing ( read accepts an\\noptional byte size, readline reads one line at a time, and so on), as well as other tools\\n(seek moves to a new file position). As we’ll see later, though, the best way to read a\\nfile today is to not read it at all —files provide an iterator that automatically reads line\\nby line in for loops and other contexts.\\nWe’ll meet the full set of file methods later in this book, but if you want a quick preview\\nnow, run a dir call on any open file and a help on any of the method names that come\\nback:\\n>>> dir(f)\\n[ ...many names omitted...\\n'buffer', 'close', 'closed', 'encoding', 'errors', 'fileno', 'flush', 'isatty',\\n'line_buffering', 'mode', 'name', 'newlines', 'read', 'readable', 'readline',\\n'readlines', 'seek', 'seekable', 'tell', 'truncate', 'writable', 'write',\\n'writelines']\\n>>>help(f.seek)\\n...try it and see...\\nLater in the book, we’ll also see that files in Python 3.0 draw a sharp distinction between\\ntext and binary data. Text files  represent content as strings and perform Unicode en-\\ncoding and decoding automatically, while binary files represent content as a special\\nbytes string type and allow you to access file content unaltered:\\n>>> data = open('data.bin', 'rb').read()       # Open binary file\\n>>> data                                       # bytes string holds binary data\\nb'\\\\x00\\\\x00\\\\x00\\\\x07spam\\\\x00\\\\x08'\\n>>> data[4:8]\\nb'spam'\\n98 | Chapter 4: \\u2002Introducing Python Object Types\", metadata={'source': 'python.pdf', 'page': 148}),\n",
       " Document(page_content=\"Although you won’t generally need to care about this distinction if you deal only with\\nASCII text, Python \\n3.0’s strings and files are an asset if you deal with internationalized\\napplications or byte-oriented data.\\nOther File-Like Tools\\nThe open function is the workhorse for most file processing you will do in Python. For\\nmore advanced tasks, though, Python comes with additional file-like tools: pipes,\\nFIFOs, sockets, keyed-access files, persistent object shelves, descriptor-based files, re-\\nlational and object-oriented database interfaces, and more. Descriptor files, for\\ninstance, support file locking and other low-level tools, and sockets provide an interface\\nfor networking and interprocess communication. We won’t cover many of these topics\\nin this book, but you’ll find them useful once you start programming Python in earnest.\\nOther Core Types\\nBeyond the core types we’ve seen so far, there are others that may or may not qualify\\nfor membership in the set, depending on how broadly it is defined. Sets, for example,\\nare a recent addition to the language that are neither mappings nor sequences; rather,\\nthey are unordered collections of unique and immutable objects. Sets are created by\\ncalling the built-in set function or using new set literals and expressions in 3.0, and\\nthey support the usual mathematical set operations (the choice of new {...} syntax for\\nset literals in 3.0 makes sense, since sets are much like the keys of a valueless dictionary):\\n>>> X = set('spam')                 # Make a set out of a sequence in 2.6 and 3.0\\n>>> Y = {'h', 'a', 'm'}             # Make a set with new 3.0 set literals\\n>>> X, Y\\n({'a', 'p', 's', 'm'}, {'a', 'h', 'm'})\\n>>> X & Y                           # Intersection\\n{'a', 'm'}\\n>>> X | Y                           # Union\\n{'a', 'p', 's', 'h', 'm'}\\n>>> X – Y                           # Difference\\n{'p', 's'}\\n>>> {x ** 2 for x in [1, 2, 3, 4]}  # Set comprehensions in 3.0\\n{16, 1, 4, 9}\\nIn addition, Python recently grew a few new numeric types: decimal numbers (fixed-\\nprecision floating-point numbers) and fraction numbers (rational numbers with both\\na numerator and a denominator). Both can be used to work around the limitations and\\ninherent inaccuracies of floating-point math:\\n>>> 1 / 3                           # Floating-point (use .0 in Python 2.6)\\n0.33333333333333331\\n>>> (2/3) + (1/2)\\nOther Core Types | 99\", metadata={'source': 'python.pdf', 'page': 149}),\n",
       " Document(page_content=\"1.1666666666666665\\n>>> import decimal                  # Decimals: fixed precision\\n>>> d = decimal.Decimal('3.141')\\n>>> d + 1\\nDecimal('4.141')\\n>>> decimal.getcontext().prec = 2\\n>>> decimal.Decimal('1.00') / decimal.Decimal('3.00')\\nDecimal('0.33')\\n>>> from fractions import Fraction  # Fractions: numerator+denominator\\n>>> f = Fraction(2, 3)\\n>>> f + 1\\nFraction(5, 3)\\n>>> f + Fraction(1, 2)\\nFraction(7, 6)\\nPython also comes \\nwith Booleans (with predefined True and False objects that are es-\\nsentially just the integers 1 and 0 with custom display logic), and it has long supported\\na special placeholder object called None commonly used to initialize names and objects:\\n>>> 1 > 2, 1 < 2                    # Booleans\\n(False, True)\\n>>> bool('spam')\\nTrue\\n>>> X = None                        # None placeholder\\n>>> print(X)\\nNone\\n>>> L = [None] * 100                # Initialize a list of 100 Nones\\n>>> L\\n[None, None, None, None, None, None, None, None, None, None, None, None,\\nNone, None, None, None, None, None, None, None, ...a list of 100 Nones...]\\nHow to Break Your Code’s Flexibility\\nI’ll have more to say about all of Python’s object types later, but one merits special\\ntreatment here. The type object, returned by the type built-in function, is an object that\\ngives the type of another object; its result differs slightly in 3.0, because types have\\nmerged with classes completely (something we’ll explore in the context of “new-style”\\nclasses in Part VI). Assuming L is still the list of the prior section:\\n# In Python 2.6:\\n>>> type(L)                         # Types: type of L is list type object\\n<type 'list'>\\n>>> type(type(L))                   # Even types are objects\\n<type 'type'>\\n# In Python 3.0:\\n>>> type(L)                         # 3.0: types are classes, and vice versa\\n<class 'list'>\\n100 | Chapter 4: \\u2002Introducing Python Object Types\", metadata={'source': 'python.pdf', 'page': 150}),\n",
       " Document(page_content=\">>> type(type(L))                   # See Chapter 31 for more on class types\\n<class 'type'>\\nBesides allowing you to explore your objects interactively, the practical application of\\nthis is that \\nit allows code to check the types of the objects it processes. In fact, there are\\nat least three ways to do so in a Python script:\\n>>> if type(L) == type([]):         # Type testing, if you must...\\n        print('yes')\\nyes\\n>>> if type(L) == list:             # Using the type name\\n        print('yes')\\nyes\\n>>> if isinstance(L, list):         # Object-oriented tests\\n        print('yes')\\nyes\\nNow that I’ve shown you all these ways to do type testing, however, I am required by\\nlaw to tell you that doing so is almost always the wrong thing to do in a Python program\\n(and often a sign of an ex-C programmer first starting to use Python!). The reason why\\nwon’t become completely clear until later in the book, when we start writing larger\\ncode units such as functions, but it’s a (perhaps the) core Python concept. By checking\\nfor specific types in your code, you effectively break its flexibility—you limit it to\\nworking on just one type. Without such tests, your code may be able to work on a\\nwhole range of types.\\nThis is related to the idea of polymorphism mentioned earlier, and it stems from\\nPython’s lack of type declarations. As you’ll learn, in Python, we code to object inter-\\nfaces (operations supported), not to types. Not caring about specific types means that\\ncode is automatically applicable to many of them—any object with a compatible in-\\nterface will work, regardless of its specific type. Although type checking is supported—\\nand even required, in some rare cases—you’ll see that it’s not usually the “Pythonic”\\nway of thinking. In fact, you’ll find that polymorphism is probably the key idea behind\\nusing Python well.\\nUser-Defined Classes\\nWe’ll study object-oriented programming  in Python—an optional but powerful feature\\nof the language that cuts development time by supporting programming by customi-\\nzation—in depth later in this book. In abstract terms, though, classes define new types\\nof objects that extend the core set, so they merit a passing glance here. Say, for example,\\nthat you wish to have a type of object that models employees. Although there is no such\\nspecific core type in Python, the following user-defined class might fit the bill:\\n>>> class Worker:\\n         def __init__(self, name, pay):          # Initialize when created\\n             self.name = name                    # self is the new object\\nOther Core Types | 101\", metadata={'source': 'python.pdf', 'page': 151}),\n",
       " Document(page_content=\"             self.pay  = pay\\n         def lastName(self):\\n             return self.name.split()[-1]        # Split string on blanks\\n         def giveRaise(self, percent):\\n             self.pay *= (1.0 + percent)         # Update pay in-place\\nThis class defines \\na new kind of object that will have name and pay attributes (sometimes\\ncalled state information ), as well as two bits of behavior coded as functions (normally\\ncalled methods). Calling the class like a function generates instances of our new type,\\nand the class’s methods automatically receive the instance being processed by a given\\nmethod call (in the self argument):\\n>>> bob = Worker('Bob Smith', 50000)             # Make two instances\\n>>> sue = Worker('Sue Jones', 60000)             # Each has name and pay attrs\\n>>> bob.lastName()                               # Call method: bob is self\\n'Smith'\\n>>> sue.lastName()                               # sue is the self subject\\n'Jones'\\n>>> sue.giveRaise(.10)                           # Updates sue's pay\\n>>> sue.pay\\n66000.0\\nThe implied “self” object is why we call this an object-oriented model: there is always\\nan implied subject in functions within a class. In a sense, though, the class-based type\\nsimply builds on and uses core types—a user-defined Worker object here, for example,\\nis just a collection of a string and a number ( name and pay, respectively), plus functions\\nfor processing those two built-in objects.\\nThe larger story of classes is that their inheritance mechanism supports software hier-\\narchies that lend themselves to customization by extension. We extend software by\\nwriting new classes, not by changing what already works. You should also know that\\nclasses are an optional feature of Python, and simpler built-in types such as lists and\\ndictionaries are often better tools than user-coded classes. This is all well beyond the\\nbounds of our introductory object-type tutorial, though, so consider this just a preview;\\nfor full disclosure on user-defined types coded with classes, you’ll have to read on to\\nPart VI.\\nAnd Everything Else\\nAs mentioned earlier, everything you can process in a Python script is a type of object,\\nso our object type tour is necessarily incomplete. However, even though everything in\\nPython is an “object,” only those types of objects we’ve met so far are considered part\\nof Python’s core type set. Other types in Python either are objects related to program\\nexecution (like functions, modules, classes, and compiled code), which we will study\\nlater, or are implemented by imported module functions, not language syntax. The\\nlatter of these also tend to have application-specific roles—text patterns, database in-\\nterfaces, network connections, and so on.\\n102 | Chapter 4: \\u2002Introducing Python Object Types\", metadata={'source': 'python.pdf', 'page': 152}),\n",
       " Document(page_content='Moreover, keep in mind that the objects we’ve met here are objects, but not necessarily\\nobject-oriented—a concept that \\nusually requires inheritance and the Python class\\nstatement, which we’ll meet again later in this book. Still, Python’s core objects are the\\nworkhorses of almost every Python script you’re likely to meet, and they usually are\\nthe basis of larger noncore types.\\nChapter Summary\\nAnd that’s a wrap for our concise data type tour. This chapter has offered a brief in-\\ntroduction to Python’s core object types and the sorts of operations we can apply to\\nthem. We’ve studied generic operations that work on many object types (sequence\\noperations such as indexing and slicing, for example), as well as type-specific operations\\navailable as method calls (for instance, string splits and list appends). We’ve also de-\\nfined some key terms, such as immutability, sequences, and polymorphism.\\nAlong the way, we’ve seen that Python’s core object types are more flexible and pow-\\nerful than what is available in lower-level languages such as C. For instance, Python’s\\nlists and dictionaries obviate most of the work you do to support collections and\\nsearching in lower-level languages. Lists are ordered collections of other objects, and\\ndictionaries are collections of other objects that are indexed by key instead of by posi-\\ntion. Both dictionaries and lists may be nested, can grow and shrink on demand, and\\nmay contain objects of any type. Moreover, their space is automatically cleaned up as\\nyou go.\\nI’ve skipped most of the details here in order to provide a quick tour, so you shouldn’t\\nexpect all of this chapter to have made sense yet. In the next few chapters, we’ll start\\nto dig deeper, filling in details of Python’s core object types that were omitted here so\\nyou can gain a more complete understanding. We’ll start off in the next chapter with\\nan in-depth look at Python numbers. First, though, another quiz to review.\\nTest Your Knowledge: Quiz\\nWe’ll explore the \\nconcepts introduced in this chapter in more detail in upcoming\\nchapters, so we’ll just cover the big ideas here:\\n1. Name four of Python’s core data types.\\n2. Why are they called “core” data types?\\n3. What does “immutable” mean, and which three of Python’s core types are con-\\nsidered immutable?\\n4. What does “sequence” mean, and which three types fall into that category?\\nTest Your Knowledge: Quiz | 103', metadata={'source': 'python.pdf', 'page': 153}),\n",
       " Document(page_content=\"5. What does “mapping” mean, and which core type is a mapping?\\n6. What is “polymorphism,” and why should you care?\\nTest Your Knowledge: Answers\\n1. Numbers, \\nstrings, lists, dictionaries, tuples, files, and sets are generally considered\\nto be the core object (data) types. Types, None, and Booleans are sometimes clas-\\nsified this way as well. There are multiple number types (integer, floating point,\\ncomplex, fraction, and decimal) and multiple string types (simple strings and Uni-\\ncode strings in Python 2.X, and text strings and byte strings in Python 3.X).\\n2. They are known as “core” types because they are part of the Python language itself\\nand are always available; to create other objects, you generally must call functions\\nin imported modules. Most of the core types have specific syntax for generating\\nthe objects: 'spam', for example, is an expression that makes a string and deter-\\nmines the set of operations that can be applied to it. Because of this, core types are\\nhardwired into Python’s syntax. In contrast, you must call the built-in open function\\nto create a file object.\\n3. An “immutable” object is an object that cannot be changed after it is created.\\nNumbers, strings, and tuples in Python fall into this category. While you cannot\\nchange an immutable object in-place, you can always make a new one by running\\nan expression.\\n4. A “sequence” is a positionally ordered collection of objects. Strings, lists, and tuples\\nare all sequences in Python. They share common sequence operations, such as\\nindexing, concatenation, and slicing, but also have type-specific method calls.\\n5. The term “mapping” denotes an object that maps keys to associated values. Py-\\nthon’s dictionary is the only mapping type in the core type set. Mappings do not\\nmaintain any left-to-right positional ordering; they support access to data stored\\nby key, plus type-specific method calls.\\n6. “Polymorphism” means that the meaning of an operation (like a +) depends on the\\nobjects being operated on. This turns out to be a key idea (perhaps the key idea)\\nbehind using Python well—not constraining code to specific types makes that code\\nautomatically applicable to many types.\\n104 | Chapter 4: \\u2002Introducing Python Object Types\", metadata={'source': 'python.pdf', 'page': 154}),\n",
       " Document(page_content='CHAPTER 5\\nNumeric Types\\nThis chapter begins our in-depth tour of the Python language. In Python, data takes\\nthe form of objects\\n—either built-in objects that Python provides, or objects we create\\nusing Python tools and other languages such as C. In fact, objects are the basis of every\\nPython program you will ever write. Because they are the most fundamental notion in\\nPython programming, objects are also our first focus in this book.\\nIn the preceding chapter, we took a quick pass over Python’s core object types. Al-\\nthough essential terms were introduced in that chapter, we avoided covering too many\\nspecifics in the interest of space. Here, we’ll begin a more careful second look at data\\ntype concepts, to fill in details we glossed over earlier. Let’s get started by exploring\\nour first data type category: Python’s numeric types.\\nNumeric Type Basics\\nMost of Python’s number types are fairly typical and will probably seem familiar if\\nyou’ve used almost any other programming language in the past. They can be used to\\nkeep track of your bank balance, the distance to Mars, the number of visitors to your\\nwebsite, and just about any other numeric quantity.\\nIn Python, numbers are not really a single object type, but a category of similar types.\\nPython supports the usual numeric types (integers and floating points), as well as literals\\nfor creating numbers and expressions for processing them. In addition, Python provides\\nmore advanced numeric programming support and objects for more advanced work.\\nA complete inventory of Python’s numeric toolbox includes:\\n• Integers and floating-point numbers\\n• Complex numbers\\n• Fixed-precision decimal numbers\\n105', metadata={'source': 'python.pdf', 'page': 155}),\n",
       " Document(page_content='• Rational fraction numbers\\n• Sets\\n• Booleans\\n•\\nUnlimited integer precision\\n• A variety of numeric built-ins and modules\\nThis chapter starts with basic numbers and fundamentals, then moves on to explore\\nthe other tools in this list. Before we jump into code, though, the next few sections get\\nus started with a brief overview of how we write and process numbers in our scripts.\\nNumeric Literals\\nAmong its basic types, Python provides integers (positive and negative whole numbers)\\nand floating-point numbers (numbers with a fractional part, sometimes called “floats”\\nfor economy). Python also allows us to write integers using hexadecimal, octal, and\\nbinary literals; offers a complex number type; and allows integers to have unlimited\\nprecision (they can grow to have as many digits as your memory space allows). Ta-\\nble 5-1  shows what Python’s numeric types look like when written out in a program,\\nas literals.\\nTable 5-1. Basic numeric literals\\nLiteral Interpretation\\n1234, −24, 0, 99999999999999 Integers (unlimited size)\\n1.23, 1., 3.14e-10, 4E210, 4.0e+210 Floating-point numbers\\n0177, 0x9ff, 0b101010 Octal, hex, and binary literals in 2.6\\n0o177, 0x9ff, 0b101010 Octal, hex, and binary literals in 3.0\\n3+4j, 3.0+4.0j, 3J Complex number literals\\nIn general, Python’s numeric type literals are straightforward to write, but a few coding\\nconcepts are worth highlighting here:\\nInteger and floating-point literals\\nIntegers are written \\nas strings of decimal digits. Floating-point numbers have a\\ndecimal point and/or an optional signed exponent introduced by an e or E and\\nfollowed by an optional sign. If you write a number with a decimal point or expo-\\nnent, Python makes it a floating-point object and uses floating-point (not integer)\\nmath when the object is used in an expression. Floating-point numbers are imple-\\nmented as C “doubles,” and therefore get as much precision as the C compiler used\\nto build the Python interpreter gives to doubles.\\n106 | Chapter 5: \\u2002Numeric Types', metadata={'source': 'python.pdf', 'page': 156}),\n",
       " Document(page_content='Integers in Python 2.6: normal and long\\nIn Python 2.6 \\nthere are two integer types, normal (32 bits) and long (unlimited\\nprecision), and an integer may end in an l or L to force it to become a long integer.\\nBecause integers are automatically converted to long integers when their values\\noverflow 32 bits, you never need to type the letter L yourself—Python automatically\\nconverts up to long integer when extra precision is needed.\\nIntegers in Python 3.0: a single type\\nIn Python 3.0, the normal and long integer types have been merged—there is only\\ninteger, which automatically supports the unlimited precision of Python 2.6’s sep-\\narate long integer type. Because of this, integers can no longer be coded with a\\ntrailing l or L, and integers never print with this character either. Apart from this,\\nmost programs are unaffected by this change, unless they do type testing that\\nchecks for 2.6 long integers.\\nHexadecimal, octal, and binary literals\\nIntegers may be coded in decimal (base 10), hexadecimal (base 16), octal (base 8),\\nor binary (base 2). Hexadecimals start with a leading 0x or 0X, followed by a string\\nof hexadecimal digits ( 0–9 and A–F). Hex digits may be coded in lower- or upper-\\ncase. Octal literals start with a leading 0o or 0O (zero and lower- or uppercase letter\\n“o”), followed by a string of digits (0–7). In 2.6 and earlier, octal literals can also\\nbe coded with just a leading 0, but not in 3.0 (this original octal form is too easily\\nconfused with decimal, and is replaced by the new 0o format). Binary literals, new\\nin 2.6 and 3.0, begin with a leading 0b or 0B, followed by binary digits (0–1).\\nNote that all of these literals produce integer objects in program code; they are just\\nalternative syntaxes for specifying values. The built-in calls hex(I), oct(I), and\\nbin(I) convert an integer to its representation string in these three bases, and\\nint(str, base) converts a runtime string to an integer per a given base.\\nComplex numbers\\nPython complex literals are written as realpart+imaginarypart, where the\\nimaginarypart is terminated with a j or J. The realpart is technically optional, so\\nthe imaginarypart may appear on its own. Internally, complex numbers are im-\\nplemented as pairs of floating-point numbers, but all numeric operations perform\\ncomplex math when applied to complex numbers. Complex numbers may also be\\ncreated with the complex(real, imag) built-in call.\\nCoding other numeric types\\nAs we’ll see later in this chapter, there are additional, more advanced number types\\nnot included in Table 5-1 . Some of these are created by calling functions in im-\\nported modules (e.g., decimals and fractions), and others have literal syntax all\\ntheir own (e.g., sets).\\nNumeric Type Basics | 107', metadata={'source': 'python.pdf', 'page': 157}),\n",
       " Document(page_content='Built-in Numeric Tools\\nBesides the built-in number \\nliterals shown in Table 5-1 , Python provides a set of tools\\nfor processing number objects:\\nExpression operators\\n+, -, *, /, >>, **, &, etc.\\nBuilt-in mathematical functions\\npow, abs, round, int, hex, bin, etc.\\nUtility modules\\nrandom, math, etc.\\nWe’ll meet all of these as we go along.\\nAlthough numbers are primarily processed with expressions, built-ins, and modules,\\nthey also have a handful of type-specific methods today, which we’ll meet in this chapter\\nas well. Floating-point numbers, for example, have an as_integer_ratio method that\\nis useful for the fraction number type, and an is_integer method to test if the number\\nis an integer. Integers have various attributes, including a new bit_length method in\\nthe upcoming Python 3.1 release that gives the number of bits necessary to represent\\nthe object’s value. Moreover, as part collection and part number, sets also support both\\nmethods and expressions.\\nSince expressions are the most essential tool for most number types, though, let’s turn\\nto them next.\\nPython Expression Operators\\nPerhaps the most fundamental tool that processes numbers is the expression: a com-\\nbination of numbers (or other objects) and operators that computes a value when exe-\\ncuted by Python. In Python, expressions are written using the usual mathematical\\nnotation and operator symbols. For instance, to add two numbers X and Y you would\\nsay X + Y, which tells Python to apply the + operator to the values named by X and Y.\\nThe result of the expression is the sum of X and Y, another number object.\\nTable 5-2 lists all the operator expressions available in Python. Many are\\nself-explanatory; for instance, the usual mathematical operators ( +, −, *, /, and so on)\\nare supported. A few will be familiar if you’ve used other languages in the past: % com-\\nputes a division remainder, << performs a bitwise left-shift, & computes a bitwise AND\\nresult, and so on. Others are more Python-specific, and not all are numeric in nature:\\nfor example, the is operator tests object identity (i.e., address in memory, a strict form\\nof equality), and lambda creates unnamed functions.\\n108 | Chapter 5: \\u2002Numeric Types', metadata={'source': 'python.pdf', 'page': 158}),\n",
       " Document(page_content='Table 5-2. Python expression operators and precedence\\nOperators Description\\nyield x Generator function send protocol\\nlambda args: expression Anonymous function generation\\nx if y else z Ternary selection (x is evaluated only if y is true)\\nx or y Logical OR (y is evaluated only if x is false)\\nx and y Logical AND (y is evaluated only if x is true)\\nnot x Logical negation\\nx in y, x not in y Membership (iterables, sets)\\nx is y, x is not y Object identity tests\\nx < y, x <= y, x > y, x >= y\\nx == y, x != yMagnitude comparison, set subset and superset;\\nValue equality operators\\nx | y Bitwise OR, set union\\nx ^ y Bitwise XOR, set symmetric difference\\nx & y Bitwise AND, set intersection\\nx << y, x >> y Shift x left or right by y bits\\nx + y\\nx – yAddition, concatenation;\\nSubtraction, set difference\\nx * y\\nx % y\\nx / y, x // yMultiplication, repetition;\\nRemainder, format;\\nDivision: true and floor\\n−x, +x Negation, identity\\n˜x Bitwise NOT (inversion)\\nx ** y Power (exponentiation)\\nx[i] Indexing (sequence, mapping, others)\\nx[i:j:k] Slicing\\nx(...) Call (function, method, class, other callable)\\nx.attr Attribute reference\\n(...) Tuple, expression, generator expression\\n[...] List, list comprehension\\n{...} Dictionary, set, set and dictionary comprehensions\\nNumeric Type Basics | 109', metadata={'source': 'python.pdf', 'page': 159}),\n",
       " Document(page_content='Since this book addresses both Python 2.6 and 3.0, here are some notes about version\\ndifferences and recent additions related to the operators in Table 5-2:\\n• In Python 2.6, value inequality can be written as either X != Y or X <> Y. In Python\\n3.0, the latter of these options is removed because it is redundant. In either version,\\nbest practice is to use X != Y for all value inequality tests.\\n• In Python 2.6, a backquotes expression `X` works the same as repr(X) and converts\\nobjects to display strings. Due to its obscurity, this expression is removed in Python\\n3.0; use the more readable str and repr built-in functions, described in “Numeric\\nDisplay Formats” on page 115.\\n• The X // Y floor division expression always truncates fractional remainders in both\\nPython 2.6 and 3.0. The X / Y  expression performs true division in 3.0 (retaining\\nremainders) and classic division in 2.6 (truncating for integers). See “Division:\\nClassic, Floor, and True” on page 117.\\n• The syntax [...] is used for both list literals and list comprehension expressions.\\nThe latter of these performs an implied loop and collects expression results in a\\nnew list. See Chapters 4, 14, and 20 for examples.\\n• The syntax (...) is used for tuples and expressions, as well as generator\\nexpressions—a form of list comprehension that produces results on demand, in-\\nstead of building a result list. See Chapters 4 and 20 for examples. The parentheses\\nmay sometimes be omitted in all three constructs.\\n• The syntax {...} is used for dictionary literals, and in Python 3.0 for set literals\\nand both dictionary and set comprehensions. See the set coverage in this chapter\\nand Chapters 4, 8, 14, and 20 for examples.\\n• The yield and ternary if/else selection expressions are available in Python 2.5 and\\nlater. The former returns send(...) arguments in generators; the latter is shorthand\\nfor a multiline if statement. yield requires parentheses if not alone on the right\\nside of an assignment statement.\\n• Comparison operators may be chained: X < Y < Z produces the same result as\\nX < Y and Y < X. See “Comparisons: Normal and Chained” on page 116 for details.\\n• In recent Pythons, the slice expression X[I:J:K] is equivalent to indexing with a\\nslice object: X[slice(I, J, K)].\\n• In Python 2.X, magnitude comparisons of mixed types—converting numbers to a\\ncommon type, and ordering other mixed types according to the type name—are\\nallowed. In Python 3.0, nonnumeric mixed-type magnitude comparisons are not\\nallowed and raise exceptions; this includes sorts by proxy.\\n• Magnitude comparisons for dictionaries are also no longer supported in Python\\n3.0 (though equality tests are); comparing sorted(dict.items()) is one possible\\nreplacement.\\nWe’ll see most of the operators in Table 5-2  in action later; first, though, we need to\\ntake a quick look at the ways these operators may be combined in expressions.\\n110 | Chapter 5: \\u2002Numeric Types', metadata={'source': 'python.pdf', 'page': 160}),\n",
       " Document(page_content='Mixed operators follow operator precedence\\nAs in most \\nlanguages, in Python, more complex expressions are coded by stringing\\ntogether the operator expressions in Table 5-2 . For instance, the sum of two multipli-\\ncations might be written as a mix of variables and operators:\\nA * B + C * D\\nSo, how does Python know which operation to perform first? The answer to this ques-\\ntion lies in operator precedence. When you write an expression with more than one\\noperator, Python groups its parts according to what are called precedence rules , and\\nthis grouping determines the order in which the expression’s parts are computed.\\nTable 5-2 is ordered by operator precedence:\\n• Operators lower in the table have higher precedence, and so bind more tightly in\\nmixed expressions.\\n• Operators in the same row in Table 5-2  generally group from left to right when\\ncombined (except for exponentiation, which groups right to left, and comparisons,\\nwhich chain left to right).\\nFor example, if you write X + Y * Z, Python evaluates the multiplication first\\n(Y * Z), then adds that result to X because * has higher precedence (is lower in the\\ntable) than +. Similarly, in this section’s original example, both multiplications ( A * B\\nand C * D) will happen before their results are added.\\nParentheses group subexpressions\\nYou can forget about precedence completely if you’re careful to group parts of expres-\\nsions with parentheses. When you enclose subexpressions in parentheses, you override\\nPython’s precedence rules; Python always evaluates expressions in parentheses first\\nbefore using their results in the enclosing expressions.\\nFor instance, instead of coding X + Y * Z, you could write one of the following to force\\nPython to evaluate the expression in the desired order:\\n(X + Y) * Z\\nX + (Y * Z)\\nIn the first case, + is applied to X and Y first, because this subexpression is wrapped in\\nparentheses. In the second case, the * is performed first (just as if there were no paren-\\ntheses at all). Generally speaking, adding parentheses in large expressions is a good\\nidea—it not only forces the evaluation order you want, but also aids readability.\\nMixed types are converted up\\nBesides mixing operators in expressions, you can also mix numeric types. For instance,\\nyou can add an integer to a floating-point number:\\n40 + 3.14\\nNumeric Type Basics | 111', metadata={'source': 'python.pdf', 'page': 161}),\n",
       " Document(page_content='But this leads to another question: what type is the result—integer or floating-point?\\nThe answer is \\nsimple, especially if you’ve used almost any other language before: in\\nmixed-type numeric expressions, Python first converts operands up to the type of the\\nmost complicated operand, and then performs the math on same-type operands. This\\nbehavior is similar to type conversions in the C language.\\nPython ranks the complexity of numeric types like so: integers are simpler than floating-\\npoint numbers, which are simpler than complex numbers. So, when an integer is mixed\\nwith a floating point, as in the preceding example, the integer is converted up to a\\nfloating-point value first, and floating-point math yields the floating-point result. Sim-\\nilarly, any mixed-type expression where one operand is a complex number results in\\nthe other operand being converted up to a complex number, and the expression yields\\na complex result. (In Python 2.6, normal integers are also converted to long integers\\nwhenever their values are too large to fit in a normal integer; in 3.0, integers subsume\\nlongs entirely.)\\nYou can force the issue by calling built-in functions to convert types manually:\\n>>> int(3.1415)     # Truncates float to integer\\n3\\n>>> float(3)        # Converts integer to float\\n3.0\\nHowever, you won’t usually need to do this: because Python automatically converts\\nup to the more complex type within an expression, the results are normally what you\\nwant.\\nAlso, keep in mind that all these mixed-type conversions apply only when mixing\\nnumeric types (e.g., an integer and a floating-point) in an expression, including those\\nusing numeric and comparison operators. In general, Python does not convert across\\nany other type boundaries automatically. Adding a string to an integer, for example,\\nresults in an error, unless you manually convert one or the other; watch for an example\\nwhen we meet strings in Chapter 7.\\nIn Python 2.6, nonnumeric mixed types can be compared, but no con-\\nversions are performed \\n(mixed types compare according to a fixed but\\narbitrary rule). In 3.0, nonnumeric mixed-type comparisons are not al-\\nlowed and raise exceptions.\\nPreview: Operator overloading and polymorphism\\nAlthough we’re focusing on built-in numbers right now, all Python operators may be\\noverloaded (i.e., implemented) by Python classes and C extension types to work on\\nobjects you create. For instance, you’ll see later that objects coded with classes may be\\nadded or concatenated with + expressions, indexed with [i] expressions, and so on.\\nFurthermore, Python itself automatically overloads some operators, such that they\\nperform different actions depending on the type of built-in objects being processed.\\n112 | Chapter 5: \\u2002Numeric Types', metadata={'source': 'python.pdf', 'page': 162}),\n",
       " Document(page_content='For example, the + operator performs addition when applied to numbers but performs\\nconcatenation when applied to sequence objects such as strings and lists. In fact, + can\\nmean anything at all when applied to objects you define with classes.\\nAs we saw in the prior chapter, this property is usually called polymorphism—a term\\nindicating that the meaning of an operation depends on the type of the objects being\\noperated on. We’ll revisit this concept when we explore functions in Chapter 16 , be-\\ncause it becomes a much more obvious feature in that context.\\nNumbers in Action\\nOn to the code! Probably the best way to understand numeric objects and expressions\\nis to see them in action, so let’s start up the interactive command line and try some\\nbasic but illustrative operations (see Chapter 3  for pointers if you need help starting an\\ninteractive session).\\nVariables and Basic Expressions\\nFirst of all, let’s exercise some basic math. In the following interaction, we first assign\\ntwo variables ( a and b) to integers so we can use them later in a larger expression.\\nVariables are simply names—created by you or Python—that are used to keep track of\\ninformation in your program. We’ll say more about this in the next chapter, but in\\nPython:\\n• Variables are created when they are first assigned values.\\n• Variables are replaced with their values when used in expressions.\\n• Variables must be assigned before they can be used in expressions.\\n• Variables refer to objects and are never declared ahead of time.\\nIn other words, these assignments cause the variables a and b to spring into existence\\nautomatically:\\n% python\\n>>> a = 3                  # Name created\\n>>> b = 4\\nI’ve also used a comment here. Recall that in Python code, text after a # mark and\\ncontinuing to the end of the line is considered to be a comment and is ignored. Com-\\nments are a way to write human-readable documentation for your code. Because code\\nyou type interactively is temporary, you won’t normally write comments in this context,\\nbut I’ve added them to some of this book’s examples to help explain the code.* In the\\nnext part of the book, we’ll meet a related feature—documentation strings—that at-\\ntaches the text of your comments to objects.\\n* If you’re working along, you don’t need to type any of the comment text from the # through to the end of\\nthe line; comments are simply ignored by Python and not required parts of the statements we’re running.\\nNumbers in Action | 113', metadata={'source': 'python.pdf', 'page': 163}),\n",
       " Document(page_content='Now, let’s use our new integer objects in some expressions. At this point, the values of\\na and b \\nare still 3 and 4, respectively. Variables like these are replaced with their values\\nwhenever they’re used inside an expression, and the expression results are echoed back\\nimmediately when working interactively:\\n>>> a + 1, a – 1           # Addition (3 + 1), subtraction (3 - 1)\\n(4, 2)\\n>>> b * 3, b / 2           # Multiplication (4 * 3), division (4 / 2)\\n(12, 2.0)\\n>>> a % 2, b ** 2          # Modulus (remainder), power (4 ** 2)\\n(1, 16)\\n>>> 2 + 4.0, 2.0 ** b      # Mixed-type conversions\\n(6.0, 16.0)\\nTechnically, the results being echoed back here are tuples of two values because the\\nlines typed at the prompt contain two expressions separated by commas; that’s why\\nthe results are displayed in parentheses (more on tuples later). Note that the expressions\\nwork because the variables a and b within them have been assigned values. If you use\\na different variable that has never been assigned, Python reports an error rather than\\nfilling in some default value:\\n>>> c * 2\\nTraceback (most recent call last):\\n  File \"<stdin>\", line 1, in ?\\nNameError: name \\'c\\' is not defined\\nYou don’t need to predeclare variables in Python, but they must have been assigned at\\nleast once before you can use them. In practice, this means you have to initialize coun-\\nters to zero before you can add to them, initialize lists to an empty list before you can\\nappend to them, and so on.\\nHere are two slightly larger expressions to illustrate operator grouping and more about\\nconversions:\\n>>> b / 2 + a               # Same as ((4 / 2) + 3)\\n5.0\\n>>> print(b / (2.0 + a))    # Same as (4 / (2.0 + 3))\\n0.8\\nIn the first expression, there are no parentheses, so Python automatically groups the\\ncomponents according to its precedence rules—because / is lower in Table 5-2 than\\n+, it binds more tightly and so is evaluated first. The result is as if the expression had\\nbeen organized with parentheses as shown in the comment to the right of the code.\\nAlso, notice that all the numbers are integers in the first expression. Because of that,\\nPython 2.6 performs integer division and addition and will give a result of 5, whereas\\nPython 3.0 performs true division with remainders and gives the result shown. If you\\nwant integer division in 3.0, code this as b // 2 + a (more on division in a moment).\\nIn the second expression, parentheses are added around the + part to force Python to\\nevaluate it first (i.e., before the /). We also made one of the operands floating-point by\\nadding a decimal point: 2.0. Because of the mixed types, Python converts the integer\\n114 | Chapter 5: \\u2002Numeric Types', metadata={'source': 'python.pdf', 'page': 164}),\n",
       " Document(page_content=\"referenced by a to a floating-point value ( 3.0) before performing the +. If all the numbers\\nin this expression were integers, integer division ( 4 / 5) would yield the truncated\\ninteger 0 in Python 2.6 but the floating-point 0.8 in Python 3.0 (again, stay tuned for\\ndivision details).\\nNumeric Display Formats\\nNotice that we used a print operation in the last of the preceding examples. Without\\nthe print, you’ll see something that may look a bit odd at first glance:\\n>>> b / (2.0 + a)           # Auto echo output: more digits\\n0.80000000000000004\\n>>> print(b / (2.0 + a))    # print rounds off digits\\n0.8\\nThe full story behind this odd result has to do with the limitations of floating-point\\nhardware and its inability to exactly represent some values in a limited number of bits.\\nBecause computer architecture is well beyond this book’s scope, though, we’ll finesse\\nthis by saying that all of the digits in the first output are really there in your computer’s\\nfloating-point hardware—it’s just that you’re not accustomed to seeing them. In fact,\\nthis is really just a display issue—the interactive prompt’s automatic result echo shows\\nmore digits than the print statement. If you don’t want to see all the digits, use print;\\nas the sidebar “str and repr Display Formats” on page 116 will explain, you’ll get a\\nuser-friendly display.\\nNote, however, that not all values have so many digits to display:\\n>>> 1 / 2.0\\n0.5\\nand that there are more ways to display the bits of a number inside your computer than\\nusing print and automatic echoes:\\n>>> num = 1 / 3.0\\n>>> num                      # Echoes\\n0.33333333333333331\\n>>> print(num)               # print rounds\\n0.333333333333\\n>>> '%e' % num               # String formatting expression\\n'3.333333e-001'\\n>>> '%4.2f' % num            # Alternative floating-point format\\n'0.33'\\n>>> '{0:4.2f}'.format(num)   # String formatting method (Python 2.6 and 3.0)\\n'0.33'\\nThe last three of these expressions employ string formatting , a tool that allows for for-\\nmat flexibility, which we will explore in the upcoming chapter on strings ( Chapter 7 ).\\nIts results are strings that are typically printed to displays or reports.\\nNumbers in Action | 115\", metadata={'source': 'python.pdf', 'page': 165}),\n",
       " Document(page_content=\"str and repr Display Formats\\nTechnically, the difference \\nbetween default interactive echoes and print corresponds\\nto the difference between the built-in repr and str functions:\\n>>> num = 1 / 3\\n>>> repr(num)              # Used by echoes: as-code form\\n'0.33333333333333331'\\n>>> str(num)               # Used by print: user-friendly form\\n'0.333333333333'\\nBoth of these convert arbitrary objects to their string representations: repr (and the\\ndefault interactive echo) produces results that look as though they were code; str (and\\nthe print operation) converts to a typically more user-friendly format if available. Some\\nobjects have both—a str for general use, and a repr with extra details. This notion will\\nresurface when we study both strings and operator overloading in classes, and you’ll\\nfind more on these built-ins in general later in the book.\\nBesides providing print strings for arbitrary objects, the str built-in is also the name of\\nthe string data type and may be called with an encoding name to decode a Unicode\\nstring from a byte string. We’ll study the latter advanced role in Chapter 36 of this book.\\nComparisons: Normal and Chained\\nSo far, we’ve \\nbeen dealing with standard numeric operations (addition and multipli-\\ncation), but numbers can also be compared. Normal comparisons work for numbers\\nexactly as you’d expect—they compare the relative magnitudes of their operands and\\nreturn a Boolean result (which we would normally test in a larger statement):\\n>>> 1 < 2                  # Less than\\nTrue\\n>>> 2.0 >= 1               # Greater than or equal: mixed-type 1 converted to 1.0\\nTrue\\n>>> 2.0 == 2.0             # Equal value\\nTrue\\n>>> 2.0 != 2.0             # Not equal value\\nFalse\\nNotice again how mixed types are allowed in numeric expressions (only); in the second\\ntest here, Python compares values in terms of the more complex type, float.\\nInterestingly, Python also allows us to chain multiple comparisons together to perform\\nrange tests. Chained comparisons are a sort of shorthand for larger Boolean expres-\\nsions. In short, Python lets us string together magnitude comparison tests to code\\nchained comparisons such as range tests. The expression (A < B < C), for instance,\\ntests whether B is between A and C; it is equivalent to the Boolean test (A < B and B <\\nC) but is easier on the eyes (and the keyboard). For example, assume the following\\nassignments:\\n116 | Chapter 5: \\u2002Numeric Types\", metadata={'source': 'python.pdf', 'page': 166}),\n",
       " Document(page_content='>>> X = 2\\n>>> Y = 4\\n>>> Z = 6\\nThe following two \\nexpressions have identical effects, but the first is shorter to type, and\\nit may run slightly faster since Python needs to evaluate Y only once:\\n>>> X < Y < Z              # Chained comparisons: range tests\\nTrue\\n>>> X < Y and Y < Z\\nTrue\\nThe same equivalence holds for false results, and arbitrary chain lengths are allowed:\\n>>> X < Y > Z\\nFalse\\n>>> X < Y and Y > Z\\nFalse\\n>>> 1 < 2 < 3.0 < 4\\nTrue\\n>>> 1 > 2 > 3.0 > 4\\nFalse\\nYou can use other comparisons in chained tests, but the resulting expressions can be-\\ncome nonintuitive unless you evaluate them the way Python does. The following, for\\ninstance, is false just because 1 is not equal to 2:\\n>>> 1 == 2 < 3        # Same as: 1 == 2 and 2 < 3\\nFalse                 # Not same as: False < 3 (which means 0 < 3, which is true)\\nPython does not compare the 1 == 2 False result to 3—this would technically mean\\nthe same as 0 < 3, which would be True (as we’ll see later in this chapter, True and\\nFalse are just customized 1 and 0).\\nDivision: Classic, Floor, and True\\nYou’ve seen how division works in the previous sections, so you should know that it\\nbehaves slightly differently in Python 3.0 and 2.6. In fact, there are actually three flavors\\nof division, and two different division operators, one of which changes in 3.0:\\nX / Y\\nClassic and true division. In Python 2.6 and earlier, this operator performs classic\\ndivision, truncating results for integers and keeping remainders for floating-point\\nnumbers. In Python 3.0, it performs true division, always keeping remainders re-\\ngardless of types.\\nX // Y\\nFloor division. Added in Python 2.2 and available in both Python 2.6 and 3.0, this\\noperator always truncates fractional remainders down to their floor, regardless of\\ntypes.\\nNumbers in Action | 117', metadata={'source': 'python.pdf', 'page': 167}),\n",
       " Document(page_content='True division was added to address the fact that the results of the original classic division\\nmodel are dependent \\non operand types, and so can be difficult to anticipate in a dy-\\nnamically typed language like Python. Classic division was removed in 3.0 because of\\nthis constraint—the / and // operators implement true and floor division in 3.0.\\nIn sum:\\n•In 3.0 , the / now always performs true division, returning a float result that includes\\nany remainder, regardless of operand types. The // performs floor division, which\\ntruncates the remainder and returns an integer for integer operands or a float if any\\noperand is a float.\\n•In 2.6 , the / does classic division, performing truncating integer division if both\\noperands are integers and float division (keeping remainders) otherwise. The //\\ndoes floor division and works as it does in 3.0, performing truncating division for\\nintegers and floor division for floats.\\nHere are the two operators at work in 3.0 and 2.6:\\nC:\\\\misc> C:\\\\Python30\\\\python\\n>>>\\n>>> 10 / 4            # Differs in 3.0: keeps remainder\\n2.5\\n>>> 10 // 4           # Same in 3.0: truncates remainder\\n2\\n>>> 10 / 4.0          # Same in 3.0: keeps remainder\\n2.5\\n>>> 10 // 4.0         # Same in 3.0: truncates to floor\\n2.0\\nC:\\\\misc> C:\\\\Python26\\\\python\\n>>>\\n>>> 10 / 4\\n2\\n>>> 10 // 4\\n2\\n>>> 10 / 4.0\\n2.5\\n>>> 10 // 4.0\\n2.0\\nNotice that the data type of the result for // is still dependent on the operand types in\\n3.0: if either is a float, the result is a float; otherwise, it is an integer. Although this may\\nseem similar to the type-dependent behavior of / in 2.X that motivated its change in\\n3.0, the type of the return value is much less critical than differences in the return value\\nitself. Moreover, because // was provided in part as a backward-compatibility tool for\\nprograms that rely on truncating integer division (and this is more common than you\\nmight expect), it must return integers for integers.\\n118 | Chapter 5: \\u2002Numeric Types', metadata={'source': 'python.pdf', 'page': 168}),\n",
       " Document(page_content='Supporting either Python\\nAlthough / behavior differs in 2.6 and 3.0, you can still support both versions in your\\ncode. If your \\nprograms depend on truncating integer division, use // in both 2.6 and\\n3.0. If your programs require floating-point results with remainders for integers, use\\nfloat to guarantee that one operand is a float around a / when run in 2.6:\\nX = Y // Z        # Always truncates, always an int result for ints in 2.6 and 3.0\\nX = Y / float(Z)  # Guarantees float division with remainder in either 2.6 or 3.0\\nAlternatively, you can enable 3.0 / division in 2.6 with a __future__ import, rather than\\nforcing it with float conversions:\\nC:\\\\misc> C:\\\\Python26\\\\python\\n>>> from __future__ import division         # Enable 3.0 \"/\" behavior\\n>>> 10 / 4\\n2.5\\n>>> 10 // 4\\n2\\nFloor versus truncation\\nOne subtlety: the // operator is generally referred to as truncating division, but it’s more\\naccurate to refer to it as floor division—it truncates the result down to its floor, which\\nmeans the closest whole number below the true result. The net effect is to round down,\\nnot strictly truncate, and this matters for negatives. You can see the difference for\\nyourself with the Python math module (modules must be imported before you can use\\ntheir contents; more on this later):\\n>>> import math\\n>>> math.floor(2.5)\\n2\\n>>> math.floor(-2.5)\\n-3\\n>>> math.trunc(2.5)\\n2\\n>>> math.trunc(-2.5)\\n-2\\nWhen running division operators, you only really truncate for positive results, since\\ntruncation is the same as floor; for negatives, it’s a floor result (really, they are both\\nfloor, but floor is the same as truncation for positives). Here’s the case for 3.0:\\nC:\\\\misc> c:\\\\python30\\\\python\\n>>> 5 / 2, 5 / −2\\n(2.5, −2.5)\\n>>> 5 // 2, 5 // −2           # Truncates to floor: rounds to first lower integer\\n(2, −3)                       # 2.5 becomes 2, −2.5 becomes −3\\n>>> 5 / 2.0, 5 / −2.0\\n(2.5, −2.5)\\nNumbers in Action | 119', metadata={'source': 'python.pdf', 'page': 169}),\n",
       " Document(page_content='>>> 5 // 2.0, 5 // −2.0       # Ditto for floats, though result is float too\\n(2.0, −3.0)\\nThe 2.6 case is similar, but / results differ again:\\nC:\\\\misc> c:\\\\python26\\\\python\\n>>> 5 / 2, 5 / −2             # Differs in 3.0\\n(2, −3)\\n>>> 5 // 2, 5 // −2           # This and the rest are the same in 2.6 and 3.0\\n(2, −3)\\n>>> 5 / 2.0, 5 / −2.0\\n(2.5, −2.5)\\n>>> 5 // 2.0, 5 // −2.0\\n(2.0, −3.0)\\nIf you really \\nwant truncation regardless of sign, you can always run a float division\\nresult through math.trunc, regardless of Python version (also see the round built-in for\\nrelated functionality):\\nC:\\\\misc> c:\\\\python30\\\\python\\n>>> import math\\n>>> 5 / −2                      # Keep remainder\\n−2.5\\n>>> 5 // −2                     # Floor below result\\n-3\\n>>> math.trunc(5 / −2)          # Truncate instead of floor\\n−2\\nC:\\\\misc> c:\\\\python26\\\\python\\n>>> import math\\n>>> 5 / float(−2)               # Remainder in 2.6\\n−2.5\\n>>> 5 / −2, 5 // −2             # Floor in 2.6\\n(−3, −3)\\n>>> math.trunc(5 / float(−2))   # Truncate in 2.6\\n−2\\nWhy does truncation matter?\\nIf you are using 3.0, here is the short story on division operators for reference:\\n>>> (5 / 2), (5 / 2.0), (5 / −2.0), (5 / −2)        # 3.0 true division\\n(2.5, 2.5, −2.5, −2.5)\\n>>> (5 // 2), (5 // 2.0), (5 // −2.0), (5 // −2)    # 3.0 floor division\\n(2, 2.0, −3.0, −3)\\n>>> (9 / 3), (9.0 / 3), (9 // 3), (9 // 3.0)        # Both\\n(3.0, 3.0, 3, 3.0)\\nFor 2.6 readers, division works as follows:\\n>>> (5 / 2), (5 / 2.0), (5 / −2.0), (5 / −2)        # 2.6 classic division\\n(2, 2.5, −2.5, −3)\\n120 | Chapter 5: \\u2002Numeric Types', metadata={'source': 'python.pdf', 'page': 170}),\n",
       " Document(page_content='>>> (5 // 2), (5 // 2.0), (5 // −2.0), (5 // −2)    # 2.6 floor division (same)\\n(2, 2.0, −3.0, −3)\\n>>> (9 / 3), (9.0 / 3), (9 // 3), (9 // 3.0)        # Both\\n(3, 3.0, 3, 3.0)\\nAlthough results have \\nyet to come in, it’s possible that the nontruncating behavior\\nof / in 3.0 may break a significant number of programs. Perhaps because of a C language\\nlegacy, many programmers rely on division truncation for integers and will have to\\nlearn to use // in such contexts instead. Watch for a simple prime number while loop\\nexample in Chapter 13 , and a corresponding exercise at the end of Part IV  that illustrates\\nthe sort of code that may be impacted by this / change. Also stay tuned for more on\\nthe special from command used in this section; it’s discussed further in Chapter 24.\\nInteger Precision\\nDivision may differ slightly across Python releases, but it’s still fairly standard. Here’s\\nsomething a bit more exotic. As mentioned earlier, Python 3.0 integers support un-\\nlimited size:\\n>>> 999999999999999999999999999999 + 1\\n1000000000000000000000000000000\\nPython 2.6 has a separate type for long integers, but it automatically converts any\\nnumber too large to store in a normal integer to this type. Hence, you don’t need to\\ncode any special syntax to use longs, and the only way you can tell that you’re using\\n2.6 longs is that they print with a trailing “L”:\\n>>> 999999999999999999999999999999 + 1\\n1000000000000000000000000000000L\\nUnlimited-precision integers are a convenient built-in tool. For instance, you can use\\nthem to count the U.S. national debt in pennies in Python directly (if you are so inclined,\\nand have enough memory on your computer for this year’s budget!). They are also why\\nwe were able to raise 2 to such large powers in the examples in Chapter 3 . Here are the\\n3.0 and 2.6 cases:\\n>>> 2 ** 200\\n1606938044258990275541962092341162602522202993782792835301376\\n>>> 2 ** 200\\n1606938044258990275541962092341162602522202993782792835301376L\\nBecause Python must do extra work to support their extended precision, integer math\\nis usually substantially slower than normal when numbers grow large. However, if you\\nneed the precision, the fact that it’s built in for you to use will likely outweigh its\\nperformance penalty.\\nNumbers in Action | 121', metadata={'source': 'python.pdf', 'page': 171}),\n",
       " Document(page_content=\"Complex Numbers\\nAlthough less widely \\nused than the types we’ve been exploring thus far, complex num-\\nbers are a distinct core object type in Python. If you know what they are, you know\\nwhy they are useful; if not, consider this section optional reading.\\nComplex numbers are represented as two floating-point numbers—the real and imag-\\ninary parts—and are coded by adding a j or J suffix to the imaginary part. We can also\\nwrite complex numbers with a nonzero real part by adding the two parts with a +. For\\nexample, the complex number with a real part of 2 and an imaginary part of −3 is written\\n2 + −3j. Here are some examples of complex math at work:\\n>>> 1j * 1J\\n(-1+0j)\\n>>> 2 + 1j * 3\\n(2+3j)\\n>>> (2 + 1j) * 3\\n(6+3j)\\nComplex numbers also allow us to extract their parts as attributes, support all the usual\\nmathematical expressions, and may be processed with tools in the standard cmath\\nmodule (the complex version of the standard math module). Complex numbers typically\\nfind roles in engineering-oriented programs. Because they are advanced tools, check\\nPython’s language reference manual for additional details.\\nHexadecimal, Octal, and Binary Notation\\nAs described earlier in this chapter, Python integers can be coded in hexadecimal, octal,\\nand binary notation, in addition to the normal base 10 decimal coding. The coding\\nrules were laid out at the start of this chapter; let’s look at some live examples here.\\nKeep in mind that these literals are simply an alternative syntax for specifying the value\\nof an integer object. For example, the following literals coded in Python 3.0 or 2.6\\nproduce normal integers with the specified values in all three bases:\\n>>> 0o1, 0o20, 0o377           # Octal literals\\n(1, 16, 255)\\n>>> 0x01, 0x10, 0xFF           # Hex literals\\n(1, 16, 255)\\n>>> 0b1, 0b10000, 0b11111111   # Binary literals\\n(1, 16, 255)\\nHere, the octal value 0o377, the hex value 0xFF, and the binary value 0b11111111 are all\\ndecimal 255. Python prints in decimal (base 10) by default but provides built-in func-\\ntions that allow you to convert integers to other bases’ digit strings:\\n>>> oct(64), hex(64), bin(64)\\n('0100', '0x40', '0b1000000')\\n122 | Chapter 5: \\u2002Numeric Types\", metadata={'source': 'python.pdf', 'page': 172}),\n",
       " Document(page_content=\"The oct function converts decimal to octal, hex to hexadecimal, and bin to binary. To\\ngo the other \\nway, the built-in int function converts a string of digits to an integer, and\\nan optional second argument lets you specify the numeric base:\\n>>> int('64'), int('100', 8), int('40', 16), int('1000000', 2)\\n(64, 64, 64, 64)\\n>>> int('0x40', 16), int('0b1000000', 2)    # Literals okay too\\n(64, 64)\\nThe eval function, which you’ll meet later in this book, treats strings as though they\\nwere Python code. Therefore, it has a similar effect (but usually runs more slowly—it\\nactually compiles and runs the string as a piece of a program, and it assumes you can\\ntrust the source of the string being run; a clever user might be able to submit a string\\nthat deletes files on your machine!):\\n>>> eval('64'), eval('0o100'), eval('0x40'), eval('0b1000000')\\n(64, 64, 64, 64)\\nFinally, you can also convert integers to octal and hexadecimal strings with string for-\\nmatting method calls and expressions:\\n>>> '{0:o}, {1:x}, {2:b}'.format(64, 64, 64)\\n'100, 40, 1000000'\\n>>> '%o, %x, %X' % (64, 255, 255)\\n'100, ff, FF'\\nString formatting is covered in more detail in Chapter 7.\\nTwo notes before moving on. First, Python 2.6 users should remember that you can\\ncode octals with simply a leading zero, the original octal format in Python:\\n>>> 0o1, 0o20, 0o377     # New octal format in 2.6 (same as 3.0)\\n(1, 16, 255)\\n>>> 01, 020, 0377        # Old octal literals in 2.6 (and earlier)\\n(1, 16, 255)\\nIn 3.0, the syntax in the second of these examples generates an error. Even though it’s\\nnot an error in 2.6, be careful not to begin a string of digits with a leading zero unless\\nyou really mean to code an octal value. Python 2.6 will treat it as base 8, which may\\nnot work as you’d expect— 010 is always decimal 8 in 2.6, not decimal 10 (despite what\\nyou may or may not think!). This, along with symmetry with the hex and binary forms,\\nis why the octal format was changed in 3.0—you must use 0o010 in 3.0, and probably\\nshould in 2.6.\\nSecondly, note that these literals can produce arbitrarily long integers. The following,\\nfor instance, creates an integer with hex notation and then displays it first in decimal\\nand then in octal and binary with converters:\\n>>> X = 0xFFFFFFFFFFFFFFFFFFFFFFFFFFFF\\n>>> X\\n5192296858534827628530496329220095L\\n>>> oct(X)\\nNumbers in Action | 123\", metadata={'source': 'python.pdf', 'page': 173}),\n",
       " Document(page_content=\"'017777777777777777777777777777777777777L'\\n>>> bin(X)\\n'0b1111111111111111111111111111111111111111111111111111111111 ...and so on...\\nSpeaking of binary digits, the next section shows tools for processing individual bits.\\nBitwise Operations\\nBesides the normal \\nnumeric operations (addition, subtraction, and so on), Python sup-\\nports most of the numeric expressions available in the C language. This includes\\noperators that treat integers as strings of binary bits. For instance, here it is at work\\nperforming bitwise shift and Boolean operations:\\n>>> x = 1               # 0001\\n>>> x << 2              # Shift left 2 bits: 0100\\n4\\n>>> x | 2               # Bitwise OR: 0011\\n3\\n>>> x & 1               # Bitwise AND: 0001\\n1\\nIn the first expression, a binary 1 (in base 2, 0001) is shifted left two slots to create a\\nbinary 4 (0100). The last two operations perform a binary OR ( 0001|0010 = 0011) and a\\nbinary AND ( 0001&0001 = 0001). Such bit-masking operations allow us to encode mul-\\ntiple flags and other values within a single integer.\\nThis is one area where the binary and hexadecimal number support in Python 2.6 and\\n3.0 become especially useful—they allow us to code and inspect numbers by bit-strings:\\n>>> X = 0b0001          # Binary literals\\n>>> X << 2              # Shift left\\n4\\n>>> bin(X << 2)         # Binary digits string\\n'0b100'\\n>>> bin(X | 0b010)      # Bitwise OR\\n'0b11'\\n>>> bin(X & 0b1)        # Bitwise AND\\n'0b1'\\n>>> X = 0xFF            # Hex literals\\n>>> bin(X)\\n'0b11111111'\\n>>> X ^ 0b10101010      # Bitwise XOR\\n85\\n>>> bin(X ^ 0b10101010)\\n'0b1010101'\\n>>> int('1010101', 2)   # String to int per base\\n85\\n>>> hex(85)             # Hex digit string\\n'0x55'\\n124 | Chapter 5: \\u2002Numeric Types\", metadata={'source': 'python.pdf', 'page': 174}),\n",
       " Document(page_content=\"We won’t go into much more detail on “bit-twiddling” here. It’s supported if you need\\nit, and it \\ncomes in handy if your Python code must deal with things like network packets\\nor packed binary data produced by a C program. Be aware, though, that bitwise oper-\\nations are often not as important in a high-level language such as Python as they are in\\na low-level language such as C. As a rule of thumb, if you find yourself wanting to flip\\nbits in Python, you should think about which language you’re really coding. In general,\\nthere are often better ways to encode information in Python than bit strings.\\nIn the upcoming Python 3.1 release, the integer bit_length method also\\nallows \\nyou to query the number of bits required to represent a number’s\\nvalue in binary. The same effect can often be achieved by subtracting 2\\nfrom the length of the bin string using the len built-in function we met\\nin Chapter 4, though it may be less efficient:\\n>>> X = 99\\n>>> bin(X), X.bit_length()\\n('0b1100011', 7)\\n>>> bin(256), (256).bit_length()\\n('0b100000000', 9)\\n>>> len(bin(256)) - 2\\n9\\nOther Built-in Numeric Tools\\nIn addition to its core object types, Python also provides both built-in functions and\\nstandard library modules for numeric processing. The pow and abs built-in functions,\\nfor instance, compute powers and absolute values, respectively. Here are some exam-\\nples of the built-in math module (which contains most of the tools in the C language’s\\nmath library) and a few built-in functions at work:\\n>>> import math\\n>>> math.pi, math.e                               # Common constants\\n(3.1415926535897931, 2.7182818284590451)\\n>>> math.sin(2 * math.pi / 180)                   # Sine, tangent, cosine\\n0.034899496702500969\\n>>> math.sqrt(144), math.sqrt(2)                  # Square root\\n(12.0, 1.4142135623730951)\\n>>> pow(2, 4), 2 ** 4                             # Exponentiation (power)\\n(16, 16)\\n>>> abs(-42.0), sum((1, 2, 3, 4))                 # Absolute value, summation\\n(42.0, 10)\\n>>> min(3, 1, 2, 4), max(3, 1, 2, 4)              # Minimum, maximum\\n(1, 4)\\nThe sum function shown here works on a sequence of numbers, and min and max accept\\neither a sequence or individual arguments. There are a variety of ways to drop the\\nNumbers in Action | 125\", metadata={'source': 'python.pdf', 'page': 175}),\n",
       " Document(page_content=\"decimal digits of floating-point numbers. We met truncation and floor earlier; we can\\nalso round, both numerically and for display purposes:\\n>>> math.floor(2.567), math.floor(-2.567)         # Floor (next-lower integer)\\n(2, −3)\\n>>> math.trunc(2.567), math.trunc(−2.567)         # Truncate (drop decimal digits)\\n(2, −2)\\n>>> int(2.567), int(−2.567)                       # Truncate (integer conversion)\\n(2, −2)\\n>>> round(2.567), round(2.467), round(2.567, 2)   # Round (Python 3.0 version)\\n(3, 2, 2.5699999999999998)\\n>>> '%.1f' % 2.567, '{0:.2f}'.format(2.567)       # Round for display (Chapter 7)\\n('2.6', '2.57')\\nAs we saw \\nearlier, the last of these produces strings that we would usually print and\\nsupports a variety of formatting options. As also described earlier, the second to last\\ntest here will output (3, 2, 2.57)  if we wrap it in a print call to request a more user-\\nfriendly display. The last two lines still differ, though—round rounds a floating-point\\nnumber but still yields a floating-point number in memory, whereas string formatting\\nproduces a string and doesn’t yield a modified number:\\n>>> (1 / 3), round(1 / 3, 2), ('%.2f' % (1 / 3))\\n(0.33333333333333331, 0.33000000000000002, '0.33')\\nInterestingly, there are three ways to compute square roots  in Python: using a module\\nfunction, an expression, or a built-in function (if you’re interested in performance, we\\nwill revisit these in an exercise and its solution at the end of Part IV , to see which runs\\nquicker):\\n>>> import math\\n>>> math.sqrt(144)              # Module\\n12.0\\n>>> 144 ** .5                   # Expression\\n12.0\\n>>> pow(144, .5)                # Built-in\\n12.0\\n>>> math.sqrt(1234567890)       # Larger numbers\\n35136.418286444619\\n>>> 1234567890 ** .5\\n35136.418286444619\\n>>> pow(1234567890, .5)\\n35136.418286444619\\nNotice that standard library modules such as math must be imported, but built-in func-\\ntions such as abs and round are always available without imports. In other words, mod-\\nules are external components, but built-in functions live in an implied namespace that\\nPython automatically searches to find names used in your program. This namespace\\ncorresponds to the module called builtins in Python 3.0 ( __builtin__ in 2.6). There\\n126 | Chapter 5: \\u2002Numeric Types\", metadata={'source': 'python.pdf', 'page': 176}),\n",
       " Document(page_content=\"is much more about name resolution in the function and module parts of this book;\\nfor now, when you hear “module,” think “import.”\\nThe standard library random\\n module must be imported as well. This module provides\\ntools for picking a random floating-point number between 0 and 1, selecting a random\\ninteger between two numbers, choosing an item at random from a sequence, and more:\\n>>> import random\\n>>> random.random()\\n0.44694718823781876\\n>>> random.random()\\n0.28970426439292829\\n>>> random.randint(1, 10)\\n5\\n>>> random.randint(1, 10)\\n4\\n>>> random.choice(['Life of Brian', 'Holy Grail', 'Meaning of Life'])\\n'Life of Brian'\\n>>> random.choice(['Life of Brian', 'Holy Grail', 'Meaning of Life'])\\n'Holy Grail'\\nThe random module can be useful for shuffling cards in games, picking images at random\\nin a slideshow GUI, performing statistical simulations, and much more. For more de-\\ntails, see Python’s library manual.\\nOther Numeric Types\\nSo far in this chapter, we’ve been using Python’s core numeric types—integer, floating\\npoint, and complex. These will suffice for most of the number crunching that most\\nprogrammers will ever need to do. Python comes with a handful of more exotic numeric\\ntypes, though, that merit a quick look here.\\nDecimal Type\\nPython 2.4 introduced a new core numeric type: the decimal object, formally known\\nas Decimal. Syntactically, decimals are created by calling a function within an imported\\nmodule, rather than running a literal expression. Functionally, decimals are like\\nfloating-point numbers, but they have a fixed number of decimal points. Hence, deci-\\nmals are fixed-precision floating-point values.\\nFor example, with decimals, we can have a floating-point value that always retains just\\ntwo decimal digits. Furthermore, we can specify how to round or truncate the extra\\ndecimal digits beyond the object’s cutoff. Although it generally incurs a small perform-\\nance penalty compared to the normal floating-point type, the decimal type is well suited\\nto representing fixed-precision quantities like sums of money and can help you achieve\\nbetter numeric accuracy.\\nOther Numeric Types | 127\", metadata={'source': 'python.pdf', 'page': 177}),\n",
       " Document(page_content=\"The basics\\nThe last point \\nmerits elaboration. As you may or may not already know, floating-point\\nmath is less than exact, because of the limited space used to store values. For example,\\nthe following should yield zero, but it does not. The result is close to zero, but there\\nare not enough bits to be precise here:\\n>>> 0.1 + 0.1 + 0.1 - 0.3\\n5.5511151231257827e-17\\nPrinting the result to produce the user-friendly display format doesn’t completely help\\neither, because the hardware related to floating-point math is inherently limited in\\nterms of accuracy:\\n>>> print(0.1 + 0.1 + 0.1 - 0.3)\\n5.55111512313e-17\\nHowever, with decimals, the result can be dead-on:\\n>>> from decimal import Decimal\\n>>> Decimal('0.1') + Decimal('0.1') + Decimal('0.1') - Decimal('0.3')\\nDecimal('0.0')\\nAs shown here, we can make decimal objects by calling the Decimal constructor function\\nin the decimal module and passing in strings that have the desired number of decimal\\ndigits for the resulting object (we can use the str function to convert floating-point\\nvalues to strings if needed). When decimals of different precision are mixed in expres-\\nsions, Python converts up to the largest number of decimal digits automatically:\\n>>> Decimal('0.1') + Decimal('0.10') + Decimal('0.10') - Decimal('0.30')\\nDecimal('0.00')\\nIn Python 3.1 (to be released after this book’s publication), it’s also\\npossible to create \\na decimal object from a floating-point object, with a\\ncall of the form decimal.Decimal.from_float(1.25). The conversion is\\nexact but can sometimes yield a large number of digits.\\nSetting precision globally\\nOther tools in the decimal module can be used to set the precision of all decimal num-\\nbers, set up error handling, and more. For instance, a context object in this module\\nallows for specifying precision (number of decimal digits) and rounding modes (down,\\nceiling, etc.). The precision is applied globally for all decimals created in the calling\\nthread:\\n>>> import decimal\\n>>> decimal.Decimal(1) / decimal.Decimal(7)\\nDecimal('0.1428571428571428571428571429')\\n>>> decimal.getcontext().prec = 4\\n>>> decimal.Decimal(1) / decimal.Decimal(7)\\nDecimal('0.1429')\\n128 | Chapter 5: \\u2002Numeric Types\", metadata={'source': 'python.pdf', 'page': 178}),\n",
       " Document(page_content=\"This is especially useful for monetary applications, where cents are represented as two\\ndecimal digits. Decimals \\nare essentially an alternative to manual rounding and string\\nformatting in this context:\\n>>> 1999 + 1.33\\n2000.3299999999999\\n>>>\\n>>> decimal.getcontext().prec = 2\\n>>> pay = decimal.Decimal(str(1999 + 1.33))\\n>>> pay\\nDecimal('2000.33')\\nDecimal context manager\\nIn Python 2.6 and 3.0 (and later), it’s also possible to reset precision temporarily by\\nusing the with context manager statement. The precision is reset to its original value\\non statement exit:\\nC:\\\\misc> C:\\\\Python30\\\\python\\n>>> import decimal\\n>>> decimal.Decimal('1.00') / decimal.Decimal('3.00')\\nDecimal('0.3333333333333333333333333333')\\n>>>\\n>>> with decimal.localcontext() as ctx:\\n...     ctx.prec = 2\\n...     decimal.Decimal('1.00') / decimal.Decimal('3.00')\\n...\\nDecimal('0.33')\\n>>>\\n>>> decimal.Decimal('1.00') / decimal.Decimal('3.00')\\nDecimal('0.3333333333333333333333333333')\\nThough useful, this statement requires much more background knowledge than you’ve\\nobtained at this point; watch for coverage of the with statement in Chapter 33.\\nBecause use of the decimal type is still relatively rare in practice, I’ll defer to Python’s\\nstandard library manuals and interactive help for more details. And because decimals\\naddress some of the same floating-point accuracy issues as the fraction type, let’s move\\non to the next section to see how the two compare.\\nFraction Type\\nPython 2.6 and 3.0 debut a new numeric type, Fraction, which implements a rational\\nnumber object. It essentially keeps both a numerator and a denominator explicitly, so\\nas to avoid some of the inaccuracies and limitations of floating-point math.\\nThe basics\\nFraction is a sort of cousin to the existing Decimal fixed-precision type described in the\\nprior section, as both can be used to control numerical accuracy by fixing decimal digits\\nand specifying rounding or truncation policies. It’s also used in similar ways—like\\nOther Numeric Types | 129\", metadata={'source': 'python.pdf', 'page': 179}),\n",
       " Document(page_content=\"Decimal, Fraction resides in a module; import its constructor and pass in a numerator\\nand a denominator to make one. The following interaction shows how:\\n>>> from fractions import Fraction\\n>>> x = Fraction(1, 3)                    # Numerator, denominator\\n>>> y = Fraction(4, 6)                    # Simplified to 2, 3 by gcd\\n>>> x\\nFraction(1, 3)\\n>>> y\\nFraction(2, 3)\\n>>> print(y)\\n2/3\\nOnce created, Fractions can be used in mathematical expressions as usual:\\n>>> x + y\\nFraction(1, 1)\\n>>> x – y                           # Results are exact: numerator, denominator\\nFraction(-1, 3)\\n>>> x * y\\nFraction(2, 9)\\nFraction objects can also be created from floating-point number strings, much like\\ndecimals:\\n>>> Fraction('.25')\\nFraction(1, 4)\\n>>> Fraction('1.25')\\nFraction(5, 4)\\n>>>\\n>>> Fraction('.25') + Fraction('1.25')\\nFraction(3, 2)\\nNumeric accuracy\\nNotice that this is different from floating-point-type math, which is constrained by the\\nunderlying limitations of floating-point hardware. To compare, here are the same op-\\nerations run with floating-point objects, and notes on their limited accuracy:\\n>>> a = 1 / 3.0                     # Only as accurate as floating-point hardware\\n>>> b = 4 / 6.0                     # Can lose precision over calculations\\n>>> a\\n0.33333333333333331\\n>>> b\\n0.66666666666666663\\n>>> a + b\\n1.0\\n>>> a - b\\n-0.33333333333333331\\n>>> a * b\\n0.22222222222222221\\nThis floating-point limitation is especially apparent for values that cannot be repre-\\nsented accurately given their limited number of bits in memory. Both Fraction and\\n130 | Chapter 5: \\u2002Numeric Types\", metadata={'source': 'python.pdf', 'page': 180}),\n",
       " Document(page_content='Decimal provide ways to get exact results, albeit at the cost of some speed. For instance,\\nin the \\nfollowing example (repeated from the prior section), floating-point numbers do\\nnot accurately give the zero answer expected, but both of the other types do:\\n>>> 0.1 + 0.1 + 0.1 - 0.3           # This should be zero (close, but not exact)\\n5.5511151231257827e-17\\n>>> from fractions import Fraction\\n>>> Fraction(1, 10) + Fraction(1, 10) + Fraction(1, 10) - Fraction(3, 10)\\nFraction(0, 1)\\n>>> from decimal import Decimal\\n>>> Decimal(\\'0.1\\') + Decimal(\\'0.1\\') + Decimal(\\'0.1\\') - Decimal(\\'0.3\\')\\nDecimal(\\'0.0\\')\\nMoreover, fractions and decimals both allow more intuitive and accurate results than\\nfloating points sometimes can, in different ways (by using rational representation and\\nby limiting precision):\\n>>> 1 / 3                              # Use 3.0 in Python 2.6 for true \"/\"\\n0.33333333333333331\\n>>> Fraction(1, 3)                     # Numeric accuracy\\nFraction(1, 3)\\n>>> import decimal\\n>>> decimal.getcontext().prec = 2\\n>>> decimal.Decimal(1) / decimal.Decimal(3)\\nDecimal(\\'0.33\\')\\nIn fact, fractions both retain accuracy and automatically simplify results. Continuing\\nthe preceding interaction:\\n>>> (1 / 3) + (6 / 12)                 # Use \".0\" in Python 2.6 for true \"/\"\\n0.83333333333333326\\n>>> Fraction(6, 12)                    # Automatically simplified\\nFraction(1, 2)\\n>>> Fraction(1, 3) + Fraction(6, 12)\\nFraction(5, 6)\\n>>> decimal.Decimal(str(1/3)) + decimal.Decimal(str(6/12))\\nDecimal(\\'0.83\\')\\n>>> 1000.0 / 1234567890\\n8.1000000737100011e-07\\n>>> Fraction(1000, 1234567890)\\nFraction(100, 123456789)\\nConversions and mixed types\\nTo support fraction conversions, floating-point objects now have a method that yields\\ntheir numerator and denominator ratio, fractions have a from_float method, and\\nOther Numeric Types | 131', metadata={'source': 'python.pdf', 'page': 181}),\n",
       " Document(page_content='float accepts a Fraction as an argument. Trace through the following interaction to\\nsee how this pans out (the * in the second test is special syntax that expands a tuple\\ninto individual arguments; more on this when we study function argument passing in\\nChapter 18):\\n>>> (2.5).as_integer_ratio()               # float object method\\n(5, 2)\\n>>> f = 2.5\\n>>> z = Fraction(*f.as_integer_ratio())    # Convert float -> fraction: two args\\n>>> z                                      # Same as Fraction(5, 2)\\nFraction(5, 2)\\n>>> x                                      # x from prior interaction\\nFraction(1, 3)\\n>>> x + z\\nFraction(17, 6)                            # 5/2 + 1/3 = 15/6 + 2/6\\n>>> float(x)                               # Convert fraction -> float\\n0.33333333333333331\\n>>> float(z)\\n2.5\\n>>> float(x + z)\\n2.8333333333333335\\n>>> 17 / 6\\n2.8333333333333335\\n>>> Fraction.from_float(1.75)              # Convert float -> fraction: other way\\nFraction(7, 4)\\n>>> Fraction(*(1.75).as_integer_ratio())\\nFraction(7, 4)\\nFinally, some type mixing is allowed in expressions, though Fraction must sometimes\\nbe manually propagated to retain accuracy. Study the following interaction to see how\\nthis works:\\n>>> x\\nFraction(1, 3)\\n>>> x + 2                                  # Fraction + int -> Fraction\\nFraction(7, 3)\\n>>> x + 2.0                                # Fraction + float -> float\\n2.3333333333333335\\n>>> x + (1./3)                             # Fraction + float -> float\\n0.66666666666666663\\n>>> x + (4./3)\\n1.6666666666666665\\n>>> x + Fraction(4, 3)                     # Fraction + Fraction -> Fraction\\nFraction(5, 3)\\nCaveat: although you can convert from floating-point to fraction, in some cases there\\nis an unavoidable precision loss when you do so, because the number is inaccurate in\\nits original floating-point form. When needed, you can simplify such results by limiting\\nthe maximum denominator value:\\n132 | Chapter 5: \\u2002Numeric Types', metadata={'source': 'python.pdf', 'page': 182}),\n",
       " Document(page_content=\">>> 4.0 / 3\\n1.3333333333333333\\n>>> (4.0 / 3).as_integer_ratio()                # Precision loss from float\\n(6004799503160661, 4503599627370496)\\n>>> x\\nFraction(1, 3)\\n>>> a = x + Fraction(*(4.0 / 3).as_integer_ratio())\\n>>> a\\nFraction(22517998136852479, 13510798882111488)\\n>>> 22517998136852479 / 13510798882111488.      # 5 / 3 (or close to it!)\\n1.6666666666666667\\n>>> a.limit_denominator(10)                     # Simplify to closest fraction\\nFraction(5, 3)\\nFor more details \\non the Fraction type, experiment further on your own and consult the\\nPython 2.6 and 3.0 library manuals and other documentation.\\nSets\\nPython 2.4 also introduced a new collection type, the set—an unordered collection of\\nunique and immutable objects that supports operations corresponding to mathemati-\\ncal set theory. By definition, an item appears only once in a set, no matter how many\\ntimes it is added. As such, sets have a variety of applications, especially in numeric and\\ndatabase-focused work.\\nBecause sets are collections of other objects, they share some behavior with objects\\nsuch as lists and dictionaries that are outside the scope of this chapter. For example,\\nsets are iterable, can grow and shrink on demand, and may contain a variety of object\\ntypes. As we’ll see, a set acts much like the keys of a valueless dictionary, but it supports\\nextra operations.\\nHowever, because sets are unordered and do not map keys to values, they are neither\\nsequence nor mapping types; they are a type category unto themselves. Moreover, be-\\ncause sets are fundamentally mathematical in nature (and for many readers, may seem\\nmore academic and be used much less often than more pervasive objects like dic-\\ntionaries), we’ll explore the basic utility of Python’s set objects here.\\nSet basics in Python 2.6\\nThere are a few ways to make sets today, depending on whether you are using Python\\n2.6 or 3.0. Since this book covers both, let’s begin with the 2.6 case, which also is\\navailable (and sometimes still required) in 3.0; we’ll refine this for 3.0 extensions in a\\nmoment. To make a set object, pass in a sequence or other iterable object to the built-\\nin set function:\\n>>> x = set('abcde')\\n>>> y = set('bdxyz')\\nOther Numeric Types | 133\", metadata={'source': 'python.pdf', 'page': 183}),\n",
       " Document(page_content=\"You get back a set object, which contains all the items in the object passed in (notice\\nthat sets do not have a positional ordering, and so are not sequences):\\n>>> x\\nset(['a', 'c', 'b', 'e', 'd'])                    # 2.6 display format\\nSets made this \\nway support the common mathematical set operations with expres-\\nsion operators. Note that we can’t perform these expressions on plain sequences—we\\nmust create sets from them in order to apply these tools:\\n>>> 'e' in x                                      # Membership\\nTrue\\n>>> x – y                                         # Difference\\nset(['a', 'c', 'e'])\\n>>> x | y                                         # Union\\nset(['a', 'c', 'b', 'e', 'd', 'y', 'x', 'z'])\\n>>> x & y                                         # Intersection\\nset(['b', 'd'])\\n>>> x ^ y                                         # Symmetric difference (XOR)\\nset(['a', 'c', 'e', 'y', 'x', 'z'])\\n>>> x > y, x < y                                  # Superset, subset\\n(False, False)\\nIn addition to expressions, the set object provides methods that correspond to these\\noperations and more, and that support set changes—the set add method inserts one\\nitem, update is an in-place union, and remove deletes an item by value (run a dir call on\\nany set instance or the set type name to see all the available methods). Assuming x and\\ny are still as they were in the prior interaction:\\n>>> z = x.intersection(y)                         # Same as x & y\\n>>> z\\nset(['b', 'd'])\\n>>> z.add('SPAM')                                 # Insert one item\\n>>> z\\nset(['b', 'd', 'SPAM'])\\n>>> z.update(set(['X', 'Y']))                     # Merge: in-place union\\n>>> z\\nset(['Y', 'X', 'b', 'd', 'SPAM'])\\n>>> z.remove('b')                                 # Delete one item\\n>>> z\\nset(['Y', 'X', 'd', 'SPAM'])\\nAs iterable containers, sets can also be used in operations such as len, for loops, and\\nlist comprehensions. Because they are unordered, though, they don’t support sequence\\noperations like indexing and slicing:\\n>>> for item in set('abc'): print(item * 3)\\n...\\naaa\\n134 | Chapter 5: \\u2002Numeric Types\", metadata={'source': 'python.pdf', 'page': 184}),\n",
       " Document(page_content=\"ccc\\nbbb\\nFinally, although the \\nset expressions shown earlier generally require two sets, their\\nmethod-based counterparts can often work with any iterable type as well:\\n>>> S = set([1, 2, 3])\\n>>> S | set([3, 4])          # Expressions require both to be sets\\nset([1, 2, 3, 4])\\n>>> S | [3, 4]\\nTypeError: unsupported operand type(s) for |: 'set' and 'list'\\n>>> S.union([3, 4])          # But their methods allow any iterable\\nset([1, 2, 3, 4])\\n>>> S.intersection((1, 3, 5))\\nset([1, 3])\\n>>> S.issubset(range(-5, 5))\\nTrue\\nFor more details on set operations, see Python’s library reference manual or a reference\\nbook. Although set operations can be coded manually in Python with other types, like\\nlists and dictionaries (and often were in the past), Python’s built-in sets use efficient\\nalgorithms and implementation techniques to provide quick and standard operation.\\nSet literals in Python 3.0\\nIf you think sets are “cool,” they recently became noticeably cooler. In Python 3.0 we\\ncan still use the set built-in to make set objects, but 3.0 also adds a new set literal form,\\nusing the curly braces formerly reserved for dictionaries. In 3.0, the following are\\nequivalent:\\nset([1, 2, 3, 4])                # Built-in call\\n{1, 2, 3, 4}                     # 3.0 set literals\\nThis syntax makes sense, given that sets are essentially like valueless dictionaries —\\nbecause they are unordered, unique, and immutable, a set’s items behave much like a\\ndictionary’s keys. This operational similarity is even more striking given that dictionary\\nkey lists in 3.0 are view objects, which support set-like behavior such as intersections\\nand unions (see Chapter 8 for more on dictionary view objects).\\nIn fact, regardless of how a set is made, 3.0 displays it using the new literal format. The\\nset built-in is still required in 3.0 to create empty sets and to build sets from existing\\niterable objects (short of using set comprehensions, discussed later in this chapter), but\\nthe new literal is convenient for initializing sets of known structure:\\nC:\\\\Misc> c:\\\\python30\\\\python\\n>>> set([1, 2, 3, 4])            # Built-in: same as in 2.6\\n{1, 2, 3, 4}\\n>>> set('spam')                  # Add all items in an iterable\\n{'a', 'p', 's', 'm'}\\n>>> {1, 2, 3, 4}                 # Set literals: new in 3.0\\nOther Numeric Types | 135\", metadata={'source': 'python.pdf', 'page': 185}),\n",
       " Document(page_content=\"{1, 2, 3, 4}\\n>>> S = {'s', 'p', 'a', 'm'}\\n>>> S.add('alot')\\n>>> S\\n{'a', 'p', 's', 'm', 'alot'}\\nAll the set \\nprocessing operations discussed in the prior section work the same in 3.0,\\nbut the result sets print differently:\\n>>> S1 = {1, 2, 3, 4}\\n>>> S1 & {1, 3}                  # Intersection\\n{1, 3}\\n>>> {1, 5, 3, 6} | S1            # Union\\n{1, 2, 3, 4, 5, 6}\\n>>> S1 - {1, 3, 4}               # Difference\\n{2}\\n>>> S1 > {1, 3}                  # Superset\\nTrue\\nNote that {} is still a dictionary in Python. Empty sets must be created with the set\\nbuilt-in, and print the same way:\\n>>> S1 - {1, 2, 3, 4}            # Empty sets print differently\\nset()\\n>>> type({})                     # Because {} is an empty dictionary\\n<class 'dict'>\\n>>> S = set()                    # Initialize an empty set\\n>>> S.add(1.23)\\n>>> S\\n{1.23}\\nAs in Python 2.6, sets created with 3.0 literals support the same methods, some of which\\nallow general iterable operands that expressions do not:\\n>>> {1, 2, 3} | {3, 4}\\n{1, 2, 3, 4}\\n>>> {1, 2, 3} | [3, 4]\\nTypeError: unsupported operand type(s) for |: 'set' and 'list'\\n>>> {1, 2, 3}.union([3, 4])\\n{1, 2, 3, 4}\\n>>> {1, 2, 3}.union({3, 4})\\n{1, 2, 3, 4}\\n>>> {1, 2, 3}.union(set([3, 4]))\\n{1, 2, 3, 4}\\n>>> {1, 2, 3}.intersection((1, 3, 5))\\n{1, 3}\\n>>> {1, 2, 3}.issubset(range(-5, 5))\\nTrue\\nImmutable constraints and frozen sets\\nSets are powerful and flexible objects, but they do have one constraint in both 3.0 and\\n2.6 that you should keep in mind—largely because of their implementation, sets can\\n136 | Chapter 5: \\u2002Numeric Types\", metadata={'source': 'python.pdf', 'page': 186}),\n",
       " Document(page_content=\"only contain immutable (a.k.a “hashable”) object types. Hence, lists and dictionaries\\ncannot be embedded \\nin sets, but tuples can if you need to store compound values.\\nTuples compare by their full values when used in set operations:\\n>>> S\\n{1.23}\\n>>> S.add([1, 2, 3])                   # Only mutable objects work in a set\\nTypeError: unhashable type: 'list'\\n>>> S.add({'a':1})\\nTypeError: unhashable type: 'dict'\\n>>> S.add((1, 2, 3))\\n>>> S                                  # No list or dict, but tuple okay\\n{1.23, (1, 2, 3)}\\n>>> S | {(4, 5, 6), (1, 2, 3)}         # Union: same as S.union(...)\\n{1.23, (4, 5, 6), (1, 2, 3)}\\n>>> (1, 2, 3) in S                     # Membership: by complete values\\nTrue\\n>>> (1, 4, 3) in S\\nFalse\\nTuples in a set, for instance, might be used to represent dates, records, IP addresses,\\nand so on (more on tuples later in this part of the book). Sets themselves are mutable\\ntoo, and so cannot be nested in other sets directly; if you need to store a set inside\\nanother set, the frozenset built-in call works just like set but creates an immutable set\\nthat cannot change and thus can be embedded in other sets.\\nSet comprehensions in Python 3.0\\nIn addition to literals, 3.0 introduces a set comprehension construct; it is similar in\\nform to the list comprehension we previewed in Chapter 4, but is coded in curly braces\\ninstead of square brackets and run to make a set instead of a list. Set comprehensions\\nrun a loop and collect the result of an expression on each iteration; a loop variable gives\\naccess to the current iteration value for use in the collection expression. The result is a\\nnew set created by running the code, with all the normal set behavior:\\n>>> {x ** 2 for x in [1, 2, 3, 4]}         # 3.0 set comprehension\\n{16, 1, 4, 9}\\nIn this expression, the loop is coded on the right, and the collection expression is coded\\non the left ( x ** 2). As for list comprehensions, we get back pretty much what this\\nexpression says: “Give me a new set containing X squared, for every X in a list.” Com-\\nprehensions can also iterate across other kinds of objects, such as strings (the first of\\nthe following examples illustrates the comprehension-based way to make a set from an\\nexisting iterable):\\n>>> {x for x in 'spam'}                    # Same as: set('spam')\\n{'a', 'p', 's', 'm'}\\n>>> {c * 4 for c in 'spam'}                # Set of collected expression results\\n{'ssss', 'aaaa', 'pppp', 'mmmm'}\\n>>> {c * 4 for c in 'spamham'}\\nOther Numeric Types | 137\", metadata={'source': 'python.pdf', 'page': 187}),\n",
       " Document(page_content=\"{'ssss', 'aaaa', 'hhhh', 'pppp', 'mmmm'}\\n>>> S = {c * 4 for c in 'spam'}\\n>>> S | {'mmmm', 'xxxx'}\\n{'ssss', 'aaaa', 'pppp', 'mmmm', 'xxxx'}\\n>>> S & {'mmmm', 'xxxx'}\\n{'mmmm'}\\nBecause the rest \\nof the comprehensions story relies upon underlying concepts we’re\\nnot yet prepared to address, we’ll postpone further details until later in this book. In\\nChapter 8 , we’ll meet a first cousin in 3.0, the dictionary comprehension, and I’ll have\\nmuch more to say about all comprehensions (list, set, dictionary, and generator) later,\\nespecially in Chapters14 and 20. As we’ll learn later, all comprehensions, including\\nsets, support additional syntax not shown here, including nested loops and if tests,\\nwhich can be difficult to understand until you’ve had a chance to study larger\\nstatements.\\nWhy sets?\\nSet operations have a variety of common uses, some more practical than mathematical.\\nFor example, because items are stored only once in a set, sets can be used to filter\\nduplicates out of other collections. Simply convert the collection to a set, and then\\nconvert it back again (because sets are iterable, they work in the list call here):\\n>>> L = [1, 2, 1, 3, 2, 4, 5]\\n>>> set(L)\\n{1, 2, 3, 4, 5}\\n>>> L = list(set(L))                     # Remove duplicates\\n>>> L\\n[1, 2, 3, 4, 5]\\nSets can also be used to keep track of where you’ve already been when traversing a\\ngraph or other cyclic structure. For example, the transitive module reloader and inher-\\nitance tree lister examples we’ll study in Chapters 24 and 30, respectively, must keep\\ntrack of items visited to avoid loops. Although recording states visited as keys in a\\ndictionary is efficient, sets offer an alternative that’s essentially equivalent (and may be\\nmore or less intuitive, depending on who you ask).\\nFinally, sets are also convenient when dealing with large data sets (database query\\nresults, for example)—the intersection of two sets contains objects in common to both\\ncategories, and the union contains all items in either set. To illustrate, here’s a some-\\nwhat more realistic example of set operations at work, applied to lists of people in a\\nhypothetical company, using 3.0 set literals (use set in 2.6):\\n>>> engineers = {'bob', 'sue', 'ann', 'vic'}\\n>>> managers  = {'tom', 'sue'}\\n>>> 'bob' in engineers                   # Is bob an engineer?\\nTrue\\n>>> engineers & managers                 # Who is both engineer and manager?\\n138 | Chapter 5: \\u2002Numeric Types\", metadata={'source': 'python.pdf', 'page': 188}),\n",
       " Document(page_content=\"{'sue'}\\n>>> engineers | managers                 # All people in either category\\n{'vic', 'sue', 'tom', 'bob', 'ann'}\\n>>> engineers – managers                 # Engineers who are not managers\\n{'vic', 'bob', 'ann'}\\n>>> managers – engineers                 # Managers who are not engineers\\n{'tom'}\\n>>> engineers > managers                 # Are all managers engineers? (superset)\\nFalse\\n>>> {'bob', 'sue'} < engineers           # Are both engineers? (subset)\\nTrue\\n>>> (managers | engineers) > managers    # All people is a superset of managers\\nTrue\\n>>> managers ^ engineers                 # Who is in one but not both?\\n{'vic', 'bob', 'ann', 'tom'}\\n>>> (managers | engineers) - (managers ^ engineers)     # Intersection!\\n{'sue'}\\nYou can find \\nmore details on set operations in the Python library manual and some\\nmathematical and relational database theory texts. Also stay tuned for Chapter 8’s\\nrevival of some of the set operations we’ve seen here, in the context of dictionary view\\nobjects in Python 3.0.\\nBooleans\\nSome argue that the Python Boolean type, bool, is numeric in nature because its two\\nvalues, True and False, are just customized versions of the integers 1 and 0 that print\\nthemselves differently. Although that’s all most programmers need to know, let’s ex-\\nplore this type in a bit more detail.\\nMore formally, Python today has an explicit Boolean data type called bool, with the\\nvalues True and False available as new preassigned built-in names. Internally, the names\\nTrue and False are instances of bool, which is in turn just a subclass (in the object-\\noriented sense) of the built-in integer type int. True and False behave exactly like the\\nintegers 1 and 0, except that they have customized printing logic—they print them-\\nselves as the words True and False, instead of the digits 1 and 0. bool accomplishes this\\nby redefining str and repr string formats for its two objects.\\nBecause of this customization, the output of Boolean expressions typed at the interac-\\ntive prompt prints as the words True and False instead of the older and less obvious 1\\nand 0. In addition, Booleans make truth values more explicit. For instance, an infinite\\nloop can now be coded as while True:  instead of the less intuitive while 1: . Similarly,\\nOther Numeric Types | 139\", metadata={'source': 'python.pdf', 'page': 189}),\n",
       " Document(page_content=\"flags can be initialized more clearly with flag = False. We’ll discuss these statements\\nfurther in Part III.\\nAgain, though, for \\nall other practical purposes, you can treat True and False as though\\nthey are predefined variables set to integer 1 and 0. Most programmers used to preassign\\nTrue and False to 1 and 0 anyway; the bool type simply makes this standard. Its im-\\nplementation can lead to curious results, though. Because True is just the integer 1 with\\na custom display format, True + 4 yields 5 in Python:\\n>>> type(True)\\n<class 'bool'>\\n>>> isinstance(True, int)\\nTrue\\n>>> True == 1                # Same value\\nTrue\\n>>> True is 1                # But different object: see the next chapter\\nFalse\\n>>> True or False            # Same as: 1 or 0\\nTrue\\n>>> True + 4                 # (Hmmm)\\n5\\nSince you probably won’t come across an expression like the last of these in real Python\\ncode, you can safely ignore its deeper metaphysical implications....\\nWe’ll revisit Booleans in Chapter 9  (to define Python’s notion of truth) and again in\\nChapter 12 (to see how Boolean operators like and and or work).\\nNumeric Extensions\\nFinally, although Python core numeric types offer plenty of power for most applica-\\ntions, there is a large library of third-party open source extensions available to address\\nmore focused needs. Because numeric programming is a popular domain for Python,\\nyou’ll find a wealth of advanced tools.\\nFor example, if you need to do serious number crunching, an optional extension for\\nPython called NumPy (Numeric Python) provides advanced numeric programming\\ntools, such as a matrix data type, vector processing, and sophisticated computation\\nlibraries. Hardcore scientific programming groups at places like Los Alamos and NASA\\nuse Python with NumPy to implement the sorts of tasks they previously coded in\\nC++, FORTRAN, or Matlab. The combination of Python and NumPy is often com-\\npared to a free, more flexible version of Matlab—you get NumPy’s performance, plus\\nthe Python language and its libraries.\\nBecause it’s so advanced, we won’t talk further about NumPy in this book. You can\\nfind additional support for advanced numeric programming in Python, including\\ngraphics and plotting tools, statistics libraries, and the popular SciPy package at Py-\\nthon’s PyPI site, or by searching the Web. Also note that NumPy is currently an optional\\nextension; it doesn’t come with Python and must be installed separately.\\n140 | Chapter 5: \\u2002Numeric Types\", metadata={'source': 'python.pdf', 'page': 190}),\n",
       " Document(page_content='Chapter Summary\\nThis chapter has taken a tour of Python’s numeric object types and the operations we\\ncan apply to \\nthem. Along the way, we met the standard integer and floating-point types,\\nas well as some more exotic and less commonly used types such as complex numbers,\\nfractions, and sets. We also explored Python’s expression syntax, type conversions,\\nbitwise operations, and various literal forms for coding numbers in scripts.\\nLater in this part of the book, I’ll fill in some details about the next object type, the\\nstring. In the next chapter, however, we’ll take some time to explore the mechanics of\\nvariable assignment in more detail than we have here. This turns out to be perhaps the\\nmost fundamental idea in Python, so make sure you check out the next chapter before\\nmoving on. First, though, it’s time to take the usual chapter quiz.\\nTest Your Knowledge: Quiz\\n1. What is the value of the expression 2 * (3 + 4)\\n in Python?\\n2. What is the value of the expression 2 * 3 + 4 in Python?\\n3. What is the value of the expression 2 + 3 * 4 in Python?\\n4. What tools can you use to find a number’s square root, as well as its square?\\n5. What is the type of the result of the expression 1 + 2.0 + 3?\\n6. How can you truncate and round a floating-point number?\\n7. How can you convert an integer to a floating-point number?\\n8. How would you display an integer in octal, hexadecimal, or binary notation?\\n9. How might you convert an octal, hexadecimal, or binary string to a plain integer?\\nTest Your Knowledge: Answers\\n1. The value will be 14, the result of 2 * 7, because the parentheses force the addition\\nto happen before the multiplication.\\n2. The value will be 10, the result of 6 + 4. Python’s operator precedence rules are\\napplied in the absence of parentheses, and multiplication has higher precedence\\nthan (i.e., happens before) addition, per Table 5-2.\\n3. This expression yields 14, the result of 2 + 12, for the same precedence reasons as\\nin the prior question.\\n4. Functions for obtaining the square root, as well as pi, tangents, and more, are\\navailable in the imported math module. To find a number’s square root, import\\nmath and call math.sqrt(N). To get a number’s square, use either the exponent\\nTest Your Knowledge: Answers | 141', metadata={'source': 'python.pdf', 'page': 191}),\n",
       " Document(page_content='expression X ** 2 or the built-in function pow(X, 2) . Either of these last two can\\nalso compute the square root when given a power of 0.5 (e.g., X ** .5).\\n5. The result will be a floating-point number: the integers are converted up to floating\\npoint, the most complex type in the expression, and floating-point math is used to\\nevaluate it.\\n6. The int(N) and math.trunc(N) functions truncate, and the round(N, digits) func-\\ntion rounds. We can also compute the floor with math.floor(N) and round for\\ndisplay with string formatting operations.\\n7. The float(I) function converts an integer to a floating point; mixing an integer\\nwith a floating point within an expression will result in a conversion as well. In\\nsome sense, Python 3.0 / division converts too—it always returns a floating-point\\nresult that includes the remainder, even if both operands are integers.\\n8. The oct(I) and hex(I) built-in functions return the octal and hexadecimal string\\nforms for an integer. The bin(I) call also returns a number’s binary digits string in\\nPython 2.6 and 3.0. The % string formatting expression and format string method\\nalso provide targets for some such conversions.\\n9. The int(S, base) function can be used to convert from octal and hexadecimal\\nstrings to normal integers (pass in 8, 16, or 2 for the base). The eval(S) function\\ncan be used for this purpose too, but it’s more expensive to run and can have\\nsecurity issues. Note that integers are always stored in binary in computer memory;\\nthese are just display string format conversions.\\n142 | Chapter 5: \\u2002Numeric Types', metadata={'source': 'python.pdf', 'page': 192}),\n",
       " Document(page_content='CHAPTER 6\\nThe Dynamic Typing Interlude\\nIn the prior chapter, we began exploring Python’s core object types in depth with a\\nlook at Python \\nnumbers. We’ll resume our object type tour in the next chapter, but\\nbefore we move on, it’s important that you get a handle on what may be the most\\nfundamental idea in Python programming and is certainly the basis of much of both\\nthe conciseness and flexibility of the Python language—dynamic typing, and the poly-\\nmorphism it yields.\\nAs you’ll see here and later in this book, in Python, we do not declare the specific types\\nof the objects our scripts use. In fact, programs should not even care about specific\\ntypes; in exchange, they are naturally applicable in more contexts than we can some-\\ntimes even plan ahead for. Because dynamic typing is the root of this flexibility, let’s\\ntake a brief look at the model here.\\nThe Case of the Missing Declaration Statements\\nIf you have a background in compiled or statically typed languages like C, C++, or Java,\\nyou might find yourself a bit perplexed at this point in the book. So far, we’ve been\\nusing variables without declaring their existence or their types, and it somehow works.\\nWhen we type a = 3 in an interactive session or program file, for instance, how does\\nPython know that a should stand for an integer? For that matter, how does Python\\nknow what a is at all?\\nOnce you start asking such questions, you’ve crossed over into the domain of Python’s\\ndynamic typing  model. In Python, types are determined automatically at runtime, not\\nin response to declarations in your code. This means that you never declare variables\\nahead of time (a concept that is perhaps simpler to grasp if you keep in mind that it all\\nboils down to variables, objects, and the links between them).\\n143', metadata={'source': 'python.pdf', 'page': 193}),\n",
       " Document(page_content='Variables, Objects, and References\\nAs you’ve seen \\nin many of the examples used so far in this book, when you run an\\nassignment statement such as a = 3 in Python, it works even if you’ve never told Python\\nto use the name a as a variable, or that a should stand for an integer-type object. In the\\nPython language, this all pans out in a very natural way, as follows:\\nVariable creation\\nA variable (i.e., name), like a, is created when your code first assigns it a value.\\nFuture assignments change the value of the already created name. Technically,\\nPython detects some names before your code runs, but you can think of it as though\\ninitial assignments make variables.\\nVariable types\\nA variable never has any type information or constraints associated with it. The\\nnotion of type lives with objects, not names. Variables are generic in nature; they\\nalways simply refer to a particular object at a particular point in time.\\nVariable use\\nWhen a variable appears in an expression, it is immediately replaced with the object\\nthat it currently refers to, whatever that may be. Further, all variables must be\\nexplicitly assigned before they can be used; referencing unassigned variables results\\nin errors.\\nIn sum, variables are created when assigned, can reference any type of object, and must\\nbe assigned before they are referenced. This means that you never need to declare names\\nused by your script, but you must initialize names before you can update them; coun-\\nters, for example, must be initialized to zero before you can add to them.\\nThis dynamic typing model is strikingly different from the typing model of traditional\\nlanguages. When you are first starting out, the model is usually easier to understand if\\nyou keep clear the distinction between names and objects. For example, when we say\\nthis:\\n>>> a = 3\\nat least conceptually, Python will perform three distinct steps to carry out the request.\\nThese steps reflect the operation of all assignments in the Python language:\\n1. Create an object to represent the value 3.\\n2. Create the variable a, if it does not yet exist.\\n3. Link the variable a to the new object 3.\\nThe net result will be a structure inside Python that resembles Figure 6-1 . As sketched,\\nvariables and objects are stored in different parts of memory and are associated by links\\n(the link is shown as a pointer in the figure). Variables always link to objects and never\\nto other variables, but larger objects may link to other objects (for instance, a list object\\nhas links to the objects it contains).\\n144 | Chapter 6: \\u2002The Dynamic Typing Interlude', metadata={'source': 'python.pdf', 'page': 194}),\n",
       " Document(page_content='These links from variables to objects are called references in Python—that is, a reference\\nis a kind of association, implemented as a pointer in memory.* Whenever the variables\\nare later used (i.e., referenced), Python automatically follows the variable-to-object\\nlinks. This is all simpler than the terminology may imply. In concrete terms:\\n•Variables are entries in a system table, with spaces for links to objects.\\n•Objects are pieces of allocated memory, with enough space to represent the values\\nfor which they stand.\\n•References are automatically followed pointers from variables to objects.\\nAt least conceptually, each time you generate a new value in your script by running an\\nexpression, Python creates a new object (i.e., a chunk of memory) to represent that\\nvalue. Internally, as an optimization, Python caches and reuses certain kinds of un-\\nchangeable objects, such as small integers and strings (each 0 is not really a new piece\\nof memory—more on this caching behavior later). But, from a logical perspective, it\\nworks as though each expression’s result value is a distinct object and each object is a\\ndistinct piece of memory.\\nTechnically speaking, objects have more structure than just enough space to represent\\ntheir values. Each object also has two standard header fields: a type designator  used to\\nmark the type of the object, and a reference counter  used to determine when it’s OK to\\nreclaim the object. To understand how these two header fields factor into the model,\\nwe need to move on.\\nTypes Live with Objects, Not Variables\\nTo see how object types come into play, watch what happens if we assign a variable\\nmultiple times:\\nFigure 6-1. Names and objects after running the assignment a = 3. Variable a becomes a reference to\\nthe object 3. \\nInternally, the variable is really a pointer to the object’s memory space created by running\\nthe literal expression 3.\\n* Readers with a background in C may find Python references similar to C pointers (memory addresses). In\\nfact, references \\nare implemented as pointers, and they often serve the same roles, especially with objects that\\ncan be changed in-place (more on this later). However, because references are always automatically\\ndereferenced when used, you can never actually do anything useful with a reference itself; this is a feature\\nthat eliminates a vast category of C bugs. You can think of Python references as C “void*” pointers, which\\nare automatically followed whenever used.\\nThe Case of the Missing Declaration Statements | 145', metadata={'source': 'python.pdf', 'page': 195}),\n",
       " Document(page_content=\">>> a = 3             # It's an integer\\n>>> a = 'spam'        # Now it's a string\\n>>> a = 1.23          # Now it's a floating point\\nThis isn’t typical \\nPython code, but it does work— a starts out as an integer, then be-\\ncomes a string, and finally becomes a floating-point number. This example tends to\\nlook especially odd to ex-C programmers, as it appears as though the type of a changes\\nfrom integer to string when we say a = 'spam'.\\nHowever, that’s not really what’s happening. In Python, things work more simply.\\nNames have no types; as stated earlier, types live with objects, not names. In the pre-\\nceding listing, we’ve simply changed a to reference different objects. Because variables\\nhave no type, we haven’t actually changed the type of the variable a; we’ve simply made\\nthe variable reference a different type of object. In fact, again, all we can ever say about\\na variable in Python is that it references a particular object at a particular point in time.\\nObjects, on the other hand, know what type they are—each object contains a header\\nfield that tags the object with its type. The integer object 3, for example, will contain\\nthe value 3, plus a designator that tells Python that the object is an integer (strictly\\nspeaking, a pointer to an object called int, the name of the integer type). The type\\ndesignator of the 'spam' string object points to the string type (called str) instead.\\nBecause objects know their types, variables don’t have to.\\nTo recap, types are associated with objects in Python, not with variables. In typical\\ncode, a given variable usually will reference just one kind of object. Because this isn’t\\na requirement, though, you’ll find that Python code tends to be much more flexible\\nthan you may be accustomed to—if you use Python well, your code might work on\\nmany types automatically.\\nI mentioned that objects have two header fields, a type designator and a reference\\ncounter. To understand the latter of these, we need to move on and take a brief look\\nat what happens at the end of an object’s life.\\nObjects Are Garbage-Collected\\nIn the prior section’s listings, we assigned the variable a to different types of objects in\\neach assignment. But when we reassign a variable, what happens to the value it was\\npreviously referencing? For example, after the following statements, what happens to\\nthe object 3?\\n>>> a = 3\\n>>> a = 'spam'\\nThe answer is that in Python, whenever a name is assigned to a new object, the space\\nheld by the prior object is reclaimed (if it is not referenced by any other name or object).\\nThis automatic reclamation of objects’ space is known as garbage collection.\\nTo illustrate, consider the following example, which sets the name x to a different object\\non each assignment:\\n146 | Chapter 6: \\u2002The Dynamic Typing Interlude\", metadata={'source': 'python.pdf', 'page': 196}),\n",
       " Document(page_content=\">>> x = 42\\n>>> x = 'shrubbery'          # Reclaim 42 now (unless referenced elsewhere)\\n>>> x = 3.1415               # Reclaim 'shrubbery' now\\n>>> x = [1, 2, 3]            # Reclaim 3.1415 now\\nFirst, notice that x\\n is set to a different type of object each time. Again, though this is\\nnot really the case, the effect is as though the type of x is changing over time. Remember,\\nin Python types live with objects, not names. Because names are just generic references\\nto objects, this sort of code works naturally.\\nSecond, notice that references to objects are discarded along the way. Each time x is\\nassigned to a new object, Python reclaims the prior object’s space. For instance, when\\nit is assigned the string 'shrubbery', the object 42 is immediately reclaimed (assuming\\nit is not referenced anywhere else)—that is, the object’s space is automatically thrown\\nback into the free space pool, to be reused for a future object.\\nInternally, Python accomplishes this feat by keeping a counter in every object that keeps\\ntrack of the number of references currently pointing to that object. As soon as (and\\nexactly when) this counter drops to zero, the object’s memory space is automatically\\nreclaimed. In the preceding listing, we’re assuming that each time x is assigned to a new\\nobject, the prior object’s reference counter drops to zero, causing it to be reclaimed.\\nThe most immediately tangible benefit of garbage collection is that it means you can\\nuse objects liberally without ever needing to free up space in your script. Python will\\nclean up unused space for you as your program runs. In practice, this eliminates a\\nsubstantial amount of bookkeeping code required in lower-level languages such as C\\nand C++.\\nTechnically speaking, Python’s garbage collection is based mainly upon \\nreference counters , as described \\nhere; however, it also has a component\\nthat detects and reclaims objects with cyclic references  in time. This\\ncomponent can be disabled if you’re sure that your code doesn’t create\\ncycles, but it is enabled by default.\\nBecause references are implemented as pointers, it’s possible for an ob-\\nject to reference itself, or reference another object that does. For exam-\\nple, exercise 3 at the end of Part I  and its solution in Appendix B  show\\nhow to create a cycle by embedding a reference to a list within itself.\\nThe same phenomenon can occur for assignments to attributes of ob-\\njects created from user-defined classes. Though relatively rare, because\\nthe reference counts for such objects never drop to zero, they must be\\ntreated specially.\\nFor more details on Python’s cycle detector, see the documentation for\\nthe gc module in Python’s library manual. Also note that this description\\nof Python’s garbage collector applies to the standard CPython only; Jy-\\nthon and IronPython may use different schemes, though the net effect\\nin all is similar—unused space is reclaimed for you automatically.\\nThe Case of the Missing Declaration Statements | 147\", metadata={'source': 'python.pdf', 'page': 197}),\n",
       " Document(page_content=\"Shared References\\nSo far, we’ve \\nseen what happens as a single variable is assigned references to objects.\\nNow let’s introduce another variable into our interaction and watch what happens to\\nits names and objects:\\n>>> a = 3\\n>>> b = a\\nTyping these two statements generates the scene captured in Figure 6-2. The second\\nline causes Python to create the variable b; the variable a is being used and not assigned\\nhere, so it is replaced with the object it references ( 3), and b is made to reference that\\nobject. The net effect is that the variables a and b wind up referencing the same object\\n(that is, pointing to the same chunk of memory). This scenario, with multiple names\\nreferencing the same object, is called a shared reference in Python.\\nFigure 6-2. Names and objects after next running the assignment b = a. Variable b becomes a reference\\nto the object \\n3. Internally, the variable is really a pointer to the object’s memory space created by\\nrunning the literal expression 3.\\nNext, suppose we extend the session with one more statement:\\n>>> a = 3\\n>>> b = a\\n>>> a = 'spam'\\nAs with all Python assignments, this statement simply makes a new object to represent\\nthe string value 'spam' and sets a to reference this new object. It does not, however,\\nchange the value of b; b still references the original object, the integer 3. The resulting\\nreference structure is shown in Figure 6-3.\\nThe same sort of thing would happen if we changed b to 'spam' instead—the assignment\\nwould change only b, not a. This behavior also occurs if there are no type differences\\nat all. For example, consider these three statements:\\n>>> a = 3\\n>>> b = a\\n>>> a = a + 2\\n148 | Chapter 6: \\u2002The Dynamic Typing Interlude\", metadata={'source': 'python.pdf', 'page': 198}),\n",
       " Document(page_content='In this sequence, the same events transpire. Python makes the variable a reference the\\nobject 3 and makes b\\n reference the same object as a, as in Figure 6-2 ; as before, the last\\nassignment then sets a to a completely different object (in this case, the integer 5, which\\nis the result of the + expression). It does not change b as a side effect. In fact, there is\\nno way to ever overwrite the value of the object 3—as introduced in Chapter 4, integers\\nare immutable and thus can never be changed in-place.\\nOne way to think of this is that, unlike in some languages, in Python variables are always\\npointers to objects, not labels of changeable memory areas: setting a variable to a new\\nvalue does not alter the original object, but rather causes the variable to reference an\\nentirely different object. The net effect is that assignment to a variable can impact only\\nthe single variable being assigned. When mutable objects and in-place changes enter\\nthe equation, though, the picture changes somewhat; to see how, let’s move on.\\nShared References and In-Place Changes\\nAs you’ll see later in this part’s chapters, there are objects and operations that perform\\nin-place object changes. For instance, an assignment to an offset in a list actually\\nchanges the list object itself in-place, rather than generating a brand new list object.\\nFor objects that support such in-place changes, you need to be more aware of shared\\nreferences, since a change from one name may impact others.\\nTo further illustrate, let’s take another look at the list objects introduced in Chap-\\nter 4 . Recall that lists, which do support in-place assignments to positions, are simply\\ncollections of other objects, coded in square brackets:\\n>>> L1 = [2, 3, 4]\\n>>> L2 = L1\\nFigure 6-3. Names and objects after finally running the assignment a = ‘spam’. Variable a references\\nthe new object \\n(i.e., piece of memory) created by running the literal expression ‘spam’, but variable b\\nstill refers to the original object 3. Because this assignment is not an in-place change to the object 3,\\nit changes only variable a, not b.\\nShared References | 149', metadata={'source': 'python.pdf', 'page': 199}),\n",
       " Document(page_content='L1 here is a list containing the objects 2, 3 , and 4. Items inside a list are accessed by their\\npositions, so L1[0] refers to object 2, the first item in the list L1. Of course, lists are also\\nobjects in their own right, just like integers and strings. After running the two prior\\nassignments, L1 and L2 reference the same object, just like a and b in the prior example\\n(see Figure 6-2). Now say that, as before, we extend this interaction to say the following:\\n>>> L1 = 24\\nThis assignment simply sets L1 is to a different object; L2 still references the original\\nlist. If we change this statement’s syntax slightly, however, it has a radically different\\neffect:\\n>>> L1 = [2, 3, 4]        # A mutable object\\n>>> L2 = L1               # Make a reference to the same object\\n>>> L1[0] = 24            # An in-place change\\n>>> L1                    # L1 is different\\n[24, 3, 4]\\n>>> L2                    # But so is L2!\\n[24, 3, 4]\\nReally, we haven’t changed L1 itself here; we’ve changed a component of the object that\\nL1 references. This sort of change overwrites part of the list object in-place. Because the\\nlist object is shared by (referenced from) other variables, though, an in-place change\\nlike this doesn’t only affect L1—that is, you must be aware that when you make such\\nchanges, they can impact other parts of your program. In this example, the effect shows\\nup in L2 as well because it references the same object as L1. Again, we haven’t actually\\nchanged L2, either, but its value will appear different because it has been overwritten.\\nThis behavior is usually what you want, but you should be aware of how it works, so\\nthat it’s expected. It’s also just the default: if you don’t want such behavior, you can\\nrequest that Python copy objects instead of making references. There are a variety of\\nways to copy a list, including using the built-in list function and the standard library\\ncopy module. Perhaps the most common way is to slice from start to finish (see Chapters\\n4 and 7 for more on slicing):\\n>>> L1 = [2, 3, 4]\\n>>> L2 = L1[:]            # Make a copy of L1\\n>>> L1[0] = 24\\n>>> L1\\n[24, 3, 4]\\n>>> L2                    # L2 is not changed\\n[2, 3, 4]\\nHere, the change made through L1 is not reflected in L2 because L2 references a copy\\nof the object L1 references; that is, the two variables point to different pieces of memory.\\n150 | Chapter 6: \\u2002The Dynamic Typing Interlude', metadata={'source': 'python.pdf', 'page': 200}),\n",
       " Document(page_content='Note that this slicing technique won’t work on the other major mutable core types,\\ndictionaries and sets, \\nbecause they are not sequences—to copy a dictionary or set,\\ninstead use their X.copy() method call. Also, note that the standard library copy module\\nhas a call for copying any object type generically, as well as a call for copying nested\\nobject structures (a dictionary with nested lists, for example):\\nimport copy\\nX = copy.copy(Y)          # Make top-level \"shallow\" copy of any object Y\\nX = copy.deepcopy(Y)      # Make deep copy of any object Y: copy all nested parts\\nWe’ll explore lists and dictionaries in more depth, and revisit the concept of shared\\nreferences and copies, in Chapters 8 and 9. For now, keep in mind that objects that can\\nbe changed in-place (that is, mutable objects) are always open to these kinds of effects.\\nIn Python, this includes lists, dictionaries, and some objects defined with class state-\\nments. If this is not the desired behavior, you can simply copy your objects as needed.\\nShared References and Equality\\nIn the interest of full disclosure, I should point out that the garbage-collection behavior\\ndescribed earlier in this chapter may be more conceptual than literal for certain types.\\nConsider these statements:\\n>>> x = 42\\n>>> x = \\'shrubbery\\'       # Reclaim 42 now?\\nBecause Python caches and reuses small integers and small strings, as mentioned earlier,\\nthe object 42 here is probably not literally reclaimed; instead, it will likely remain in a\\nsystem table to be reused the next time you generate a 42 in your code. Most kinds of\\nobjects, though, are reclaimed immediately when they are no longer referenced; for\\nthose that are not, the caching mechanism is irrelevant to your code.\\nFor instance, because of Python’s reference model, there are two different ways to check\\nfor equality in a Python program. Let’s create a shared reference to demonstrate:\\n>>> L = [1, 2, 3]\\n>>> M = L                 # M and L reference the same object\\n>>> L == M                # Same value\\nTrue\\n>>> L is M                # Same object\\nTrue\\nThe first technique here, the == operator, tests whether the two referenced objects have\\nthe same values; this is the method almost always used for equality checks in Python.\\nThe second method, the is operator, instead tests for object identity—it returns True\\nonly if both names point to the exact same object, so it is a much stronger form of\\nequality testing.\\nShared References | 151', metadata={'source': 'python.pdf', 'page': 201}),\n",
       " Document(page_content='Really, is simply compares the pointers that implement references, and it serves as a\\nway to \\ndetect shared references in your code if needed. It returns False if the names\\npoint to equivalent but different objects, as is the case when we run two different literal\\nexpressions:\\n>>> L = [1, 2, 3]\\n>>> M = [1, 2, 3]         # M and L reference different objects\\n>>> L == M                # Same values\\nTrue\\n>>> L is M                # Different objects\\nFalse\\nNow, watch what happens when we perform the same operations on small numbers:\\n>>> X = 42\\n>>> Y = 42                # Should be two different objects\\n>>> X == Y\\nTrue\\n>>> X is Y                # Same object anyhow: caching at work!\\nTrue\\nIn this interaction, X and Y should be == (same value), but not is (same object) because\\nwe ran two different literal expressions. Because small integers and strings are cached\\nand reused, though, is tells us they reference the same single object.\\nIn fact, if you really want to look under the hood, you can always ask Python how many\\nreferences there are to an object: the getrefcount function in the standard sys module\\nreturns the object’s reference count. When I ask about the integer object 1 in the IDLE\\nGUI, for instance, it reports 837 reuses of this same object (most of which are in IDLE’s\\nsystem code, not mine):\\n>>> import sys\\n>>> sys.getrefcount(1)    # 837 pointers to this shared piece of memory\\n837\\nThis object caching and reuse is irrelevant to your code (unless you run the is check!).\\nBecause you cannot change numbers or strings in-place, it doesn’t matter how many\\nreferences there are to the same object. Still, this behavior reflects one of the many ways\\nPython optimizes its model for execution speed.\\nDynamic Typing Is Everywhere\\nOf course, you don’t really need to draw name/object diagrams with circles and arrows\\nto use Python. When you’re starting out, though, it sometimes helps you understand\\nunusual cases if you can trace their reference structures. If a mutable object changes\\nout from under you when passed around your program, for example, chances are you\\nare witnessing some of this chapter’s subject matter firsthand.\\nMoreover, even if dynamic typing seems a little abstract at this point, you probably will\\ncare about it eventually. Because everything seems to work by assignment and\\nreferences in Python, a basic understanding of this model is useful in many different\\n152 | Chapter 6: \\u2002The Dynamic Typing Interlude', metadata={'source': 'python.pdf', 'page': 202}),\n",
       " Document(page_content='contexts. As you’ll see, it works the same in assignment statements, function argu-\\nments, for loop variables, \\nmodule imports, class attributes, and more. The good news\\nis that there is just one assignment model in Python; once you get a handle on dynamic\\ntyping, you’ll find that it works the same everywhere in the language.\\nAt the most practical level, dynamic typing means there is less code for you to write.\\nJust as importantly, though, dynamic typing is also the root of Python’s polymor-\\nphism, a concept we introduced in Chapter 4  and will revisit again later in this book.\\nBecause we do not constrain types in Python code, it is highly flexible. As you’ll see,\\nwhen used well, dynamic typing and the polymorphism it provides produce code that\\nautomatically adapts to new requirements as your systems evolve.\\nChapter Summary\\nThis chapter took a deeper look at Python’s dynamic typing model—that is, the way\\nthat Python keeps track of object types for us automatically, rather than requiring us\\nto code declaration statements in our scripts. Along the way, we learned how variables\\nand objects are associated by references in Python; we also explored the idea of garbage\\ncollection, learned how shared references to objects can affect multiple variables, and\\nsaw how references impact the notion of equality in Python.\\nBecause there is just one assignment model in Python, and because assignment pops\\nup everywhere in the language, it’s important that you have a handle on the model\\nbefore moving on. The following quiz should help you review some of this chapter’s\\nideas. After that, we’ll resume our object tour in the next chapter, with strings.\\nTest Your Knowledge: Quiz\\n1. Consider the following three statements. Do they change the value printed for A\\n?\\nA = \"spam\"\\nB = A\\nB = \"shrubbery\"\\n2. Consider these three statements. Do they change the printed value of A?\\nA = [\"spam\"]\\nB = A\\nB[0] = \"shrubbery\"\\n3. How about these—is A changed now?\\nA = [\"spam\"]\\nB = A[:]\\nB[0] = \"shrubbery\"\\nTest Your Knowledge: Quiz | 153', metadata={'source': 'python.pdf', 'page': 203}),\n",
       " Document(page_content='Test Your Knowledge: Answers\\n1. No: A \\nstill prints as \"spam\". When B is assigned to the string \"shrubbery\", all that\\nhappens is that the variable B is reset to point to the new string object. A and B\\ninitially share (i.e., reference/point to) the same single string object \"spam\", but two\\nnames are never linked together in Python. Thus, setting B to a different object has\\nno effect on A. The same would be true if the last statement here was B = B +\\n\\'shrubbery\\', by the way—the concatenation would make a new object for its result,\\nwhich would then be assigned to B only. We can never overwrite a string (or num-\\nber, or tuple) in-place, because strings are immutable.\\n2. Yes: A now prints as [\"shrubbery\"]. Technically, we haven’t really changed either\\nA or B; instead, we’ve changed part of the object they both reference (point to) by\\noverwriting that object in-place through the variable B. Because A references the\\nsame object as B, the update is reflected in A as well.\\n3. No: A still prints as [\"spam\"]. The in-place assignment through B has no effect this\\ntime because the slice expression made a copy of the list object before it was as-\\nsigned to B. After the second assignment statement, there are two different list\\nobjects that have the same value (in Python, we say they are ==, but not is). The\\nthird statement changes the value of the list object pointed to by B, but not that\\npointed to by A.\\n154 | Chapter 6: \\u2002The Dynamic Typing Interlude', metadata={'source': 'python.pdf', 'page': 204}),\n",
       " Document(page_content='CHAPTER 7\\nStrings\\nThe next major type on our built-in object tour is the Python string—an ordered col-\\nlection \\nof characters used to store and represent text-based information. We looked\\nbriefly at strings in Chapter 4 . Here, we will revisit them in more depth, filling in some\\nof the details we skipped then.\\nFrom a functional perspective, strings can be used to represent just about anything that\\ncan be encoded as text: symbols and words (e.g., your name), contents of text files\\nloaded into memory, Internet addresses, Python programs, and so on. They can also\\nbe used to hold the absolute binary values of bytes, and multibyte Unicode text used\\nin internationalized programs.\\nYou may have used strings in other languages, too. Python’s strings serve the same role\\nas character arrays in languages such as C, but they are a somewhat higher-level tool\\nthan arrays. Unlike in C, in Python, strings come with a powerful set of processing\\ntools. Also unlike languages such as C, Python has no distinct type for individual char-\\nacters; instead, you just use one-character strings.\\nStrictly speaking, Python strings are categorized as immutable sequences, meaning that\\nthe characters they contain have a left-to-right positional order and that they cannot\\nbe changed in-place. In fact, strings are the first representative of the larger class of\\nobjects called sequences that we will study here. Pay special attention to the sequence\\noperations introduced in this chapter, because they will work the same on other se-\\nquence types we’ll explore later, such as lists and tuples.\\nTable 7-1  previews common string literals and operations we will discuss in this chap-\\nter. Empty strings are written as a pair of quotation marks (single or double) with\\nnothing in between, and there are a variety of ways to code strings. For processing,\\nstrings support expression operations such as concatenation (combining strings), slic-\\ning (extracting sections), indexing (fetching by offset), and so on. Besides expressions,\\nPython also provides a set of string methods that implement common string-specific\\ntasks, as well as modules for more advanced text-processing tasks such as pattern\\nmatching. We’ll explore all of these later in the chapter.\\n155', metadata={'source': 'python.pdf', 'page': 205}),\n",
       " Document(page_content='Table 7-1. Common string literals and operations\\nOperation Interpretation\\nS = \\'\\' Empty string\\nS = \"spam\\'s\" Double quotes, same as single\\nS = \\'s\\\\np\\\\ta\\\\x00m\\' Escape sequences\\nS = \"\"\"...\"\"\" Triple-quoted block strings\\nS = r\\'\\\\temp\\\\spam\\' Raw strings\\nS = b\\'spam\\' Byte strings in 3.0 (Chapter 36)\\nS = u\\'spam\\' Unicode strings in 2.6 only (Chapter 36)\\nS1 + S2\\nS * 3Concatenate, repeat\\nS[i]\\nS[i:j]\\nlen(S)Index, slice, length\\n\"a %s parrot\" % kind String formatting expression\\n\"a {0} parrot\".format(kind) String formatting method in 2.6 and 3.0\\nS.find(\\'pa\\')\\nS.rstrip()\\nS.replace(\\'pa\\', \\'xx\\')\\nS.split(\\',\\')\\nS.isdigit()\\nS.lower()\\nS.endswith(\\'spam\\')\\n\\'spam\\'.join(strlist)\\nS.encode(\\'latin-1\\')String method calls: search,\\nremove whitespace,\\nreplacement,\\nsplit on delimiter,\\ncontent test,\\ncase conversion,\\nend test,\\ndelimiter join,\\nUnicode encoding, etc.\\nfor x in S: print(x)\\n\\'spam\\' in S\\n[c * 2 for c in S]\\nmap(ord, S)Iteration, membership\\nBeyond the core set of string tools in Table 7-1 , Python also supports more advanced\\npattern-based string processing with the standard library’s re (regular expression)\\nmodule, introduced in Chapter 4 , and even higher-level text processing tools such as\\nXML parsers, discussed briefly in Chapter 36. This book’s scope, though, is focused\\non the fundamentals represented by Table 7-1.\\n156 | Chapter 7: \\u2002Strings', metadata={'source': 'python.pdf', 'page': 206}),\n",
       " Document(page_content='To cover the basics, this chapter begins with an overview of string literal forms and\\nstring expressions, then \\nmoves on to look at more advanced tools such as string meth-\\nods and formatting. Python comes with many string tools, and we won’t look at them\\nall here; the complete story is chronicled in the Python library manual. Our goal here\\nis to explore enough commonly used tools to give you a representative sample; methods\\nwe won’t see in action here, for example, are largely analogous to those we will.\\nContent note: Technically speaking, this chapter tells only part of the\\nstring story in Python—the part most programmers need to know. It\\npresents the basic str string type, which handles ASCII text and works\\nthe same regardless of which version of Python you use. That is, this\\nchapter intentionally limits its scope to the string processing essentials\\nthat are used in most Python scripts.\\nFrom a more formal perspective, ASCII is a simple form of Unicode text.\\nPython addresses the distinction between text and binary data by in-\\ncluding distinct object types:\\n• In Python 3.0 there are three string types: str is used for Unicode\\ntext (ASCII or otherwise), bytes is used for binary data (including\\nencoded text), and bytearray is a mutable variant of bytes.\\n• In Python 2.6, unicode strings represent wide Unicode text, and\\nstr strings handle both 8-bit text and binary data.\\nThe bytearray type is also available as a back-port in 2.6, but not earlier,\\nand it’s not as closely bound to binary data as it is in 3.0. Because most\\nprogrammers don’t need to dig into the details of Unicode encodings or\\nbinary data formats, though, I’ve moved all such details to the Advanced\\nTopics part of this book, in Chapter 36.\\nIf you do need to deal with more advanced string concepts such as al-\\nternative character sets or packed binary data and files, see Chap-\\nter 36  after reading the material here. For now, we’ll focus on the basic\\nstring type and its operations. As you’ll find, the basics we’ll study here\\nalso apply directly to the more advanced string types in Python’s toolset.\\nString Literals\\nBy and large, strings are fairly easy to use in Python. Perhaps the most complicated\\nthing about them is that there are so many ways to write them in your code:\\n• Single quotes: \\'spa\"m\\'\\n• Double quotes: \"spa\\'m\"\\n• Triple quotes: \\'\\'\\'... spam ...\\'\\'\\', \"\"\"... spam ...\"\"\"\\n• Escape sequences: \"s\\\\tp\\\\na\\\\0m\"\\n• Raw strings: r\"C:\\\\new\\\\test.spm\"\\nString Literals | 157', metadata={'source': 'python.pdf', 'page': 207}),\n",
       " Document(page_content='• Byte strings in 3.0 (see Chapter 36): b\\'sp\\\\x01am\\'\\n• Unicode strings in 2.6 only (see Chapter 36\\n): u\\'eggs\\\\u0020spam\\'\\nThe single- and double-quoted forms are by far the most common; the others serve\\nspecialized roles, and we’re postponing discussion of the last two advanced forms until\\nChapter 36. Let’s take a quick look at all the other options in turn.\\nSingle- and Double-Quoted Strings Are the Same\\nAround Python strings, single and double quote characters are interchangeable. That\\nis, string literals can be written enclosed in either two single or two double quotes—\\nthe two forms work the same and return the same type of object. For example, the\\nfollowing two strings are identical, once coded:\\n>>> \\'shrubbery\\', \"shrubbery\"\\n(\\'shrubbery\\', \\'shrubbery\\')\\nThe reason for supporting both is that it allows you to embed a quote character of the\\nother variety inside a string without escaping it with a backslash. You may embed a\\nsingle quote character in a string enclosed in double quote characters, and vice versa:\\n>>> \\'knight\"s\\', \"knight\\'s\"\\n(\\'knight\"s\\', \"knight\\'s\")\\nIncidentally, Python automatically concatenates adjacent string literals in any expres-\\nsion, although it is almost as simple to add a + operator between them to invoke con-\\ncatenation explicitly (as we’ll see in Chapter 12, wrapping this form in parentheses also\\nallows it to span multiple lines):\\n>>> title = \"Meaning \" \\'of\\' \" Life\"        # Implicit concatenation\\n>>> title\\n\\'Meaning of Life\\'\\nNotice that adding commas between these strings would result in a tuple, not a string.\\nAlso notice in all of these outputs that Python prefers to print strings in single quotes,\\nunless they embed one. You can also embed quotes by escaping them with backslashes:\\n>>> \\'knight\\\\\\'s\\', \"knight\\\\\"s\"\\n(\"knight\\'s\", \\'knight\"s\\')\\nTo understand why, you need to know how escapes work in general.\\nEscape Sequences Represent Special Bytes\\nThe last example embedded a quote inside a string by preceding it with a backslash.\\nThis is representative of a general pattern in strings: backslashes are used to introduce\\nspecial byte codings known as escape sequences.\\nEscape sequences let us embed byte codes in strings that cannot easily be typed on a\\nkeyboard. The character \\\\, and one or more characters following it in the string literal,\\nare replaced with a single character in the resulting string object, which has the binary\\n158 | Chapter 7: \\u2002Strings', metadata={'source': 'python.pdf', 'page': 208}),\n",
       " Document(page_content='value specified by the escape sequence. For example, here is a five-character string that\\nembeds a newline and a tab:\\n>>> s = \\'a\\\\nb\\\\tc\\'\\nThe two characters \\\\n\\n stand for a single character—the byte containing the binary value\\nof the newline character in your character set (usually, ASCII code 10). Similarly, the\\nsequence \\\\t is replaced with the tab character. The way this string looks when printed\\ndepends on how you print it. The interactive echo shows the special characters as\\nescapes, but print interprets them instead:\\n>>> s\\n\\'a\\\\nb\\\\tc\\'\\n>>> print(s)\\na\\nb       c\\nTo be completely sure how many bytes are in this string, use the built-in len function—\\nit returns the actual number of bytes in a string, regardless of how it is displayed:\\n>>> len(s)\\n5\\nThis string is five bytes long: it contains an ASCII a byte, a newline byte, an ASCII b\\nbyte, and so on. Note that the original backslash characters are not really stored with\\nthe string in memory; they are used to tell Python to store special byte values in the\\nstring. For coding such special bytes, Python recognizes a full set of escape code se-\\nquences, listed in Table 7-2.\\nTable 7-2. String backslash characters\\nEscape Meaning\\n\\\\newline Ignored (continuation line)\\n\\\\\\\\ Backslash (stores one \\\\)\\n\\\\\\' Single quote (stores \\')\\n\\\\\" Double quote (stores \")\\n\\\\a Bell\\n\\\\b Backspace\\n\\\\f Formfeed\\n\\\\n Newline (linefeed)\\n\\\\r Carriage return\\n\\\\t Horizontal tab\\n\\\\v Vertical tab\\n\\\\xhh Character with hex value hh (at most 2 digits)\\n\\\\ooo Character with octal value ooo (up to 3 digits)\\n\\\\0 Null: binary 0 character (doesn’t end string)\\nString Literals | 159', metadata={'source': 'python.pdf', 'page': 209}),\n",
       " Document(page_content='Escape Meaning\\n\\\\N{ id } Unicode database ID\\n\\\\uhhhh Unicode 16-bit hex\\n\\\\Uhhhhhhhh Unicode 32-bit hexa\\n\\\\other Not an escape (keeps both \\\\ and other)\\naThe \\\\Uhhhh... escape sequence takes exactly eight hexadecimal digits (h); both \\\\u and \\\\U can be used only in Unicode string literals.\\nSome escape sequences \\nallow you to embed absolute binary values into the bytes of a\\nstring. For instance, here’s a five-character string that embeds two binary zero bytes\\n(coded as octal escapes of one digit):\\n>>> s = \\'a\\\\0b\\\\0c\\'\\n>>> s\\n\\'a\\\\x00b\\\\x00c\\'\\n>>> len(s)\\n5\\nIn Python, the zero (null) byte does not terminate a string the way it typically does in\\nC. Instead, Python keeps both the string’s length and text in memory. In fact, no char-\\nacter terminates a string in Python. Here’s a string that is all absolute binary escape\\ncodes—a binary 1 and 2 (coded in octal), followed by a binary 3 (coded in hexadecimal):\\n>>> s = \\'\\\\001\\\\002\\\\x03\\'\\n>>> s\\n\\'\\\\x01\\\\x02\\\\x03\\'\\n>>> len(s)\\n3\\nNotice that Python displays nonprintable characters in hex, regardless of how they were\\nspecified. You can freely combine absolute value escapes and the more symbolic escape\\ntypes in Table 7-2 . The following string contains the characters “spam”, a tab and\\nnewline, and an absolute zero value byte coded in hex:\\n>>> S = \"s\\\\tp\\\\na\\\\x00m\"\\n>>> S\\n\\'s\\\\tp\\\\na\\\\x00m\\'\\n>>> len(S)\\n7\\n>>> print(S)\\ns       p\\na m\\nThis becomes more important to know when you process binary data files in Python.\\nBecause their contents are represented as strings in your scripts, it’s OK to process\\nbinary files that contain any sorts of binary byte values (more on files in Chapter 9).*\\n* If you need to care about binary data files, the chief distinction is that you open them in binary mode (using\\nopen mode flags with a b, such as \\'rb\\'\\n, \\'wb\\', and so on). In Python 3.0, binary file content is a bytes string,\\nwith an interface similar to that of normal strings; in 2.6, such content is a normal str string. See also the\\nstandard struct module introduced in Chapter 9 , which can parse binary data loaded from a file, and the\\nextended coverage of binary files and byte strings in Chapter 36.\\n160 | Chapter 7: \\u2002Strings', metadata={'source': 'python.pdf', 'page': 210}),\n",
       " Document(page_content='Finally, as the last entry in Table 7-2  implies, if Python does not recognize the character\\nafter a \\\\ as being a valid escape code, it simply keeps the backslash in the resulting string:\\n>>> x = \"C:\\\\py\\\\code\"           # Keeps \\\\ literally\\n>>> x\\n\\'C:\\\\\\\\py\\\\\\\\code\\'\\n>>> len(x)\\n10\\nUnless you’re able to commit all of Table 7-2 to memory, though, you probably\\nshouldn’t rely on this behavior.† To code literal backslashes explicitly such that they\\nare retained in your strings, double them up ( \\\\\\\\ is an escape for one \\\\) or use raw strings;\\nthe next section shows how.\\nRaw Strings Suppress Escapes\\nAs we’ve seen, escape sequences are handy for embedding special byte codes within\\nstrings. Sometimes, though, the special treatment of backslashes for introducing es-\\ncapes can lead to trouble. It’s surprisingly common, for instance, to see Python new-\\ncomers in classes trying to open a file with a filename argument that looks something\\nlike this:\\nmyfile = open(\\'C:\\\\new\\\\text.dat\\', \\'w\\')\\nthinking that they will open a file called text.dat in the directory C:\\\\new. The problem\\nhere is that \\\\n is taken to stand for a newline character, and \\\\t is replaced with a tab.\\nIn effect, the call tries to open a file named C:(newline)ew(tab)ext.dat, with usually less\\nthan stellar results.\\nThis is just the sort of thing that raw strings are useful for. If the letter r (uppercase or\\nlowercase) appears just before the opening quote of a string, it turns off the escape\\nmechanism. The result is that Python retains your backslashes literally, exactly as you\\ntype them. Therefore, to fix the filename problem, just remember to add the letter r on\\nWindows:\\nmyfile = open(r\\'C:\\\\new\\\\text.dat\\', \\'w\\')\\nAlternatively, because two backslashes are really an escape sequence for one backslash,\\nyou can keep your backslashes by simply doubling them up:\\nmyfile = open(\\'C:\\\\\\\\new\\\\\\\\text.dat\\', \\'w\\')\\nIn fact, Python itself sometimes uses this doubling scheme when it prints strings with\\nembedded backslashes:\\n>>> path = r\\'C:\\\\new\\\\text.dat\\'\\n>>> path                          # Show as Python code\\n\\'C:\\\\\\\\new\\\\\\\\text.dat\\'\\n>>> print(path)                   # User-friendly format\\n† In classes, I’ve met people who have indeed committed most or all of this table to memory; I’d probably think\\nthat was really sick, but for the fact that I’m a member of the set, too.\\nString Literals | 161', metadata={'source': 'python.pdf', 'page': 211}),\n",
       " Document(page_content='C:\\\\new\\\\text.dat\\n>>> len(path)                     # String length\\n15\\nAs with numeric \\nrepresentation, the default format at the interactive prompt prints\\nresults as if they were code, and therefore escapes backslashes in the output. The\\nprint statement provides a more user-friendly format that shows that there is actually\\nonly one backslash in each spot. To verify this is the case, you can check the result of\\nthe built-in len function, which returns the number of bytes in the string, independent\\nof display formats. If you count the characters in the print(path) output, you’ll see that\\nthere really is just 1 character per backslash, for a total of 15.\\nBesides directory paths on Windows, raw strings are also commonly used for regular\\nexpressions (text pattern matching, supported with the re module introduced in Chap-\\nter 4 ). Also note that Python scripts can usually use forward slashes in directory paths\\non Windows and Unix because Python tries to interpret paths portably (i.e., \\'C:/new/\\ntext.dat\\' works when opening files, too). Raw strings are useful if you code paths using\\nnative Windows backslashes, though.\\nDespite its role, even a raw string cannot end in a single backslash, be-\\ncause the backslash \\nescapes the following quote character—you still\\nmust escape the surrounding quote character to embed it in the string.\\nThat is, r\"...\\\\\" is not a valid string literal—a raw string cannot end in\\nan odd number of backslashes. If you need to end a raw string with a\\nsingle backslash, you can use two and slice off the second\\n(r\\'1\\\\nb\\\\tc\\\\\\\\\\'[:-1]), tack one on manually ( r\\'1\\\\nb\\\\tc\\' + \\'\\\\\\\\\\'), or skip\\nthe raw string syntax and just double up the backslashes in a normal\\nstring (\\'1\\\\\\\\nb\\\\\\\\tc\\\\\\\\\\'). All three of these forms create the same eight-\\ncharacter string containing three backslashes.\\nTriple Quotes Code Multiline Block Strings\\nSo far, you’ve seen single quotes, double quotes, escapes, and raw strings in action. \\nPython also has a triple-quoted string literal format, sometimes called a block string,\\nthat is a syntactic convenience for coding multiline text data. This form begins with\\nthree quotes (of either the single or double variety), is followed by any number of lines\\nof text, and is closed with the same triple-quote sequence that opened it. Single and\\ndouble quotes embedded in the string’s text may be, but do not have to be, escaped—\\nthe string does not end until Python sees three unescaped quotes of the same kind used\\nto start the literal. For example:\\n>>> mantra = \"\"\"Always look\\n...  on the bright\\n... side of life.\"\"\"\\n>>>\\n>>> mantra\\n\\'Always look\\\\n on the bright\\\\nside of life.\\'\\n162 | Chapter 7: \\u2002Strings', metadata={'source': 'python.pdf', 'page': 212}),\n",
       " Document(page_content='This string spans three lines (in some interfaces, the interactive prompt changes\\nto ... on continuation \\nlines; IDLE simply drops down one line). Python collects all the\\ntriple-quoted text into a single multiline string, with embedded newline characters\\n(\\\\n) at the places where your code has line breaks. Notice that, as in the literal, the\\nsecond line in the result has a leading space, but the third does not—what you type is\\ntruly what you get. To see the string with the newlines interpreted, print it instead of\\nechoing:\\n>>> print(mantra)\\nAlways look\\n on the bright\\nside of life.\\nTriple-quoted strings are useful any time you need multiline text in your program; for\\nexample, to embed multiline error messages or HTML or XML code in your source\\ncode files. You can embed such blocks directly in your scripts without resorting to\\nexternal text files or explicit concatenation and newline characters.\\nTriple-quoted strings are also commonly used for documentation strings, which are\\nstring literals that are taken as comments when they appear at specific points in your\\nfile (more on these later in the book). These don’t have to be triple-quoted blocks, but\\nthey usually are to allow for multiline comments.\\nFinally, triple-quoted strings are also sometimes used as a “horribly hackish” way to\\ntemporarily disable lines of code during development (OK, it’s not really too horrible,\\nand it’s actually a fairly common practice). If you wish to turn off a few lines of code\\nand run your script again, simply put three quotes above and below them, like this:\\nX = 1\\n\"\"\"\\nimport os                            # Disable this code temporarily\\nprint(os.getcwd())\\n\"\"\"\\nY = 2\\nI said this was hackish because Python really does make a string out of the lines of code\\ndisabled this way, but this is probably not significant in terms of performance. For large\\nsections of code, it’s also easier than manually adding hash marks before each line and\\nlater removing them. This is especially true if you are using a text editor that does not\\nhave support for editing Python code specifically. In Python, practicality often beats\\naesthetics.\\nStrings in Action\\nOnce you’ve created a string with the literal expressions we just met, you will almost\\ncertainly want to do things with it. This section and the next two demonstrate string\\nexpressions, methods, and formatting—the first line of text-processing tools in the\\nPython language.\\nStrings in Action | 163', metadata={'source': 'python.pdf', 'page': 213}),\n",
       " Document(page_content='Basic Operations\\nLet’s begin by interacting \\nwith the Python interpreter to illustrate the basic string op-\\nerations listed earlier in Table 7-1. Strings can be concatenated using the + operator\\nand repeated using the * operator:\\n% python\\n>>> len(\\'abc\\')            # Length: number of items\\n3\\n>>> \\'abc\\' + \\'def\\'         # Concatenation: a new string\\n\\'abcdef\\'\\n>>> \\'Ni!\\' * 4             # Repetition: like \"Ni!\" + \"Ni!\" + ...\\n\\'Ni!Ni!Ni!Ni!\\'\\nFormally, adding two string objects creates a new string object, with the contents of its\\noperands joined. Repetition is like adding a string to itself a number of times. In both\\ncases, Python lets you create arbitrarily sized strings; there’s no need to predeclare\\nanything in Python, including the sizes of data structures.‡ The len built-in function\\nreturns the length of a string (or any other object with a length).\\nRepetition may seem a bit obscure at first, but it comes in handy in a surprising number\\nof contexts. For example, to print a line of 80 dashes, you can count up to 80, or let\\nPython count for you:\\n>>> print(\\'------- ...more... ---\\')      # 80 dashes, the hard way\\n>>> print(\\'-\\' * 80)                      # 80 dashes, the easy way\\nNotice that operator overloading is at work here already: we’re using the same + and\\n* operators that perform addition and multiplication when using numbers. Python does\\nthe correct operation because it knows the types of the objects being added and mul-\\ntiplied. But be careful: the rules aren’t quite as liberal as you might expect. For instance,\\nPython doesn’t allow you to mix numbers and strings in + expressions: \\'abc\\'+9 raises\\nan error instead of automatically converting 9 to a string.\\nAs shown in the last row in Table 7-1 , you can also iterate over strings in loops using\\nfor statements and test membership for both characters and substrings with the in\\nexpression operator, which is essentially a search. For substrings, in is much like the\\nstr.find() method covered later in this chapter, but it returns a Boolean result instead\\nof the substring’s position:\\n>>> myjob = \"hacker\"\\n>>> for c in myjob: print(c, end=\\' \\')   # Step through items\\n...\\n‡ Unlike with C character arrays, you don’t need to allocate or manage storage arrays when using Python\\nstrings; you \\ncan simply create string objects as needed and let Python manage the underlying memory space.\\nAs discussed in Chapter 6 , Python reclaims unused objects’ memory space automatically, using a reference-\\ncount garbage-collection strategy. Each object keeps track of the number of names, data structures, etc., that\\nreference it; when the count reaches zero, Python frees the object’s space. This scheme means Python doesn’t\\nhave to stop and scan all the memory to find unused space to free (an additional garbage component also\\ncollects cyclic objects).\\n164 | Chapter 7: \\u2002Strings', metadata={'source': 'python.pdf', 'page': 214}),\n",
       " Document(page_content='h a c k e r\\n>>> \"k\" in myjob                        # Found\\nTrue\\n>>> \"z\" in myjob                        # Not found\\nFalse\\n>>> \\'spam\\' in \\'abcspamdef\\'              # Substring search, no position returned\\nTrue\\nThe for loop assigns \\na variable to successive items in a sequence (here, a string) and\\nexecutes one or more statements for each item. In effect, the variable c becomes a cursor\\nstepping across the string here. We will discuss iteration tools like these and others\\nlisted in Table 7-1  in more detail later in this book (especially in Chapters 14 and 20).\\nIndexing and Slicing\\nBecause strings are defined as ordered collections of characters, we can access their\\ncomponents by position. In Python, characters in a string are fetched by indexing—\\nproviding the numeric offset of the desired component in square brackets after the\\nstring. You get back the one-character string at the specified position.\\nAs in the C language, Python offsets start at 0 and end at one less than the length of\\nthe string. Unlike C, however, Python also lets you fetch items from sequences such\\nas strings using negative offsets. Technically, a negative offset is added to the length of\\na string to derive a positive offset. You can also think of negative offsets as counting\\nbackward from the end. The following interaction demonstrates:\\n>>> S = \\'spam\\'\\n>>> S[0], S[−2]                         # Indexing from front or end\\n(\\'s\\', \\'a\\')\\n>>> S[1:3], S[1:], S[:−1]               # Slicing: extract a section\\n(\\'pa\\', \\'pam\\', \\'spa\\')\\nThe first line defines a four-character string and assigns it the name S. The next line\\nindexes it in two ways: S[0] fetches the item at offset 0 from the left (the one-character\\nstring \\'s\\'), and S[−2] gets the item at offset 2 back from the end (or equivalently, at\\noffset (4 + (–2)) from the front). Offsets and slices map to cells as shown in Figure 7-1.§\\nThe last line in the preceding example demonstrates slicing, a generalized form of in-\\ndexing that returns an entire section, not a single item. Probably the best way to think\\nof slicing is that it is a type of parsing (analyzing structure), especially when applied to\\nstrings—it allows us to extract an entire section (substring) in a single step. Slices can\\nbe used to extract columns of data, chop off leading and trailing text, and more. In fact,\\nwe’ll explore slicing in the context of text parsing later in this chapter.\\nThe basics of slicing are straightforward. When you index a sequence object such as a\\nstring on a pair of offsets separated by a colon, Python returns a new object containing\\n§ More mathematically minded readers (and students in my classes) sometimes detect a small asymmetry here:\\nthe leftmost \\nitem is at offset 0, but the rightmost is at offset –1. Alas, there is no such thing as a distinct –0\\nvalue in Python.\\nStrings in Action | 165', metadata={'source': 'python.pdf', 'page': 215}),\n",
       " Document(page_content='the contiguous section identified by the offset pair. The left offset is taken to be the\\nlower bound (inclusive\\n), and the right is the upper bound ( noninclusive). That is, Python\\nfetches all items from the lower bound up to but not including the upper bound, and\\nreturns a new object containing the fetched items. If omitted, the left and right bounds\\ndefault to 0 and the length of the object you are slicing, respectively.\\nFor instance, in the example we just saw, S[1:3] extracts the items at offsets 1 and 2:\\nit grabs the second and third items, and stops before the fourth item at offset 3. Next,\\nS[1:] gets all items beyond the first —the upper bound, which is not specified, defaults\\nto the length of the string. Finally, S[:−1] fetches all but the last item —the lower bound\\ndefaults to 0, and −1 refers to the last item, noninclusive.\\nThis may seem confusing at first glance, but indexing and slicing are simple and pow-\\nerful tools to use, once you get the knack. Remember, if you’re unsure about the effects\\nof a slice, try it out interactively. In the next chapter, you’ll see that it’s even possible\\nto change an entire section of another object in one step by assigning to a slice (though\\nnot for immutables like strings). Here’s a summary of the details for reference:\\n•Indexing (S[i]) fetches components at offsets:\\n— The first item is at offset 0.\\n— Negative indexes mean to count backward from the end or right.\\n—S[0] fetches the first item.\\n—S[−2] fetches the second item from the end (like S[len(S)−2]).\\n•Slicing (S[i:j]) extracts contiguous sections of sequences:\\n— The upper bound is noninclusive.\\n— Slice boundaries default to 0 and the sequence length, if omitted.\\n—S[1:3] fetches items at offsets 1 up to but not including 3.\\n—S[1:] fetches items at offset 1 through the end (the sequence length).\\nFigure 7-1. Offsets and slices: positive offsets start from the left end (offset 0 is the first item), and\\nnegatives count back \\nfrom the right end (offset −1 is the last item). Either kind of offset can be used\\nto give positions in indexing and slicing operations.\\n166 | Chapter 7: \\u2002Strings', metadata={'source': 'python.pdf', 'page': 216}),\n",
       " Document(page_content='—S[:3] fetches items at offset 0 up to but not including 3.\\n—S[:−1] fetches items at offset 0 up to but not including the last item.\\n—S[:] fetches items \\nat offsets 0 through the end—this effectively performs a top-\\nlevel copy of S.\\nThe last item listed here turns out to be a very common trick: it makes a full top-level\\ncopy of a sequence object—an object with the same value, but a distinct piece of mem-\\nory (you’ll find more on copies in Chapter 9). This isn’t very useful for immutable\\nobjects like strings, but it comes in handy for objects that may be changed in-place,\\nsuch as lists.\\nIn the next chapter, you’ll see that the syntax used to index by offset (square brackets)\\nis used to index dictionaries by key as well; the operations look the same but have\\ndifferent interpretations.\\nExtended slicing: the third limit and slice objects\\nIn Python 2.3 and later, slice expressions have support for an optional third index, used\\nas a step (sometimes called a stride). The step is added to the index of each item ex-\\ntracted. The full-blown form of a slice is now X[I:J:K], which means “extract all the\\nitems in X, from offset I through J−1, by K.” The third limit, K, defaults to 1, which is\\nwhy normally all items in a slice are extracted from left to right. If you specify an explicit\\nvalue, however, you can use the third limit to skip items or to reverse their order.\\nFor instance, X[1:10:2] will fetch every other item  in X from offsets 1–9; that is, it will\\ncollect the items at offsets 1, 3, 5, 7, and 9. As usual, the first and second limits default\\nto 0 and the length of the sequence, respectively, so X[::2] gets every other item from\\nthe beginning to the end of the sequence:\\n>>> S = \\'abcdefghijklmnop\\'\\n>>> S[1:10:2]\\n\\'bdfhj\\'\\n>>> S[::2]\\n\\'acegikmo\\'\\nYou can also use a negative stride. For example, the slicing expression \"hello\"[::−1]\\nreturns the new string \"olleh\"—the first two bounds default to 0 and the length of the\\nsequence, as before, and a stride of −1 indicates that the slice should go from right to\\nleft instead of the usual left to right. The effect, therefore, is to reverse the sequence:\\n>>> S = \\'hello\\'\\n>>> S[::−1]\\n\\'olleh\\'\\nWith a negative stride, the meanings of the first two bounds are essentially reversed.\\nThat is, the slice S[5:1:−1] fetches the items from 2 to 5, in reverse order (the result\\ncontains items from offsets 5, 4, 3, and 2):\\nStrings in Action | 167', metadata={'source': 'python.pdf', 'page': 217}),\n",
       " Document(page_content=\">>> S = 'abcedfg'\\n>>> S[5:1:−1]\\n'fdec'\\nSkipping and reversing \\nlike this are the most common use cases for three-limit slices,\\nbut see Python’s standard library manual for more details (or run a few experiments\\ninteractively). We’ll revisit three-limit slices again later in this book, in conjunction\\nwith the for loop statement.\\nLater in the book, we’ll also learn that slicing is equivalent to indexing with a slice\\nobject, a finding of importance to class writers seeking to support both operations:\\n>>> 'spam'[1:3]                        # Slicing syntax\\n'pa'\\n>>> 'spam'[slice(1, 3)]                # Slice objects\\n'pa'\\n>>> 'spam'[::-1]\\n'maps'\\n>>> 'spam'[slice(None, None, −1)]\\n'maps'\\nWhy You Will Care: Slices\\nThroughout this book, \\nI will include common use case sidebars (such as this one) to\\ngive you a peek at how some of the language features being introduced are typically\\nused in real programs. Because you won’t be able to make much sense of real use cases\\nuntil you’ve seen more of the Python picture, these sidebars necessarily contain many\\nreferences to topics not introduced yet; at most, you should consider them previews of\\nways that you may find these abstract language concepts useful for common program-\\nming tasks.\\nFor instance, you’ll see later that the argument words listed on a system command line\\nused to launch a Python program are made available in the argv attribute of the built-\\nin sys module:\\n# File echo.py\\nimport sys\\nprint(sys.argv)\\n% python echo.py −a −b −c\\n['echo.py', '−a', '−b', '−c']\\nUsually, you’re only interested in inspecting the arguments that follow the program\\nname. This leads to a very typical application of slices: a single slice expression can be\\nused to return all but the first item of a list. Here, sys.argv[1:] returns the desired list,\\n['−a', '−b', '−c']. You can then process this list without having to accommodate the\\nprogram name at the front.\\nSlices are also often used to clean up lines read from input files. If you know that a line\\nwill have an end-of-line character at the end (a \\\\n newline marker), you can get rid of\\nit with a single expression such as line[:−1], which extracts all but the last character\\nin the line (the lower limit defaults to 0). In both cases, slices do the job of logic that\\nmust be explicit in a lower-level language.\\n168 | Chapter 7: \\u2002Strings\", metadata={'source': 'python.pdf', 'page': 218}),\n",
       " Document(page_content='Note that calling the line.rstrip method is often preferred for stripping newline char-\\nacters because this call leaves the line intact if it has no newline character at the end—\\na common case for files created with some text-editing tools. Slicing works if you’re\\nsure the line is properly terminated.\\nString Conversion Tools\\nOne of Python’s \\ndesign mottos is that it refuses the temptation to guess. As a prime\\nexample, you cannot add a number and a string together in Python, even if the string\\nlooks like a number (i.e., is all digits):\\n>>> \"42\" + 1\\nTypeError: cannot concatenate \\'str\\' and \\'int\\' objects\\nThis is by design: because + can mean both addition and concatenation, the choice of\\nconversion would be ambiguous. So, Python treats this as an error. In Python, magic\\nis generally omitted if it will make your life more complex.\\nWhat to do, then, if your script obtains a number as a text string from a file or user\\ninterface? The trick is that you need to employ conversion tools before you can treat a\\nstring like a number, or vice versa. For instance:\\n>>> int(\"42\"), str(42)          # Convert from/to string\\n(42, \\'42\\')\\n>>> repr(42)                    # Convert to as-code string\\n\\'42\\'\\nThe int function converts a string to a number, and the str function converts a number\\nto its string representation (essentially, what it looks like when printed). The repr\\nfunction (and the older backquotes expression, removed in Python 3.0) also converts\\nan object to its string representation, but returns the object as a string of code that can\\nbe rerun to recreate the object. For strings, the result has quotes around it if displayed\\nwith a print statement:\\n>>> print(str(\\'spam\\'), repr(\\'spam\\'))\\n(\\'spam\\', \"\\'spam\\'\")\\nSee the sidebar “str and repr Display Formats” on page 116 for more on this topic. Of\\nthese, int and str are the generally prescribed conversion techniques.\\nNow, although you can’t mix strings and number types around operators such as +,\\nyou can manually convert operands before that operation if needed:\\n>>> S = \"42\"\\n>>> I = 1\\n>>> S + I\\nTypeError: cannot concatenate \\'str\\' and \\'int\\' objects\\n>>> int(S) + I            # Force addition\\n43\\nStrings in Action | 169', metadata={'source': 'python.pdf', 'page': 219}),\n",
       " Document(page_content='>>> S + str(I)            # Force concatenation\\n\\'421\\'\\nSimilar built-in functions \\nhandle floating-point number conversions to and from\\nstrings:\\n>>> str(3.1415), float(\"1.5\")\\n(\\'3.1415\\', 1.5)\\n>>> text = \"1.234E-10\"\\n>>> float(text)\\n1.2340000000000001e-010\\nLater, we’ll further study the built-in eval function; it runs a string containing Python\\nexpression code and so can convert a string to any kind of object. The functions int\\nand float convert only to numbers, but this restriction means they are usually faster\\n(and more secure, because they do not accept arbitrary expression code). As we saw\\nbriefly in Chapter 5 , the string formatting expression also provides a way to convert\\nnumbers to strings. We’ll discuss formatting further later in this chapter.\\nCharacter code conversions\\nOn the subject of conversions, it is also possible to convert a single character to its\\nunderlying ASCII integer code by passing it to the built-in ord function—this returns\\nthe actual binary value of the corresponding byte in memory. The chr function performs\\nthe inverse operation, taking an ASCII integer code and converting it to the corre-\\nsponding character:\\n>>> ord(\\'s\\')\\n115\\n>>> chr(115)\\n\\'s\\'\\nYou can use a loop to apply these functions to all characters in a string. These tools can\\nalso be used to perform a sort of string-based math. To advance to the next character,\\nfor example, convert and do the math in integer:\\n>>> S = \\'5\\'\\n>>> S = chr(ord(S) + 1)\\n>>> S\\n\\'6\\'\\n>>> S = chr(ord(S) + 1)\\n>>> S\\n\\'7\\'\\nAt least for single-character strings, this provides an alternative to using the built-in\\nint function to convert from string to integer:\\n>>> int(\\'5\\')\\n5\\n>>> ord(\\'5\\') - ord(\\'0\\')\\n5\\n170 | Chapter 7: \\u2002Strings', metadata={'source': 'python.pdf', 'page': 220}),\n",
       " Document(page_content='Such conversions can be used in conjunction with looping statements, introduced in\\nChapter 4  and \\ncovered in depth in the next part of this book, to convert a string of\\nbinary digits to their corresponding integer values. Each time through the loop, multiply\\nthe current value by 2 and add the next digit’s integer value:\\n>>> B = \\'1101\\'                 # Convert binary digits to integer with ord\\n>>> I = 0\\n>>> while B != \\'\\':\\n...     I = I * 2 + (ord(B[0]) - ord(\\'0\\'))\\n...     B = B[1:]\\n...\\n>>> I\\n13\\nA left-shift operation (I << 1) would have the same effect as multiplying by 2 here.\\nWe’ll leave this change as a suggested exercise, though, both because we haven’t stud-\\nied loops in detail yet and because the int and bin built-ins we met in Chapter 5 handle\\nbinary conversion tasks for us in Python 2.6 and 3.0:\\n>>> int(\\'1101\\', 2)             # Convert binary to integer: built-in\\n13\\n>>> bin(13)                    # Convert integer to binary\\n\\'0b1101\\'\\nGiven enough time, Python tends to automate most common tasks!\\nChanging Strings\\nRemember the term “immutable sequence”? The immutable part means that you can’t\\nchange a string in-place (e.g., by assigning to an index):\\n>>> S = \\'spam\\'\\n>>> S[0] = \"x\"\\nRaises an error!\\nSo, how do you modify text information in Python? To change a string, you need to\\nbuild and assign a new string using tools such as concatenation and slicing, and then,\\nif desired, assign the result back to the string’s original name:\\n>>> S = S + \\'SPAM!\\'         # To change a string, make a new one\\n>>> S\\n\\'spamSPAM!\\'\\n>>> S = S[:4] + \\'Burger\\' + S[−1]\\n>>> S\\n\\'spamBurger!\\'\\nThe first example adds a substring at the end of S, by concatenation (really, it makes a\\nnew string and assigns it back to S, but you can think of this as “changing” the original\\nstring). The second example replaces four characters with six by slicing, indexing, and\\nconcatenating. As you’ll see in the next section, you can achieve similar effects with\\nstring method calls like replace:\\nStrings in Action | 171', metadata={'source': 'python.pdf', 'page': 221}),\n",
       " Document(page_content=\">>> S = 'splot'\\n>>> S = S.replace('pl', 'pamal')\\n>>> S\\n'spamalot'\\nLike every operation \\nthat yields a new string value, string methods generate new string\\nobjects. If you want to retain those objects, you can assign them to variable names.\\nGenerating a new string object for each string change is not as inefficient as it may\\nsound—remember, as discussed in the preceding chapter, Python automatically gar-\\nbage collects (reclaims the space of) old unused string objects as you go, so newer\\nobjects reuse the space held by prior values. Python is usually more efficient than you\\nmight expect.\\nFinally, it’s also possible to build up new text values with string formatting expressions.\\nBoth of the following substitute objects into a string, in a sense converting the objects\\nto strings and changing the original string according to a format specification:\\n>>> 'That is %d %s bird!' % (1, 'dead')           # Format expression\\nThat is 1 dead bird!\\n>>> 'That is {0} {1} bird!'.format(1, 'dead')     # Format method in 2.6 and 3.0\\n'That is 1 dead bird!'\\nDespite the substitution metaphor, though, the result of formatting is a new string\\nobject, not a modified one. We’ll study formatting later in this chapter; as we’ll find,\\nformatting turns out to be more general and useful than this example implies. Because\\nthe second of the preceding calls is provided as a method, though, let’s get a handle on\\nstring method calls before we explore formatting further.\\nAs we’ll see in Chapter 36 , Python 3.0 and 2.6 introduce a new string\\ntype known as bytearray, which is mutable and so may be changed in\\nplace. bytearray objects aren’t really strings; they’re sequences of small,\\n8-bit integers. However, they support most of the same operations as\\nnormal strings and print as ASCII characters when displayed. As such,\\nthey provide another option for large amounts of text that must be\\nchanged frequently. In Chapter 36 we’ll also see that ord and chr handle\\nUnicode characters, too, which might not be stored in single bytes.\\nString Methods\\nIn addition to expression operators, strings provide a set of methods that implement\\nmore sophisticated text-processing tasks. Methods are simply functions that are asso-\\nciated with particular objects. Technically, they are attributes attached to objects that\\nhappen to reference callable functions. In Python, expressions and built-in functions\\nmay work across a range of types, but methods are generally specific to object types —\\nstring methods, for example, work only on string objects. The method sets of some\\ntypes intersect in Python 3.0 (e.g., many types have a count method), but they are still\\nmore type-specific than other tools.\\n172 | Chapter 7: \\u2002Strings\", metadata={'source': 'python.pdf', 'page': 222}),\n",
       " Document(page_content='In finer-grained detail, functions are packages of code, and method calls combine two\\noperations at once (an attribute fetch and a call):\\nAttribute fetches\\nAn expression of the \\nform object.attribute means “fetch the value of attribute\\nin object.”\\nCall expressions\\nAn expression of the form function(arguments) means “invoke the code of\\nfunction, passing zero or more comma-separated argument objects to it, and return\\nfunction’s result value.”\\nPutting these two together allows us to call a method of an object. The method call\\nexpression object.method(arguments) is evaluated from left to right—Python will first\\nfetch the method of the object and then call it, passing in the arguments. If the method\\ncomputes a result, it will come back as the result of the entire method-call expression.\\nAs you’ll see throughout this part of the book, most objects have callable methods, and\\nall are accessed using this same method-call syntax. To call an object method, as you’ll\\nsee in the following sections, you have to go through an existing object.\\nTable 7-3  summarizes the methods and call patterns for built-in string objects in Python\\n3.0; these change frequently, so be sure to check Python’s standard library manual for\\nthe most up-to-date list, or run a help call on any string interactively. Python 2.6’s string\\nmethods vary slightly; it includes a decode, for example, because of its different handling\\nof Unicode data (something we’ll discuss in Chapter 36 ). In this table, S is a string\\nobject, and optional arguments are enclosed in square brackets. String methods in this\\ntable implement higher-level operations such as splitting and joining, case conversions,\\ncontent tests, and substring searches and replacements.\\nTable 7-3. String method calls in Python 3.0\\nS.capitalize() S.ljust(width [, fill])\\nS.center(width [, fill]) S.lower()\\nS.count(sub [, start [, end]]) S.lstrip([chars])\\nS.encode([encoding [,errors]]) S.maketrans(x[, y[, z]])\\nS.endswith(suffix [, start [, end]]) S.partition(sep)\\nS.expandtabs([tabsize]) S.replace(old, new [, count])\\nS.find(sub [, start [, end]]) S.rfind(sub [,start [,end]])\\nS.format(fmtstr, *args, **kwargs) S.rindex(sub [, start [, end]])\\nS.index(sub [, start [, end]]) S.rjust(width [, fill])\\nS.isalnum() S.rpartition(sep)\\nS.isalpha() S.rsplit([sep[, maxsplit]])\\nS.isdecimal() S.rstrip([chars])\\nS.isdigit() S.split([sep [,maxsplit]])\\nString Methods | 173', metadata={'source': 'python.pdf', 'page': 223}),\n",
       " Document(page_content=\"S.isidentifier() S.splitlines([keepends])\\nS.islower() S.startswith(prefix [, start [, end]])\\nS.isnumeric() S.strip([chars])\\nS.isprintable() S.swapcase()\\nS.isspace() S.title()\\nS.istitle() S.translate(map)\\nS.isupper() S.upper()\\nS.join(iterable) S.zfill(width)\\nAs you can see, there are quite a few string methods, and we don’t have space to cover\\nthem all; see Python’s library manual or reference texts for all the fine points. To help\\nyou get started, \\nthough, let’s work through some code that demonstrates some of the\\nmost commonly used methods in action, and illustrates Python text-processing basics\\nalong the way.\\nString Method Examples: Changing Strings\\nAs we’ve seen, because strings are immutable, they cannot be changed in-place directly.\\nTo make a new text value from an existing string, you construct a new string with\\noperations such as slicing and concatenation. For example, to replace two characters\\nin the middle of a string, you can use code like this:\\n>>> S = 'spammy'\\n>>> S = S[:3] + 'xx' + S[5:]\\n>>> S\\n'spaxxy'\\nBut, if you’re really just out to replace a substring, you can use the string replace method\\ninstead:\\n>>> S = 'spammy'\\n>>> S = S.replace('mm', 'xx')\\n>>> S\\n'spaxxy'\\nThe replace method is more general than this code implies. It takes as arguments the\\noriginal substring (of any length) and the string (of any length) to replace it with, and\\nperforms a global search and replace:\\n>>> 'aa$bb$cc$dd'.replace('$', 'SPAM')\\n'aaSPAMbbSPAMccSPAMdd'\\nIn such a role, replace can be used as a tool to implement template replacements (e.g.,\\nin form letters). Notice that this time we simply printed the result, instead of assigning\\nit to a name—you need to assign results to names only if you want to retain them for\\nlater use.\\n174 | Chapter 7: \\u2002Strings\", metadata={'source': 'python.pdf', 'page': 224}),\n",
       " Document(page_content=\"If you need to replace one fixed-size string that can occur at any offset, you can do a\\nreplacement again, or \\nsearch for the substring with the string find method and then\\nslice:\\n>>> S = 'xxxxSPAMxxxxSPAMxxxx'\\n>>> where = S.find('SPAM')            # Search for position\\n>>> where                             # Occurs at offset 4\\n4\\n>>> S = S[:where] + 'EGGS' + S[(where+4):]\\n>>> S\\n'xxxxEGGSxxxxSPAMxxxx'\\nThe find method returns the offset where the substring appears (by default, searching\\nfrom the front), or −1 if it is not found. As we saw earlier, it’s a substring search operation\\njust like the in expression, but find returns the position of a located substring.\\nAnother option is to use replace with a third argument to limit it to a single substitution:\\n>>> S = 'xxxxSPAMxxxxSPAMxxxx'\\n>>> S.replace('SPAM', 'EGGS')         # Replace all\\n'xxxxEGGSxxxxEGGSxxxx'\\n>>> S.replace('SPAM', 'EGGS', 1)      # Replace one\\n'xxxxEGGSxxxxSPAMxxxx'\\nNotice that replace returns a new string object each time. Because strings are immut-\\nable, methods never really change the subject strings in-place, even if they are called\\n“replace”!\\nThe fact that concatenation operations and the replace method generate new string\\nobjects each time they are run is actually a potential downside of using them to change\\nstrings. If you have to apply many changes to a very large string, you might be able to\\nimprove your script’s performance by converting the string to an object that does sup-\\nport in-place changes:\\n>>> S = 'spammy'\\n>>> L = list(S)\\n>>> L\\n['s', 'p', 'a', 'm', 'm', 'y']\\nThe built-in list function (or an object construction call) builds a new list out of the\\nitems in any sequence—in this case, “exploding” the characters of a string into a list.\\nOnce the string is in this form, you can make multiple changes to it without generating\\na new copy for each change:\\n>>> L[3] = 'x'                        # Works for lists, not strings\\n>>> L[4] = 'x'\\n>>> L\\n['s', 'p', 'a', 'x', 'x', 'y']\\nIf, after your changes, you need to convert back to a string (e.g., to write to a file), use\\nthe string join method to “implode” the list back into a string:\\nString Methods | 175\", metadata={'source': 'python.pdf', 'page': 225}),\n",
       " Document(page_content=\">>> S = ''.join(L)\\n>>> S\\n'spaxxy'\\nThe join method may \\nlook a bit backward at first sight. Because it is a method of strings\\n(not of lists), it is called through the desired delimiter. join puts the strings in a list (or\\nother iterable) together, with the delimiter between list items; in this case, it uses an\\nempty string delimiter to convert from a list back to a string. More generally, any string\\ndelimiter and iterable of strings will do:\\n>>> 'SPAM'.join(['eggs', 'sausage', 'ham', 'toast'])\\n'eggsSPAMsausageSPAMhamSPAMtoast'\\nIn fact, joining substrings all at once this way often runs much faster than concatenating\\nthem individually. Be sure to also see the earlier note about the mutable bytearray string\\nin Python 3.0 and 2.6, described fully in Chapter 36 ; because it may be changed in\\nplace, it offers an alternative to this list/join combination for some kinds of text that\\nmust be changed often.\\nString Method Examples: Parsing Text\\nAnother common role for string methods is as a simple form of text parsing—that is,\\nanalyzing structure and extracting substrings. To extract substrings at fixed offsets, we\\ncan employ slicing techniques:\\n>>> line = 'aaa bbb ccc'\\n>>> col1 = line[0:3]\\n>>> col3 = line[8:]\\n>>> col1\\n'aaa'\\n>>> col3\\n'ccc'\\nHere, the columns of data appear at fixed offsets and so may be sliced out of the original\\nstring. This technique passes for parsing, as long as the components of your data have\\nfixed positions. If instead some sort of delimiter separates the data, you can pull out its\\ncomponents by splitting. This will work even if the data may show up at arbitrary\\npositions within the string:\\n>>> line = 'aaa bbb  ccc'\\n>>> cols = line.split()\\n>>> cols\\n['aaa', 'bbb', 'ccc']\\nThe string split method chops up a string into a list of substrings, around a delimiter\\nstring. We didn’t pass a delimiter in the prior example, so it defaults to whitespace—\\nthe string is split at groups of one or more spaces, tabs, and newlines, and we get back\\na list of the resulting substrings. In other applications, more tangible delimiters may\\nseparate the data. This example splits (and hence parses) the string at commas, a sep-\\narator common in data returned by some database tools:\\n176 | Chapter 7: \\u2002Strings\", metadata={'source': 'python.pdf', 'page': 226}),\n",
       " Document(page_content='>>> line = \\'bob,hacker,40\\'\\n>>> line.split(\\',\\')\\n[\\'bob\\', \\'hacker\\', \\'40\\']\\nDelimiters can be longer than a single character, too:\\n>>> line = \"i\\'mSPAMaSPAMlumberjack\"\\n>>> line.split(\"SPAM\")\\n[\"i\\'m\", \\'a\\', \\'lumberjack\\']\\nAlthough there are \\nlimits to the parsing potential of slicing and splitting, both run very\\nfast and can handle basic text-extraction chores.\\nOther Common String Methods in Action\\nOther string methods have more focused roles—for example, to strip off whitespace\\nat the end of a line of text, perform case conversions, test content, and test for a substring\\nat the end or front:\\n>>> line = \"The knights who say Ni!\\\\n\"\\n>>> line.rstrip()\\n\\'The knights who say Ni!\\'\\n>>> line.upper()\\n\\'THE KNIGHTS WHO SAY NI!\\\\n\\'\\n>>> line.isalpha()\\nFalse\\n>>> line.endswith(\\'Ni!\\\\n\\')\\nTrue\\n>>> line.startswith(\\'The\\')\\nTrue\\nAlternative techniques can also sometimes be used to achieve the same results as string\\nmethods—the in membership operator can be used to test for the presence of a sub-\\nstring, for instance, and length and slicing operations can be used to mimic endswith:\\n>>> line\\n\\'The knights who say Ni!\\\\n\\'\\n>>> line.find(\\'Ni\\') != −1       # Search via method call or expression\\nTrue\\n>>> \\'Ni\\' in line\\nTrue\\n>>> sub = \\'Ni!\\\\n\\'\\n>>> line.endswith(sub)          # End test via method call or slice\\nTrue\\n>>> line[-len(sub):] == sub\\nTrue\\nSee also the format string formatting method described later in this chapter; it provides\\nmore advanced substitution tools that combine many operations in a single step.\\nAgain, because there are so many methods available for strings, we won’t look at every\\none here. You’ll see some additional string examples later in this book, but for more\\nString Methods | 177', metadata={'source': 'python.pdf', 'page': 227}),\n",
       " Document(page_content=\"details you can also turn to the Python library manual and other documentation\\nsources, or simply \\nexperiment interactively on your own. You can also check the\\nhelp(S.method) results for a method of any string object S for more hints.\\nNote that none of the string methods accepts patterns—for pattern-based text pro-\\ncessing, you must use the Python re standard library module, an advanced tool that\\nwas introduced in Chapter 4 but is mostly outside the scope of this text (one further\\nexample appears at the end of Chapter 36 ). Because of this limitation, though, string\\nmethods may sometimes run more quickly than the re module’s tools.\\nThe Original string Module (Gone in 3.0)\\nThe history of Python’s string methods is somewhat convoluted. For roughly the first\\ndecade of its existence, Python provided a standard library module called string that\\ncontained functions that largely mirrored the current set of string object methods. In\\nresponse to user requests, in Python 2.0 these functions were made available as methods\\nof string objects. Because so many people had written so much code that relied on the\\noriginal string module, however, it was retained for backward compatibility.\\nToday, you should use only string methods , not the original string module. In fact, the\\noriginal module-call forms of today’s string methods have been removed completely\\nfrom Python in Release 3.0. However, because you may still see the module in use in\\nolder Python code, a brief look is in order here.\\nThe upshot of this legacy is that in Python 2.6, there technically are still two ways to\\ninvoke advanced string operations: by calling object methods, or by calling string\\nmodule functions and passing in the objects as arguments. For instance, given a variable\\nX assigned to a string object, calling an object method:\\nX.method(arguments)\\nis usually equivalent to calling the same operation through the string module (provided\\nthat you have already imported the module):\\nstring.method(X, arguments)\\nHere’s an example of the method scheme in action:\\n>>> S = 'a+b+c+'\\n>>> x = S.replace('+', 'spam')\\n>>> x\\n'aspambspamcspam'\\nTo access the same operation through the string module in Python 2.6, you need to\\nimport the module (at least once in your process) and pass in the object:\\n>>> import string\\n>>> y = string.replace(S, '+', 'spam')\\n>>> y\\n'aspambspamcspam'\\n178 | Chapter 7: \\u2002Strings\", metadata={'source': 'python.pdf', 'page': 228}),\n",
       " Document(page_content='Because the module approach was the standard for so long, and because strings are\\nsuch a central \\ncomponent of most programs, you might see both call patterns in Python\\n2.X code you come across.\\nAgain, though, today you should always use method calls instead of the older module\\ncalls. There are good reasons for this, besides the fact that the module calls have gone\\naway in Release 3.0. For one thing, the module call scheme requires you to import the\\nstring module (methods do not require imports). For another, the module makes calls\\na few characters longer to type (when you load the module with import, that is, not\\nusing from). And, finally, the module runs more slowly than methods (the module maps\\nmost calls back to the methods and so incurs an extra call along the way).\\nThe original string module itself, without its string method equivalents, is retained in\\nPython 3.0 because it contains additional tools, including predefined string constants\\nand a template object system (a relatively obscure tool omitted here—see the Python\\nlibrary manual for details on template objects). Unless you really want to have to change\\nyour 2.6 code to use 3.0, though, you should consider the basic string operation calls\\nin it to be just ghosts from the past.\\nString Formatting Expressions\\nAlthough you can get a lot done with the string methods and sequence operations we’ve\\nalready met, Python also provides a more advanced way to combine string processing\\ntasks—string formatting  allows us to perform multiple type-specific substitutions on a\\nstring in a single step. It’s never strictly required, but it can be convenient, especially\\nwhen formatting text to be displayed to a program’s users. Due to the wealth of new\\nideas in the Python world, string formatting is available in two flavors in Python today:\\nString formatting expressions\\nThe original technique, available since Python’s inception; this is based upon the\\nC language’s “printf” model and is used in much existing code.\\nString formatting method calls\\nA newer technique added in Python 2.6 and 3.0; this is more unique to Python and\\nlargely overlaps with string formatting expression functionality.\\nSince the method call flavor is new, there is some chance that one or the other of these\\nmay become deprecated over time. The expressions are more likely to be deprecated\\nin later Python releases, though this should depend on the future practice of real Python\\nprogrammers. As they are largely just variations on a theme, though, either technique\\nis valid to use today. Since string formatting expressions are the original in this depart-\\nment, let’s start with them.\\nPython defines the % binary operator to work on strings (you may recall that this is also\\nthe remainder of division, or modulus, operator for numbers). When applied to strings,\\nthe % operator provides a simple way to format values as strings according to a format\\nString Formatting Expressions | 179', metadata={'source': 'python.pdf', 'page': 229}),\n",
       " Document(page_content='definition. In short, the % operator provides a compact way to code multiple string\\nsubstitutions all at once, instead of building and concatenating parts individually.\\nTo format strings:\\n1. On the left of the % operator, provide a format string containing one or more em-\\nbedded conversion targets, each of which starts with a % (e.g., %d).\\n2. On the right of the % operator, provide the object (or objects, embedded in a tuple)\\nthat you want Python to insert into the format string on the left in place of the\\nconversion target (or targets).\\nFor instance, in the formatting example we saw earlier in this chapter, the integer 1\\nreplaces the %d in the format string on the left, and the string \\'dead\\' replaces the %s.\\nThe result is a new string that reflects these two substitutions:\\n>>> \\'That is %d %s bird!\\' % (1, \\'dead\\')           # Format expression\\nThat is 1 dead bird!\\nTechnically speaking, string formatting expressions are usually optional—you can\\ngenerally do similar work with multiple concatenations and conversions. However,\\nformatting allows us to combine many steps into a single operation. It’s powerful\\nenough to warrant a few more examples:\\n>>> exclamation = \"Ni\"\\n>>> \"The knights who say %s!\" % exclamation\\n\\'The knights who say Ni!\\'\\n>>> \"%d %s %d you\" % (1, \\'spam\\', 4)\\n\\'1 spam 4 you\\'\\n>>> \"%s -- %s -- %s\" % (42, 3.14159, [1, 2, 3])\\n\\'42 -- 3.14159 -- [1, 2, 3]\\'\\nThe first example here plugs the string \"Ni\" into the target on the left, replacing the\\n%s marker. In the second example, three values are inserted into the target string. Note\\nthat when you’re inserting more than one value, you need to group the values on the\\nright in parentheses (i.e., put them in a tuple). The % formatting expression operator\\nexpects either a single item or a tuple of one or more items on its right side.\\nThe third example again inserts three values—an integer, a floating-point object, and\\na list object—but notice that all of the targets on the left are %s, which stands for con-\\nversion to string. As every type of object can be converted to a string (the one used\\nwhen printing), every object type works with the %s conversion code. Because of this,\\nunless you will be doing some special formatting, %s is often the only code you need to\\nremember for the formatting expression.\\nAgain, keep in mind that formatting always makes a new string, rather than changing\\nthe string on the left; because strings are immutable, it must work this way. As before,\\nassign the result to a variable name if you need to retain it.\\n180 | Chapter 7: \\u2002Strings', metadata={'source': 'python.pdf', 'page': 230}),\n",
       " Document(page_content='Advanced String Formatting Expressions\\nFor more advanced \\ntype-specific formatting, you can use any of the conversion type\\ncodes listed in Table 7-4  in formatting expressions; they appear after the % character in\\nsubstitution targets. C programmers will recognize most of these because Python string\\nformatting supports all the usual C printf format codes (but returns the result, instead\\nof displaying it, like printf). Some of the format codes in the table provide alternative\\nways to format the same type; for instance, %e, %f, and %g provide alternative ways to\\nformat floating-point numbers.\\nTable 7-4. String formatting type codes\\nCode Meaning\\ns String (or any object’s str(X) string)\\nr s, but uses repr, not str\\nc Character\\nd Decimal (integer)\\ni Integer\\nu Same as d (obsolete: no longer unsigned)\\no Octal integer\\nx Hex integer\\nX x, but prints uppercase\\ne Floating-point exponent, lowercase\\nE Same as e, but prints uppercase\\nf Floating-point decimal\\nF Floating-point decimal\\ng Floating-point e or f\\nG Floating-point E or F\\n% Literal %\\nIn fact, conversion targets in the format string on the expression’s left side support a\\nvariety of conversion \\noperations with a fairly sophisticated syntax all their own. The\\ngeneral structure of conversion targets looks like this:\\n%[(name)][flags][width][.precision]typecode\\nThe character type codes in Table 7-4  show up at the end of the target string. Between\\nthe % and the character code, you can do any of the following: provide a dictionary key;\\nlist flags that specify things like left justification ( −), numeric sign (+), and zero fills\\n(0); give a total minimum field width and the number of digits after a decimal point;\\nand more. Both width and precision can also be coded as a * to specify that they should\\ntake their values from the next item in the input values.\\nString Formatting Expressions | 181', metadata={'source': 'python.pdf', 'page': 231}),\n",
       " Document(page_content='Formatting target syntax is documented in full in the Python standard manuals, but to\\ndemonstrate common usage, \\nlet’s look at a few examples. This one formats integers by\\ndefault, and then in a six-character field with left justification and zero padding:\\n>>> x = 1234\\n>>> res = \"integers: ...%d...%−6d...%06d\" % (x, x, x)\\n>>> res\\n\\'integers: ...1234...1234  ...001234\\'\\nThe %e, %f, and %g formats display floating-point numbers in different ways, as the\\nfollowing interaction demonstrates ( %E is the same as %e but the exponent is uppercase):\\n>>> x = 1.23456789\\n>>> x\\n1.2345678899999999\\n>>> \\'%e | %f | %g\\' % (x, x, x)\\n\\'1.234568e+00 | 1.234568 | 1.23457\\'\\n>>> \\'%E\\' % x\\n\\'1.234568E+00\\'\\nFor floating-point numbers, you can achieve a variety of additional formatting effects\\nby specifying left justification, zero padding, numeric signs, field width, and digits after\\nthe decimal point. For simpler tasks, you might get by with simply converting to strings\\nwith a format expression or the str built-in function shown earlier:\\n>>> \\'%−6.2f | %05.2f | %+06.1f\\' % (x, x, x)\\n\\'1.23   | 01.23 | +001.2\\'\\n>>> \"%s\" % x, str(x)\\n(\\'1.23456789\\', \\'1.23456789\\')\\nWhen sizes are not known until runtime, you can have the width and precision com-\\nputed by specifying them with a * in the format string to force their values to be taken\\nfrom the next item in the inputs to the right of the % operator—the 4 in the tuple here\\ngives precision:\\n>>> \\'%f, %.2f, %.*f\\' % (1/3.0, 1/3.0, 4, 1/3.0)\\n\\'0.333333, 0.33, 0.3333\\'\\nIf you’re interested in this feature, experiment with some of these examples and oper-\\nations on your own for more information.\\nDictionary-Based String Formatting Expressions\\nString formatting also allows conversion targets on the left to refer to the keys in a\\ndictionary on the right and fetch the corresponding values. I haven’t told you much\\nabout dictionaries yet, so here’s an example that demonstrates the basics:\\n>>> \"%(n)d %(x)s\" % {\"n\":1, \"x\":\"spam\"}\\n\\'1 spam\\'\\n182 | Chapter 7: \\u2002Strings', metadata={'source': 'python.pdf', 'page': 232}),\n",
       " Document(page_content='Here, the (n) and (x) in the format string refer to keys in the dictionary literal on the\\nright and fetch their associated values. Programs that generate text such as HTML or\\nXML often use this technique—you can build up a dictionary of values and substitute\\nthem all at once with a single formatting expression that uses key-based references:\\n>>> reply = \"\"\"                               # Template with substitution targets\\nGreetings...\\nHello %(name)s!\\nYour age squared is %(age)s\\n\"\"\"\\n>>> values = {\\'name\\': \\'Bob\\', \\'age\\': 40}       # Build up values to substitute\\n>>> print(reply % values)                     # Perform substitutions\\nGreetings...\\nHello Bob!\\nYour age squared is 40\\nThis trick is also used in conjunction with the vars built-in function, which returns a\\ndictionary containing all the variables that exist in the place it is called:\\n>>> food = \\'spam\\'\\n>>> age = 40\\n>>> vars()\\n{\\'food\\': \\'spam\\', \\'age\\': 40, ...many more... }\\nWhen used on the right of a format operation, this allows the format string to refer to\\nvariables by name (i.e., by dictionary key):\\n>>> \"%(age)d %(food)s\" % vars()\\n\\'40 spam\\'\\nWe’ll study dictionaries in more depth in Chapter 8 . See also Chapter 5  for examples\\nthat convert to hexadecimal and octal number strings with the %x and %o formatting\\ntarget codes.\\nString Formatting Method Calls\\nAs mentioned earlier, Python 2.6 and 3.0 introduced a new way to format strings that\\nis seen by some as a bit more Python-specific. Unlike formatting expressions, formatting\\nmethod calls are not closely based upon the C language’s “printf” model, and they are\\nmore verbose and explicit in intent. On the other hand, the new technique still relies\\non some “printf” concepts, such as type codes and formatting specifications. Moreover,\\nit largely overlaps with (and sometimes requires a bit more code than) formatting ex-\\npressions, and it can be just as complex in advanced roles. Because of this, there is no\\nbest-use recommendation between expressions and method calls today, so most pro-\\ngrammers would be well served by a cursory understanding of both schemes.\\nString Formatting Method Calls | 183', metadata={'source': 'python.pdf', 'page': 233}),\n",
       " Document(page_content=\"The Basics\\nIn short, the \\nnew string object’s format method in 2.6 and 3.0 (and later) uses the subject\\nstring as a template and takes any number of arguments that represent values to be\\nsubstituted according to the template. Within the subject string, curly braces designate\\nsubstitution targets and arguments to be inserted either by position (e.g., {1}) or key-\\nword (e.g., {food}). As we’ll learn when we study argument passing in depth in Chap-\\nter 18, arguments to functions and methods may be passed by position or keyword\\nname, and Python’s ability to collect arbitrarily many positional and keyword argu-\\nments allows for such general method call patterns. In Python 2.6 and 3.0, for example:\\n>>> template = '{0}, {1} and {2}'                             # By position\\n>>> template.format('spam', 'ham', 'eggs')\\n'spam, ham and eggs'\\n>>> template = '{motto}, {pork} and {food}'                   # By keyword\\n>>> template.format(motto='spam', pork='ham', food='eggs')\\n'spam, ham and eggs'\\n>>> template = '{motto}, {0} and {food}'                      # By both\\n>>> template.format('ham', motto='spam', food='eggs')\\n'spam, ham and eggs'\\nNaturally, the string can also be a literal that creates a temporary string, and arbitrary\\nobject types can be substituted:\\n>>> '{motto}, {0} and {food}'.format(42, motto=3.14, food=[1, 2])\\n'3.14, 42 and [1, 2]'\\nJust as with the % expression and other string methods, format creates and returns a\\nnew string object, which can be printed immediately or saved for further work (recall\\nthat strings are immutable, so format really must make a new object). String formatting\\nis not just for display:\\n>>> X = '{motto}, {0} and {food}'.format(42, motto=3.14, food=[1, 2])\\n>>> X\\n'3.14, 42 and [1, 2]'\\n>>> X.split(' and ')\\n['3.14, 42', '[1, 2]']\\n>>> Y = X.replace('and', 'but under no circumstances')\\n>>> Y\\n'3.14, 42 but under no circumstances [1, 2]'\\nAdding Keys, Attributes, and Offsets\\nLike % formatting expressions, format calls can become more complex to support more\\nadvanced usage. For instance, format strings can name object attributes and dictionary\\nkeys—as in normal Python syntax, square brackets name dictionary keys and dots\\ndenote object attributes of an item referenced by position or keyword. The first of the\\n184 | Chapter 7: \\u2002Strings\", metadata={'source': 'python.pdf', 'page': 234}),\n",
       " Document(page_content='following examples indexes a dictionary on the key “spam” and then fetches the at-\\ntribute “platform” from \\nthe already imported sys module object. The second does the\\nsame, but names the objects by keyword instead of position:\\n>>> import sys\\n>>> \\'My {1[spam]} runs {0.platform}\\'.format(sys, {\\'spam\\': \\'laptop\\'})\\n\\'My laptop runs win32\\'\\n>>> \\'My {config[spam]} runs {sys.platform}\\'.format(sys=sys,\\n                                                  config={\\'spam\\': \\'laptop\\'})\\n\\'My laptop runs win32\\'\\nSquare brackets in format strings can name list (and other sequence) offsets to perform\\nindexing, too, but only single positive offsets work syntactically within format strings,\\nso this feature is not as general as you might think. As with % expressions, to name\\nnegative offsets or slices, or to use arbitrary expression results in general, you must run\\nexpressions outside the format string itself:\\n>>> somelist = list(\\'SPAM\\')\\n>>> somelist\\n[\\'S\\', \\'P\\', \\'A\\', \\'M\\']\\n>>> \\'first={0[0]}, third={0[2]}\\'.format(somelist)\\n\\'first=S, third=A\\'\\n>>> \\'first={0}, last={1}\\'.format(somelist[0], somelist[-1])   # [-1] fails in fmt\\n\\'first=S, last=M\\'\\n>>> parts = somelist[0], somelist[-1], somelist[1:3]          # [1:3] fails in fmt\\n>>> \\'first={0}, last={1}, middle={2}\\'.format(*parts)\\n\"first=S, last=M, middle=[\\'P\\', \\'A\\']\"\\nAdding Specific Formatting\\nAnother similarity with % expressions is that more specific layouts can be achieved by\\nadding extra syntax in the format string. For the formatting method, we use a colon\\nafter the substitution target’s identification, followed by a format specifier that can\\nname the field size, justification, and a specific type code. Here’s the formal structure\\nof what can appear as a substitution target in a format string:\\n{fieldname!conversionflag:formatspec}\\nIn this substitution target syntax:\\n•fieldname is a number or keyword naming an argument, followed by optional\\n“.name” attribute or “[index]” component references.\\n•conversionflag can be r, s, or a to call repr, str, or ascii built-in functions on the\\nvalue, respectively.\\nString Formatting Method Calls | 185', metadata={'source': 'python.pdf', 'page': 235}),\n",
       " Document(page_content=\"•formatspec specifies how the value should be presented, including details such as\\nfield width, alignment, padding, decimal precision, and so on, and ends with an\\noptional data type code.\\nThe formatspec component after the colon character is formally described as follows\\n(brackets denote optional components and are not coded literally):\\n[[fill]align][sign][#][0][width][.precision][typecode]\\nalign may be <, >, =, or ^, for left alignment, right alignment, padding after a sign\\ncharacter, or centered alignment, respectively. The formatspec also contains nested\\n{} format strings with field names only, to take values from the arguments list dynam-\\nically (much like the * in formatting expressions).\\nSee Python’s library manual for more on substitution syntax and a list of the available\\ntype codes—they almost completely overlap with those used in % expressions and listed\\npreviously in Table 7-4, but the format method also allows a “b” type code used to\\ndisplay integers in binary format (it’s equivalent to using the bin built-in call), allows\\na “%” type code to display percentages, and uses only “d” for base-10 integers (not “i”\\nor “u”).\\nAs an example, in the following {0:10} means the first positional argument in a field\\n10 characters wide, {1:<10} means the second positional argument left-justified in a\\n10-character-wide field, and {0.platform:>10} means the platform attribute of the first\\nargument right-justified in a 10-character-wide field:\\n>>> '{0:10} = {1:10}'.format('spam', 123.4567)\\n'spam       =    123.457'\\n>>> '{0:>10} = {1:<10}'.format('spam', 123.4567)\\n'      spam = 123.457   '\\n>>> '{0.platform:>10} = {1[item]:<10}'.format(sys, dict(item='laptop'))\\n'     win32 = laptop    '\\nFloating-point numbers support the same type codes and formatting specificity in for-\\nmatting method calls as in % expressions. For instance, in the following {2:g} means\\nthe third argument formatted by default according to the “g” floating-point represen-\\ntation, {1:.2f} designates the “f” floating-point format with just 2 decimal digits, and\\n{2:06.2f} adds a field with a width of 6 characters and zero padding on the left:\\n>>> '{0:e}, {1:.3e}, {2:g}'.format(3.14159, 3.14159, 3.14159)\\n'3.141590e+00, 3.142e+00, 3.14159'\\n>>> '{0:f}, {1:.2f}, {2:06.2f}'.format(3.14159, 3.14159, 3.14159)\\n'3.141590, 3.14, 003.14'\\nHex, octal, and binary formats are supported by the format method as well. In fact,\\nstring formatting is an alternative to some of the built-in functions that format integers\\nto a given base:\\n186 | Chapter 7: \\u2002Strings\", metadata={'source': 'python.pdf', 'page': 236}),\n",
       " Document(page_content=\">>> '{0:X}, {1:o}, {2:b}'.format(255, 255, 255)      # Hex, octal, binary\\n'FF, 377, 11111111'\\n>>> bin(255), int('11111111', 2), 0b11111111         # Other to/from binary\\n('0b11111111', 255, 255)\\n>>> hex(255), int('FF', 16), 0xFF                    # Other to/from hex\\n('0xff', 255, 255)\\n>>> oct(255), int('377', 8), 0o377, 0377             # Other to/from octal\\n('0377', 255, 255, 255)                              # 0377 works in 2.6, not 3.0!\\nFormatting parameters can \\neither be hardcoded in format strings or taken from the\\narguments list dynamically by nested format syntax, much like the star syntax in for-\\nmatting expressions:\\n>>> '{0:.2f}'.format(1 / 3.0)                        # Parameters hardcoded\\n'0.33'\\n>>> '%.2f' % (1 / 3.0)\\n'0.33'\\n>>> '{0:.{1}f}'.format(1 / 3.0, 4)                   # Take value from arguments\\n'0.3333'\\n>>> '%.*f' % (4, 1 / 3.0)                            # Ditto for expression\\n'0.3333'\\nFinally, Python 2.6 and 3.0 also provide a new built-in format function, which can be\\nused to format a single item. It’s a more concise alternative to the string format method,\\nand is roughly similar to formatting a single item with the % formatting expression:\\n>>> '{0:.2f}'.format(1.2345)                         # String method\\n'1.23'\\n>>> format(1.2345, '.2f')                            # Built-in function\\n'1.23'\\n>>> '%.2f' % 1.2345                                  # Expression\\n'1.23'\\nTechnically, the format built-in runs the subject object’s __format__ method, which the\\nstr.format method does internally for each formatted item. It’s still more verbose than\\nthe original % expression’s equivalent, though—which leads us to the next section.\\nComparison to the % Formatting Expression\\nIf you study the prior sections closely, you’ll probably notice that at least for positional\\nreferences and dictionary keys, the string format method looks very much like the %\\nformatting expression, especially in advanced use with type codes and extra formatting\\nsyntax. In fact, in common use cases formatting expressions may be easier to code than\\nformatting method calls, especially when using the generic %s print-string substitution\\ntarget:\\nprint('%s=%s' % ('spam', 42))            # 2.X+ format expression\\nprint('{0}={1}'.format('spam', 42))      # 3.0 (and 2.6) format method\\nString Formatting Method Calls | 187\", metadata={'source': 'python.pdf', 'page': 237}),\n",
       " Document(page_content='As we’ll see in a moment, though, more complex formatting tends to be a draw in terms\\nof complexity (difficult \\ntasks are generally difficult, regardless of approach), and some\\nsee the formatting method as largely redundant.\\nOn the other hand, the formatting method also offers a few potential advantages. For\\nexample, the original % expression can’t handle keywords, attribute references, and\\nbinary type codes, although dictionary key references in % format strings can often\\nachieve similar goals. To see how the two techniques overlap, compare the following\\n% expressions to the equivalent format method calls shown earlier:\\n# The basics: with % instead of format()\\n>>> template = \\'%s, %s, %s\\'\\n>>> template % (\\'spam\\', \\'ham\\', \\'eggs\\')                        # By position\\n    \\'spam, ham, eggs\\'\\n>>> template = \\'%(motto)s, %(pork)s and %(food)s\\'\\n>>> template % dict(motto=\\'spam\\', pork=\\'ham\\', food=\\'eggs\\')    # By key\\n\\'spam, ham and eggs\\'\\n>>> \\'%s, %s and %s\\' % (3.14, 42, [1, 2])                      # Arbitrary types\\n\\'3.14, 42 and [1, 2]\\'\\n# Adding keys, attributes, and offsets\\n>>> \\'My %(spam)s runs %(platform)s\\' % {\\'spam\\': \\'laptop\\', \\'platform\\': sys.platform}\\n\\'My laptop runs win32\\'\\n>>> \\'My %(spam)s runs %(platform)s\\' % dict(spam=\\'laptop\\', platform=sys.platform)\\n\\'My laptop runs win32\\'\\n>>> somelist = list(\\'SPAM\\')\\n>>> parts = somelist[0], somelist[-1], somelist[1:3]\\n>>> \\'first=%s, last=%s, middle=%s\\' % parts\\n\"first=S, last=M, middle=[\\'P\\', \\'A\\']\"\\nWhen more complex formatting is applied the two techniques approach parity in terms\\nof complexity, although if you compare the following with the format method call\\nequivalents listed earlier you’ll again find that the % expressions tend to be a bit simpler\\nand more concise:\\n# Adding specific formatting\\n>>> \\'%-10s = %10s\\' % (\\'spam\\', 123.4567)\\n\\'spam       =   123.4567\\'\\n>>> \\'%10s = %-10s\\' % (\\'spam\\', 123.4567)\\n\\'      spam = 123.4567  \\'\\n>>> \\'%(plat)10s = %(item)-10s\\' % dict(plat=sys.platform, item=\\'laptop\\')\\n\\'     win32 = laptop    \\'\\n188 | Chapter 7: \\u2002Strings', metadata={'source': 'python.pdf', 'page': 238}),\n",
       " Document(page_content=\"# Floating-point numbers\\n>>> '%e, %.3e, %g' % (3.14159, 3.14159, 3.14159)\\n'3.141590e+00, 3.142e+00, 3.14159'\\n>>> '%f, %.2f, %06.2f' % (3.14159, 3.14159, 3.14159)\\n'3.141590, 3.14, 003.14'\\n# Hex and octal, but not binary\\n>>> '%x, %o' % (255, 255)\\n'ff, 377'\\nThe format method has \\na handful of advanced features that the % expression does not,\\nbut even more involved formatting still seems to be essentially a draw in terms of com-\\nplexity. For instance, the following shows the same result generated with both\\ntechniques, with field sizes and justifications and various argument reference methods:\\n# Hardcoded references in both\\n>>> import sys\\n>>> 'My {1[spam]:<8} runs {0.platform:>8}'.format(sys, {'spam': 'laptop'})\\n'My laptop   runs    win32'\\n>>> 'My %(spam)-8s runs %(plat)8s' % dict(spam='laptop', plat=sys.platform)\\n'My laptop   runs    win32'\\nIn practice, programs are less likely to hardcode references like this than to execute\\ncode that builds up a set of substitution data ahead of time (to collect data to substitute\\ninto an HTML template all at once, for instance). When we account for common prac-\\ntice in examples like this, the comparison between the format method and the % ex-\\npression is even more direct (as we’ll see in Chapter 18 , the **data in the method call\\nhere is special syntax that unpacks a dictionary of keys and values into individual\\n“name=value” keyword arguments so they can be referenced by name in the format\\nstring):\\n# Building data ahead of time in both\\n>>> data = dict(platform=sys.platform, spam='laptop')\\n>>> 'My {spam:<8} runs {platform:>8}'.format(**data)\\n'My laptop   runs    win32'\\n>>> 'My %(spam)-8s runs %(platform)8s' % data\\n'My laptop   runs    win32'\\nAs usual, the Python community will have to decide whether % expressions, format\\nmethod calls, or a toolset with both techniques proves better over time. Experiment\\nwith these techniques on your own to get a feel for what they offer, and be sure to see\\nthe Python 2.6 and 3.0 library manuals for more details.\\nString Formatting Method Calls | 189\", metadata={'source': 'python.pdf', 'page': 239}),\n",
       " Document(page_content=\"String format method enhancements in Python 3.1: The upcoming 3.1\\nrelease (in alpha form as this chapter was being written) will add a\\nthousand-separator syntax for numbers, which inserts commas between\\nthree-digit groups. Add a comma before the type code to make this\\nwork, as follows:\\n>>> '{0:d}'.format(999999999999)\\n'999999999999'\\n>>> '{0:,d}'.format(999999999999)\\n'999,999,999,999'\\nPython 3.1 also assigns relative numbers to substitution targets auto-\\nmatically if they are not included explicitly, though using this extension\\nmay negate one of the main benefits of the formatting method, as the\\nnext section describes:\\n>>> '{:,d}'.format(999999999999)\\n'999,999,999,999'\\n>>> '{:,d} {:,d}'.format(9999999, 8888888)\\n'9,999,999 8,888,888'\\n>>> '{:,.2f}'.format(296999.2567)\\n'296,999.26'\\nThis book doesn’t cover 3.1 officially, so you should take this as a pre-\\nview. Python 3.1 will also address a major performance issue in\\n3.0 related to the speed of file input/output operations, which made 3.0\\nimpractical for many types of programs. See the 3.1 release notes for\\nmore details. See also the formats.py comma-insertion and\\nmoney-formatting function examples in Chapter 24  for a manual solu-\\ntion that can be imported and used prior to Python 3.1.\\nWhy the New Format Method?\\nNow that I’ve gone to such lengths to compare and contrast the two formatting tech-\\nniques, I need to explain why you might want to consider using the format method\\nvariant at times. In short, although the formatting method can sometimes require more\\ncode, it also:\\n• Has a few extra features not found in the % expression\\n• Can make substitution value references more explicit\\n• Trades an operator for an arguably more mnemonic method name\\n• Does not support different syntax for single and multiple substitution value cases\\nAlthough both techniques are available today and the formatting expression is still\\nwidely used, the format method might eventually subsume it. But because the choice\\nis currently still yours to make, let’s briefly expand on some of the differences before\\nmoving on.\\n190 | Chapter 7: \\u2002Strings\", metadata={'source': 'python.pdf', 'page': 240}),\n",
       " Document(page_content=\"Extra features\\nThe method call \\nsupports a few extras that the expression does not, such as binary type\\ncodes and (coming in Python 3.1) thousands groupings. In addition, the method call\\nsupports key and attribute references directly. As we’ve seen, though, the formatting\\nexpression can usually achieve the same effects in other ways:\\n>>> '{0:b}'.format((2 ** 16) −1)\\n'1111111111111111'\\n>>> '%b' % ((2 ** 16) −1)\\nValueError: unsupported format character 'b' (0x62) at index 1\\n>>> bin((2 ** 16) −1)\\n'0b1111111111111111'\\n>>> '%s' % bin((2 ** 16) −1)[2:]\\n'1111111111111111'\\nSee also the prior examples that compare dictionary-based formatting in the % expres-\\nsion to key and attribute references in the format method; especially in common prac-\\ntice, the two seem largely variations on a theme.\\nExplicit value references\\nOne use case where the format method is at least debatably clearer is when there are\\nmany values to be substituted into the format string. The lister.py classes example we’ll\\nmeet in Chapter 30 , for example, substitutes six items into a single string, and in this\\ncase the method’s {i} position labels seem easier to read than the expression’s %s:\\n'\\\\n%s<Class %s, address %s:\\\\n%s%s%s>\\\\n' % (...)               # Expression\\n'\\\\n{0}<Class {1}, address {2}:\\\\n{3}{4}{5}>\\\\n'.format(...)     # Method\\nOn the other hand, using dictionary keys in % expressions can mitigate much of this\\ndifference. This is also something of a worst-case scenario for formatting complexity,\\nand not very common in practice; more typical use cases seem largely a tossup. More-\\nover, in Python 3.1 (still in alpha release form as I write these words), numbering sub-\\nstitution values will become optional, thereby subverting this purported benefit\\naltogether:\\nC:\\\\misc> C:\\\\Python31\\\\python\\n>>> 'The {0} side {1} {2}'.format('bright', 'of', 'life')\\n'The bright side of life'\\n>>>\\n>>> 'The {} side {} {}'.format('bright', 'of', 'life')        # Python 3.1+\\n'The bright side of life'\\n>>>\\n>>> 'The %s side %s %s' % ('bright', 'of', 'life')\\n'The bright side of life'\\nString Formatting Method Calls | 191\", metadata={'source': 'python.pdf', 'page': 241}),\n",
       " Document(page_content=\"Using 3.1’s automatic relative numbering like this seems to negate a large part of the\\nmethod’s advantage. Compare \\nthe effect on floating-point formatting, for example—\\nthe formatting expression is still more concise, and still seems less cluttered:\\nC:\\\\misc> C:\\\\Python31\\\\python\\n>>> '{0:f}, {1:.2f}, {2:05.2f}'.format(3.14159, 3.14159, 3.14159)\\n'3.141590, 3.14, 03.14'\\n>>>\\n>>> '{:f}, {:.2f}, {:06.2f}'.format(3.14159, 3.14159, 3.14159)\\n'3.141590, 3.14, 003.14'\\n>>>\\n>>> '%f, %.2f, %06.2f' % (3.14159, 3.14159, 3.14159)\\n'3.141590, 3.14, 003.14'\\nMethod names and general arguments\\nGiven this 3.1 auto-numbering change, the only clearly remaining potential advantages\\nof the formatting method are that it replaces the % operator with a more mnemonic\\nformat method name and does not distinguish between single and multiple substitution\\nvalues. The former may make the method appear simpler to beginners at first glance\\n(“format” may be easier to parse than multiple “%” characters), though this is too\\nsubjective to call.\\nThe latter difference might be more significant—with the format expression, a single\\nvalue can be given by itself, but multiple values must be enclosed in a tuple:\\n>>> '%.2f' % 1.2345\\n'1.23'\\n>>> '%.2f %s' % (1.2345, 99)\\n'1.23 99'\\nTechnically, the formatting expression accepts either a single substitution value, or a\\ntuple of one or more items. In fact, because a single item can be given either by itself or\\nwithin a tuple, a tuple to be formatted must be provided as nested tuples:\\n>>> '%s' % 1.23\\n'1.23'\\n>>> '%s' % (1.23,)\\n'1.23'\\n>>> '%s' % ((1.23,),)\\n'(1.23,)'\\nThe formatting method, on the other hand, tightens this up by accepting general func-\\ntion arguments in both cases:\\n>>> '{0:.2f}'.format(1.2345)\\n'1.23'\\n>>> '{0:.2f} {1}'.format(1.2345, 99)\\n'1.23 99'\\n>>> '{0}'.format(1.23)\\n'1.23'\\n>>> '{0}'.format((1.23,))\\n'(1.23,)'\\n192 | Chapter 7: \\u2002Strings\", metadata={'source': 'python.pdf', 'page': 242}),\n",
       " Document(page_content='Consequently, it might be less confusing to beginners and cause fewer programming\\nmistakes. This is \\nstill a fairly minor issue, though—if you always enclose values in a\\ntuple and ignore the nontupled option, the expression is essentially the same as the\\nmethod call here. Moreover, the method incurs an extra price in inflated code size to\\nachieve its limited flexibility. Given that the expression has been used extensively\\nthroughout Python’s history, it’s not clear that this point justifies breaking existing\\ncode for a new tool that is so similar, as the next section argues.\\nPossible future deprecation?\\nAs mentioned earlier, there is some risk that Python developers may deprecate the %\\nexpression in favor of the format method in the future. In fact, there is a note to this\\neffect in Python 3.0’s manuals.\\nThis has not yet occurred, of course, and both formatting techniques are fully available\\nand reasonable to use in Python 2.6 and 3.0 (the versions of Python this book covers).\\nBoth techniques are supported in the upcoming Python 3.1 release as well, so depre-\\ncation of either seems unlikely for the foreseeable future. Moreover, because formatting\\nexpressions are used extensively in almost all existing Python code written to date, most\\nprogrammers will benefit from being familiar with both techniques for many years to\\ncome.\\nIf this deprecation ever does occur, though, you may need to recode all your % expres-\\nsions as format methods, and translate those that appear in this book, in order to use\\na newer Python release. At the risk of editorializing here, I hope that such a change will\\nbe based upon the future common practice of actual Python programmers, not the\\nwhims of a handful of core developers—particularly given that the window for Python\\n3.0’s many incompatible changes is now closed. Frankly, this deprecation would seem\\nlike trading one complicated thing for another complicated thing—one that is largely\\nequivalent to the tool it would replace! If you care about migrating to future Python\\nreleases, though, be sure to watch for developments on this front over time.\\nGeneral Type Categories\\nNow that we’ve explored the first of Python’s collection objects, the string, let’s pause\\nto define a few general type concepts that will apply to most of the types we look at\\nfrom here on. With regard to built-in types, it turns out that operations work the same\\nfor all the types in the same category, so we’ll only need to define most of these ideas\\nonce. We’ve only examined numbers and strings so far, but because they are repre-\\nsentative of two of the three major type categories in Python, you already know more\\nabout several other types than you might think.\\nGeneral Type Categories | 193', metadata={'source': 'python.pdf', 'page': 243}),\n",
       " Document(page_content='Types Share Operation Sets by Categories\\nAs you’ve learned, \\nstrings are immutable sequences: they cannot be changed in-place\\n(the immutable part), and they are positionally ordered collections that are accessed by\\noffset (the sequence part). Now, it so happens that all the sequences we’ll study in this\\npart of the book respond to the same sequence operations shown in this chapter at\\nwork on strings—concatenation, indexing, iteration, and so on. More formally, there\\nare three major type (and operation) categories in Python:\\nNumbers (integer, floating-point, decimal, fraction, others)\\nSupport addition, multiplication, etc.\\nSequences (strings, lists, tuples)\\nSupport indexing, slicing, concatenation, etc.\\nMappings (dictionaries)\\nSupport indexing by key, etc.\\nSets are something of a category unto themselves (they don’t map keys to values and\\nare not positionally ordered sequences), and we haven’t yet explored mappings on our\\nin-depth tour (dictionaries are discussed in the next chapter). However, many of the\\nother types we will encounter will be similar to numbers and strings. For example, for\\nany sequence objects X and Y:\\n•X + Y makes a new sequence object with the contents of both operands.\\n•X * N makes a new sequence object with N copies of the sequence operand X.\\nIn other words, these operations work the same way on any kind of sequence, including\\nstrings, lists, tuples, and some user-defined object types. The only difference is that the\\nnew result object you get back is of the same type as the operands X and Y—if you\\nconcatenate lists, you get back a new list, not a string. Indexing, slicing, and other\\nsequence operations work the same on all sequences, too; the type of the objects being\\nprocessed tells Python which flavor of the task to perform.\\nMutable Types Can Be Changed In-Place\\nThe immutable classification is an important constraint to be aware of, yet it tends to\\ntrip up new users. If an object type is immutable, you cannot change its value in-place;\\nPython raises an error if you try. Instead, you must run code to make a new object\\ncontaining the new value. The major core types in Python break down as follows:\\nImmutables (numbers, strings, tuples, frozensets)\\nNone of the object types in the immutable category support in-place changes,\\nthough we can always run expressions to make new objects and assign their results\\nto variables as needed.\\n194 | Chapter 7: \\u2002Strings', metadata={'source': 'python.pdf', 'page': 244}),\n",
       " Document(page_content='Mutables (lists, dictionaries, sets)\\nConversely, the mutable \\ntypes can always be changed in-place with operations that\\ndo not create new objects. Although such objects can be copied, in-place changes\\nsupport direct modification.\\nGenerally, immutable types give some degree of integrity by guaranteeing that an object\\nwon’t be changed by another part of a program. For a refresher on why this matters,\\nsee the discussion of shared object references in Chapter 6 . To see how lists, diction-\\naries, and tuples participate in type categories, we need to move ahead to the next\\nchapter.\\nChapter Summary\\nIn this chapter, we took an in-depth tour of the string object type. We learned about\\ncoding string literals, and we explored string operations, including sequence expres-\\nsions, string method calls, and string formatting with both expressions and method\\ncalls. Along the way, we studied a variety of concepts in depth, such as slicing, method\\ncall syntax, and triple-quoted block strings. We also defined some core ideas common\\nto a variety of types: sequences, for example, share an entire set of operations.\\nIn the next chapter, we’ll continue our types tour with a look at the most general object\\ncollections in Python—lists and dictionaries. As you’ll find, much of what you’ve\\nlearned here will apply to those types as well. And as mentioned earlier, in the final part\\nof this book we’ll return to Python’s string model to flesh out the details of Unicode\\ntext and binary data, which are of interest to some, but not all, Python programmers.\\nBefore moving on, though, here’s another chapter quiz to review the material covered \\nhere.\\nTest Your Knowledge: Quiz\\n1. Can the string find\\n method be used to search a list?\\n2. Can a string slice expression be used on a list?\\n3. How would you convert a character to its ASCII integer code? How would you\\nconvert the other way, from an integer to a character?\\n4. How might you go about changing a string in Python?\\n5. Given a string S with the value \"s,pa,m\", name two ways to extract the two char-\\nacters in the middle.\\n6. How many characters are there in the string \"a\\\\nb\\\\x1f\\\\000d\"?\\n7. Why might you use the string module instead of string method calls?\\nTest Your Knowledge: Quiz | 195', metadata={'source': 'python.pdf', 'page': 245}),\n",
       " Document(page_content='Test Your Knowledge: Answers\\n1. No, because methods \\nare always type-specific; that is, they only work on a single\\ndata type. Expressions like X+Y and built-in functions like len(X) are generic,\\nthough, and may work on a variety of types. In this case, for instance, the in mem-\\nbership expression has a similar effect as the string find, but it can be used to search\\nboth strings and lists. In Python 3.0, there is some attempt to group methods by\\ncategories (for example, the mutable sequence types list and bytearray have sim-\\nilar method sets), but methods are still more type-specific than other operation sets.\\n2. Yes. Unlike methods, expressions are generic and apply to many types. In this case,\\nthe slice expression is really a sequence operation—it works on any type of se-\\nquence object, including strings, lists, and tuples. The only difference is that when\\nyou slice a list, you get back a new list.\\n3. The built-in ord(S) function converts from a one-character string to an integer\\ncharacter code; chr(I) converts from the integer code back to a string.\\n4. Strings cannot be changed; they are immutable. However, you can achieve a similar\\neffect by creating a new string—by concatenating, slicing, running formatting ex-\\npressions, or using a method call like replace—and then assigning the result back\\nto the original variable name.\\n5. You can slice the string using S[2:4], or split on the comma and index the string\\nusing S.split(\\',\\')[1]. Try these interactively to see for yourself.\\n6. Six. The string \"a\\\\nb\\\\x1f\\\\000d\" contains the bytes a, newline ( \\\\n), b, binary 31 (a\\nhex escape \\\\x1f), binary 0 (an octal escape \\\\000), and d. Pass the string to the built-\\nin len function to verify this, and print each of its character’s ord results to see the\\nactual byte values. See Table 7-2 for more details.\\n7. You should never use the string module instead of string object method calls\\ntoday—it’s deprecated, and its calls are removed completely in Python 3.0. The\\nonly reason for using the string module at all is for its other tools, such as prede-\\nfined constants. You might also see it appear in what is now very old and dusty\\nPython code.\\n196 | Chapter 7: \\u2002Strings', metadata={'source': 'python.pdf', 'page': 246}),\n",
       " Document(page_content='CHAPTER 8\\nLists and Dictionaries\\nThis chapter presents the list and dictionary object types, both of which are collections\\nof other objects. \\nThese two types are the main workhorses in almost all Python scripts.\\nAs you’ll see, both types are remarkably flexible: they can be changed in-place, can\\ngrow and shrink on demand, and may contain and be nested in any other kind of object.\\nBy leveraging these types, you can build up and process arbitrarily rich information\\nstructures in your scripts.\\nLists\\nThe next stop on our built-in object tour is the Python list. Lists are Python’s most\\nflexible ordered collection object type. Unlike strings, lists can contain any sort of\\nobject: numbers, strings, and even other lists. Also, unlike strings, lists may be changed\\nin-place by assignment to offsets and slices, list method calls, deletion statements, and\\nmore—they are mutable objects.\\nPython lists do the work of most of the collection data structures you might have to\\nimplement manually in lower-level languages such as C. Here is a quick look at their\\nmain properties. Python lists are:\\nOrdered collections of arbitrary objects\\nFrom a functional view, lists are just places to collect other objects so you can treat\\nthem as groups. Lists also maintain a left-to-right positional ordering among the\\nitems they contain (i.e., they are sequences).\\nAccessed by offset\\nJust as with strings, you can fetch a component object out of a list by indexing the\\nlist on the object’s offset. Because items in lists are ordered by their positions, you\\ncan also do tasks such as slicing and concatenation.\\n197', metadata={'source': 'python.pdf', 'page': 247}),\n",
       " Document(page_content=\"Variable-length, heterogeneous, and arbitrarily nestable\\nUnlike strings, lists \\ncan grow and shrink in-place (their lengths can vary), and they\\ncan contain any sort of object, not just one-character strings (they’re\\nheterogeneous). Because lists can contain other complex objects, they also support\\narbitrary nesting; you can create lists of lists of lists, and so on.\\nOf the category “mutable sequence”\\nIn terms of our type category qualifiers, lists are mutable (i.e., can be changed in-\\nplace) and can respond to all the sequence operations used with strings, such as\\nindexing, slicing, and concatenation. In fact, sequence operations work the same\\non lists as they do on strings; the only difference is that sequence operations such\\nas concatenation and slicing return new lists instead of new strings when applied\\nto lists. Because lists are mutable, however, they also support other operations that\\nstrings don’t (such as deletion and index assignment operations, which change the\\nlists in-place).\\nArrays of object references\\nTechnically, Python lists contain zero or more references to other objects. Lists\\nmight remind you of arrays of pointers (addresses) if you have a background in\\nsome other languages. Fetching an item from a Python list is about as fast as in-\\ndexing a C array; in fact, lists really are arrays inside the standard Python inter-\\npreter, not linked structures. As we learned in Chapter 6 , though, Python always\\nfollows a reference to an object whenever the reference is used, so your program\\ndeals only with objects. Whenever you assign an object to a data structure com-\\nponent or variable name, Python always stores a reference to that same object, not\\na copy of it (unless you request a copy explicitly).\\nTable 8-1  summarizes common and representative list object operations. As usual, for\\nthe full story see the Python standard library manual, or run a help(list) or\\ndir(list) call interactively for a complete list of list methods—you can pass in a real\\nlist, or the word list, which is the name of the list data type.\\nTable 8-1. Common list literals and operations\\nOperation Interpretation\\nL = [] An empty list\\nL = [0, 1, 2, 3] Four items: indexes 0..3\\nL = ['abc', ['def', 'ghi']] Nested sublists\\nL = list('spam')\\nL = list(range(-4, 4))Lists of an iterable’s items, list of successive integers\\nL[i]\\nL[i][j]\\nL[i:j]\\nlen(L)Index, index of index, slice, length\\n198 | Chapter 8: \\u2002Lists and Dictionaries\", metadata={'source': 'python.pdf', 'page': 248}),\n",
       " Document(page_content=\"Operation Interpretation\\nL1 + L2\\nL * 3Concatenate, repeat\\nfor x in L: print(x)\\n3 in LIteration, membership\\nL.append(4)\\nL.extend([5,6,7])\\nL.insert(I, X)Methods: growing\\nL.index(1)\\nL.count(X)Methods: searching\\nL.sort()\\nL.reverse()Methods: sorting, reversing, etc.\\ndel L[k]\\ndel L[i:j]\\nL.pop()\\nL.remove(2)\\nL[i:j] = []Methods, statement: shrinking\\nL[i] = 1\\nL[i:j] = [4,5,6]Index assignment, slice assignment\\nL = [x**2 for x in range(5)]\\nlist(map(ord, 'spam'))List comprehensions and maps (Chapters 14, 20)\\nWhen written down as a literal expression, a list is coded as a series of objects (really,\\nexpressions that return \\nobjects) in square brackets, separated by commas. For instance,\\nthe second row in Table 8-1  assigns the variable L to a four-item list. A nested list is\\ncoded as a nested square-bracketed series (row 3), and the empty list is just a square-\\nbracket pair with nothing inside (row 1).*\\nMany of the operations in Table 8-1  should look familiar, as they are the same sequence\\noperations we put to work on strings—indexing, concatenation, iteration, and so on.\\nLists also respond to list-specific method calls (which provide utilities such as sorting,\\nreversing, adding items to the end, etc.), as well as in-place change operations (deleting\\nitems, assignment to indexes and slices, and so forth). Lists have these tools for change\\noperations because they are a mutable object type.\\n* In practice, you won’t see many lists written out like this in list-processing programs. It’s more common to\\nsee code \\nthat processes lists constructed dynamically (at runtime). In fact, although it’s important to master\\nliteral syntax, most data structures in Python are built by running program code at runtime.\\nLists | 199\", metadata={'source': 'python.pdf', 'page': 249}),\n",
       " Document(page_content='Lists in Action\\nPerhaps the best \\nway to understand lists is to see them at work. Let’s once again turn\\nto some simple interpreter interactions to illustrate the operations in Table 8-1.\\nBasic List Operations\\nBecause they are sequences, lists support many of the same operations as strings. For\\nexample, lists respond to the + and * operators much like strings—they mean concat-\\nenation and repetition here too, except that the result is a new list, not a string:\\n% python\\n>>> len([1, 2, 3])                           # Length\\n3\\n>>> [1, 2, 3] + [4, 5, 6]                    # Concatenation\\n[1, 2, 3, 4, 5, 6]\\n>>> [\\'Ni!\\'] * 4                              # Repetition\\n[\\'Ni!\\', \\'Ni!\\', \\'Ni!\\', \\'Ni!\\']\\nAlthough the + operator works the same for lists and strings, it’s important to know\\nthat it expects the same sort of sequence on both sides—otherwise, you get a type error\\nwhen the code runs. For instance, you cannot concatenate a list and a string unless you\\nfirst convert the list to a string (using tools such as str or % formatting) or convert the\\nstring to a list (the list built-in function does the trick):\\n>>> str([1, 2]) + \"34\"               # Same as \"[1, 2]\" + \"34\"\\n\\'[1, 2]34\\'\\n>>> [1, 2] + list(\"34\")              # Same as [1, 2] + [\"3\", \"4\"]\\n[1, 2, \\'3\\', \\'4\\']\\nList Iteration and Comprehensions\\nMore generally, lists respond to all the sequence operations we used on strings in the\\nprior chapter, including iteration tools:\\n>>> 3 in [1, 2, 3]                           # Membership\\nTrue\\n>>> for x in [1, 2, 3]:\\n...     print(x, end=\\' \\')                    # Iteration\\n...\\n1 2 3\\nWe will talk more formally about for iteration and the range built-ins in Chapter 13 ,\\nbecause they are related to statement syntax. In short, for loops step through items in\\nany sequence from left to right, executing one or more statements for each item.\\nThe last items in Table 8-1, list comprehensions and map calls, are covered in more detail\\nin Chapter 14  and expanded on in Chapter 20 . Their basic operation is straightforward,\\nthough—as introduced in Chapter 4 , list comprehensions are a way to build a new list\\n200 | Chapter 8: \\u2002Lists and Dictionaries', metadata={'source': 'python.pdf', 'page': 250}),\n",
       " Document(page_content=\"by applying an expression to each item in a sequence, and are close relatives to for\\nloops:\\n>>> res = [c * 4 for c in 'SPAM']            # List comprehensions\\n>>> res\\n['SSSS', 'PPPP', 'AAAA', 'MMMM']\\nThis expression is \\nfunctionally equivalent to a for loop that builds up a list of results\\nmanually, but as we’ll learn in later chapters, list comprehensions are simpler to code\\nand faster to run today:\\n>>> res = []\\n>>> for c in 'SPAM':                         # List comprehension equivalent\\n...     res.append(c * 4)\\n...\\n>>> res\\n['SSSS', 'PPPP', 'AAAA', 'MMMM']\\nAs also introduced in Chapter 4, the map built-in function does similar work, but applies\\na function to items in a sequence and collects all the results in a new list:\\n>>> list(map(abs, [−1, −2, 0, 1, 2]))        # map function across sequence\\n[1, 2, 0, 1, 2]\\nBecause we’re not quite ready for the full iteration story, we’ll postpone further details\\nfor now, but watch for a similar comprehension expression for dictionaries later in this\\nchapter.\\nIndexing, Slicing, and Matrixes\\nBecauselists are sequences, indexing and slicing work the same way for lists as they do\\nfor strings. However, the result of indexing a list is whatever type of object lives at the\\noffset you specify, while slicing a list always returns a new list:\\n>>> L = ['spam', 'Spam', 'SPAM!']\\n>>> L[2]                             # Offsets start at zero\\n'SPAM!'\\n>>> L[−2]                            # Negative: count from the right\\n'Spam'\\n>>> L[1:]                            # Slicing fetches sections\\n['Spam', 'SPAM!']\\nOne note here: because you can nest lists and other object types within lists, you will\\nsometimes need to string together index operations to go deeper into a data structure.\\nFor example, one of the simplest ways to represent matrixes (multidimensional arrays)\\nin Python is as lists with nested sublists. Here’s a basic 3 × 3 two-dimensional list-based\\narray:\\n>>> matrix = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]\\nWith one index, you get an entire row (really, a nested sublist), and with two, you get\\nan item within the row:\\nLists in Action | 201\", metadata={'source': 'python.pdf', 'page': 251}),\n",
       " Document(page_content=\">>> matrix[1]\\n[4, 5, 6]\\n>>> matrix[1][1]\\n5\\n>>> matrix[2][0]\\n7\\n>>> matrix = [[1, 2, 3],\\n...           [4, 5, 6],\\n...           [7, 8, 9]]\\n>>> matrix[1][1]\\n5\\nNotice in the \\npreceding interaction that lists can naturally span multiple lines if you\\nwant them to because they are contained by a pair of brackets (more on syntax in the\\nnext part of the book). Later in this chapter, you’ll also see a dictionary-based matrix\\nrepresentation. For high-powered numeric work, the NumPy extension mentioned in\\nChapter 5 provides other ways to handle matrixes.\\nChanging Lists In-Place\\nBecause lists are mutable, they support operations that change a list object in-place.\\nThat is, the operations in this section all modify the list object directly, without requir-\\ning that you make a new copy, as you had to for strings. Because Python deals only in\\nobject references, this distinction between changing an object in-place and creating a\\nnew object matters—as discussed in Chapter 6 , if you change an object in-place, you\\nmight impact more than one reference to it at the same time.\\nIndex and slice assignments\\nWhen using a list, you can change its contents by assigning to either a particular item\\n(offset) or an entire section (slice):\\n>>> L = ['spam', 'Spam', 'SPAM!']\\n>>> L[1] = 'eggs'                 # Index assignment\\n>>> L\\n['spam', 'eggs', 'SPAM!']\\n>>> L[0:2] = ['eat', 'more']      # Slice assignment: delete+insert\\n>>> L                             # Replaces items 0,1\\n['eat', 'more', 'SPAM!']\\nBoth index and slice assignments are in-place changes—they modify the subject list\\ndirectly, rather than generating a new list object for the result. Index assignment in\\nPython works much as it does in C and most other languages: Python replaces the\\nobject reference at the designated offset with a new one.\\nSlice assignment , the last operation in the preceding example, replaces an entire section\\nof a list in a single step. Because it can be a bit complex, it is perhaps best thought of\\nas a combination of two steps:\\n202 | Chapter 8: \\u2002Lists and Dictionaries\", metadata={'source': 'python.pdf', 'page': 252}),\n",
       " Document(page_content=\"1.Deletion. The slice you specify to the left of the = is deleted.\\n2.Insertion. The new \\nitems contained in the object to the right of the = are inserted\\ninto the list on the left, at the place where the old slice was deleted.†\\nThis isn’t what really happens, but it tends to help clarify why the number of items\\ninserted doesn’t have to match the number of items deleted. For instance, given a list\\nL that has the value [1,2,3], the assignment L[1:2]=[4,5] sets L to the list [1,4,5,3].\\nPython first deletes the 2 (a one-item slice), then inserts the 4 and 5 where the deleted\\n2 used to be. This also explains why L[1:2]=[] is really a deletion operation—Python\\ndeletes the slice (the item at offset 1), and then inserts nothing.\\nIn effect, slice assignment replaces an entire section, or “column,” all at once. Because\\nthe length of the sequence being assigned does not have to match the length of the slice\\nbeing assigned to, slice assignment can be used to replace (by overwriting), expand (by\\ninserting), or shrink (by deleting) the subject list. It’s a powerful operation, but frankly,\\none that you may not see very often in practice. There are usually more straightforward\\nways to replace, insert, and delete (concatenation and the insert, pop, and remove list\\nmethods, for example), which Python programmers tend to prefer in practice.\\nList method calls\\nLike strings, Python list objects also support type-specific method calls, many of which\\nchange the subject list in-place:\\n>>> L.append('please')                # Append method call: add item at end\\n>>> L\\n['eat', 'more', 'SPAM!', 'please']\\n>>> L.sort()                          # Sort list items ('S' < 'e')\\n>>> L\\n['SPAM!', 'eat', 'more', 'please']\\nMethods were introduced in Chapter 7 . In brief, they are functions (really, attributes\\nthat reference functions) that are associated with particular objects. Methods provide\\ntype-specific tools; the list methods presented here, for instance, are generally available\\nonly for lists.\\nPerhaps the most commonly used list method is append, which simply tacks a single\\nitem (object reference) onto the end of the list. Unlike concatenation, append expects\\nyou to pass in a single object, not a list. The effect of L.append(X) is similar to L+[X],\\nbut while the former changes L in-place, the latter makes a new list.‡\\nAnother commonly seen method, sort, orders a list in-place; it uses Python standard\\ncomparison tests (here, string comparisons), and by default sorts in ascending order.\\n† This description needs elaboration when the value and the slice being assigned overlap: L[2:5]=L[3:6], for\\ninstance, works fine because the value to be inserted is fetched before the deletion happens on the left.\\n‡\\nUnlike + concatenation, append doesn’t have to generate new objects, so it’s usually faster. You can also mimic\\nappend with clever slice assignments: L[len(L):]=[X] is like L.append(X), and L[:0]=[X] is like appending at\\nthe front of a list. Both delete an empty slice and insert X, changing L in-place quickly, like append.\\nLists in Action | 203\", metadata={'source': 'python.pdf', 'page': 253}),\n",
       " Document(page_content='You can modify sort behavior by passing in keyword arguments—a special\\n“name=value” syntax in function calls that specifies passing by name and is often used\\nfor giving configuration options. In sorts, the key argument gives a one-argument func-\\ntion that returns the value to be used in sorting, and the reverse argument allows sorts\\nto be made in descending instead of ascending order:\\n>>> L = [\\'abc\\', \\'ABD\\', \\'aBe\\']\\n>>> L.sort()                                # Sort with mixed case\\n>>> L\\n[\\'ABD\\', \\'aBe\\', \\'abc\\']\\n>>> L = [\\'abc\\', \\'ABD\\', \\'aBe\\']\\n>>> L.sort(key=str.lower)                   # Normalize to lowercase\\n>>> L\\n[\\'abc\\', \\'ABD\\', \\'aBe\\']\\n>>>\\n>>> L = [\\'abc\\', \\'ABD\\', \\'aBe\\']\\n>>> L.sort(key=str.lower, reverse=True)     # Change sort order\\n>>> L\\n[\\'aBe\\', \\'ABD\\', \\'abc\\']\\nThe sort key argument might also be useful when sorting lists of dictionaries, to pick\\nout a sort key by indexing each dictionary. We’ll study dictionaries later in this chapter,\\nand you’ll learn more about keyword function arguments in Part IV.\\nComparison and sorts in 3.0 : In Python 2.6 and earlier, comparisons of\\ndifferently \\ntyped objects (e.g., a string and a list) work—the language\\ndefines a fixed ordering among different types, which is deterministic,\\nif not aesthetically pleasing. That is, the ordering is based on the names\\nof the types involved: all integers are less than all strings, for example,\\nbecause \"int\" is less than \"str\". Comparisons never automatically con-\\nvert types, except when comparing numeric type objects.\\nIn Python 3.0, this has changed: comparison of mixed types raises an\\nexception instead of falling back on the fixed cross-type ordering. Be-\\ncause sorting uses comparisons internally, this means that [1, 2,\\n\\'spam\\'].sort() succeeds in Python 2.X but will raise an exception in\\nPython 3.0 and later.\\nPython 3.0 also no longer supports passing in an arbitrary comparison\\nfunction to sorts, to implement different orderings. The suggested work-\\naround is to use the key=func keyword argument to code value trans-\\nformations during the sort, and use the reverse=True keyword argument\\nto change the sort order to descending. These were the typical uses of\\ncomparison functions in the past.\\nOne warning here: beware that append and sort change the associated list object in-\\nplace, but don’t return the list as a result (technically, they both return a value called\\nNone). If you say something like L=L.append(X), you won’t get the modified value of L\\n(in fact, you’ll lose the reference to the list altogether!). When you use attributes such\\nas append and sort, objects are changed as a side effect, so there’s no reason to reassign.\\n204 | Chapter 8: \\u2002Lists and Dictionaries', metadata={'source': 'python.pdf', 'page': 254}),\n",
       " Document(page_content=\"Partly because of such constraints, sorting is also available in recent Pythons as a built-\\nin function, which \\nsorts any collection (not just lists) and returns a new list for the result\\n(instead of in-place changes):\\n>>> L = ['abc', 'ABD', 'aBe']\\n>>> sorted(L, key=str.lower, reverse=True)          # Sorting built-in\\n['aBe', 'ABD', 'abc']\\n>>> L = ['abc', 'ABD', 'aBe']\\n>>> sorted([x.lower() for x in L], reverse=True)    # Pretransform items: differs!\\n['abe', 'abd', 'abc']\\nNotice the last example here—we can convert to lowercase prior to the sort with a list\\ncomprehension, but the result does not contain the original list’s values as it does with\\nthe key argument. The latter is applied temporarily during the sort, instead of changing\\nthe values to be sorted. As we move along, we’ll see contexts in which the sorted built-\\nin can sometimes be more useful than the sort method.\\nLike strings, lists have other methods that perform other specialized operations. For\\ninstance, reverse reverses the list in-place, and the extend and pop methods insert mul-\\ntiple items at the end of and delete an item from the end of the list, respectively. There\\nis also a reversed built-in function that works much like sorted, but it must be wrapped\\nin a list call because it’s an iterator (more on iterators later):\\n>>> L = [1, 2]\\n>>> L.extend([3,4,5])                # Add many items at end\\n>>> L\\n[1, 2, 3, 4, 5]\\n>>> L.pop()                          # Delete and return last item\\n5\\n>>> L\\n[1, 2, 3, 4]\\n>>> L.reverse()                      # In-place reversal method\\n>>> L\\n[4, 3, 2, 1]\\n>>> list(reversed(L))                # Reversal built-in with a result\\n[1, 2, 3, 4]\\nIn some types of programs, the list pop method used here is often used in conjunction\\nwith append to implement a quick last-in-first-out (LIFO) stack structure. The end of\\nthe list serves as the top of the stack:\\n>>> L = []\\n>>> L.append(1)                      # Push onto stack\\n>>> L.append(2)\\n>>> L\\n[1, 2]\\n>>> L.pop()                          # Pop off stack\\n2\\n>>> L\\n[1]\\nLists in Action | 205\", metadata={'source': 'python.pdf', 'page': 255}),\n",
       " Document(page_content=\"The pop method also accepts an optional offset of the item to be deleted and returned\\n(the default \\nis the last item). Other list methods remove an item by value ( remove), insert\\nan item at an offset (insert), search for an item’s offset (index), and more:\\n>>> L = ['spam', 'eggs', 'ham']\\n>>> L.index('eggs')                  # Index of an object\\n1\\n>>> L.insert(1, 'toast')             # Insert at position\\n>>> L\\n['spam', 'toast', 'eggs', 'ham']\\n>>> L.remove('eggs')                 # Delete by value\\n>>> L\\n['spam', 'toast', 'ham']\\n>>> L.pop(1)                         # Delete by position\\n'toast'\\n>>> L\\n['spam', 'ham']\\nSee other documentation sources or experiment with these calls interactively on your\\nown to learn more about list methods.\\nOther common list operations\\nBecause lists are mutable, you can use the del statement to delete an item or section\\nin-place:\\n>>> L\\n['SPAM!', 'eat', 'more', 'please']\\n>>> del L[0]                         # Delete one item\\n>>> L\\n['eat', 'more', 'please']\\n>>> del L[1:]                        # Delete an entire section\\n>>> L                                # Same as L[1:] = []\\n['eat']\\nBecause slice assignment is a deletion plus an insertion, you can also delete a section\\nof a list by assigning an empty list to a slice ( L[i:j]=[]); Python deletes the slice named\\non the left, and then inserts nothing. Assigning an empty list to an index, on the other\\nhand, just stores a reference to the empty list in the specified slot, rather than deleting\\nit:\\n>>> L = ['Already', 'got', 'one']\\n>>> L[1:] = []\\n>>> L\\n['Already']\\n>>> L[0] = []\\n>>> L\\n[[]]\\nAlthough all the operations just discussed are typical, there are additional list methods\\nand operations not illustrated here (including methods for inserting and searching).\\nFor a comprehensive and up-to-date list of type tools, you should always consult\\n206 | Chapter 8: \\u2002Lists and Dictionaries\", metadata={'source': 'python.pdf', 'page': 256}),\n",
       " Document(page_content='Python’s manuals, Python’s dir and help functions (which we first met in Chapter 4 ),\\nor one of the reference texts mentioned in the Preface.\\nI’d also like to remind you one more time that all the in-place change operations dis-\\ncussed here work only for mutable objects: they won’t work on strings (or tuples, dis-\\ncussed in Chapter 9 ), no matter how hard you try. Mutability is an inherent property\\nof each object type.\\nDictionaries\\nApart from lists, dictionaries are perhaps the most flexible built-in data type in Python.\\nIf you think of lists as ordered collections of objects, you can think of dictionaries as\\nunordered collections; the chief distinction is that in dictionaries, items are stored and\\nfetched by key, instead of by positional offset.\\nBeing a built-in type, dictionaries can replace many of the searching algorithms and\\ndata structures you might have to implement manually in lower-level languages—\\nindexing a dictionary is a very fast search operation. Dictionaries also sometimes do\\nthe work of records and symbol tables used in other languages, can represent sparse\\n(mostly empty) data structures, and much more. Here’s a rundown of their main prop-\\nerties. Python dictionaries are:\\nAccessed by key, not offset\\nDictionaries are sometimes called associative arrays or hashes. They associate a set\\nof values with keys, so you can fetch an item out of a dictionary using the key under\\nwhich you originally stored it. You use the same indexing operation to get com-\\nponents in a dictionary as you do in a list, but the index takes the form of a key,\\nnot a relative offset.\\nUnordered collections of arbitrary objects\\nUnlike in a list, items stored in a dictionary aren’t kept in any particular order; in\\nfact, Python randomizes their left-to-right order to provide quick lookup. Keys\\nprovide the symbolic (not physical) locations of items in a dictionary.\\nVariable-length, heterogeneous, and arbitrarily nestable\\nLike lists, dictionaries can grow and shrink in-place (without new copies being\\nmade), they can contain objects of any type, and they support nesting to any depth\\n(they can contain lists, other dictionaries, and so on).\\nOf the category “mutable mapping”\\nDictionaries can be changed in-place by assigning to indexes (they are mutable),\\nbut they don’t support the sequence operations that work on strings and lists.\\nBecause dictionaries are unordered collections, operations that depend on a fixed\\npositional order (e.g., concatenation, slicing) don’t make sense. Instead, diction-\\naries are the only built-in representatives of the mapping type category (objects\\nthat map keys to values).\\nDictionaries | 207', metadata={'source': 'python.pdf', 'page': 257}),\n",
       " Document(page_content=\"Tables of object references (hash tables)\\nIf lists are arrays of \\nobject references that support access by position, dictionaries\\nare unordered tables of object references that support access by key. Internally,\\ndictionaries are implemented as hash tables (data structures that support very fast\\nretrieval), which start small and grow on demand. Moreover, Python employs op-\\ntimized hashing algorithms to find keys, so retrieval is quick. Like lists, dictionaries\\nstore object references (not copies).\\nTable 8-2  summarizes some of the most common and representative dictionary oper-\\nations (again, see the library manual or run a dir(dict) or help(dict) call for a complete\\nlist—dict is the name of the type). When coded as a literal expression, a dictionary is\\nwritten as a series of key:value pairs, separated by commas, enclosed in curly\\nbraces.§ An empty dictionary is an empty set of braces, and dictionaries can be nested\\nby writing one as a value inside another dictionary, or within a list or tuple.\\nTable 8-2. Common dictionary literals and operations\\nOperation Interpretation\\nD = {} Empty dictionary\\nD = {'spam': 2, 'eggs': 3} Two-item dictionary\\nD = {'food': {'ham': 1, 'egg': 2}} Nesting\\nD = dict(name='Bob', age=40)\\nD = dict(zip(keyslist, valslist))\\nD = dict.fromkeys(['a', 'b'])Alternative construction techniques:\\nkeywords, zipped pairs, key lists\\nD['eggs']\\nD['food']['ham']Indexing by key\\n'eggs' in D Membership: key present test\\nD.keys()\\nD.values()\\nD.items()\\nD.copy()\\nD.get(key, default)\\nD.update(D2)\\nD.pop(key)Methods: keys,\\nvalues,\\nkeys+values,\\ncopies,\\ndefaults,\\nmerge,\\ndelete, etc.\\nlen(D) Length: number of stored entries\\nD[key] = 42 Adding/changing keys\\n§ As with lists, you won’t often see dictionaries constructed using literals. Lists and dictionaries are grown in\\ndifferent ways, \\nthough. As you’ll see in the next section, dictionaries are typically built up by assigning to\\nnew keys at runtime; this approach fails for lists (lists are commonly grown with append instead).\\n208 | Chapter 8: \\u2002Lists and Dictionaries\", metadata={'source': 'python.pdf', 'page': 258}),\n",
       " Document(page_content=\"Operation Interpretation\\ndel D[key] Deleting entries by key\\nlist(D.keys())\\nD1.keys() & D2.keys()Dictionary views (Python 3.0)\\nD = {x: x*2 for x in range(10)} Dictionary comprehensions (Python 3.0)\\nDictionaries in Action\\nAs Table 8-2 \\nsuggests, dictionaries are indexed by key, and nested dictionary entries\\nare referenced by a series of indexes (keys in square brackets). When Python creates a\\ndictionary, it stores its items in any left-to-right order it chooses; to fetch a value back,\\nyou supply the key with which it is associated, not its relative position. Let’s go back\\nto the interpreter to get a feel for some of the dictionary operations in Table 8-2.\\nBasic Dictionary Operations\\nIn normal operation, you create dictionaries with literals and store and access items by\\nkey with indexing:\\n% python\\n>>> D = {'spam': 2, 'ham': 1, 'eggs': 3}      # Make a dictionary\\n>>> D['spam']                                 # Fetch a value by key\\n2\\n>>> D                                         # Order is scrambled\\n{'eggs': 3, 'ham': 1, 'spam': 2}\\nHere, the dictionary is assigned to the variable D; the value of the key 'spam' is the\\ninteger 2, and so on. We use the same square bracket syntax to index dictionaries by\\nkey as we did to index lists by offset, but here it means access by key, not by position.\\nNotice the end of this example: the left-to-right order of keys in a dictionary will almost\\nalways be different from what you originally typed. This is on purpose: to implement\\nfast key lookup (a.k.a. hashing), keys need to be reordered in memory. That’s why\\noperations that assume a fixed left-to-right order (e.g., slicing, concatenation) do not\\napply to dictionaries; you can fetch values only by key, not by position.\\nThe built-in len function works on dictionaries, too; it returns the number of items\\nstored in the dictionary or, equivalently, the length of its keys list. The dictionary in\\nmembership operator allows you to test for key existence, and the keys method returns\\nall the keys in the dictionary. The latter of these can be useful for processing dictionaries\\nsequentially, but you shouldn’t depend on the order of the keys list. Because the keys\\nresult can be used as a normal list, however, it can always be sorted if order matters\\n(more on sorting and dictionaries later):\\n>>> len(D)                                    # Number of entries in dictionary\\n3\\n>>> 'ham' in D                                # Key membership test alternative\\nDictionaries in Action | 209\", metadata={'source': 'python.pdf', 'page': 259}),\n",
       " Document(page_content=\"True\\n>>> list(D.keys())                            # Create a new list of my keys\\n['eggs', 'ham', 'spam']\\nNotice the second \\nexpression in this listing. As mentioned earlier, the in membership\\ntest used for strings and lists also works on dictionaries—it checks whether a key is\\nstored in the dictionary. Technically, this works because dictionaries define iterators\\nthat step through their keys lists. Other types provide iterators that reflect their\\ncommon uses; files, for example, have iterators that read line by line. We’ll discuss\\niterators in Chapters 14 and 20.\\nAlso note the syntax of the last example in this listing. We have to enclose it in a list\\ncall in Python 3.0 for similar reasons— keys in 3.0 returns an iterator, instead of a\\nphysical list. The list call forces it to produce all its values at once so we can print\\nthem. In 2.6, keys builds and returns an actual list, so the list call isn’t needed to\\ndisplay results. More on this later in this chapter.\\nThe order of keys in a dictionary is arbitrary and can change from release\\nto release, so \\ndon’t be alarmed if your dictionaries print in a different\\norder than shown here. In fact, the order has changed for me too—I’m\\nrunning all these examples with Python 3.0, but their keys had a differ-\\nent order in an earlier edition when displayed. You shouldn’t depend\\non dictionary key ordering, in either programs or books!\\nChanging Dictionaries In-Place\\nLet’s continue with our interactive session. Dictionaries, like lists, are mutable, so you\\ncan change, expand, and shrink them in-place without making new dictionaries: simply\\nassign a value to a key to change or create an entry. The del statement works here, too;\\nit deletes the entry associated with the key specified as an index. Notice also the nesting\\nof a list inside a dictionary in this example (the value of the key 'ham'). All collection\\ndata types in Python can nest inside each other arbitrarily:\\n>>> D\\n{'eggs': 3, 'ham': 1, 'spam': 2}\\n>>> D['ham'] = ['grill', 'bake', 'fry']           # Change entry\\n>>> D\\n{'eggs': 3, 'ham': ['grill', 'bake', 'fry'], 'spam': 2}\\n>>> del D['eggs']                                 # Delete entry\\n>>> D\\n{'ham': ['grill', 'bake', 'fry'], 'spam': 2}\\n>>> D['brunch'] = 'Bacon'                         # Add new entry\\n>>> D\\n{'brunch': 'Bacon', 'ham': ['grill', 'bake', 'fry'], 'spam': 2}\\n210 | Chapter 8: \\u2002Lists and Dictionaries\", metadata={'source': 'python.pdf', 'page': 260}),\n",
       " Document(page_content=\"As with lists, assigning to an existing index in a dictionary changes its associated value.\\nUnlike with lists, \\nhowever, whenever you assign a new dictionary key (one that hasn’t\\nbeen assigned before) you create a new entry in the dictionary, as was done in the\\nprevious example for the key 'brunch'. This doesn’t work for lists because Python\\nconsiders an offset beyond the end of a list out of bounds and throws an error. To\\nexpand a list, you need to use tools such as the append method or slice assignment\\ninstead.\\nMore Dictionary Methods\\nDictionary methods provide a variety of tools. For instance, the dictionary values and\\nitems methods return the dictionary’s values and (key,value) pair tuples, respectively\\n(as with keys, wrap them in a list call in Python 3.0 to collect their values for display):\\n>>> D = {'spam': 2, 'ham': 1, 'eggs': 3}\\n>>> list(D.values())\\n[3, 1, 2]\\n>>> list(D.items())\\n [('eggs', 3), ('ham', 1), ('spam', 2)]\\nSuch lists are useful in loops that need to step through dictionary entries one by one.\\nFetching a nonexistent key is normally an error, but the get method returns a default\\nvalue (None, or a passed-in default) if the key doesn’t exist. It’s an easy way to fill in a\\ndefault for a key that isn’t present and avoid a missing-key error:\\n>>> D.get('spam')                          # A key that is there\\n2\\n>>> print(D.get('toast'))                  # A key that is missing\\nNone\\n>>> D.get('toast', 88)\\n88\\nThe update method provides something similar to concatenation for dictionaries,\\nthough it has nothing to do with left-to-right ordering (again, there is no such thing in\\ndictionaries). It merges the keys and values of one dictionary into another, blindly\\noverwriting values of the same key:\\n>>> D\\n{'eggs': 3, 'ham': 1, 'spam': 2}\\n>>> D2 = {'toast':4, 'muffin':5}\\n>>> D.update(D2)\\n>>> D\\n{'toast': 4, 'muffin': 5, 'eggs': 3, 'ham': 1, 'spam': 2}\\nFinally, the dictionary pop method deletes a key from a dictionary and returns the value\\nit had. It’s similar to the list pop method, but it takes a key instead of an optional\\nposition:\\n# pop a dictionary by key\\n>>> D\\n{'toast': 4, 'muffin': 5, 'eggs': 3, 'ham': 1, 'spam': 2}\\n>>> D.pop('muffin')\\nDictionaries in Action | 211\", metadata={'source': 'python.pdf', 'page': 261}),\n",
       " Document(page_content=\"5\\n>>> D.pop('toast')                         # Delete and return from a key\\n4\\n>>> D\\n{'eggs': 3, 'ham': 1, 'spam': 2}\\n# pop a list by position\\n>>> L = ['aa', 'bb', 'cc', 'dd']\\n>>> L.pop()                                # Delete and return from the end\\n'dd'\\n>>> L\\n['aa', 'bb', 'cc']\\n>>> L.pop(1)                               # Delete from a specific position\\n'bb'\\n>>> L\\n['aa', 'cc']\\nDictionaries also provide \\na copy method; we’ll discuss this in Chapter 9 , as it’s a way\\nto avoid the potential side effects of shared references to the same dictionary. In fact,\\ndictionaries come with many more methods than those listed in Table 8-2; see the\\nPython library manual or other documentation sources for a comprehensive list.\\nA Languages Table\\nLet’s look at a more realistic dictionary example. The following example creates a table\\nthat maps programming language names (the keys) to their creators (the values). You\\nfetch creator names by indexing on language names:\\n>>> table = {'Python':  'Guido van Rossum',\\n...          'Perl':    'Larry Wall',\\n...          'Tcl':     'John Ousterhout' }\\n>>>\\n>>> language = 'Python'\\n>>> creator  = table[language]\\n>>> creator\\n'Guido van Rossum'\\n>>> for lang in table:                     # Same as: for lang in table.keys()\\n...     print(lang, '\\\\t', table[lang])\\n...\\nTcl     John Ousterhout\\nPython  Guido van Rossum\\nPerl    Larry Wall\\nThe last command uses a for loop, which we haven’t covered in detail yet. If you aren’t\\nfamiliar with for loops, this command simply iterates through each key in the table\\nand prints a tab-separated list of keys and their values. We’ll learn more about for loops\\nin Chapter 13.\\nDictionaries aren’t sequences like lists and strings, but if you need to step through the\\nitems in a dictionary, it’s easy—calling the dictionary keys method returns all stored\\n212 | Chapter 8: \\u2002Lists and Dictionaries\", metadata={'source': 'python.pdf', 'page': 262}),\n",
       " Document(page_content='keys, which you can iterate through with a for. If needed, you can index from key to\\nvalue inside the for loop, as was done in this code.\\nIn fact, Python also lets you step through a dictionary’s keys list without actually calling\\nthe keys method in most for loops. For any dictionary D, saying for key in D: works\\nthe same as saying the complete for key in D.keys():. This is really just another in-\\nstance of the iterators mentioned earlier, which allow the in membership operator to\\nwork on dictionaries as well (more on iterators later in this book).\\nDictionary Usage Notes\\nDictionaries are fairly straightforward tools once you get the hang of them, but here\\nare a few additional pointers and reminders you should be aware of when using them:\\n•Sequence operations don’t work . Dictionaries are mappings, not sequences; be-\\ncause there’s no notion of ordering among their items, things like concatenation\\n(an ordered joining) and slicing (extracting a contiguous section) simply don’t ap-\\nply. In fact, Python raises an error when your code runs if you try to do such things.\\n•Assigning to new indexes adds entries . Keys can be created when you write a\\ndictionary literal (in which case they are embedded in the literal itself), or when\\nyou assign values to new keys of an existing dictionary object. The end result is the\\nsame.\\n•Keys need not always be strings . Our examples so far have used strings as keys,\\nbut any other immutable objects (i.e., not lists) work just as well. For instance, you\\ncan use integers as keys, which makes the dictionary look much like a list (when\\nindexing, at least). Tuples are sometimes used as dictionary keys too, allowing for\\ncompound key values. Class instance objects (discussed in Part VI ) can also be used\\nas keys, as long as they have the proper protocol methods; roughly, they need to\\ntell Python that their values are hashable and won’t change, as otherwise they\\nwould be useless as fixed keys.\\nUsing dictionaries to simulate flexible lists\\nThe last point in the prior list is important enough to demonstrate with a few examples.\\nWhen you use lists, it is illegal to assign to an offset that is off the end of the list:\\n>>> L = []\\n>>> L[99] = \\'spam\\'\\nTraceback (most recent call last):\\n  File \"<stdin>\", line 1, in ?\\nIndexError: list assignment index out of range\\nAlthough you can use repetition to preallocate as big a list as you’ll need (e.g.,\\n[0]*100), you can also do something that looks similar with dictionaries that does not\\nrequire such space allocations. By using integer keys, dictionaries can emulate lists that\\nseem to grow on offset assignment:\\nDictionaries in Action | 213', metadata={'source': 'python.pdf', 'page': 263}),\n",
       " Document(page_content='>>> D = {}\\n>>> D[99] = \\'spam\\'\\n>>> D[99]\\n\\'spam\\'\\n>>> D\\n{99: \\'spam\\'}\\nHere, it looks \\nas if D is a 100-item list, but it’s really a dictionary with a single entry; the\\nvalue of the key 99 is the string \\'spam\\'. You can access this structure with offsets much\\nlike a list, but you don’t have to allocate space for all the positions you might ever need\\nto assign values to in the future. When used like this, dictionaries are like more flexible\\nequivalents of lists.\\nUsing dictionaries for sparse data structures\\nIn a similar way, dictionary keys are also commonly leveraged to implement sparse data\\nstructures—for example, multidimensional arrays where only a few positions have val-\\nues stored in them:\\n>>> Matrix = {}\\n>>> Matrix[(2, 3, 4)] = 88\\n>>> Matrix[(7, 8, 9)] = 99\\n>>>\\n>>> X = 2; Y = 3; Z = 4           # ; separates statements\\n>>> Matrix[(X, Y, Z)]\\n88\\n>>> Matrix\\n{(2, 3, 4): 88, (7, 8, 9): 99}\\nHere, we’ve used a dictionary to represent a three-dimensional array that is empty\\nexcept for the two positions (2,3,4) and (7,8,9). The keys are tuples that record the\\ncoordinates of nonempty slots. Rather than allocating a large and mostly empty three-\\ndimensional matrix to hold these values, we can use a simple two-item dictionary. In\\nthis scheme, accessing an empty slot triggers a nonexistent key exception, as these slots\\nare not physically stored:\\n>>> Matrix[(2,3,6)]\\nTraceback (most recent call last):\\n  File \"<stdin>\", line 1, in ?\\nKeyError: (2, 3, 6)\\nAvoiding missing-key errors\\nErrors for nonexistent key fetches are common in sparse matrixes, but you probably\\nwon’t want them to shut down your program. There are at least three ways to fill in a\\ndefault value instead of getting such an error message—you can test for keys ahead of\\ntime in if statements, use a try statement to catch and recover from the exception\\nexplicitly, or simply use the dictionary get method shown earlier to provide a default\\nfor keys that do not exist:\\n>>> if (2,3,6) in Matrix:              # Check for key before fetch\\n...     print(Matrix[(2,3,6)])         # See Chapter 12 for if/else\\n214 | Chapter 8: \\u2002Lists and Dictionaries', metadata={'source': 'python.pdf', 'page': 264}),\n",
       " Document(page_content=\"... else:\\n...     print(0)\\n...\\n0\\n>>> try:\\n...     print(Matrix[(2,3,6)])         # Try to index\\n... except KeyError:                   # Catch and recover\\n...     print(0)                       # See Chapter 33 for try/except\\n...\\n0\\n>>> Matrix.get((2,3,4), 0)             # Exists; fetch and return\\n88\\n>>> Matrix.get((2,3,6), 0)             # Doesn't exist; use default arg\\n0\\nOf these, the get\\n method is the most concise in terms of coding requirements; we’ll\\nstudy the if and try statements in more detail later in this book.\\nUsing dictionaries as “records”\\nAs you can see, dictionaries can play many roles in Python. In general, they can replace\\nsearch data structures (because indexing by key is a search operation) and can represent\\nmany types of structured information. For example, dictionaries are one of many ways\\nto describe the properties of an item in your program’s domain; that is, they can serve\\nthe same role as “records” or “structs” in other languages.\\nThe following, for example, fills out a dictionary by assigning to new keys over time:\\n>>> rec = {}\\n>>> rec['name'] = 'mel'\\n>>> rec['age']  = 45\\n>>> rec['job']  = 'trainer/writer'\\n>>>\\n>>> print(rec['name'])\\nmel\\nEspecially when nested, Python’s built-in data types allow us to easily represent struc-\\ntured information. This example again uses a dictionary to capture object properties,\\nbut it codes it all at once (rather than assigning to each key separately) and nests a list\\nand a dictionary to represent structured property values:\\n>>> mel = {'name': 'Mark',\\n...        'jobs': ['trainer', 'writer'],\\n...        'web':  'www.rmi.net/˜lutz',\\n...        'home': {'state': 'CO', 'zip':80513}}\\nTo fetch components of nested objects, simply string together indexing operations:\\n>>> mel['name']\\n'Mark'\\n>>> mel['jobs']\\n['trainer', 'writer']\\n>>> mel['jobs'][1]\\n'writer'\\nDictionaries in Action | 215\", metadata={'source': 'python.pdf', 'page': 265}),\n",
       " Document(page_content='>>> mel[\\'home\\'][\\'zip\\']\\n80513\\nAlthough we’ll learn \\nin Part VI  that classes (which group both data and logic) can be\\nbetter in this record role, dictionaries are an easy-to-use tool for simpler requirements.\\nWhy You Will Care: Dictionary Interfaces\\nDictionaries aren’t just \\na convenient way to store information by key in your\\nprograms—some Python extensions also present interfaces that look like and work the\\nsame as dictionaries. For instance, Python’s interface to DBM access-by-key files looks\\nmuch like a dictionary that must be opened. Strings are stored and fetched using key\\nindexes:\\nimport anydbm\\nfile = anydbm.open(\"filename\") # Link to file\\nfile[\\'key\\'] = \\'data\\'           # Store data by key\\ndata = file[\\'key\\']             # Fetch data by key\\nIn Chapter 27 , you’ll see that you can store entire Python objects this way, too, if you\\nreplace anydbm in the preceding code with shelve (shelves are access-by-key databases\\nof persistent Python objects). For Internet work, Python’s CGI script support also\\npresents a dictionary-like interface. A call to cgi.FieldStorage yields a dictionary-like\\nobject with one entry per input field on the client’s web page:\\nimport cgi\\nform = cgi.FieldStorage()      # Parse form data\\nif \\'name\\' in form:\\n    showReply(\\'Hello, \\' + form[\\'name\\'].value)\\nAll of these, like dictionaries, are instances of mappings. Once you learn dictionary\\ninterfaces, you’ll find that they apply to a variety of built-in tools in Python.\\nOther Ways to Make Dictionaries\\nFinally, note that \\nbecause dictionaries are so useful, more ways to build them have\\nemerged over time. In Python 2.3 and later, for example, the last two calls to the dict\\nconstructor (really, type name) shown here have the same effect as the literal and key-\\nassignment forms above them:\\n{\\'name\\': \\'mel\\', \\'age\\': 45}             # Traditional literal expression\\nD = {}                                 # Assign by keys dynamically\\nD[\\'name\\'] = \\'mel\\'\\nD[\\'age\\']  = 45\\ndict(name=\\'mel\\', age=45)               # dict keyword argument form\\ndict([(\\'name\\', \\'mel\\'), (\\'age\\', 45)])   # dict key/value tuples form\\nAll four of these forms create the same two-key dictionary, but they are useful in dif-\\nfering circumstances:\\n216 | Chapter 8: \\u2002Lists and Dictionaries', metadata={'source': 'python.pdf', 'page': 266}),\n",
       " Document(page_content=\"• The first is handy if you can spell out the entire dictionary ahead of time.\\n• The second is of use if you need to create the dictionary one field at a time on the\\nfly.\\n• The third involves less typing than the first, but it requires all keys to be strings.\\n•\\nThe last is useful if you need to build up keys and values as sequences at runtime.\\nWe met keyword arguments earlier when sorting; the third form illustrated in this code\\nlisting has become especially popular in Python code today, since it has less syntax (and\\nhence there is less opportunity for mistakes). As suggested previously in Table 8-2 , the\\nlast form in the listing is also commonly used in conjunction with the zip function, to\\ncombine separate lists of keys and values obtained dynamically at runtime (parsed out\\nof a data file’s columns, for instance). More on this option in the next section.\\nProvided all the key’s values are the same initially, you can also create a dictionary with\\nthis special form—simply pass in a list of keys and an initial value for all of the values\\n(the default is None):\\n>>> dict.fromkeys(['a', 'b'], 0)\\n{'a': 0, 'b': 0}\\nAlthough you could get by with just literals and key assignments at this point in your\\nPython career, you’ll probably find uses for all of these dictionary-creation forms as\\nyou start applying them in realistic, flexible, and dynamic Python programs.\\nThe listings in this section document the various ways to create dictionaries in both\\nPython 2.6 and 3.0. However, there is yet another way to create dictionaries, available\\nonly in Python 3.0 (and later): the dictionary comprehension  expression. To see how\\nthis last form looks, we need to move on to the next section.\\nDictionary Changes in Python 3.0\\nThis chapter has so far focused on dictionary basics that span releases, but the dic-\\ntionary’s functionality has mutated in Python 3.0. If you are using Python 2.X code,\\nyou may come across some dictionary tools that either behave differently or are missing\\naltogether in 3.0. Moreover, 3.0 coders have access to additional dictionary tools not\\navailable in 2.X. Specifically, dictionaries in 3.0:\\n• Support a new dictionary comprehension expression, a close cousin to list and set\\ncomprehensions\\n• Return iterable views instead of lists for the methods D.keys, D.values, and D.items\\n• Require new coding styles for scanning by sorted keys, because of the prior point\\n• No longer support relative magnitude comparisons directly—compare manually\\ninstead\\n• No longer have the D.has_key method—the in membership test is used instead\\nLet’s take a look at what’s new in 3.0 dictionaries.\\nDictionaries in Action | 217\", metadata={'source': 'python.pdf', 'page': 267}),\n",
       " Document(page_content=\"Dictionary comprehensions\\nAs mentioned at \\nthe end of the prior section, dictionaries in 3.0 can also be created\\nwith dictionary comprehensions. Like the set comprehensions we met in Chapter 5,\\ndictionary comprehensions are available only in 3.0 (not in 2.6). Like the longstanding\\nlist comprehensions we met briefly in Chapter 4  and earlier in this chapter, they run an\\nimplied loop, collecting the key/value results of expressions on each iteration and using\\nthem to fill out a new dictionary. A loop variable allows the comprehension to use loop\\niteration values along the way.\\nFor example, a standard way to initialize a dictionary dynamically in both 2.6 and 3.0\\nis to zip together its keys and values and pass the result to the dict call. As we’ll learn\\nin more detail in Chapter 13 , the zip function is a way to construct a dictionary from\\nkey and value lists in a single call. If you cannot predict the set of keys and values in\\nyour code, you can always build them up as lists and zip them together:\\n>>> list(zip(['a', 'b', 'c'], [1, 2, 3]))        # Zip together keys and values\\n[('a', 1), ('b', 2), ('c', 3)]\\n>>> D = dict(zip(['a', 'b', 'c'], [1, 2, 3]))    # Make a dict from zip result\\n>>> D\\n{'a': 1, 'c': 3, 'b': 2}\\nIn Python 3.0, you can achieve the same effect with a dictionary comprehension ex-\\npression. The following builds a new dictionary with a key/value pair for every such\\npair in the zip result (it reads almost the same in Python, but with a bit more formality):\\nC:\\\\misc> c:\\\\python30\\\\python                      # Use a dict comprehension\\n>>> D = {k: v for (k, v) in zip(['a', 'b', 'c'], [1, 2, 3])}\\n>>> D\\n{'a': 1, 'c': 3, 'b': 2}\\nComprehensions actually require more code in this case, but they are also more general\\nthan this example implies—we can use them to map a single stream of values to dic-\\ntionaries as well, and keys can be computed with expressions just like values:\\n>>> D = {x: x ** 2 for x in [1, 2, 3, 4]}        # Or: range(1, 5)\\n>>> D\\n{1: 1, 2: 4, 3: 9, 4: 16}\\n>>> D = {c: c * 4 for c in 'SPAM'}               # Loop over any iterable\\n>>> D\\n{'A': 'AAAA', 'P': 'PPPP', 'S': 'SSSS', 'M': 'MMMM'}\\n>>> D = {c.lower(): c + '!' for c in ['SPAM', 'EGGS', 'HAM']}\\n>>> D\\n{'eggs': 'EGGS!', 'ham': 'HAM!', 'spam': 'SPAM!'}\\nDictionary comprehensions are also useful for initializing dictionaries from keys lists,\\nin much the same way as the fromkeys method we met at the end of the preceding\\nsection:\\n218 | Chapter 8: \\u2002Lists and Dictionaries\", metadata={'source': 'python.pdf', 'page': 268}),\n",
       " Document(page_content=\">>> D = dict.fromkeys(['a', 'b', 'c'], 0)        # Initialize dict from keys\\n>>> D\\n{'a': 0, 'c': 0, 'b': 0}\\n>>> D = {k:0 for k in ['a', 'b', 'c']}           # Same, but with a comprehension\\n>>> D\\n{'a': 0, 'c': 0, 'b': 0}\\n>>> D = dict.fromkeys('spam')                    # Other iterators, default value\\n>>> D\\n{'a': None, 'p': None, 's': None, 'm': None}\\n>>> D = {k: None for k in 'spam'}\\n>>> D\\n{'a': None, 'p': None, 's': None, 'm': None}\\nLike related tools, \\ndictionary comprehensions support additional syntax not shown\\nhere, including nested loops and if clauses. Unfortunately, to truly understand dic-\\ntionary comprehensions, we need to also know more about iteration statements and\\nconcepts in Python, and we don’t yet have enough information to address that story\\nwell. We’ll learn much more about all flavors of comprehensions (list, set, and dic-\\ntionary) in Chapters 14 and 20, so we’ll defer further details until later. We’ll also study\\nthe zip built-in we used in this section in more detail in Chapter 13 , when we explore\\nfor loops.\\nDictionary views\\nIn 3.0 the dictionary keys, values, and items methods all return view objects , whereas\\nin 2.6 they return actual result lists. View objects are iterables, which simply means\\nobjects that generate result items one at a time, instead of producing the result list all\\nat once in memory. Besides being iterable, dictionary views also retain the original order\\nof dictionary components, reflect future changes to the dictionary, and may support\\nset operations. On the other hand, they are not lists, and they do not support operations\\nlike indexing or the list sort method; nor do they display their items when printed.\\nWe’ll discuss the notion of iterables more formally in Chapter 14 , but for our purposes\\nhere it’s enough to know that we have to run the results of these three methods through\\nthe list built-in if we want to apply list operations or display their values:\\n>>> D = dict(a=1, b=2, c=3)\\n>>> D\\n{'a': 1, 'c': 3, 'b': 2}\\n>>> K = D.keys()                   # Makes a view object in 3.0, not a list\\n>>> K\\n<dict_keys object at 0x026D83C0>\\n>>> list(K)                        # Force a real list in 3.0 if needed\\n['a', 'c', 'b']\\n>>> V = D.values()                 # Ditto for values and items views\\n>>> V\\n<dict_values object at 0x026D8260>\\nDictionaries in Action | 219\", metadata={'source': 'python.pdf', 'page': 269}),\n",
       " Document(page_content=\">>> list(V)\\n[1, 3, 2]\\n>>> list(D.items())\\n[('a', 1), ('c', 3), ('b', 2)]\\n>>> K[0]                           # List operations fail unless converted\\nTypeError: 'dict_keys' object does not support indexing\\n>>> list(K)[0]\\n'a'\\nApart from when \\ndisplaying results at the interactive prompt, you will probably rarely\\neven notice this change, because looping constructs in Python automatically force\\niterable objects to produce one result on each iteration:\\n>>> for k in D.keys(): print(k)    # Iterators used automatically in loops\\n...\\na\\nc\\nb\\nIn addition, 3.0 dictionaries still have iterators themselves, which return successive\\nkeys—as in 2.6, it’s still often not necessary to call keys directly:\\n>>> for key in D: print(key)       # Still no need to call keys() to iterate\\n...\\na\\nc\\nb\\nUnlike 2.X’s list results, though, dictionary views in 3.0 are not carved in stone when\\ncreated—they dynamically reflect future changes  made to the dictionary after the view\\nobject has been created:\\n>>> D = {'a':1, 'b':2, 'c':3}\\n>>> D\\n{'a': 1, 'c': 3, 'b': 2}\\n>>> K = D.keys()\\n>>> V = D.values()\\n>>> list(K)                        # Views maintain same order as dictionary\\n['a', 'c', 'b']\\n>>> list(V)\\n[1, 3, 2]\\n>>> del D['b']                     # Change the dictionary in-place\\n>>> D\\n{'a': 1, 'c': 3}\\n>>> list(K)                        # Reflected in any current view objects\\n['a', 'c']\\n>>> list(V)                        # Not true in 2.X!\\n[1, 3]\\n220 | Chapter 8: \\u2002Lists and Dictionaries\", metadata={'source': 'python.pdf', 'page': 270}),\n",
       " Document(page_content=\"Dictionary views and sets\\nAlso unlike 2.X’s \\nlist results, 3.0’s view objects returned by the keys method are set-\\nlike and support common set operations such as intersection and union; values views\\nare not, since they aren’t unique, but items results are if their (key, value) pairs are\\nunique and hashable. Given that sets behave much like valueless dictionaries (and are\\neven coded in curly braces like dictionaries in 3.0), this is a logical symmetry. Like\\ndictionary keys, set items are unordered, unique, and immutable.\\nHere is what keys lists look like when used in set operations. In set operations, views\\nmay be mixed with other views, sets, and dictionaries (dictionaries are treated the same\\nas their keys views in this context):\\n>>> K | {'x': 4}                   # Keys (and some items) views are set-like\\n{'a', 'x', 'c'}\\n>>> V & {'x': 4}\\nTypeError: unsupported operand type(s) for &: 'dict_values' and 'dict'\\n>>> V & {'x': 4}.values()\\nTypeError: unsupported operand type(s) for &: 'dict_values' and 'dict_values'\\n>>> D = {'a':1, 'b':2, 'c':3}\\n>>> D.keys() & D.keys()            # Intersect keys views\\n{'a', 'c', 'b'}\\n>>> D.keys() & {'b'}               # Intersect keys and set\\n{'b'}\\n>>> D.keys() & {'b': 1}            # Intersect keys and dict\\n{'b'}\\n>>> D.keys() | {'b', 'c', 'd'}     # Union keys and set\\n{'a', 'c', 'b', 'd'}\\nDictionary items views are set-like too if they are hashable—that is, if they contain only\\nimmutable objects:\\n>>> D = {'a': 1}\\n>>> list(D.items())                # Items set-like if hashable\\n[('a', 1)]\\n>>> D.items() | D.keys()           # Union view and view\\n{('a', 1), 'a'}\\n>>> D.items() | D                  # dict treated same as its keys\\n{('a', 1), 'a'}\\n>>> D.items() | {('c', 3), ('d', 4)}           # Set of key/value pairs\\n{('a', 1), ('d', 4), ('c', 3)}\\n>>> dict(D.items() | {('c', 3), ('d', 4)})     # dict accepts iterable sets too\\n{'a': 1, 'c': 3, 'd': 4}\\nFor more details on set operations in general, see Chapter 5 . Now, let’s look at three\\nother quick coding notes for 3.0 dictionaries.\\nDictionaries in Action | 221\", metadata={'source': 'python.pdf', 'page': 271}),\n",
       " Document(page_content=\"Sorting dictionary keys\\nFirst of all, because keys \\ndoes not return a list, the traditional coding pattern for scan-\\nning a dictionary by sorted keys in 2.X won’t work in 3.0. You must either convert to\\na list manually or use the sorted call introduced in Chapter 4  and earlier in this chapter\\non either a keys view or the dictionary itself:\\n>>> D = {'a':1, 'b':2, 'c':3}\\n>>> D\\n{'a': 1, 'c': 3, 'b': 2}\\n>>> Ks = D.keys()                            # Sorting a view object doesn't work!\\n>>> Ks.sort()\\nAttributeError: 'dict_keys' object has no attribute 'sort'\\n>>> Ks = list(Ks)                            # Force it to be a list and then sort\\n>>> Ks.sort()\\n>>> for k in Ks: print(k, D[k])\\n...\\na 1\\nb 2\\nc 3\\n>>> D\\n{'a': 1, 'c': 3, 'b': 2}\\n>>> Ks = D.keys()                            # Or you can use sorted() on the keys\\n>>> for k in sorted(Ks): print(k, D[k])      # sorted() accepts any iterable\\n...                                          # sorted() returns its result\\na 1\\nb 2\\nc 3\\n>>> D\\n{'a': 1, 'c': 3, 'b': 2}                     # Better yet, sort the dict directly\\n>>> for k in sorted(D): print(k, D[k])       # dict iterators return keys\\n...\\na 1\\nb 2\\nc 3\\nDictionary magnitude comparisons no longer work\\nSecondly, while in Python 2.6 dictionaries may be compared for relative magnitude\\ndirectly with <, >, and so on, in Python 3.0 this no longer works. However, it can be\\nsimulated by comparing sorted keys lists manually:\\nsorted(D1.items()) < sorted(D2.items())      # Like 2.6 D1 < D2\\nDictionary equality tests still work in 3.0, though. Since we’ll revisit this in the next\\nchapter in the context of comparisons at large, we’ll defer further details here.\\n222 | Chapter 8: \\u2002Lists and Dictionaries\", metadata={'source': 'python.pdf', 'page': 272}),\n",
       " Document(page_content=\"The has_key method is dead: long live in!\\nFinally, the widely \\nused dictionary has_key key presence test method is gone in 3.0.\\nInstead, use the in membership expression, or a get with a default test (of these, in is\\ngenerally preferred):\\n>>> D\\n{'a': 1, 'c': 3, 'b': 2}\\n>>> D.has_key('c')                                        # 2.X only: True/False\\nAttributeError: 'dict' object has no attribute 'has_key'\\n>>> 'c' in D\\nTrue\\n>>> 'x' in D\\nFalse\\n>>> if 'c' in D: print('present', D['c'])                 # Preferred in 3.0\\n...\\npresent 3\\n>>> print(D.get('c'))\\n3\\n>>> print(D.get('x'))\\nNone\\n>>> if D.get('c') != None: print('present', D['c'])       # Another option\\n...\\npresent 3\\nIf you work in 2.6 and care about 3.0 compatibility, note that the first two changes\\n(comprehensions and views) can only be coded in 3.0, but the last three ( sorted, manual\\ncomparisons, and in) can be coded in 2.6 today to ease 3.0 migration in the future.\\nChapter Summary\\nIn this chapter, we explored the list and dictionary types—probably the two most\\ncommon, flexible, and powerful collection types you will see and use in Python code.\\nWe learned that the list type supports positionally ordered collections of arbitrary ob-\\njects, and that it may be freely nested and grown and shrunk on demand. The dictionary\\ntype is similar, but it stores items by key instead of by position and does not maintain\\nany reliable left-to-right order among its items. Both lists and dictionaries are mutable,\\nand so support a variety of in-place change operations not available for strings: for\\nexample, lists can be grown by append calls, and dictionaries by assignment to new keys.\\nIn the next chapter, we will wrap up our in-depth core object type tour by looking at\\ntuples and files. After that, we’ll move on to statements that code the logic that processes\\nour objects, taking us another step toward writing complete programs. Before we tackle\\nthose topics, though, here are some chapter quiz questions to review.\\nChapter Summary | 223\", metadata={'source': 'python.pdf', 'page': 273}),\n",
       " Document(page_content=\"Test Your Knowledge: Quiz\\n1. Name two ways to build a list containing five integer zeros.\\n2. Name \\ntwo ways to build a dictionary with two keys, 'a' and 'b', each having an\\nassociated value of 0.\\n3. Name four operations that change a list object in-place.\\n4. Name four operations that change a dictionary object in-place.\\nTest Your Knowledge: Answers\\n1. A literal expression like [0, 0, 0, 0, 0] and a repetition expression like [0] * 5\\nwill each create a list of five zeros. In practice, you might also build one up with a\\nloop that starts with an empty list and appends 0 to it in each iteration:\\nL.append(0). A list comprehension ( [0 for i in range(5)]) could work here, too,\\nbut this is more work than you need to do.\\n2. A literal expression such as {'a': 0, 'b': 0} or a series of assignments like D = {},\\nD['a'] = 0 , and D['b'] = 0  would create the desired dictionary. You can also use\\nthe newer and simpler-to-code dict(a=0, b=0) keyword form, or the more flexible\\ndict([('a', 0), ('b', 0)]) key/value sequences form. Or, because all the values\\nare the same, you can use the special form dict.fromkeys('ab', 0). In 3.0, you can\\nalso use a dictionary comprehension: {k:0 for k in 'ab'}.\\n3. The append and extend methods grow a list in-place, the sort and reverse methods\\norder and reverse lists, the insert method inserts an item at an offset, the remove\\nand pop methods delete from a list by value and by position, the del statement\\ndeletes an item or slice, and index and slice assignment statements replace an item\\nor entire section. Pick any four of these for the quiz.\\n4. Dictionaries are primarily changed by assignment to a new or existing key, which\\ncreates or changes the key’s entry in the table. Also, the del statement deletes a\\nkey’s entry, the dictionary update method merges one dictionary into another in-\\nplace, and D.pop(key) removes a key and returns the value it had. Dictionaries also\\nhave other, more exotic in-place change methods not listed in this chapter, such\\nas setdefault; see reference sources for more details.\\n224 | Chapter 8: \\u2002Lists and Dictionaries\", metadata={'source': 'python.pdf', 'page': 274}),\n",
       " Document(page_content='CHAPTER 9\\nTuples, Files, and Everything Else\\nThis chapter rounds out our in-depth look at the core object types in Python by ex-\\nploring the tuple, a collection of other objects that cannot be changed, and the file, an\\ninterface to external \\nfiles on your computer. As you’ll see, the tuple is a relatively simple\\nobject that largely performs operations you’ve already learned about for strings and\\nlists. The file object is a commonly used and full-featured tool for processing files; the\\nbasic overview of files here is supplemented by larger examples in later chapters.\\nThis chapter also concludes this part of the book by looking at properties common to\\nall the core object types we’ve met—the notions of equality, comparisons, object cop-\\nies, and so on. We’ll also briefly explore other object types in the Python toolbox; as\\nyou’ll see, although we’ve covered all the primary built-in types, the object story in\\nPython is broader than I’ve implied thus far. Finally, we’ll close this part of the book\\nby taking a look at a set of common object type pitfalls and exploring some exercises\\nthat will allow you to experiment with the ideas you’ve learned.\\nTuples\\nThe last collection type in our survey is the Python tuple. Tuples construct simple\\ngroups of objects. They work exactly like lists, except that tuples can’t be changed in-\\nplace (they’re immutable) and are usually written as a series of items in parentheses,\\nnot square brackets. Although they don’t support as many methods, tuples share most\\nof their properties with lists. Here’s a quick look at the basics. Tuples are:\\nOrdered collections of arbitrary objects\\nLike strings and lists, tuples are positionally ordered collections of objects (i.e.,\\nthey maintain a left-to-right order among their contents); like lists, they can embed\\nany kind of object.\\nAccessed by offset\\nLike strings and lists, items in a tuple are accessed by offset (not by key); they\\nsupport all the offset-based access operations, such as indexing and slicing.\\n225', metadata={'source': 'python.pdf', 'page': 275}),\n",
       " Document(page_content=\"Of the category “immutable sequence”\\nLike strings and \\nlists, tuples are sequences; they support many of the same opera-\\ntions. However, like strings, tuples are immutable; they don’t support any of the\\nin-place change operations applied to lists.\\nFixed-length, heterogeneous, and arbitrarily nestable\\nBecause tuples are immutable, you cannot change the size of a tuple without mak-\\ning a copy. On the other hand, tuples can hold any type of object, including other\\ncompound objects (e.g., lists, dictionaries, other tuples), and so support arbitrary\\nnesting.\\nArrays of object references\\nLike lists, tuples are best thought of as object reference arrays; tuples store access\\npoints to other objects (references), and indexing a tuple is relatively quick.\\nTable 9-1  highlights common tuple operations. A tuple is written as a series of objects\\n(technically, expressions that generate objects), separated by commas and normally\\nenclosed in parentheses. An empty tuple is just a parentheses pair with nothing inside.\\nTable 9-1. Common tuple literals and operations\\nOperation Interpretation\\n() An empty tuple\\nT = (0,) A one-item tuple (not an expression)\\nT = (0, 'Ni', 1.2, 3) A four-item tuple\\nT = 0, 'Ni', 1.2, 3 Another four-item tuple (same as prior line)\\nT = ('abc', ('def', 'ghi')) Nested tuples\\nT = tuple('spam') Tuple of items in an iterable\\nT[i]\\nT[i][j]\\nT[i:j]\\nlen(T)Index, index of index, slice, length\\nT1 + T2\\nT * 3Concatenate, repeat\\nfor x in T: print(x)\\n'spam' in T\\n[x ** 2 for x in T]Iteration, membership\\nT.index('Ni')\\nT.count('Ni')Methods in 2.6 and 3.0: search, count\\n226 | Chapter 9: \\u2002Tuples, Files, and Everything Else\", metadata={'source': 'python.pdf', 'page': 276}),\n",
       " Document(page_content='Tuples in Action\\nAs usual, let’s \\nstart an interactive session to explore tuples at work. Notice in Ta-\\nble 9-1  that tuples do not have all the methods that lists have (e.g., an append call won’t\\nwork here). They do, however, support the usual sequence operations that we saw for\\nboth strings and lists:\\n>>> (1, 2) + (3, 4)            # Concatenation\\n(1, 2, 3, 4)\\n>>> (1, 2) * 4                 # Repetition\\n(1, 2, 1, 2, 1, 2, 1, 2)\\n>>> T = (1, 2, 3, 4)           # Indexing, slicing\\n>>> T[0], T[1:3]\\n(1, (2, 3))\\nTuple syntax peculiarities: Commas and parentheses\\nThe second and fourth entries in Table 9-1  merit a bit more explanation. Because \\nparentheses can also enclose expressions (see Chapter 5), you need to do something\\nspecial to tell Python when a single object in parentheses is a tuple object and not a\\nsimple expression. If you really want a single-item tuple, simply add a trailing comma\\nafter the single item, before the closing parenthesis:\\n>>> x = (40)                   # An integer!\\n>>> x\\n40\\n>>> y = (40,)                  # A tuple containing an integer\\n>>> y\\n(40,)\\nAs a special case, Python also allows you to omit the opening and closing parentheses\\nfor a tuple in contexts where it isn’t syntactically ambiguous to do so. For instance, the\\nfourth line of Table 9-1  simply lists four items separated by commas. In the context of\\nan assignment statement, Python recognizes this as a tuple, even though it doesn’t have\\nparentheses.\\nNow, some people will tell you to always use parentheses in your tuples, and some will\\ntell you to never use parentheses in tuples (and still others have lives, and won’t tell\\nyou what to do with your tuples!). The only significant places where the parentheses\\nare required are when a tuple is passed as a literal in a function call (where parentheses\\nmatter), and when one is listed in a Python 2.X print statement (where commas are\\nsignificant).\\nFor beginners, the best advice is that it’s probably easier to use the parentheses than it\\nis to figure out when they are optional. Many programmers (myself included) also find\\nthat parentheses tend to aid script readability by making the tuples more explicit, but\\nyour mileage may vary.\\nTuples | 227', metadata={'source': 'python.pdf', 'page': 277}),\n",
       " Document(page_content=\"Conversions, methods, and immutability\\nApart from literal \\nsyntax differences, tuple operations (the middle rows in Table 9-1 )\\nare identical to string and list operations. The only differences worth noting are that\\nthe +, *, and slicing operations return new tuples when applied to tuples, and that tuples\\ndon’t provide the same methods you saw for strings, lists, and dictionaries. If you want\\nto sort a tuple, for example, you’ll usually have to either first convert it to a list to gain\\naccess to a sorting method call and make it a mutable object, or use the newer sorted\\nbuilt-in that accepts any sequence object (and more):\\n>>> T = ('cc', 'aa', 'dd', 'bb')\\n>>> tmp = list(T)                  # Make a list from a tuple's items\\n>>> tmp.sort()                     # Sort the list\\n>>> tmp\\n['aa', 'bb', 'cc', 'dd']\\n>>> T = tuple(tmp)                 # Make a tuple from the list's items\\n>>> T\\n('aa', 'bb', 'cc', 'dd')\\n>>> sorted(T)                      # Or use the sorted built-in\\n['aa', 'bb', 'cc', 'dd']\\nHere, the list and tuple built-in functions are used to convert the object to a list and\\nthen back to a tuple; really, both calls make new objects, but the net effect is like a\\nconversion.\\nList comprehensions can also be used to convert tuples. The following, for example,\\nmakes a list from a tuple, adding 20 to each item along the way:\\n>>> T = (1, 2, 3, 4, 5)\\n>>> L = [x + 20 for x in T]\\n>>> L\\n[21, 22, 23, 24, 25]\\nList comprehensions are really sequence operations—they always build new lists, but\\nthey may be used to iterate over any sequence objects, including tuples, strings, and\\nother lists. As we’ll see later in the book, they even work on some things that are not\\nphysically stored sequences—any iterable objects will do, including files, which are\\nautomatically read line by line.\\nAlthough tuples don’t have the same methods as lists and strings, they do have two of\\ntheir own as of Python 2.6 and 3.0— index and count works as they do for lists, but\\nthey are defined for tuple objects:\\n>>> T = (1, 2, 3, 2, 4, 2)         # Tuple methods in 2.6 and 3.0\\n>>> T.index(2)                     # Offset of first appearance of 2\\n1\\n>>> T.index(2, 2)                  # Offset of appearance after offset 2\\n3\\n>>> T.count(2)                     # How many 2s are there?\\n3\\n228 | Chapter 9: \\u2002Tuples, Files, and Everything Else\", metadata={'source': 'python.pdf', 'page': 278}),\n",
       " Document(page_content=\"Prior to 2.6 and 3.0, tuples have no methods at all—this was an old Python convention\\nfor immutable types, \\nwhich was violated years ago on grounds of practicality with\\nstrings, and more recently with both numbers and tuples.\\nAlso, note that the rule about tuple immutability applies only to the top level of the\\ntuple itself, not to its contents. A list inside a tuple, for instance, can be changed as usual:\\n>>> T = (1, [2, 3], 4)\\n>>> T[1] = 'spam'                  # This fails: can't change tuple itself\\nTypeError: object doesn't support item assignment\\n>>> T[1][0] = 'spam'               # This works: can change mutables inside\\n>>> T\\n(1, ['spam', 3], 4)\\nFor most programs, this one-level-deep immutability is sufficient for common tuple\\nroles. Which, coincidentally, brings us to the next section.\\nWhy Lists and Tuples?\\nThis seems to be the first question that always comes up when teaching beginners about\\ntuples: why do we need tuples if we have lists? Some of the reasoning may be historic;\\nPython’s creator is a mathematician by training, and he has been quoted as seeing a\\ntuple as a simple association of objects and a list as a data structure that changes over\\ntime. In fact, this use of the word “tuple” derives from mathematics, as does its frequent\\nuse for a row in a relational database table.\\nThe best answer, however, seems to be that the immutability of tuples provides some\\nintegrity—you can be sure a tuple won’t be changed through another reference else-\\nwhere in a program, but there’s no such guarantee for lists. Tuples, therefore, serve a\\nsimilar role to “constant” declarations in other languages, though the notion of\\nconstantness is associated with objects in Python, not variables.\\nTuples can also be used in places that lists cannot—for example, as dictionary keys\\n(see the sparse matrix example in Chapter 8). Some built-in operations may also require\\nor imply tuples, not lists, though such operations have often been generalized in recent\\nyears. As a rule of thumb, lists are the tool of choice for ordered collections that might\\nneed to change; tuples can handle the other cases of fixed associations.\\nFiles\\nYou may already be familiar with the notion of files, which are named storage com-\\npartments on your computer that are managed by your operating system. The last major\\nbuilt-in object type that we’ll examine on our object types tour provides a way to access\\nthose files inside Python programs.\\nFiles | 229\", metadata={'source': 'python.pdf', 'page': 279}),\n",
       " Document(page_content=\"In short, the built-in open function creates a Python file object, which serves as a link\\nto a file residing on your machine. After calling open, you can transfer strings of data\\nto and from the associated external file by calling the returned file object’s methods.\\nCompared to the types you’ve seen so far, file objects are somewhat unusual. They’re\\nnot numbers, sequences, or mappings, and they don’t respond to expression operators;\\nthey export only methods for common file-processing tasks. Most file methods are\\nconcerned with performing input from and output to the external file associated with\\na file object, but other file methods allow us to seek to a new position in the file, flush\\noutput buffers, and so on. Table 9-2 summarizes common file operations.\\nTable 9-2. Common file operations\\nOperation Interpretation\\noutput = open(r'C:\\\\spam', 'w') Create output file ('w' means write)\\ninput = open('data', 'r') Create input file ('r' means read)\\ninput = open('data') Same as prior line ('r' is the default)\\naString = input.read() Read entire file into a single string\\naString = input.read(N) Read up to next N characters (or bytes) into a string\\naString = input.readline() Read next line (including \\\\n newline) into a string\\naList = input.readlines() Read entire file into list of line strings (with \\\\n)\\noutput.write(aString) Write a string of characters (or bytes) into file\\noutput.writelines(aList) Write all line strings in a list into file\\noutput.close() Manual close (done for you when file is collected)\\noutput.flush() Flush output buffer to disk without closing\\nanyFile.seek(N) Change file position to offset N for next operation\\nfor line in open('data'): use line File iterators read line by line\\nopen('f.txt', encoding='latin-1') Python 3.0 Unicode text files (str strings)\\nopen('f.bin', 'rb') Python 3.0 binary bytes files (bytes strings)\\nOpening Files\\nTo open a \\nfile, a program calls the built-in open function, with the external filename\\nfirst, followed by a processing mode. The mode is typically the string 'r' to open for\\ntext input (the default), 'w' to create and open for text output, or 'a' to open for\\nappending text to the end. The processing mode argument can specify additional\\noptions:\\n• Adding a b to the mode string allows for binary data (end-of-line translations and\\n3.0 Unicode encodings are turned off).\\n230 | Chapter 9: \\u2002Tuples, Files, and Everything Else\", metadata={'source': 'python.pdf', 'page': 280}),\n",
       " Document(page_content='• Adding a + opens the file for both input and output (i.e., you can both read and\\nwrite to the same file object, often in conjunction with seek operations to reposition\\nin the file).\\nBoth arguments to open must be Python strings, and an optional third argument can\\nbe used to control output buffering—passing a zero means that output is unbuffered\\n(it is transferred to the external file immediately on a write method call). The external\\nfilename argument may include a platform-specific and absolute or relative directory\\npath prefix; without a directory path, the file is assumed to exist in the current working\\ndirectory (i.e., where the script runs). We’ll cover file fundamentals and explore some\\nbasic examples here, but we won’t go into all file-processing mode options; as usual,\\nconsult the Python library manual for additional details.\\nUsing Files\\nOnce you make a file object with open, you can call its methods to read from or write\\nto the associated external file. In all cases, file text takes the form of strings in Python\\nprograms; reading a file returns its text in strings, and text is passed to the write methods\\nas strings. Reading and writing methods come in multiple flavors; Table 9-2 lists the\\nmost common. Here are a few fundamental usage notes:\\nFile iterators are best for reading lines\\nThough the reading and writing methods in the table are common, keep in mind\\nthat probably the best way to read lines from a text file today is to not read the file\\nat all—as we’ll see in Chapter 14 , files also have an iterator that automatically reads\\none line at a time in a for loop, list comprehension, or other iteration context.\\nContent is strings, not objects\\nNotice in Table 9-2  that data read from a file always comes back to your script as\\na string, so you’ll have to convert it to a different type of Python object if a string\\nis not what you need. Similarly, unlike with the print operation, Python does not\\nadd any formatting and does not convert objects to strings automatically when you\\nwrite data to a file—you must send an already formatted string. Because of this,\\nthe tools we have already met to convert objects to and from strings (e.g., int,\\nfloat, str, and the string formatting expression and method) come in handy when\\ndealing with files. Python also includes advanced standard library tools for han-\\ndling generic object storage (such as the pickle module) and for dealing with\\npacked binary data in files (such as the struct module). We’ll see both of these at\\nwork later in this chapter.\\nclose is usually optional\\nCalling the file close method terminates your connection to the external file. As\\ndiscussed in Chapter 6, in Python an object’s memory space is automatically re-\\nclaimed as soon as the object is no longer referenced anywhere in the program.\\nWhen file objects are reclaimed, Python also automatically closes the files if they\\nare still open (this also happens when a program shuts down). This means you\\nFiles | 231', metadata={'source': 'python.pdf', 'page': 281}),\n",
       " Document(page_content=\"don’t always need to manually close your files, especially in simple scripts that\\ndon’t run for \\nlong. On the other hand, including manual close calls can’t hurt and\\nis usually a good idea in larger systems. Also, strictly speaking, this auto-close-on-\\ncollection feature of files is not part of the language definition, and it may change\\nover time. Consequently, manually issuing file close method calls is a good habit\\nto form. (For an alternative way to guarantee automatic file closes, also see this\\nsection’s later discussion of the file object’s context manager , used with the new\\nwith/as statement in Python 2.6 and 3.0.)\\nFiles are buffered and seekable.\\nThe prior paragraph’s notes about closing files are important, because closing both\\nfrees up operating system resources and flushes output buffers. By default, output\\nfiles are always buffered, which means that text you write may not be transferred\\nfrom memory to disk immediately—closing a file, or running its flush method,\\nforces the buffered data to disk. You can avoid buffering with extra open arguments,\\nbut it may impede performance. Python files are also random-access on a byte offset\\nbasis—their seek method allows your scripts to jump around to read and write at\\nspecific locations.\\nFiles in Action\\nLet’s work through a simple example that demonstrates file-processing basics. The\\nfollowing code begins by opening a new text file for output, writing two lines (strings\\nterminated with a newline marker, \\\\n), and closing the file. Later, the example opens\\nthe same file again in input mode and reads the lines back one at a time with\\nreadline. Notice that the third readline call returns an empty string; this is how Python\\nfile methods tell you that you’ve reached the end of the file (empty lines in the file come\\nback as strings containing just a newline character, not as empty strings). Here’s the\\ncomplete interaction:\\n>>> myfile = open('myfile.txt', 'w')        # Open for text output: create/empty\\n>>> myfile.write('hello text file\\\\n')       # Write a line of text: string\\n16\\n>>> myfile.write('goodbye text file\\\\n')\\n18\\n>>> myfile.close()                          # Flush output buffers to disk\\n>>> myfile = open('myfile.txt')             # Open for text input: 'r' is default\\n>>> myfile.readline()                       # Read the lines back\\n'hello text file\\\\n'\\n>>> myfile.readline()\\n'goodbye text file\\\\n'\\n>>> myfile.readline()                       # Empty string: end of file\\n''\\nNotice that file write calls return the number of characters written in Python 3.0; in\\n2.6 they don’t, so you won’t see these numbers echoed interactively. This example\\nwrites each line of text, including its end-of-line terminator, \\\\n, as a string; write\\n232 | Chapter 9: \\u2002Tuples, Files, and Everything Else\", metadata={'source': 'python.pdf', 'page': 282}),\n",
       " Document(page_content=\"methods don’t add the end-of-line character for us, so we must include it to properly\\nterminate our \\nlines (otherwise the next write will simply extend the current line in the\\nfile).\\nIf you want to display the file’s content with end-of-line characters interpreted, read\\nthe entire file into a string all at once with the file object’s read method and print it:\\n>>> open('myfile.txt').read()               # Read all at once into string\\n'hello text file\\\\ngoodbye text file\\\\n'\\n>>> print(open('myfile.txt').read())        # User-friendly display\\nhello text file\\ngoodbye text file\\nAnd if you want to scan a text file line by line, file iterators  are often your best option:\\n>>> for line in open('myfile'):             # Use file iterators, not reads\\n...     print(line, end='')\\n...\\nhello text file\\ngoodbye text file\\nWhen coded this way, the temporary file object created by open will automatically read\\nand return one line on each loop iteration. This form is usually easiest to code, good\\non memory use, and may be faster than some other options (depending on many var-\\niables, of course). Since we haven’t reached statements or iterators yet, though, you’ll\\nhave to wait until Chapter 14 for a more complete explanation of this code.\\nText and binary files in Python 3.0\\nStrictly speaking, the example in the prior section uses text files. In both Python 3.0\\nand 2.6, file type is determined by the second argument to open, the mode string—an\\nincluded “b” means binary. Python has always supported both text and binary files,\\nbut in Python 3.0 there is a sharper distinction between the two:\\n•Text files  represent content as normal str strings, perform Unicode encoding and\\ndecoding automatically, and perform end-of-line translation by default.\\n•Binary files  represent content as a special bytes string type and allow programs to\\naccess file content unaltered.\\nIn contrast, Python 2.6 text files handle both 8-bit text and binary data, and a special\\nstring type and file interface ( unicode strings and codecs.open) handles Unicode text.\\nThe differences in Python 3.0 stem from the fact that simple and Unicode text have\\nbeen merged in the normal string type—which makes sense, given that all text is Uni-\\ncode, including ASCII and other 8-bit encodings.\\nBecause most programmers deal only with ASCII text, they can get by with the basic\\ntext file interface used in the prior example, and normal strings. All strings are techni-\\ncally Unicode in 3.0, but ASCII users will not generally notice. In fact, files and strings\\nwork the same in 3.0 and 2.6 if your script’s scope is limited to such simple forms of text.\\nFiles | 233\", metadata={'source': 'python.pdf', 'page': 283}),\n",
       " Document(page_content=\"If you need to handle internationalized applications or byte-oriented data, though, the\\ndistinction in 3.0 \\nimpacts your code (usually for the better). In general, you must use\\nbytes strings for binary files, and normal str strings for text files. Moreover, because\\ntext files implement Unicode encodings, you cannot open a binary data file in text\\nmode—decoding its content to Unicode text will likely fail.\\nLet’s look at an example. When you read a binary data file you get back a bytes object—\\na sequence of small integers that represent absolute byte values (which may or may not\\ncorrespond to characters), which looks and feels almost exactly like a normal string:\\n>>> data = open('data.bin', 'rb').read()    # Open binary file: rb=read binary\\n>>> data                                    # bytes string holds binary data\\nb'\\\\x00\\\\x00\\\\x00\\\\x07spam\\\\x00\\\\x08'\\n>>> data[4:8]                               # Act like strings\\nb'spam'\\n>>> data[0]                                 # But really are small 8-bit integers\\n115\\n>>> bin(data[0])                            # Python 3.0 bin() function\\n'0b1110011'\\nIn addition, binary files do not perform any end-of-line translation on data; text files\\nby default map all forms to and from \\\\n when written and read and implement Unicode\\nencodings on transfers. Since Unicode and binary data is of marginal interest to many\\nPython programmers, we’ll postpone the full story until Chapter 36 . For now, let’s\\nmove on to some more substantial file examples.\\nStoring and parsing Python objects in files\\nOur next example writes a variety of Python objects into a text file on multiple lines.\\nNotice that it must convert objects to strings using conversion tools. Again, file data is\\nalways strings in our scripts, and write methods do not do any automatic to-string\\nformatting for us (for space, I’m omitting byte-count return values from write methods\\nfrom here on):\\n>>> X, Y, Z = 43, 44, 45                    # Native Python objects\\n>>> S = 'Spam'                              # Must be strings to store in file\\n>>> D = {'a': 1, 'b': 2}\\n>>> L = [1, 2, 3]\\n>>>\\n>>> F = open('datafile.txt', 'w')           # Create output file\\n>>> F.write(S + '\\\\n')                       # Terminate lines with \\\\n\\n>>> F.write('%s,%s,%s\\\\n' % (X, Y, Z))       # Convert numbers to strings\\n>>> F.write(str(L) + '$' + str(D) + '\\\\n')   # Convert and separate with $\\n>>> F.close()\\nOnce we have created our file, we can inspect its contents by opening it and reading it\\ninto a string (a single operation). Notice that the interactive echo gives the exact byte\\ncontents, while the print operation interprets embedded end-of-line characters to ren-\\nder a more user-friendly display:\\n>>> chars = open('datafile.txt').read()        # Raw string display\\n>>> chars\\n234 | Chapter 9: \\u2002Tuples, Files, and Everything Else\", metadata={'source': 'python.pdf', 'page': 284}),\n",
       " Document(page_content='\"Spam\\\\n43,44,45\\\\n[1, 2, 3]${\\'a\\': 1, \\'b\\': 2}\\\\n\"\\n>>> print(chars)                               # User-friendly display\\nSpam\\n43,44,45\\n[1, 2, 3]${\\'a\\': 1, \\'b\\': 2}\\nWe now have \\nto use other conversion tools to translate from the strings in the text file\\nto real Python objects. As Python never converts strings to numbers (or other types of\\nobjects) automatically, this is required if we need to gain access to normal object tools\\nlike indexing, addition, and so on:\\n>>> F = open(\\'datafile.txt\\')                  # Open again\\n>>> line = F.readline()                       # Read one line\\n>>> line\\n\\'Spam\\\\n\\'\\n>>> line.rstrip()                             # Remove end-of-line\\n\\'Spam\\'\\nFor this first line, we used the string rstrip method to get rid of the trailing end-of-line\\ncharacter; a line[:−1] slice would work, too, but only if we can be sure all lines end in\\nthe \\\\n character (the last line in a file sometimes does not).\\nSo far, we’ve read the line containing the string. Now let’s grab the next line, which\\ncontains numbers, and parse out (that is, extract) the objects on that line:\\n>>> line = F.readline()                       # Next line from file\\n>>> line                                      # It\\'s a string here\\n\\'43,44,45\\\\n\\'\\n>>> parts = line.split(\\',\\')                   # Split (parse) on commas\\n>>> parts\\n[\\'43\\', \\'44\\', \\'45\\\\n\\']\\nWe used the string split method here to chop up the line on its comma delimiters; the\\nresult is a list of substrings containing the individual numbers. We still must convert\\nfrom strings to integers, though, if we wish to perform math on these:\\n>>> int(parts[1])                             # Convert from string to int\\n44\\n>>> numbers = [int(P) for P in parts]         # Convert all in list at once\\n>>> numbers\\n[43, 44, 45]\\nAs we have learned, int translates a string of digits into an integer object, and the list\\ncomprehension expression introduced in Chapter 4  can apply the call to each item in\\nour list all at once (you’ll find more on list comprehensions later in this book). Notice\\nthat we didn’t have to run rstrip to delete the \\\\n at the end of the last part; int and\\nsome other converters quietly ignore whitespace around digits.\\nFinally, to convert the stored list and dictionary in the third line of the file, we can run\\nthem through eval, a built-in function that treats a string as a piece of executable pro-\\ngram code (technically, a string containing a Python expression):\\n>>> line = F.readline()\\n>>> line\\nFiles | 235', metadata={'source': 'python.pdf', 'page': 285}),\n",
       " Document(page_content='\"[1, 2, 3]${\\'a\\': 1, \\'b\\': 2}\\\\n\"\\n>>> parts = line.split(\\'$\\')                   # Split (parse) on $\\n>>> parts\\n[\\'[1, 2, 3]\\', \"{\\'a\\': 1, \\'b\\': 2}\\\\n\"]\\n>>> eval(parts[0])                            # Convert to any object type\\n[1, 2, 3]\\n>>> objects = [eval(P) for P in parts]        # Do same for all in list\\n>>> objects\\n[[1, 2, 3], {\\'a\\': 1, \\'b\\': 2}]\\nBecause the end \\nresult of all this parsing and converting is a list of normal Python objects\\ninstead of strings, we can now apply list and dictionary operations to them in our script.\\nStoring native Python objects with pickle\\nUsing eval to convert from strings to objects, as demonstrated in the preceding code,\\nis a powerful tool. In fact, sometimes it’s too powerful. eval will happily run any Python\\nexpression—even one that might delete all the files on your computer, given the nec-\\nessary permissions! If you really want to store native Python objects, but you can’t trust\\nthe source of the data in the file, Python’s standard library pickle module is ideal.\\nThe pickle module is an advanced tool that allows us to store almost any Python object\\nin a file directly, with no to- or from-string conversion requirement on our part. It’s like\\na super-general data formatting and parsing utility. To store a dictionary in a file, for\\ninstance, we pickle it directly:\\n>>> D = {\\'a\\': 1, \\'b\\': 2}\\n>>> F = open(\\'datafile.pkl\\', \\'wb\\')\\n>>> import pickle\\n>>> pickle.dump(D, F)                         # Pickle any object to file\\n>>> F.close()\\nThen, to get the dictionary back later, we simply use pickle again to re-create it:\\n>>> F = open(\\'datafile.pkl\\', \\'rb\\')\\n>>> E = pickle.load(F)                        # Load any object from file\\n>>> E\\n{\\'a\\': 1, \\'b\\': 2}\\nWe get back an equivalent dictionary object, with no manual splitting or converting\\nrequired. The pickle module performs what is known as object serialization —convert-\\ning objects to and from strings of bytes—but requires very little work on our part. In\\nfact, pickle internally translates our dictionary to a string form, though it’s not much\\nto look at (and may vary if we pickle in other data protocol modes):\\n>>> open(\\'datafile.pkl\\', \\'rb\\').read()         # Format is prone to change!\\nb\\'\\\\x80\\\\x03}q\\\\x00(X\\\\x01\\\\x00\\\\x00\\\\x00aq\\\\x01K\\\\x01X\\\\x01\\\\x00\\\\x00\\\\x00bq\\\\x02K\\\\x02u.\\'\\nBecause pickle can reconstruct the object from this format, we don’t have to deal with\\nthat ourselves. For more on the pickle module, see the Python standard library manual,\\nor import pickle and pass it to help interactively. While you’re exploring, also take a\\nlook at the shelve module. shelve is a tool that uses pickle to store Python objects in\\nan access-by-key filesystem, which is beyond our scope here (though you will get to see\\n236 | Chapter 9: \\u2002Tuples, Files, and Everything Else', metadata={'source': 'python.pdf', 'page': 286}),\n",
       " Document(page_content=\"an example of shelve in action in Chapter 27 , and other pickle examples in Chapters\\n30 and 36).\\nNote that I opened the file used to store the pickled object in binary\\nmode; binary mode \\nis always required in Python 3.0, because the pickler\\ncreates and uses a bytes string object, and these objects imply binary-\\nmode files (text-mode files imply str strings in 3.0). In earlier Pythons\\nit’s OK to use text-mode files for protocol 0 (the default, which creates\\nASCII text), as long as text mode is used consistently; higher protocols\\nrequire binary-mode files. Python 3.0’s default protocol is 3 (binary),\\nbut it creates bytes even for protocol 0. See Chapter 36 , Python’s library\\nmanual, or reference books for more details on this.\\nPython 2.6 also has a cPickle module, which is an optimized version of\\npickle that can be imported directly for speed. Python 3.0 renames this\\nmodule _pickle and uses it automatically in pickle—scripts simply im-\\nport pickle and let Python optimize itself.\\nStoring and parsing packed binary data in files\\nOne other file-related note before we move on: some advanced applications also need\\nto deal with packed binary data, created perhaps by a C language program. Python’s\\nstandard library includes a tool to help in this domain—the struct module knows how\\nto both compose and parse packed binary data. In a sense, this is another data-\\nconversion tool that interprets strings in files as binary data.\\nTo create a packed binary data file, for example, open it in 'wb' (write binary) mode,\\nand pass struct a format string and some Python objects. The format string used here\\nmeans pack as a 4-byte integer, a 4-character string, and a 2-byte integer, all in big-\\nendian form (other format codes handle padding bytes, floating-point numbers, and\\nmore):\\n>>> F = open('data.bin', 'wb')                     # Open binary output file\\n>>> import struct\\n>>> data = struct.pack('>i4sh', 7, 'spam', 8)      # Make packed binary data\\n>>> data\\nb'\\\\x00\\\\x00\\\\x00\\\\x07spam\\\\x00\\\\x08'\\n>>> F.write(data)                                  # Write byte string\\n>>> F.close()\\nPython creates a binary bytes data string, which we write out to the file normally—this\\none consists mostly of nonprintable characters printed in hexadecimal escapes, and is\\nthe same binary file we met earlier. To parse the values out to normal Python objects,\\nwe simply read the string back and unpack it using the same format string. Python\\nextracts the values into normal Python objects—integers and a string:\\n>>> F = open('data.bin', 'rb')\\n>>> data = F.read()                                # Get packed binary data\\n>>> data\\nb'\\\\x00\\\\x00\\\\x00\\\\x07spam\\\\x00\\\\x08'\\nFiles | 237\", metadata={'source': 'python.pdf', 'page': 287}),\n",
       " Document(page_content=\">>> values = struct.unpack('>i4sh', data)          # Convert to Python objects\\n>>> values\\n(7, 'spam', 8)\\nBinary data files \\nare advanced and somewhat low-level tools that we won’t cover in\\nmore detail here; for more help, see Chapter 36 , consult the Python library manual, or\\nimport struct and pass it to the help function interactively. Also note that the binary\\nfile-processing modes 'wb' and 'rb' can be used to process a simpler binary file such\\nas an image or audio file as a whole without having to unpack its contents.\\nFile context managers\\nYou’ll also want to watch for Chapter 33’s discussion of the file’s context manager\\nsupport, new in Python 3.0 and 2.6. Though more a feature of exception processing\\nthan files themselves, it allows us to wrap file-processing code in a logic layer that\\nensures that the file will be closed automatically on exit, instead of relying on the auto-\\nclose on garbage collection:\\nwith open(r'C:\\\\misc\\\\data.txt') as myfile:        # See Chapter 33 for details\\n    for line in myfile:\\n        ...use line here...\\nThe try/finally statement we’ll look at in Chapter 33 can provide similar functionality,\\nbut at some cost in extra code—three extra lines, to be precise (though we can often\\navoid both options and let Python close files for us automatically):\\nmyfile = open(r'C:\\\\misc\\\\data.txt')\\ntry:\\n    for line in myfile:\\n        ...use line here...\\nfinally:\\n    myfile.close()\\nSince both these options require more information than we have yet obtained, we’ll\\npostpone details until later in this book.\\nOther File Tools\\nThere are additional, more advanced file methods shown in Table 9-2 , and even more\\nthat are not in the table. For instance, as mentioned earlier, seek resets your current\\nposition in a file (the next read or write happens at that position), flush forces buffered\\noutput to be written out to disk (by default, files are always buffered), and so on.\\nThe Python standard library manual and the reference books described in the Preface\\nprovide complete lists of file methods; for a quick look, run a dir or help call interac-\\ntively, passing in an open file object (in Python 2.6 but not 3.0, you can pass in the\\nname file instead). For more file-processing examples, watch for the sidebar “Why\\nYou Will Care: File Scanners” on page 340. It sketches common file-scanning loop\\ncode patterns with statements we have not covered enough yet to use here.\\n238 | Chapter 9: \\u2002Tuples, Files, and Everything Else\", metadata={'source': 'python.pdf', 'page': 288}),\n",
       " Document(page_content='Also, note that although the open function and the file objects it returns are your main\\ninterface to external files in a Python script, there are additional file-like tools in the\\nPython toolset. Also available, to name a few, are:\\nStandard streams\\nPreopened file objects in the sys module, such as sys.stdout (see “Print Opera-\\ntions” on page 297)\\nDescriptor files in the os module\\nInteger file handles that support lower-level tools such as file locking\\nSockets, pipes, and FIFOs\\nFile-like objects used to synchronize processes or communicate over networks\\nAccess-by-key files known as “shelves”\\nUsed to store unaltered Python objects directly, by key (used in Chapter 27)\\nShell command streams\\nTools such as os.popen and subprocess.Popen that support spawning shell com-\\nmands and reading and writing to their standard streams\\nThe third-party open source domain offers even more file-like tools, including support\\nfor communicating with serial ports in the PySerial extension and interactive programs\\nin the pexpect system. See more advanced Python texts and the Web at large for addi-\\ntional information on file-like tools.\\nVersion skew note : In Python 2.5 and earlier, the built-in name open is\\nessentially a synonym for the name file, and files may technically be\\nopened by calling either open or file (though open is generally preferred\\nfor opening). In Python 3.0, the name file is no longer available, be-\\ncause of its redundancy with open.\\nPython 2.6 users may also use the name file as the file object type, in\\norder to customize files with object-oriented programming (described\\nlater in this book). In Python 3.0, files have changed radically. The\\nclasses used to implement file objects live in the standard library module\\nio. See this module’s documentation or code for the classes it makes\\navailable for customization, and run a type(F) call on open files F for \\nhints.\\nType Categories Revisited\\nNow that we’ve seen all of Python’s core built-in types in action, let’s wrap up our\\nobject types tour by reviewing some of the properties they share. Table 9-3 classifies\\nall the major types we’ve seen so far according to the type categories introduced earlier.\\nHere are some points to remember:\\nType Categories Revisited | 239', metadata={'source': 'python.pdf', 'page': 289}),\n",
       " Document(page_content='• Objects share operations according to their category; for instance, strings, lists,\\nand tuples \\nall share sequence operations such as concatenation, length, and\\nindexing.\\n• Only mutable objects (lists, dictionaries, and sets) may be changed in-place; you\\ncannot change numbers, strings, or tuples in-place.\\n• Files export only methods, so mutability doesn’t really apply to them—their state\\nmay be changed when they are processed, but this isn’t quite the same as Python\\ncore type mutability constraints.\\n• “Numbers” in Table 9-3  includes all number types: integer (and the distinct long\\ninteger in 2.6), floating-point, complex, decimal, and fraction.\\n• “Strings” in Table 9-3  includes str, as well as bytes in 3.0 and unicode in 2.6; the\\nbytearray string type in 3.0 is mutable.\\n• Sets are something like the keys of a valueless dictionary, but they don’t map to\\nvalues and are not ordered, so sets are neither a mapping nor a sequence type;\\nfrozenset is an immutable variant of set.\\n• In addition to type category operations, as of Python 2.6 and 3.0 all the types in\\nTable 9-3 have callable methods, which are generally specific to their type.\\nTable 9-3. Object classifications\\nObject type Category Mutable?\\nNumbers (all) Numeric No\\nStrings Sequence No\\nLists Sequence Yes\\nDictionaries Mapping Yes\\nTuples Sequence No\\nFiles Extension N/A\\nSets Set Yes\\nfrozenset Set No\\nbytearray (3.0) Sequence Yes\\nWhy You Will Care: Operator Overloading\\nIn Part VI  of this \\nbook, we’ll see that objects we implement with classes can pick and\\nchoose from these categories arbitrarily. For instance, if we want to provide a new kind\\nof specialized sequence object that is consistent with built-in sequences, we can code\\na class that overloads things like indexing and concatenation:\\nclass MySequence:\\n     def __getitem__(self, index):\\n         # Called on self[index], others\\n     def __add__(self, other):\\n         # Called on self + other\\n240 | Chapter 9: \\u2002Tuples, Files, and Everything Else', metadata={'source': 'python.pdf', 'page': 290}),\n",
       " Document(page_content=\"and so on. We can also make the new object mutable or not by selectively implementing\\nmethods called for \\nin-place change operations (e.g., __setitem__ is called on\\nself[index]=value assignments). Although it’s beyond this book’s scope, it’s also pos-\\nsible to implement new objects in an external language like C as C extension types. For\\nthese, we fill in C function pointer slots to choose between number, sequence, and\\nmapping operation sets.\\nObject Flexibility\\nThis part of \\nthe book introduced a number of compound object types (collections with\\ncomponents). In general:\\n• Lists, dictionaries, and tuples can hold any kind of object.\\n• Lists, dictionaries, and tuples can be arbitrarily nested.\\n• Lists and dictionaries can dynamically grow and shrink.\\nBecause they support arbitrary structures, Python’s compound object types are good\\nat representing complex information in programs. For example, values in dictionaries\\nmay be lists, which may contain tuples, which may contain dictionaries, and so on. The\\nnesting can be as deep as needed to model the data to be processed.\\nLet’s look at an example of nesting. The following interaction defines a tree of nested\\ncompound sequence objects, shown in Figure 9-1 . To access its components, you may\\ninclude as many index operations as required. Python evaluates the indexes from left\\nto right, and fetches a reference to a more deeply nested object at each step. Fig-\\nure 9-1  may be a pathologically complicated data structure, but it illustrates the syntax\\nused to access nested objects in general:\\n>>> L = ['abc', [(1, 2), ([3], 4)], 5]\\n>>> L[1]\\n[(1, 2), ([3], 4)]\\n>>> L[1][1]\\n([3], 4)\\n>>> L[1][1][0]\\n[3]\\n>>> L[1][1][0][0]\\n3\\nReferences Versus Copies\\nChapter 6  mentioned that assignments always store references to objects, not copies\\nof those objects. In practice, this is usually what you want. Because assignments can\\ngenerate multiple references to the same object, though, it’s important to be aware that\\nchanging a mutable object in-place may affect other references to the same object\\nReferences Versus Copies | 241\", metadata={'source': 'python.pdf', 'page': 291}),\n",
       " Document(page_content=\"elsewhere in your program. If you don’t want such behavior, you’ll need to tell Python\\nto copy the object explicitly.\\nWe studied \\nthis phenomenon in Chapter 6 , but it can become more subtle when larger\\nobjects come into play. For instance, the following example creates a list assigned to\\nX, and another list assigned to L that embeds a reference back to list X. It also creates a\\ndictionary D that contains another reference back to list X:\\n>>> X = [1, 2, 3]\\n>>> L = ['a', X, 'b']            # Embed references to X's object\\n>>> D = {'x':X, 'y':2}\\nAt this point, there are three references to the first list created: from the name X, from\\ninside the list assigned to L, and from inside the dictionary assigned to D. The situation\\nis illustrated in Figure 9-2.\\nBecause lists are mutable, changing the shared list object from any of the three refer-\\nences also changes what the other two reference:\\n>>> X[1] = 'surprise'             # Changes all three references!\\n>>> L\\n['a', [1, 'surprise', 3], 'b']\\n>>> D\\n{'x': [1, 'surprise', 3], 'y': 2}\\nReferences are a higher-level analog of pointers in other languages. Although you can’t\\ngrab hold of the reference itself, it’s possible to store the same reference in more than\\none place (variables, lists, and so on). This is a feature—you can pass a large object\\nFigure 9-1. A nested object tree with the offsets of its components, created by running the literal\\nexpression ['abc', [(1, \\n2), ([3], 4)], 5]. Syntactically nested objects are internally represented as\\nreferences (i.e., pointers) to separate pieces of memory.\\n242 | Chapter 9: \\u2002Tuples, Files, and Everything Else\", metadata={'source': 'python.pdf', 'page': 292}),\n",
       " Document(page_content=\"around a program without generating expensive copies of it along the way. If you really\\ndo want copies, however, you can request them:\\n• Slice expressions with empty limits ( L[:]) copy sequences.\\n•\\nThe dictionary and set copy method (X.copy()) copies a dictionary or set.\\n• Some built-in functions, such as list, make copies (list(L)).\\n• The copy standard library module makes full copies.\\nFor example, say you have a list and a dictionary, and you don’t want their values to\\nbe changed through other variables:\\n>>> L = [1,2,3]\\n>>> D = {'a':1, 'b':2}\\nTo prevent this, simply assign copies to the other variables, not references to the same\\nobjects:\\n>>> A = L[:]                      # Instead of A = L (or list(L))\\n>>> B = D.copy()                  # Instead of B = D (ditto for sets)\\nThis way, changes made from the other variables will change the copies, not the\\noriginals:\\n>>> A[1] = 'Ni'\\n>>> B['c'] = 'spam'\\n>>>\\n>>> L, D\\n([1, 2, 3], {'a': 1, 'b': 2})\\n>>> A, B\\n([1, 'Ni', 3], {'a': 1, 'c': 'spam', 'b': 2})\\nIn terms of our original example, you can avoid the reference side effects by slicing the\\noriginal list instead of simply naming it:\\nFigure 9-2. Shared object references: because the list referenced by variable X is also referenced from\\nwithin the objects \\nreferenced by L and D, changing the shared list from X makes it look different from\\nL and D, too.\\nReferences Versus Copies | 243\", metadata={'source': 'python.pdf', 'page': 293}),\n",
       " Document(page_content=\">>> X = [1, 2, 3]\\n>>> L = ['a', X[:], 'b']           # Embed copies of X's object\\n>>> D = {'x':X[:], 'y':2}\\nThis changes the \\npicture in Figure 9-2 —L and D will now point to different lists than\\nX. The net effect is that changes made through X will impact only X, not L and D; similarly,\\nchanges to L or D will not impact X.\\nOne final note on copies: empty-limit slices and the dictionary copy method only make\\ntop-level copies; that is, they do not copy nested data structures, if any are present. If\\nyou need a complete, fully independent copy of a deeply nested data structure, use the\\nstandard copy module: include an import copy statement and say X = copy.deep\\ncopy(Y) to fully copy an arbitrarily nested object Y. This call recursively traverses objects\\nto copy all their parts. This is a much more rare case, though (which is why you have\\nto say more to make it go). References are usually what you will want; when they are\\nnot, slices and copy methods are usually as much copying as you’ll need to do.\\nComparisons, Equality, and Truth\\nAll Python objects also respond to comparisons: tests for equality, relative magnitude,\\nand so on. Python comparisons always inspect all parts of compound objects until a\\nresult can be determined. In fact, when nested objects are present, Python automatically\\ntraverses data structures to apply comparisons recursively from left to right, and as\\ndeeply as needed. The first difference found along the way determines the comparison\\nresult.\\nFor instance, a comparison of list objects compares all their components automatically:\\n>>> L1 = [1, ('a', 3)]           # Same value, unique objects\\n>>> L2 = [1, ('a', 3)]\\n>>> L1 == L2, L1 is L2           # Equivalent? Same object?\\n(True, False)\\nHere, L1 and L2 are assigned lists that are equivalent but distinct objects. Because of\\nthe nature of Python references (studied in Chapter 6 ), there are two ways to test for \\nequality:\\n•The == operator tests value equivalence . Python performs an equivalence test,\\ncomparing all nested objects recursively.\\n•The is operator tests object identity . Python tests whether the two are really the\\nsame object (i.e., live at the same address in memory).\\nIn the preceding example, L1 and L2 pass the == test (they have equivalent values because\\nall their components are equivalent) but fail the is check (they reference two different\\nobjects, and hence two different pieces of memory). Notice what happens for short\\nstrings, though:\\n>>> S1 = 'spam'\\n>>> S2 = 'spam'\\n244 | Chapter 9: \\u2002Tuples, Files, and Everything Else\", metadata={'source': 'python.pdf', 'page': 294}),\n",
       " Document(page_content='>>> S1 == S2, S1 is S2\\n(True, True)\\nHere, we should \\nagain have two distinct objects that happen to have the same value:\\n== should be true, and is should be false. But because Python internally caches and\\nreuses some strings as an optimization, there really is just a single string \\'spam\\' in\\nmemory, shared by S1 and S2; hence, the is identity test reports a true result. To trigger\\nthe normal behavior, we need to use longer strings:\\n>>> S1 = \\'a longer string\\'\\n>>> S2 = \\'a longer string\\'\\n>>> S1 == S2, S1 is S2\\n(True, False)\\nOf course, because strings are immutable, the object caching mechanism is irrelevant\\nto your code—strings can’t be changed in-place, regardless of how many variables refer\\nto them. If identity tests seem confusing, see Chapter 6  for a refresher on object refer-\\nence concepts.\\nAs a rule of thumb, the == operator is what you will want to use for almost all equality\\nchecks; is is reserved for highly specialized roles. We’ll see cases where these operators\\nare put to use later in the book.\\nRelative magnitude comparisons are also applied recursively to nested data structures:\\n>>> L1 = [1, (\\'a\\', 3)]\\n>>> L2 = [1, (\\'a\\', 2)]\\n>>> L1 < L2, L1 == L2, L1 > L2        # Less, equal, greater: tuple of results\\n(False, False, True)\\nHere, L1 is greater than L2 because the nested 3 is greater than 2. The result of the last\\nline is really a tuple of three objects—the results of the three expressions typed (an\\nexample of a tuple without its enclosing parentheses).\\nIn general, Python compares types as follows:\\n• Numbers are compared by relative magnitude.\\n• Strings are compared lexicographically, character by character (\"abc\" < \"ac\").\\n• Lists and tuples are compared by comparing each component from left to right.\\n• Dictionaries compare as equal if their sorted (key, value) lists are equal. Relative\\nmagnitude comparisons are not supported for dictionaries in Python 3.0, but they\\nwork in 2.6 and earlier as though comparing sorted (key, value) lists.\\n• Nonnumeric mixed-type comparisons (e.g., 1 < \\'spam\\' ) are errors in Python 3.0.\\nThey are allowed in Python 2.6, but use a fixed but arbitrary ordering rule. By\\nproxy, this also applies to sorts, which use comparisons internally: nonnumeric\\nmixed-type collections cannot be sorted in 3.0.\\nIn general, comparisons of structured objects proceed as though you had written the\\nobjects as literals and compared all their parts one at a time from left to right. In later\\nchapters, we’ll see other object types that can change the way they get compared.\\nComparisons, Equality, and Truth | 245', metadata={'source': 'python.pdf', 'page': 295}),\n",
       " Document(page_content=\"Python 3.0 Dictionary Comparisons\\nThe second to \\nlast point in the preceding section merits illustration. In Python 2.6 and\\nearlier, dictionaries support magnitude comparisons, as though you were comparing\\nsorted key/value lists:\\nC:\\\\misc> c:\\\\python26\\\\python\\n>>> D1 = {'a':1, 'b':2}\\n>>> D2 = {'a':1, 'b':3}\\n>>> D1 == D2\\nFalse\\n>>> D1 < D2\\nTrue\\nIn Python 3.0, magnitude comparisons for dictionaries are removed because they incur\\ntoo much overhead when equality is desired (equality uses an optimized scheme in 3.0\\nthat doesn’t literally compare sorted key/value lists). The alternative in 3.0 is to either\\nwrite loops to compare values by key or compare the sorted key/value lists manually—\\nthe items dictionary methods and sorted built-in suffice:\\nC:\\\\misc> c:\\\\python30\\\\python\\n>>> D1 = {'a':1, 'b':2}\\n>>> D2 = {'a':1, 'b':3}\\n>>> D1 == D2\\nFalse\\n>>> D1 < D2\\nTypeError: unorderable types: dict() < dict()\\n>>> list(D1.items())\\n[('a', 1), ('b', 2)]\\n>>> sorted(D1.items())\\n[('a', 1), ('b', 2)]\\n>>> sorted(D1.items()) < sorted(D2.items())\\nTrue\\n>>> sorted(D1.items()) > sorted(D2.items())\\nFalse\\nIn practice, most programs requiring this behavior will develop more efficient ways to\\ncompare data in dictionaries than either this workaround or the original behavior in\\nPython 2.6.\\nThe Meaning of True and False in Python\\nNotice that the test results returned in the last two examples represent true and false\\nvalues. They print as the words True and False, but now that we’re using logical tests\\nlike these in earnest, I should be a bit more formal about what these names really mean.\\nIn Python, as in most programming languages, an integer 0 represents false, and an\\ninteger 1 represents true. In addition, though, Python recognizes any empty data struc-\\nture as false and any nonempty data structure as true. More generally, the notions of\\n246 | Chapter 9: \\u2002Tuples, Files, and Everything Else\", metadata={'source': 'python.pdf', 'page': 296}),\n",
       " Document(page_content='true and false are intrinsic properties of every object in Python—each object is either\\ntrue or false, as follows:\\n• Numbers are true if nonzero.\\n• Other objects are true if nonempty.\\nTable 9-4\\n gives examples of true and false objects in Python.\\nTable 9-4. Example object truth values\\nObject Value\\n\"spam\" True\\n\"\" False\\n[] False\\n{} False\\n1 True\\n0.0 False\\nNone False\\nAs one application, because objects are true or false themselves, it’s common to see\\nPython programmers code \\ntests like if X:, which, assuming X is a string, is the same\\nas if X != \\'\\':. In other words, you can test the object itself, instead of comparing it\\nto an empty object. (More on if statements in Part III.)\\nThe None object\\nAs shown in the last item in Table 9-4 , Python also provides a special object called\\nNone, which is always considered to be false. None was introduced in Chapter 4; it is the\\nonly value of a special data type in Python and typically serves as an empty placeholder\\n(much like a NULL pointer in C).\\nFor example, recall that for lists you cannot assign to an offset unless that offset already\\nexists (the list does not magically grow if you make an out-of-bounds assignment). To\\npreallocate a 100-item list such that you can add to any of the 100 offsets, you can fill\\nit with None objects:\\n>>> L = [None] * 100\\n>>>\\n>>> L\\n[None, None, None, None, None, None, None, ... ]\\nThis doesn’t limit the size of the list (it can still grow and shrink later), but simply\\npresets an initial size to allow for future index assignments. You could initialize a list\\nwith zeros the same way, of course, but best practice dictates using None if the list’s\\ncontents are not yet known.\\nComparisons, Equality, and Truth | 247', metadata={'source': 'python.pdf', 'page': 297}),\n",
       " Document(page_content=\"Keep in mind that None does not mean “undefined.” That is, None is something, not\\nnothing (despite its name!)—it is a real object and piece of memory, given a built-in\\nname by Python. Watch for other uses of this special object later in the book; it is also\\nthe default return value of functions, as we’ll see in Part IV.\\nThe bool type\\nAlso keep in mind that the Python Boolean type bool, introduced in Chapter 5 , simply\\naugments the notions of true and false in Python. As we learned in Chapter 5 , the built-\\nin words True and False are just customized versions of the integers 1 and 0—it’s as if\\nthese two words have been preassigned to 1 and 0 everywhere in Python. Because of\\nthe way this new type is implemented, this is really just a minor extension to the notions\\nof true and false already described, designed to make truth values more explicit:\\n• When used explicitly in truth test code, the words True and False are equivalent\\nto 1 and 0, but they make the programmer’s intent clearer.\\n• Results of Boolean tests run interactively print as the words True and False, instead\\nof as 1 and 0, to make the type of result clearer.\\nYou are not required to use only Boolean types in logical statements such as if; all\\nobjects are still inherently true or false, and all the Boolean concepts mentioned in this\\nchapter still work as described if you use other types. Python also provides a bool built-\\nin function that can be used to test the Boolean value of an object (i.e., whether it is\\nTrue—that is, nonzero or nonempty):\\n>>> bool(1)\\nTrue\\n>>> bool('spam')\\nTrue\\n>>> bool({})\\nFalse\\nIn practice, though, you’ll rarely notice the Boolean type produced by logic tests, be-\\ncause Boolean results are used automatically by if statements and other selection tools.\\nWe’ll explore Booleans further when we study logical statements in Chapter 12.\\nPython’s Type Hierarchies\\nFigure 9-3  summarizes all the built-in object types available in Python and their rela-\\ntionships. We’ve looked at the most prominent of these; most of the other kinds of\\nobjects in Figure 9-3 correspond to program units (e.g., functions and modules) or\\nexposed interpreter internals (e.g., stack frames and compiled code).\\nThe main point to notice here is that everything in a Python system is an object type\\nand may be processed by your Python programs. For instance, you can pass a class to\\na function, assign it to a variable, stuff it in a list or dictionary, and so on.\\n248 | Chapter 9: \\u2002Tuples, Files, and Everything Else\", metadata={'source': 'python.pdf', 'page': 298}),\n",
       " Document(page_content='Figure 9-3. Python’s major built-in object types, organized by categories. Everything is a type of object\\nin Python, even the type of an object!\\nPython’s Type Hierarchies | 249', metadata={'source': 'python.pdf', 'page': 299}),\n",
       " Document(page_content='Type Objects\\nIn fact, even \\ntypes themselves are an object type in Python: the type of an object is an\\nobject of type type (say that three times fast!). Seriously, a call to the built-in function\\ntype(X) returns the type object of object X. The practical application of this is that type\\nobjects can be used for manual type comparisons in Python if statements. However,\\nfor reasons introduced in Chapter 4 , manual type testing is usually not the right thing\\nto do in Python, since it limits your code’s flexibility.\\nOne note on type names: as of Python 2.2, each core type has a new built-in name\\nadded to support type customization through object-oriented subclassing: dict, list,\\nstr, tuple, int, float, complex, bytes, type, set, and more (in Python 2.6 but not 3.0,\\nfile is also a type name and a synonym for open). Calls to these names are really object\\nconstructor calls, not simply conversion functions, though you can treat them as simple\\nfunctions for basic usage.\\nIn addition, the types standard library module in Python 3.0 provides additional type\\nnames for types that are not available as built-ins (e.g., the type of a function; in Python\\n2.6 but not 3.0, this module also includes synonyms for built-in type names), and it is\\npossible to do type tests with the isinstance function. For example, all of the following\\ntype tests are true:\\ntype([1]) == type([])               # Type of another list\\ntype([1]) == list                   # List type name\\nisinstance([1], list)               # List or customization thereof\\nimport types                        # types has names for other types\\ndef f(): pass\\ntype(f) == types.FunctionType\\nBecause types can be subclassed in Python today, the isinstance technique is generally\\nrecommended. See Chapter 31  for more on subclassing built-in types in Python 2.2 and\\nlater.\\nAlso in Chapter 31 , we will explore how type(X) and type-testing in general apply to\\ninstances of user-defined classes. In short, in Python 3.0 and for new-style classes in\\nPython 2.6, the type of a class instance is the class from which the instance was made.\\nFor classic classes in Python 2.6 and earlier, all class instances are of the type “instance,”\\nand we must compare instance __class__ attributes to compare their types meaning-\\nfully. Since we’re not ready for classes yet, we’ll postpone the rest of this story until\\nChapter 31.\\nOther Types in Python\\nBesides the core objects studied in this part of the book, and the program-unit objects\\nsuch as functions, modules, and classes that we’ll meet later, a typical Python instal-\\nlation has dozens of additional object types available as linked-in C extensions or\\n250 | Chapter 9: \\u2002Tuples, Files, and Everything Else', metadata={'source': 'python.pdf', 'page': 300}),\n",
       " Document(page_content=\"Python classes—regular expression objects, DBM files, GUI widgets, network sockets,\\nand so on.\\nThe main difference between these extra tools and the built-in types we’ve seen so far\\nis that \\nthe built-ins provide special language creation syntax for their objects (e.g., 4 for\\nan integer, [1,2] for a list, the open function for files, and def and lambda for functions).\\nOther tools are generally made available in standard library modules that you must first\\nimport to use. For instance, to make a regular expression object, you import re and call\\nre.compile(). See Python’s library reference for a comprehensive guide to all the tools\\navailable to Python programs.\\nBuilt-in Type Gotchas\\nThat’s the end of our look at core data types. We’ll wrap up this part of the book with\\na discussion of common problems that seem to bite new users (and the occasional\\nexpert), along with their solutions. Some of this is a review of ideas we’ve already cov-\\nered, but these issues are important enough to warn about again here.\\nAssignment Creates References, Not Copies\\nBecause this is such a central concept, I’ll mention it again: you need to understand\\nwhat’s going on with shared references in your program. For instance, in the following\\nexample, the list object assigned to the name L is referenced from L and from inside the\\nlist assigned to the name M. Changing L in-place changes what M references, too:\\n>>> L = [1, 2, 3]\\n>>> M = ['X', L, 'Y']           # Embed a reference to L\\n>>> M\\n['X', [1, 2, 3], 'Y']\\n>>> L[1] = 0                    # Changes M too\\n>>> M\\n['X', [1, 0, 3], 'Y']\\nThis effect usually becomes important only in larger programs, and shared references\\nare often exactly what you want. If they’re not, you can avoid sharing objects by copying\\nthem explicitly. For lists, you can always make a top-level copy by using an empty-\\nlimits slice:\\n>>> L = [1, 2, 3]\\n>>> M = ['X', L[:], 'Y']        # Embed a copy of L\\n>>> L[1] = 0                    # Changes only L, not M\\n>>> L\\n[1, 0, 3]\\n>>> M\\n['X', [1, 2, 3], 'Y']\\nBuilt-in Type Gotchas | 251\", metadata={'source': 'python.pdf', 'page': 301}),\n",
       " Document(page_content=\"Remember, slice limits default to 0 and the length of the sequence being sliced; if both\\nare omitted, the \\nslice extracts every item in the sequence and so makes a top-level copy\\n(a new, unshared object).\\nRepetition Adds One Level Deep\\nRepeating a sequence is like adding it to itself a number of times. However, when\\nmutable sequences are nested, the effect might not always be what you expect. For\\ninstance, in the following example X is assigned to L repeated four times, whereas Y is\\nassigned to a list containing L repeated four times:\\n>>> L = [4, 5, 6]\\n>>> X = L * 4                   # Like [4, 5, 6] + [4, 5, 6] + ...\\n>>> Y = [L] * 4                 # [L] + [L] + ... = [L, L,...]\\n>>> X\\n[4, 5, 6, 4, 5, 6, 4, 5, 6, 4, 5, 6]\\n>>> Y\\n[[4, 5, 6], [4, 5, 6], [4, 5, 6], [4, 5, 6]]\\nBecause L was nested in the second repetition, Y winds up embedding references back\\nto the original list assigned to L, and so is open to the same sorts of side effects noted\\nin the last section:\\n>>> L[1] = 0                    # Impacts Y but not X\\n>>> X\\n[4, 5, 6, 4, 5, 6, 4, 5, 6, 4, 5, 6]\\n>>> Y\\n[[4, 0, 6], [4, 0, 6], [4, 0, 6], [4, 0, 6]]\\nThe same solutions to this problem apply here as in the previous section, as this is really\\njust another way to create the shared mutable object reference case. If you remember\\nthat repetition, concatenation, and slicing copy only the top level of their operand\\nobjects, these sorts of cases make much more sense.\\nBeware of Cyclic Data Structures\\nWe actually encountered this concept in a prior exercise: if a collection object contains\\na reference to itself, it’s called a cyclic object . Python prints a [...] whenever it detects\\na cycle in the object, rather than getting stuck in an infinite loop:\\n>>> L = ['grail']                # Append reference to same object\\n>>> L.append(L)                  # Generates cycle in object: [...]\\n>>> L\\n['grail', [...]]\\nBesides understanding that the three dots in square brackets represent a cycle in the\\nobject, this case is worth knowing about because it can lead to gotchas—cyclic struc-\\ntures may cause code of your own to fall into unexpected loops if you don’t anticipate\\nthem. For instance, some programs keep a list or dictionary of already visited items and\\n252 | Chapter 9: \\u2002Tuples, Files, and Everything Else\", metadata={'source': 'python.pdf', 'page': 302}),\n",
       " Document(page_content='check it to determine whether they’re in a cycle. See the solutions to the “Test Your\\nKnowledge: Part I Exercises”  in Appendix B  for \\nmore on this problem, and check out\\nthe reloadall.py program in Chapter 24 for a solution.\\nDon’t use cyclic references unless you really need to. There are good reasons to create\\ncycles, but unless you have code that knows how to handle them, you probably won’t\\nwant to make your objects reference themselves very often in practice.\\nImmutable Types Can’t Be Changed In-Place\\nYou can’t change an immutable object in-place. Instead, you construct a new object\\nwith slicing, concatenation, and so on, and assign it back to the original reference, if\\nneeded:\\nT = (1, 2, 3)\\nT[2] = 4              # Error!\\nT = T[:2] + (4,)      # OK: (1, 2, 4)\\nThat might seem like extra coding work, but the upside is that the previous gotchas\\ncan’t happen when you’re using immutable objects such as tuples and strings; because\\nthey can’t be changed in-place, they are not open to the sorts of side effects that lists are.\\nChapter Summary\\nThis chapter explored the last two major core object types—the tuple and the file. We\\nlearned that tuples support all the usual sequence operations, have just a few methods,\\nand do not allow any in-place changes because they are immutable. We also learned\\nthat files are returned by the built-in open function and provide methods for reading\\nand writing data. We explored how to translate Python objects to and from strings for\\nstoring in files, and we looked at the pickle and struct modules for advanced roles\\n(object serialization and binary data). Finally, we wrapped up by reviewing some prop-\\nerties common to all object types (e.g., shared references) and went through a list of\\ncommon mistakes (“gotchas”) in the object type domain.\\nIn the next part, we’ll shift gears, turning to the topic of statement syntax in Python—\\nwe’ll explore all of Python’s basic procedural statements in the chapters that follow.\\nThe next chapter kicks off that part of the book with an introduction to Python’s general\\nsyntax model, which is applicable to all statement types. Before moving on, though,\\ntake the chapter quiz, and then work through the end-of-part lab exercises to review\\ntype concepts. Statements largely just create and process objects, so make sure you’ve\\nmastered this domain by working through all the exercises before reading on.\\nChapter Summary | 253', metadata={'source': 'python.pdf', 'page': 303}),\n",
       " Document(page_content=\"Test Your Knowledge: Quiz\\n1. How can you \\ndetermine how large a tuple is? Why is this tool located where it is?\\n2. Write an expression that changes the first item in a tuple. (4, 5, 6) should become\\n(1, 5, 6) in the process.\\n3. What is the default for the processing mode argument in a file open call?\\n4. What module might you use to store Python objects in a file without converting\\nthem to strings yourself?\\n5. How might you go about copying all parts of a nested structure at once?\\n6. When does Python consider an object true?\\n7. What is your quest?\\nTest Your Knowledge: Answers\\n1. The built-in len function returns the length (number of contained items) for any\\ncontainer object in Python, including tuples. It is a built-in function instead of a\\ntype method because it applies to many different types of objects. In general, built-\\nin functions and expressions may span many object types; methods are specific to\\na single object type, though some may be available on more than one type ( index,\\nfor example, works on lists and tuples).\\n2. Because they are immutable, you can’t really change tuples in-place, but you can\\ngenerate a new tuple with the desired value. Given T = (4, 5, 6), you can change\\nthe first item by making a new tuple from its parts by slicing and concatenating:\\nT = (1,) + T[1:]. (Recall that single-item tuples require a trailing comma.) You\\ncould also convert the tuple to a list, change it in-place, and convert it back to a\\ntuple, but this is more expensive and is rarely required in practice—simply use a\\nlist if you know that the object will require in-place changes.\\n3. The default for the processing mode argument in a file open call is 'r', for reading\\ntext input. For input text files, simply pass in the external file’s name.\\n4. The pickle module can be used to store Python objects in a file without explicitly\\nconverting them to strings. The struct module is related, but it assumes the data\\nis to be in packed binary format in the file.\\n5. Import the copy module, and call copy.deepcopy(X) if you need to copy all parts of\\na nested structure X. This is also rarely seen in practice; references are usually the\\ndesired behavior, and shallow copies (e.g., aList[:], aDict.copy()) usually suffice\\nfor most copies.\\n254 | Chapter 9: \\u2002Tuples, Files, and Everything Else\", metadata={'source': 'python.pdf', 'page': 304}),\n",
       " Document(page_content='6. An object is considered true if it is either a nonzero number or a nonempty collec-\\ntion object. \\nThe built-in words True and False are essentially predefined to have\\nthe same meanings as integer 1 and 0, respectively.\\n7. Acceptable answers include “To learn Python,” “To move on to the next part of\\nthe book,” or “To seek the Holy Grail.”\\nTest Your Knowledge: Part II Exercises\\nThis session asks you to get your feet wet with built-in object fundamentals. As before,\\na few new ideas may pop up along the way, so be sure to flip to the answers in Appen-\\ndix B  when you’re done (or when you’re not, if necessary). If you have limited time, I\\nsuggest starting with exercises 10 and 11 (the most practical of the bunch), and then\\nworking from first to last as time allows. This is all fundamental material, though, so\\ntry to do as many of these as you can.\\n1.The basics. Experiment interactively with the common type operations found in\\nthe various operation tables in this part of the book. To get started, bring up the\\nPython interactive interpreter, type each of the following expressions, and try to\\nexplain what’s happening in each case. Note that the semicolon in some of these\\nis being used as a statement separator, to squeeze multiple statements onto a single\\nline: for example, X=1;X assigns and then prints a variable (more on statement\\nsyntax in the next part of the book). Also remember that a comma between ex-\\npressions usually builds a tuple, even if there are no enclosing parentheses: X,Y,Z\\nis a three-item tuple, which Python prints back to you in parentheses.\\n2 ** 16\\n2 / 5, 2 / 5.0\\n\"spam\" + \"eggs\"\\nS = \"ham\"\\n\"eggs \" + S\\nS * 5\\nS[:0]\\n\"green %s and %s\" % (\"eggs\", S)\\n\\'green {0} and {1}\\'.format(\\'eggs\\', S)\\n(\\'x\\',)[0]\\n(\\'x\\', \\'y\\')[1]\\nL = [1,2,3] + [4,5,6]\\nL, L[:], L[:0], L[−2], L[−2:]\\n([1,2,3] + [4,5,6])[2:4]\\n[L[2], L[3]]\\nL.reverse(); L\\nL.sort(); L\\nL.index(4)\\n{\\'a\\':1, \\'b\\':2}[\\'b\\']\\nD = {\\'x\\':1, \\'y\\':2, \\'z\\':3}\\nTest Your Knowledge: Part II Exercises | 255', metadata={'source': 'python.pdf', 'page': 305}),\n",
       " Document(page_content='D[\\'w\\'] = 0\\nD[\\'x\\'] + D[\\'w\\']\\nD[(1,2,3)] = 4\\nlist(D.keys()), list(D.values()), (1,2,3) in D\\n[[]], [\"\",[],(),{},None]\\n2.Indexing and slicing . At the \\ninteractive prompt, define a list named L that contains\\nfour strings or numbers (e.g., L=[0,1,2,3]). Then, experiment with some boundary\\ncases; you may not ever see these cases in real programs, but they are intended to\\nmake you think about the underlying model, and some may be useful in less arti-\\nficial forms:\\na. What happens when you try to index out of bounds (e.g., L[4])?\\nb. What about slicing out of bounds (e.g., L[−1000:100])?\\nc. Finally, how does Python handle it if you try to extract a sequence in reverse,\\nwith the lower bound greater than the higher bound (e.g., L[3:1])? Hint: try\\nassigning to this slice ( L[3:1]=[\\'?\\']), and see where the value is put. Do you\\nthink this may be the same phenomenon you saw when slicing out of bounds?\\n3.Indexing, slicing, and  del. Define another list L with four items, and assign an empty\\nlist to one of its offsets (e.g., L[2]=[]). What happens? Then, assign an empty list\\nto a slice (L[2:3]=[]). What happens now? Recall that slice assignment deletes the\\nslice and inserts the new value where it used to be.\\nThe del statement deletes offsets, keys, attributes, and names. Use it on your list\\nto delete an item (e.g., del L[0]). What happens if you delete an entire slice\\n(del L[1:] )? What happens when you assign a nonsequence to a slice ( L[1:2]=1)?\\n4.Tuple assignment. Type the following lines:\\n>>> X = \\'spam\\'\\n>>> Y = \\'eggs\\'\\n>>> X, Y = Y, X\\nWhat do you think is happening to X and Y when you type this sequence?\\n5.Dictionary keys. Consider the following code fragments:\\n>>> D = {}\\n>>> D[1] = \\'a\\'\\n>>> D[2] = \\'b\\'\\nYou’ve learned that dictionaries aren’t accessed by offsets, so what’s going on here?\\nDoes the following shed any light on the subject? (Hint: strings, integers, and tuples\\nshare which type category?)\\n>>> D[(1, 2, 3)] = \\'c\\'\\n>>> D\\n{1: \\'a\\', 2: \\'b\\', (1, 2, 3): \\'c\\'}\\n256 | Chapter 9: \\u2002Tuples, Files, and Everything Else', metadata={'source': 'python.pdf', 'page': 306}),\n",
       " Document(page_content='6.Dictionary indexing . Create a dictionary named D with three entries, for keys \\'a\\',\\n\\'b\\', and \\'c\\'. What happens if you try to index a nonexistent key ( D[\\'d\\'])? What\\ndoes Python do if you try to assign to a nonexistent key \\'d\\' (e.g., D[\\'d\\']=\\'spam\\')?\\nHow does this compare to out-of-bounds assignments and references for lists?\\nDoes this sound like the rule for variable names?\\n7.Generic operations. Run interactive tests to answer the following questions:\\na. What happens when you try to use the + operator on different/mixed types\\n(e.g., string + list, list + tuple)?\\nb. Does + work when one of the operands is a dictionary?\\nc. Does the append method work for both lists and strings? How about using the\\nkeys method on lists? (Hint: what does append assume about its subject object?)\\nd. Finally, what type of object do you get back when you slice or concatenate two\\nlists or two strings?\\n8.String indexing. Define a string S of four characters: S = \"spam\". Then type the\\nfollowing expression: S[0][0][0][0][0]. Any clue as to what’s happening this time?\\n(Hint: recall that a string is a collection of characters, but Python characters are\\none-character strings.) Does this indexing expression still work if you apply it to a\\nlist such as [\\'s\\', \\'p\\', \\'a\\', \\'m\\']? Why?\\n9.Immutable types . Define a string S of four characters again: S = \"spam\". Write an\\nassignment that changes the string to \"slam\", using only slicing and concatenation.\\nCould you perform the same operation using just indexing and concatenation?\\nHow about index assignment?\\n10.Nesting. Write a data structure that represents your personal information: name\\n(first, middle, last), age, job, address, email address, and phone number. You may\\nbuild the data structure with any combination of built-in object types you like (lists,\\ntuples, dictionaries, strings, numbers). Then, access the individual components of\\nyour data structures by indexing. Do some structures make more sense than others\\nfor this object?\\n11.Files. Write a script that creates a new output file called myfile.txt and writes the\\nstring \"Hello file world!\" into it. Then write another script that opens\\nmyfile.txt and reads and prints its contents. Run your two scripts from the system\\ncommand line. Does the new file show up in the directory where you ran your\\nscripts? What if you add a different directory path to the filename passed to open?\\nNote: file write methods do not add newline characters to your strings; add an\\nexplicit \\\\n at the end of the string if you want to fully terminate the line in the file.\\nTest Your Knowledge: Part II Exercises | 257', metadata={'source': 'python.pdf', 'page': 307}),\n",
       " Document(page_content='', metadata={'source': 'python.pdf', 'page': 308}),\n",
       " Document(page_content='PART III\\nStatements and Syntax', metadata={'source': 'python.pdf', 'page': 309}),\n",
       " Document(page_content='', metadata={'source': 'python.pdf', 'page': 310}),\n",
       " Document(page_content='CHAPTER 10\\nIntroducing Python Statements\\nNow that you’re familiar with Python’s core built-in object types, this chapter begins\\nour exploration of \\nits fundamental statement forms. As in the previous part, we’ll begin\\nhere with a general introduction to statement syntax, and we’ll follow up with more\\ndetails about specific statements in the next few chapters.\\nIn simple terms, statements are the things you write to tell Python what your programs\\nshould do. If programs “do things with stuff,” statements are the way you specify what\\nsort of things a program does. Python is a procedural, statement-based language; by\\ncombining statements, you specify a procedure that Python performs to satisfy a pro-\\ngram’s goals.\\nPython Program Structure Revisited\\nAnother way to understand the role of statements is to revisit the concept hierarchy\\nintroduced in Chapter 4 , which talked about built-in objects and the expressions used\\nto manipulate them. This chapter climbs the hierarchy to the next level:\\n1. Programs are composed of modules.\\n2. Modules contain statements.\\n3.Statements contain expressions.\\n4. Expressions create and process objects.\\nAt its core, Python syntax is composed of statements and expressions. Expressions\\nprocess objects and are embedded in statements. Statements code the larger logic of a\\nprogram’s operation—they use and direct expressions to process the objects we studied\\nin the preceding chapters. Moreover, statements are where objects spring into existence\\n(e.g., in expressions within assignment statements), and some statements create en-\\ntirely new kinds of objects (functions, classes, and so on). Statements always exist in\\nmodules, which themselves are managed with statements.\\n261', metadata={'source': 'python.pdf', 'page': 311}),\n",
       " Document(page_content='Python’s Statements\\nTable 10-1  summarizes \\nPython’s statement set. This part of the book deals with entries\\nin the table from the top through break and continue. You’ve informally been intro-\\nduced to a few of the statements in Table 10-1  already; this part of the book will fill in\\ndetails that were skipped earlier, introduce the rest of Python’s procedural statement\\nset, and cover the overall syntax model. Statements lower in Table 10-1  that have to\\ndo with larger program units—functions, classes, modules, and exceptions—lead to\\nlarger programming ideas, so they will each have a section of their own. More focused\\nstatements (like del, which deletes various components) are covered elsewhere in the\\nbook, or in Python’s standard manuals.\\nTable 10-1. Python 3.0 statements\\nStatement Role Example\\nAssignment Creating referencesa, *b = \\'good\\', \\'bad\\', \\'ugly\\'\\nCalls and other expressions Running functionslog.write(\"spam, ham\")\\nprint calls Printing objectsprint(\\'The Killer\\', joke)\\nif/elif/else Selecting actionsif \"python\" in text:\\n    print(text)\\nfor/else Sequence iterationfor x in mylist:\\n    print(x)\\nwhile/else General loopswhile X > Y:\\n    print(\\'hello\\')\\npass Empty placeholderwhile True:\\n    pass\\nbreak Loop exitwhile True:\\n    if exittest(): break\\ncontinue Loop continuewhile True:\\n    if skiptest(): continue\\ndef Functions and methodsdef f(a, b, c=1, *d):\\n    print(a+b+c+d[0])\\nreturn Functions resultsdef f(a, b, c=1, *d):\\n    return a+b+c+d[0]\\nyield Generator functionsdef gen(n):\\n    for i in n: yield i*2\\nglobal Namespacesx = \\'old\\'\\ndef function():\\n    global x, y; x = \\'new\\'\\nnonlocal Namespaces (3.0+)def outer():\\n    x = \\'old\\'\\n    def function():\\n        nonlocal x; x = \\'new\\'\\nimport Module accessimport sys\\nfrom Attribute accessfrom sys import stdin\\nclass Building objectsclass Subclass(Superclass):\\n    staticData = []\\n    def method(self): pass\\n262 | Chapter 10: \\u2002Introducing Python Statements', metadata={'source': 'python.pdf', 'page': 312}),\n",
       " Document(page_content=\"Statement Role Example\\ntry/except/ finally Catching exceptionstry:\\n    action()\\nexcept:\\n    print('action error')\\nraise Triggering exceptionsraise EndSearch(location)\\nassert Debugging checksassert X > Y, 'X too small'\\nwith/as Context managers (2.6+)with open('data') as myfile:\\n    process(myfile)\\ndel Deleting referencesdel data[k]\\ndel data[i:j]\\ndel obj.attr\\ndel variable\\nTable 10-1  reflects the statement forms in Python 3.0—units of code that each have a\\nspecific syntax and purpose. Here are a few fine points about its content:\\n• Assignment statements come \\nin a variety of syntax flavors, described in Chap-\\nter 11: basic, sequence, augmented, and more.\\n•print is technically neither a reserved word nor a statement in 3.0, but a built-in\\nfunction call; because it will nearly always be run as an expression statement,\\nthough (that is, on a line by itself), it’s generally thought of as a statement type.\\nWe’ll study print operations in Chapter 11 the next chapter.\\n•yield is actually an expression instead of a statement too, as of 2.5; like print, it’s\\ntypically used in a line by itself and so is included in this table, but scripts occa-\\nsionally assign or otherwise use its result, as we’ll see in Chapter 20 . As an expres-\\nsion, yield is also a reserved word, unlike print.\\nMost of this table applies to Python 2.6, too, except where it doesn’t—if you are using\\nPython 2.6 or older, here are a few notes for your Python, too:\\n• In 2.6, nonlocal is not available; as we’ll see in Chapter 17 , there are alternative\\nways to achieve this statement’s writeable state-retention effect.\\n• In 2.6, print is a statement instead of a built-in function call, with specific syntax\\ncovered in Chapter 11.\\n• In 2.6, the 3.0 exec code execution built-in function is a statement, with specific\\nsyntax; since it supports enclosing parentheses, though, you can generally use its\\n3.0 call form in 2.6 code.\\n• In 2.5, the try/except and try/finally statements were merged: the two were for-\\nmerly separate statements, but we can now say both except and finally in the same\\ntry statement.\\n• In 2.5, with/as is an optional extension, and it is not available unless you explicitly\\nturn it on by running the statement from __future__ import with_statement (see\\nChapter 33).\\nPython Program Structure Revisited | 263\", metadata={'source': 'python.pdf', 'page': 313}),\n",
       " Document(page_content='A Tale of Two ifs\\nBefore we delve \\ninto the details of any of the concrete statements in Table 10-1 , I want\\nto begin our look at Python statement syntax by showing you what you are not going\\nto type in Python code so you can compare and contrast it with other syntax models\\nyou might have seen in the past.\\nConsider the following if statement, coded in a C-like language:\\nif (x > y) {\\n    x = 1;\\n    y = 2;\\n}\\nThis might be a statement in C, C++, Java, JavaScript, or Perl. Now, look at the equiv-\\nalent statement in the Python language:\\nif x > y:\\n    x = 1\\n    y = 2\\nThe first thing that may pop out at you is that the equivalent Python statement is less,\\nwell, cluttered—that is, there are fewer syntactic components. This is by design; as a\\nscripting language, one of Python’s goals is to make programmers’ lives easier by re-\\nquiring less typing.\\nMore specifically, when you compare the two syntax models, you’ll notice that Python\\nadds one new thing to the mix, and that three items that are present in the C-like\\nlanguage are not present in Python code.\\nWhat Python Adds\\nThe one new syntax component in Python is the colon character ( :). All Python com-\\npound statements  (i.e., statements that have statements nested inside them) follow the\\nsame general pattern of a header line terminated in a colon, followed by a nested block\\nof code usually indented underneath the header line, like this:\\nHeader line:\\n    Nested statement block\\nThe colon is required, and omitting it is probably the most common coding mistake\\namong new Python programmers—it’s certainly one I’ve witnessed thousands of times\\nin Python training classes. In fact, if you are new to Python, you’ll almost certainly\\nforget the colon character very soon. Most Python-friendly editors make this mistake\\neasy to spot, and including it eventually becomes an unconscious habit (so much so\\nthat you may start typing colons in your C++ code, too, generating many entertaining\\nerror messages from your C++ compiler!).\\n264 | Chapter 10: \\u2002Introducing Python Statements', metadata={'source': 'python.pdf', 'page': 314}),\n",
       " Document(page_content='What Python Removes\\nAlthough Python requires \\nthe extra colon character, there are three things programmers\\nin C-like languages must include that you don’t generally have to in Python.\\nParentheses are optional\\nThe first of these is the set of parentheses around the tests at the top of the statement:\\nif (x < y)\\nThe parentheses here are required by the syntax of many C-like languages. In Python,\\nthough, they are not—we simply omit the parentheses, and the statement works the\\nsame way:\\nif x < y\\nTechnically speaking, because every expression can be enclosed in parentheses, in-\\ncluding them will not hurt in this Python code, and they are not treated as an error if\\npresent. But don’t do that : you’ll be wearing out your keyboard needlessly, and broad-\\ncasting to the world that you’re an ex-C programmer still learning Python (I was once,\\ntoo). The Python way is to simply omit the parentheses in these kinds of statements\\naltogether.\\nEnd of line is end of statement\\nThe second and more significant syntax component you won’t find in Python code is\\nthe semicolon. You don’t need to terminate statements with semicolons in Python the\\nway you do in C-like languages:\\nx = 1;\\nIn Python, the general rule is that the end of a line automatically terminates the state-\\nment that appears on that line. In other words, you can leave off the semicolons, and\\nit works the same way:\\nx = 1\\nThere are some ways to work around this rule, as you’ll see in a moment. But, in general,\\nyou write one statement per line for the vast majority of Python code, and no semicolon\\nis required.\\nHere, too, if you are pining for your C programming days (if such a state is possible...)\\nyou can continue to use semicolons at the end of each statement—the language lets\\nyou get away with them if they are present. But don’t do that either  (really!); again, doing\\nso tells the world that you’re still a C programmer who hasn’t quite made the switch\\nto Python coding. The Pythonic style is to leave off the semicolons altogether.\\nA Tale of Two ifs | 265', metadata={'source': 'python.pdf', 'page': 315}),\n",
       " Document(page_content='End of indentation is end of block\\nThe third and \\nfinal syntax component that Python removes, and the one that may seem\\nthe most unusual to soon-to-be-ex-C programmers (until they’ve used it for 10 minutes\\nand realize it’s actually a feature), is that you do not type anything explicit in your code\\nto syntactically mark the beginning and end of a nested block of code. You don’t need\\nto include begin/end, then/endif, or braces around the nested block, as you do in C-\\nlike languages:\\nif (x > y) {\\n    x = 1;\\n    y = 2;\\n}\\nInstead, in Python, we consistently indent all the statements in a given single nested\\nblock the same distance to the right, and Python uses the statements’ physical inden-\\ntation to determine where the block starts and stops:\\nif x > y:\\n    x = 1\\n    y = 2\\nBy indentation, I mean the blank whitespace all the way to the left of the two nested\\nstatements here. Python doesn’t care how you indent (you may use either spaces or\\ntabs), or how much you indent (you may use any number of spaces or tabs). In fact,\\nthe indentation of one nested block can be totally different from that of another. The\\nsyntax rule is only that for a given single nested block, all of its statements must be\\nindented the same distance to the right. If this is not the case, you will get a syntax\\nerror, and your code will not run until you repair its indentation to be consistent.\\nWhy Indentation Syntax?\\nThe indentation rule may seem unusual at first glance to programmers accustomed to\\nC-like languages, but it is a deliberate feature of Python, and it’s one of the main ways\\nthat Python almost forces programmers to produce uniform, regular, and readable\\ncode. It essentially means that you must line up your code vertically, in columns, ac-\\ncording to its logical structure. The net effect is to make your code more consistent and\\nreadable (unlike much of the code written in C-like languages).\\nTo put that more strongly, aligning your code according to its logical structure is a\\nmajor part of making it readable, and thus reusable and maintainable, by yourself and\\nothers. In fact, even if you never use Python after reading this book, you should get into\\nthe habit of aligning your code for readability in any block-structured language. Python\\nforces the issue by making this a part of its syntax, but it’s an important thing to do in\\nany programming language, and it has a huge impact on the usefulness of your code.\\nYour experience may vary, but when I was still doing development on a full-time basis,\\nI was mostly paid to work on large old C++ programs that had been worked on by\\nmany programmers over the years. Almost invariably, each programmer had his or her\\n266 | Chapter 10: \\u2002Introducing Python Statements', metadata={'source': 'python.pdf', 'page': 316}),\n",
       " Document(page_content='own style for indenting code. For example, I’d often be asked to change a while loop\\ncoded in the C++ language that began like this:\\nwhile (x > 0) {\\nBefore we even \\nget into indentation, there are three or four ways that programmers can\\narrange these braces in a C-like language, and organizations often have political debates\\nand write standards manuals to address the options (which seems more than a little\\noff-topic for the problem to be solved by programming). Ignoring that, here’s the sce-\\nnario I often encountered in C++ code. The first person who worked on the code\\nindented the loop four spaces:\\nwhile (x > 0) {\\n    --------;\\n    --------;\\nThat person eventually moved on to management, only to be replaced by someone who\\nliked to indent further to the right:\\nwhile (x > 0) {\\n    --------;\\n    --------;\\n           --------;\\n           --------;\\nThat person later moved on to other opportunities, and someone else picked up the\\ncode who liked to indent less:\\nwhile (x > 0) {\\n    --------;\\n    --------;\\n           --------;\\n           --------;\\n--------;\\n--------;\\n}\\nAnd so on. Eventually, the block is terminated by a closing brace ( }), which of course\\nmakes this “block-structured code” (he says, sarcastically). In any block-structured\\nlanguage, Python or otherwise, if nested blocks are not indented consistently, they\\nbecome very difficult for the reader to interpret, change, or reuse, because the code no\\nlonger visually reflects its logical meaning. Readability matters, and indentation is a\\nmajor component of readability.\\nHere is another example that may have burned you in the past if you’ve done much\\nprogramming in a C-like language. Consider the following statement in C:\\nif (x)\\n     if (y)\\n          statement1;\\nelse\\n     statement2;\\nA Tale of Two ifs | 267', metadata={'source': 'python.pdf', 'page': 317}),\n",
       " Document(page_content='Which if does the else here go with? Surprisingly, the else is paired with the nested\\nif statement ( if (y) ), even though it looks visually as though it is associated with the\\nouter if (x). This is a classic pitfall in the C language, and it can lead to the reader\\ncompletely misinterpreting the code and changing it incorrectly in ways that might not\\nbe uncovered until the Mars rover crashes into a giant rock!\\nThis cannot happen in Python—because indentation is significant, the way the code\\nlooks is the way it will work. Consider an equivalent Python statement:\\nif x:\\n     if y:\\n          statement1\\nelse:\\n     statement2\\nIn this example, the if that the else lines up with vertically is the one it is associated\\nwith logically (the outer if x). In a sense, Python is a WYSIWYG language—what you\\nsee is what you get because the way code looks is the way it runs, regardless of who\\ncoded it.\\nIf this still isn’t enough to underscore the benefits of Python’s syntax, here’s another\\nanecdote. Early in my career, I worked at a successful company that developed systems\\nsoftware in the C language, where consistent indentation is not required. Even so, when\\nwe checked our code into source control at the end of the day, this company ran an\\nautomated script that analyzed the indentation used in the code. If the script noticed\\nthat we’d indented our code inconsistently, we received an automated email about it\\nthe next morning—and so did our managers!\\nThe point is that even when a language doesn’t require it, good programmers know\\nthat consistent use of indentation has a huge impact on code readability and quality.\\nThe fact that Python promotes this to the level of syntax is seen by most as a feature of\\nthe language.\\nAlso keep in mind that nearly every programmer-friendly text editor has built-in sup-\\nport for Python’s syntax model. In the IDLE Python GUI, for example, lines of code\\nare automatically indented when you are typing a nested block; pressing the Backspace\\nkey backs up one level of indentation, and you can customize how far to the right IDLE\\nindents statements in a nested block. There is no universal standard on this: four spaces\\nor one tab per level is common, but it’s up to you to decide how and how much you\\nwish to indent. Indent further to the right for further nested blocks, and less to close\\nthe prior block.\\nAs a rule of thumb, you probably shouldn’t mix tabs and spaces in the same block in\\nPython, unless you do so consistently; use tabs or spaces in a given block, but not both\\n(in fact, Python 3.0 now issues an error for inconsistent use of tabs and spaces, as we’ll\\nsee in Chapter 12 ). But you probably shouldn’t mix tabs or spaces in indentation in\\nany structured language—such code can cause major readability issues if the next pro-\\ngrammer has his or her editor set to display tabs differently than yours. C-like languages\\n268 | Chapter 10: \\u2002Introducing Python Statements', metadata={'source': 'python.pdf', 'page': 318}),\n",
       " Document(page_content='might let coders get away with this, but they shouldn’t: the result can be a mangled\\nmess.\\nI can’t stress \\nenough that regardless of which language you code in, you should be\\nindenting consistently for readability. In fact, if you weren’t taught to do this earlier in\\nyour career, your teachers did you a disservice. Most programmers—especially those\\nwho must read others’ code—consider it a major asset that Python elevates this to the\\nlevel of syntax. Moreover, generating tabs instead of braces is no more difficult in prac-\\ntice for tools that must output Python code. In general, if you do what you should be\\ndoing in a C-like language anyhow, but get rid of the braces, your code will satisfy\\nPython’s syntax rules.\\nA Few Special Cases\\nAs mentioned previously, in Python’s syntax model:\\n• The end of a line terminates the statement on that line (without semicolons).\\n• Nested statements are blocked and associated by their physical indentation (with-\\nout braces).\\nThose rules cover almost all Python code you’ll write or see in practice. However,\\nPython also provides some special-purpose rules that allow customization of both\\nstatements and nested statement blocks.\\nStatement rule special cases\\nAlthough statements normally appear one per line, it is possible to squeeze more than\\none statement onto a single line in Python by separating them with semicolons:\\na = 1; b = 2; print(a + b)               # Three statements on one line\\nThis is the only place in Python where semicolons are required: as statement separa-\\ntors. This only works, though, if the statements thus combined are not themselves\\ncompound statements. In other words, you can chain together only simple statements,\\nlike assignments, prints, and function calls. Compound statements must still appear\\non lines of their own (otherwise, you could squeeze an entire program onto one line,\\nwhich probably would not make you very popular among your coworkers!).\\nThe other special rule for statements is essentially the inverse: you can make a single\\nstatement span across multiple lines. To make this work, you simply have to enclose\\npart of your statement in a bracketed pair—parentheses ( ()), square brackets ( []), or \\ncurly braces ( {}). Any code enclosed in these constructs can cross multiple lines: your\\nstatement doesn’t end until Python reaches the line containing the closing part of the\\npair. For instance, to continue a list literal:\\nmlist = [111,\\n         222,\\n         333]\\nA Tale of Two ifs | 269', metadata={'source': 'python.pdf', 'page': 319}),\n",
       " Document(page_content=\"Because the code is enclosed in a square brackets pair, Python simply drops down to\\nthe next line \\nuntil it encounters the closing bracket. The curly braces surrounding dic-\\ntionaries (as well as set literals and dictionary and set comprehensions in 3.0) allow\\nthem to span lines this way too, and parentheses handle tuples, function calls, and\\nexpressions. The indentation of the continuation lines does not matter, though com-\\nmon sense dictates that the lines should be aligned somehow for readability.\\nParentheses are the catchall device—because any expression can be wrapped up in\\nthem, simply inserting a left parenthesis allows you to drop down to the next line and\\ncontinue your statement:\\nX = (A + B +\\n     C + D)\\nThis technique works with compound statements, too, by the way. Anywhere you need\\nto code a large expression, simply wrap it in parentheses to continue it on the next line:\\nif (A == 1 and\\n    B == 2 and\\n    C == 3):\\n        print('spam' * 3)\\nAn older rule also allows for continuation lines when the prior line ends in a backslash:\\nX = A + B + \\\\                # An error-prone alternative\\n      C + D\\nThis alternative technique is dated, though, and is frowned on today because it’s dif-\\nficult to notice and maintain the backslashes, and it’s fairly brittle—there can be no\\nspaces after the backslash, and omitting it can have unexpected effects if the next line\\nis mistaken to be a new statement. It’s also another throwback to the C language, where\\nit is commonly used in “#define” macros; again, when in Pythonland, do as Pythonistas\\ndo, not as C programmers do.\\nBlock rule special case\\nAs mentioned previously, statements in a nested block of code are normally associated\\nby being indented the same amount to the right. As one special case here, the body of\\na compound statement can instead appear on the same line as the header in Python,\\nafter the colon:\\nif x > y: print(x)\\nThis allows us to code single-line if statements, single-line loops, and so on. Here again,\\nthough, this will work only if the body of the compound statement itself does not\\ncontain any compound statements. That is, only simple statements—assignments,\\nprints, function calls, and the like—are allowed after the colon. Larger statements must\\nstill appear on lines by themselves. Extra parts of compound statements (such as the\\nelse part of an if, which we’ll meet later) must also be on separate lines of their own.\\nThe body can consist of multiple simple statements separated by semicolons, but this\\ntends to be frowned upon.\\n270 | Chapter 10: \\u2002Introducing Python Statements\", metadata={'source': 'python.pdf', 'page': 320}),\n",
       " Document(page_content=\"In general, even though it’s not always required, if you keep all your statements on\\nindividual lines and \\nalways indent your nested blocks, your code will be easier to read\\nand change in the future. Moreover, some code profiling and coverage tools may not\\nbe able to distinguish between multiple statements squeezed onto a single line or the\\nheader and body of a one-line compound statement. It is almost always to your ad-\\nvantage to keep things simple in Python.\\nTo see a prime and common exception to one of these rules in action, however (the use\\nof a single-line if statement to break out of a loop), let’s move on to the next section\\nand write some real code.\\nA Quick Example: Interactive Loops\\nWe’ll see all these syntax rules in action when we tour Python’s specific compound\\nstatements in the next few chapters, but they work the same everywhere in the Python\\nlanguage. To get started, let’s work through a brief, realistic example that demonstrates\\nthe way that statement syntax and statement nesting come together in practice, and\\nintroduces a few statements along the way.\\nA Simple Interactive Loop\\nSuppose you’re asked to write a Python program that interacts with a user in a console\\nwindow. Maybe you’re accepting inputs to send to a database, or reading numbers to\\nbe used in a calculation. Regardless of the purpose, you need to code a loop that reads\\none or more inputs from a user typing on a keyboard, and prints back a result for each.\\nIn other words, you need to write a classic read/evaluate/print loop program.\\nIn Python, typical boilerplate code for such an interactive loop might look like this:\\nwhile True:\\n    reply = input('Enter text:')\\n    if reply == 'stop': break\\n    print(reply.upper())\\nThis code makes use of a few new ideas:\\n• The code leverages the Python while loop, Python’s most general looping state-\\nment. We’ll study the while statement in more detail later, but in short, it consists\\nof the word while, followed by an expression that is interpreted as a true or false\\nresult, followed by a nested block of code that is repeated while the test at the top\\nis true (the word True here is considered always true).\\n• The input built-in function we met earlier in the book is used here for general\\nconsole input—it prints its optional argument string as a prompt and returns the\\nuser’s typed reply as a string.\\n• A single-line if statement that makes use of the special rule for nested blocks also\\nappears here: the body of the if appears on the header line after the colon instead\\nA Quick Example: Interactive Loops | 271\", metadata={'source': 'python.pdf', 'page': 321}),\n",
       " Document(page_content=\"of being indented on a new line underneath it. This would work either way, but as\\nit’s coded, we’ve saved an extra line.\\n• Finally, the Python break\\n statement is used to exit the loop immediately—it simply\\njumps out of the loop statement altogether, and the program continues after the\\nloop. Without this exit statement, the while would loop forever, as its test is always\\ntrue.\\nIn effect, this combination of statements essentially means “read a line from the user\\nand print it in uppercase until the user enters the word ‘stop.’” There are other ways\\nto code such a loop, but the form used here is very common in Python code.\\nNotice that all three lines nested under the while header line are indented the same\\namount—because they line up vertically in a column this way, they are the block of\\ncode that is associated with the while test and repeated. Either the end of the source\\nfile or a lesser-indented statement will terminate the loop body block.\\nWhen run, here is the sort of interaction we get from this code:\\nEnter text:spam\\nSPAM\\nEnter text:42\\n42\\nEnter text:stop\\nVersion skew note : This example is coded for Python 3.0. If you are\\nworking in Python 2.6 or earlier, the code works the same, but you\\nshould use raw_input instead of input, and you can omit the outer pa-\\nrentheses in print statements. In 3.0 the former was renamed, and the\\nlatter is a built-in function instead of a statement (more on prints in the\\nnext chapter).\\nDoing Math on User Inputs\\nOur script works, but now suppose that instead of converting a text string to uppercase,\\nwe want to do some math with numeric input—squaring it, for example, perhaps in\\nsome misguided effort to discourage users who happen to be obsessed with youth. We\\nmight try statements like these to achieve the desired effect:\\n>>> reply = '20'\\n>>> reply ** 2\\n...error text omitted...\\nTypeError: unsupported operand type(s) for ** or pow(): 'str' and 'int'\\nThis won’t quite work in our script, though, because (as discussed in the prior part of\\nthe book) Python won’t convert object types in expressions unless they are all numeric,\\nand input from a user is always returned to our script as a string. We cannot raise a\\nstring of digits to a power unless we convert it manually to an integer:\\n272 | Chapter 10: \\u2002Introducing Python Statements\", metadata={'source': 'python.pdf', 'page': 322}),\n",
       " Document(page_content=\">>> int(reply) ** 2\\n400\\nArmed with this \\ninformation, we can now recode our loop to perform the necessary\\nmath. Type the following in a file to test it:\\nwhile True:\\n    reply = input('Enter text:')\\n    if reply == 'stop': break\\n    print(int(reply) ** 2)\\nprint('Bye')\\nThis script uses a single-line if statement to exit on “stop” as before, but it also converts\\ninputs to perform the required math. This version also adds an exit message at the\\nbottom. Because the print statement in the last line is not indented as much as the\\nnested block of code, it is not considered part of the loop body and will run only once,\\nafter the loop is exited:\\nEnter text:2\\n4\\nEnter text:40\\n1600\\nEnter text:stop\\nBye\\nOne note here: I’m assuming that this code is stored in and run from a script file. If you\\nare entering this code interactively, be sure to include a blank line (i.e., press Enter\\ntwice) before the final print statement, to terminate the loop. The final print doesn’t\\nquite make sense in interactive mode, though (you’ll have to code it after interacting\\nwith the loop!).\\nHandling Errors by Testing Inputs\\nSo far so good, but notice what happens when the input is invalid:\\nEnter text:xxx\\n...error text omitted...\\nValueError: invalid literal for int() with base 10: 'xxx'\\nThe built-in int function raises an exception here in the face of a mistake. If we want\\nour script to be robust, we can check the string’s content ahead of time with the string\\nobject’s isdigit method:\\n>>> S = '123'\\n>>> T = 'xxx'\\n>>> S.isdigit(), T.isdigit()\\n(True, False)\\nThis also gives us an excuse to further nest the statements in our example. The following\\nnew version of our interactive script uses a full-blown if statement to work around the\\nexception on errors:\\nwhile True:\\n    reply = input('Enter text:')\\nA Quick Example: Interactive Loops | 273\", metadata={'source': 'python.pdf', 'page': 323}),\n",
       " Document(page_content=\"    if reply == 'stop':\\n        break\\n    elif not reply.isdigit():\\n        print('Bad!' * 8)\\n    else:\\n        print(int(reply) ** 2)\\nprint('Bye')\\nWe’ll study the if statement in \\nmore detail in Chapter 12 , but it’s a fairly lightweight\\ntool for coding logic in scripts. In its full form, it consists of the word if followed by a\\ntest and an associated block of code, one or more optional elif (“else if”) tests and\\ncode blocks, and an optional else part, with an associated block of code at the bottom\\nto serve as a default. Python runs the block of code associated with the first test that is\\ntrue, working from top to bottom, or the else part if all tests are false.\\nThe if, elif, and else parts in the preceding example are associated as part of the same\\nstatement because they all line up vertically (i.e., share the same level of indentation).\\nThe if statement spans from the word if to the start of the print statement on the last\\nline of the script. In turn, the entire if block is part of the while loop because all of it\\nis indented under the loop’s header line. Statement nesting is natural once you get the\\nhang of it.\\nWhen we run our new script, its code catches errors before they occur and prints an\\n(arguably silly) error message to demonstrate:\\nEnter text:5\\n25\\nEnter text:xyz\\nBad!Bad!Bad!Bad!Bad!Bad!Bad!Bad!\\nEnter text:10\\n100\\nEnter text:stop\\nHandling Errors with try Statements\\nThe preceding solution works, but as you’ll see later in the book, the most general way\\nto handle errors in Python is to catch and recover from them completely using the\\nPython try statement. We’ll explore this statement in depth in Part VII  of this book,\\nbut as a preview, using a try here can lead to code that some would claim is simpler\\nthan the prior version:\\nwhile True:\\n    reply = input('Enter text:')\\n    if reply == 'stop': break\\n    try:\\n        num = int(reply)\\n    except:\\n        print('Bad!' * 8)\\n    else:\\n        print(int(reply) ** 2)\\nprint('Bye')\\n274 | Chapter 10: \\u2002Introducing Python Statements\", metadata={'source': 'python.pdf', 'page': 324}),\n",
       " Document(page_content=\"This version works exactly like the previous one, but we’ve replaced the explicit error\\ncheck with code \\nthat assumes the conversion will work and wraps it up in an exception\\nhandler for cases when it doesn’t. This try statement is composed of the word try,\\nfollowed by the main block of code (the action we are trying to run), followed by an\\nexcept part that gives the exception handler code and an else part to be run if no\\nexception is raised in the try part. Python first runs the try part, then runs either the\\nexcept part (if an exception occurs) or the else part (if no exception occurs).\\nIn terms of statement nesting, because the words try, except, and else are all indented\\nto the same level, they are all considered part of the same single try statement. Notice\\nthat the else part is associated with the try here, not the if. As we’ve seen, else can\\nappear in if statements in Python, but it can also appear in try statements and loops—\\nits indentation tells you what statement it is a part of. In this case, the try statement\\nspans from the word try through the code indented under the word else, because the\\nelse is indented to the same level as try. The if statement in this code is a one-liner\\nand ends after the break.\\nAgain, we’ll come back to the try statement later in this book. For now, be aware that\\nbecause try can be used to intercept any error, it reduces the amount of error-checking\\ncode you have to write, and it’s a very general approach to dealing with unusual cases.\\nIf we wanted to support input of floating-point numbers instead of just integers, for\\nexample, using try would be much easier than manual error testing—we could simply\\nrun a float call and catch its exceptions, instead of trying to analyze all possible floating-\\npoint syntax.\\nNesting Code Three Levels Deep\\nLet’s look at one last mutation of our script. Nesting can take us even further if we need\\nit to—we could, for example, branch to one of a set of alternatives based on the relative\\nmagnitude of a valid input:\\nwhile True:\\n    reply = input('Enter text:')\\n    if reply == 'stop':\\n        break\\n    elif not reply.isdigit():\\n        print('Bad!' * 8)\\n    else:\\n        num = int(reply)\\n        if num < 20:\\n            print('low')\\n        else:\\n            print(num ** 2)\\nprint('Bye')\\nA Quick Example: Interactive Loops | 275\", metadata={'source': 'python.pdf', 'page': 325}),\n",
       " Document(page_content='This version includes an if statement nested in the else clause of another if statement,\\nwhich is in turn nested in the while loop. When code is conditional, or repeated like\\nthis, we simply indent it further to the right. The net effect is like that of the prior\\nversions, but we’ll now print “low” for numbers less than 20:\\nEnter text:19\\nlow\\nEnter text:20\\n400\\nEnter text:spam\\nBad!Bad!Bad!Bad!Bad!Bad!Bad!Bad!\\nEnter text:stop\\nBye\\nChapter Summary\\nThat concludes our quick look at Python statement syntax. This chapter introduced\\nthe general rules for coding statements and blocks of code. As you’ve learned, in Python\\nwe normally code one statement per line and indent all the statements in a nested block\\nthe same amount (indentation is part of Python’s syntax). However, we also looked at\\na few exceptions to these rules, including continuation lines and single-line tests and\\nloops. Finally, we put these ideas to work in an interactive script that demonstrated a\\nhandful of statements and showed statement syntax in action.\\nIn the next chapter, we’ll start to dig deeper by going over each of Python’s basic pro-\\ncedural statements in depth. As you’ll see, though, all statements follow the same gen-\\neral rules introduced here.\\nTest Your Knowledge: Quiz\\n1. What three things are required in a C-like language but omitted in Python?\\n2.How is a statement normally terminated in Python?\\n3.\\nHow are the statements in a nested block of code normally associated in Python?\\n4. How can you make a single statement span multiple lines?\\n5. How can you code a compound statement on a single line?\\n6. Is there any valid reason to type a semicolon at the end of a statement in Python?\\n7. What is a try statement for?\\n8. What is the most common coding mistake among Python beginners?\\n276 | Chapter 10: \\u2002Introducing Python Statements', metadata={'source': 'python.pdf', 'page': 326}),\n",
       " Document(page_content='Test Your Knowledge: Answers\\n1. C-like languages require \\nparentheses around the tests in some statements, semi-\\ncolons at the end of each statement, and braces around a nested block of code.\\n2. The end of a line terminates the statement that appears on that line. Alternatively,\\nif more than one statement appears on the same line, they can be terminated with\\nsemicolons; similarly, if a statement spans many lines, you must terminate it by\\nclosing a bracketed syntactic pair.\\n3. The statements in a nested block are all indented the same number of tabs or spaces.\\n4. A statement can be made to span many lines by enclosing part of it in parentheses,\\nsquare brackets, or curly braces; the statement ends when Python sees a line that\\ncontains the closing part of the pair.\\n5. The body of a compound statement can be moved to the header line after the colon,\\nbut only if the body consists of only noncompound statements.\\n6. Only when you need to squeeze more than one statement onto a single line of code.\\nEven then, this only works if all the statements are noncompound, and it’s dis-\\ncouraged because it can lead to code that is difficult to read.\\n7. The try statement is used to catch and recover from exceptions (errors) in a Python\\nscript. It’s usually an alternative to manually checking for errors in your code.\\n8. Forgetting to type the colon character at the end of the header line in a compound\\nstatement is the most common beginner’s mistake. If you haven’t made it yet, you\\nprobably will soon!\\nTest Your Knowledge: Answers | 277', metadata={'source': 'python.pdf', 'page': 327}),\n",
       " Document(page_content='', metadata={'source': 'python.pdf', 'page': 328}),\n",
       " Document(page_content='CHAPTER 11\\nAssignments, Expressions, and Prints\\nNow that we’ve had a quick introduction to Python statement syntax, this chapter\\nbegins our in-depth \\ntour of specific Python statements. We’ll begin with the basics:\\nassignment statements, expression statements, and print operations. We’ve already\\nseen all of these in action, but here we’ll fill in important details we’ve skipped so far.\\nAlthough they’re fairly simple, as you’ll see, there are optional variations for each of\\nthese statement types that will come in handy once you begin writing real Python\\nprograms.\\nAssignment Statements\\nWe’ve been using the Python assignment statement for a while to assign objects to\\nnames. In its basic form, you write the target of an assignment on the left of an equals\\nsign, and the object to be assigned on the right. The target on the left may be a name\\nor object component, and the object on the right can be an arbitrary expression that\\ncomputes an object. For the most part, assignments are straightforward, but here are\\na few properties to keep in mind:\\n•Assignments create object references. As discussed in Chapter 6, Python as-\\nsignments store references to objects in names or data structure components. They\\nalways create references to objects instead of copying the objects. Because of that,\\nPython variables are more like pointers than data storage areas.\\n•Names are created when first assigned . Python creates a variable name the first\\ntime you assign it a value (i.e., an object reference), so there’s no need to predeclare\\nnames ahead of time. Some (but not all) data structure slots are created when\\nassigned, too (e.g., dictionary entries, some object attributes). Once assigned, a\\nname is replaced with the value it references whenever it appears in an expression.\\n•Names must be assigned before being referenced . It’s an error to use a name\\nto which you haven’t yet assigned a value. Python raises an exception if you try,\\nrather than returning some sort of ambiguous default value; if it returned a default\\ninstead, it would be more difficult for you to spot typos in your code.\\n279', metadata={'source': 'python.pdf', 'page': 329}),\n",
       " Document(page_content=\"•Some operations perform assignments implicitly . In this section we’re con-\\ncerned with the = statement, but assignment occurs in many contexts in Python.\\nFor instance, we’ll see later that module imports, function and class definitions,\\nfor loop variables, and function arguments are all implicit assignments. Because\\nassignment works the same everywhere it pops up, all these contexts simply bind\\nnames to object references at runtime.\\nAssignment Statement Forms\\nAlthough assignment is a general and pervasive concept in Python, we are primarily\\ninterested in assignment statements in this chapter. Table 11-1  illustrates the different\\nassignment statement forms in Python.\\nTable 11-1. Assignment statement forms\\nOperation Interpretation\\nspam = 'Spam' Basic form\\nspam, ham = 'yum', 'YUM' Tuple assignment (positional)\\n[spam, ham] = ['yum', 'YUM'] List assignment (positional)\\na, b, c, d = 'spam' Sequence assignment, generalized\\na, *b = 'spam' Extended sequence unpacking (Python 3.0)\\nspam = ham = 'lunch' Multiple-target assignment\\nspams += 42 Augmented assignment (equivalent to spams = spams + 42)\\nThe first form in Table 11-1 is by far the most common: binding a name (or data struc-\\nture component) to a single object. In fact, you could get all your work done with this\\nbasic form alone. The other table entries represent special forms that are all optional,\\nbut that programmers often find convenient in practice:\\nTuple- and list-unpacking assignments\\nThe second and third forms in the table are related. When you code a tuple or list\\non the left side of the =, Python pairs objects on the right side with targets on the\\nleft by position and assigns them from left to right. For example, in the second line\\nof Table 11-1, the name spam is assigned the string 'yum', and the name ham is bound\\nto the string 'YUM'. In this case Python internally makes a tuple of the items on the\\nright, which is why this is called tuple-unpacking assignment.\\nSequence assignments\\nIn recent versions of Python, tuple and list assignments have been generalized into\\ninstances of what we now call sequence assignment —any sequence of names can\\nbe assigned to any sequence of values, and Python assigns the items one at a time\\nby position. We can even mix and match the types of the sequences involved. The\\nfourth line in Table 11-1 , for example, pairs a tuple of names with a string of\\ncharacters: a is assigned 's', b is assigned 'p', and so on.\\n280 | Chapter 11: \\u2002Assignments, Expressions, and Prints\", metadata={'source': 'python.pdf', 'page': 330}),\n",
       " Document(page_content=\"Extended sequence unpacking\\nIn Python 3.0, a \\nnew form of sequence assignment allows us to be more flexible in\\nhow we select portions of a sequence to assign. The fifth line in Table 11-1 , for\\nexample, matches a with the first character in the string on the right and b with the\\nrest: a is assigned 's', and b is assigned 'pam'. This provides a simpler alternative\\nto assigning the results of manual slicing operations.\\nMultiple-target assignments\\nThe sixth line in Table 11-1  shows the multiple-target form of assignment. In this\\nform, Python assigns a reference to the same object (the object farthest to the right)\\nto all the targets on the left. In the table, the names spam and ham are both assigned\\nreferences to the same string object, 'lunch'. The effect is the same as if we had\\ncoded ham = 'lunch' followed by spam = ham, as ham evaluates to the original string\\nobject (i.e., not a separate copy of that object).\\nAugmented assignments\\nThe last line in Table 11-1  is an example of augmented assignment —a shorthand\\nthat combines an expression and an assignment in a concise way. Saying spam +=\\n42, for example, has the same effect as spam = spam + 42, but the augmented form\\nrequires less typing and is generally quicker to run. In addition, if the subject is\\nmutable and supports the operation, an augmented assignment may run even\\nquicker by choosing an in-place update operation instead of an object copy. There\\nis one augmented assignment statement for every binary expression operator in\\nPython.\\nSequence Assignments\\nWe’ve already used basic assignments in this book. Here are a few simple examples of\\nsequence-unpacking assignments in action:\\n% python\\n>>> nudge = 1\\n>>> wink  = 2\\n>>> A, B = nudge, wink             # Tuple assignment\\n>>> A, B                           # Like A = nudge; B = wink\\n(1, 2)\\n>>> [C, D] = [nudge, wink]         # List assignment\\n>>> C, D\\n(1, 2)\\nNotice that we really are coding two tuples in the third line in this interaction—we’ve\\njust omitted their enclosing parentheses. Python pairs the values in the tuple on the\\nright side of the assignment operator with the variables in the tuple on the left side and\\nassigns the values one at a time.\\nTuple assignment leads to a common coding trick in Python that was introduced in a\\nsolution to the exercises at the end of Part II. Because Python creates a temporary tuple\\nthat saves the original values of the variables on the right while the statement runs,\\nAssignment Statements | 281\", metadata={'source': 'python.pdf', 'page': 331}),\n",
       " Document(page_content='unpacking assignments are also a way to swap two variables’ values without creating\\na temporary variable of your own—the tuple on the right remembers the prior values\\nof the variables automatically:\\n>>> nudge = 1\\n>>> wink  = 2\\n>>> nudge, wink = wink, nudge      # Tuples: swaps values\\n>>> nudge, wink                    # Like T = nudge; nudge = wink; wink = T\\n(2, 1)\\nIn fact, the original tuple and list assignment forms in Python have been generalized to\\naccept any type of sequence on the right as long as it is of the same length as the sequence\\non the left. You can assign a tuple of values to a list of variables, a string of characters\\nto a tuple of variables, and so on. In all cases, Python assigns items in the sequence on\\nthe right to variables in the sequence on the left by position, from left to right:\\n>>> [a, b, c] = (1, 2, 3)          # Assign tuple of values to list of names\\n>>> a, c\\n(1, 3)\\n>>> (a, b, c) = \"ABC\"              # Assign string of characters to tuple\\n>>> a, c\\n(\\'A\\', \\'C\\')\\nTechnically speaking, sequence assignment actually supports any iterable object on the\\nright, not just any sequence. This is a more general concept that we will explore in\\nChapters 14 and 20.\\nAdvanced sequence assignment patterns\\nAlthough we can mix and match sequence types around the = symbol, we must have\\nthe same number  of items on the right as we have variables on the left, or we’ll get an\\nerror. Python 3.0 allows us to be more general with extended unpacking syntax, de-\\nscribed in the next section. But normally, and always in Python 2.X, the number of\\nitems in the assignment target and subject must match:\\n>>> string = \\'SPAM\\'\\n>>> a, b, c, d = string                            # Same number on both sides\\n>>> a, d\\n(\\'S\\', \\'M\\')\\n>>> a, b, c = string                               # Error if not\\n...error text omitted...\\nValueError: too many values to unpack\\nTo be more general, we can slice. There are a variety of ways to employ slicing to make\\nthis last case work:\\n>>> a, b, c = string[0], string[1], string[2:]     # Index and slice\\n>>> a, b, c\\n(\\'S\\', \\'P\\', \\'AM\\')\\n>>> a, b, c = list(string[:2]) + [string[2:]]      # Slice and concatenate\\n>>> a, b, c\\n282 | Chapter 11: \\u2002Assignments, Expressions, and Prints', metadata={'source': 'python.pdf', 'page': 332}),\n",
       " Document(page_content=\"('S', 'P', 'AM')\\n>>> a, b = string[:2]                              # Same, but simpler\\n>>> c = string[2:]\\n>>> a, b, c\\n('S', 'P', 'AM')\\n>>> (a, b), c = string[:2], string[2:]             # Nested sequences\\n>>> a, b, c\\n('S', 'P', 'AM')\\nAs the last \\nexample in this interaction demonstrates, we can even assign nested se-\\nquences, and Python unpacks their parts according to their shape, as expected. In this\\ncase, we are assigning a tuple of two items, where the first item is a nested sequence (a\\nstring), exactly as though we had coded it this way:\\n>>> ((a, b), c) = ('SP', 'AM')                     # Paired by shape and position\\n>>> a, b, c\\n('S', 'P', 'AM')\\nPython pairs the first string on the right ( 'SP') with the first tuple on the left ( (a, b) )\\nand assigns one character at a time, before assigning the entire second string ( 'AM') to\\nthe variable c all at once. In this event, the sequence-nesting shape of the object on the\\nleft must match that of the object on the right. Nested sequence assignment like this is\\nsomewhat advanced, and rare to see, but it can be convenient for picking out the parts\\nof data structures with known shapes.\\nFor example, we’ll see in Chapter 13  that this technique also works in for loops, because\\nloop items are assigned to the target given in the loop header:\\nfor (a, b, c) in [(1, 2, 3), (4, 5, 6)]: ...          # Simple tuple assignment\\nfor ((a, b), c) in [((1, 2), 3), ((4, 5), 6)]: ...    # Nested tuple assignment\\nIn a note in Chapter 18 , we’ll also see that this nested tuple (really, sequence) unpacking\\nassignment form works for function argument lists in Python 2.6 (though not in 3.0),\\nbecause function arguments are passed by assignment as well:\\ndef f(((a, b), c)):              # For arguments too in Python 2.6, but not 3.0\\nf(((1, 2), 3))\\nSequence-unpacking assignments also give rise to another common coding idiom in\\nPython—assigning an integer series to a set of variables:\\n>>> red, green, blue = range(3)\\n>>> red, blue\\n(0, 2)\\nThis initializes the three names to the integer codes 0, 1, and 2, respectively (it’s Python’s\\nequivalent of the enumerated data types you may have seen in other languages). To\\nmake sense of this, you need to know that the range built-in function generates a list\\nof successive integers:\\nAssignment Statements | 283\", metadata={'source': 'python.pdf', 'page': 333}),\n",
       " Document(page_content='>>> range(3)                             # Use list(range(3)) in Python 3.0\\n[0, 1, 2]\\nBecause range is commonly used in for loops, we’ll say more about it in Chapter 13.\\nAnother place you \\nmay see a tuple assignment at work is for splitting a sequence into\\nits front and the rest in loops like this:\\n>>> L = [1, 2, 3, 4]\\n>>> while L:\\n...     front, L = L[0], L[1:]           # See next section for 3.0 alternative\\n...     print(front, L)\\n...\\n1 [2, 3, 4]\\n2 [3, 4]\\n3 [4]\\n4 []\\nThe tuple assignment in the loop here could be coded as the following two lines instead,\\nbut it’s often more convenient to string them together:\\n...     front = L[0]\\n...     L = L[1:]\\nNotice that this code is using the list as a sort of stack data structure, which can often\\nalso be achieved with the append and pop methods of list objects; here, front =\\nL.pop(0) would have much the same effect as the tuple assignment statement, but it\\nwould be an in-place change. We’ll learn more about while loops, and other (often\\nbetter) ways to step through a sequence with for loops, in Chapter 13.\\nExtended Sequence Unpacking in Python 3.0\\nThe prior section demonstrated how to use manual slicing to make sequence assign-\\nments more general. In Python 3.0 (but not 2.6), sequence assignment has been gen-\\neralized to make this easier. In short, a single starred name, *X, can be used in the\\nassignment target in order to specify a more general matching against the sequence—\\nthe starred name is assigned a list, which collects all items in the sequence not assigned\\nto other names. This is especially handy for common coding patterns such as splitting\\na sequence into its “front” and “rest”, as in the preceding section’s last example.\\nExtended unpacking in action\\nLet’s look at an example. As we’ve seen, sequence assignments normally require exactly\\nas many names in the target on the left as there are items in the subject on the right.\\nWe get an error if the lengths disagree (unless we manually sliced on the right, as shown\\nin the prior section):\\nC:\\\\misc> c:\\\\python30\\\\python\\n>>> seq = [1, 2, 3, 4]\\n>>> a, b, c, d = seq\\n>>> print(a, b, c, d)\\n1 2 3 4\\n284 | Chapter 11: \\u2002Assignments, Expressions, and Prints', metadata={'source': 'python.pdf', 'page': 334}),\n",
       " Document(page_content=\">>> a, b = seq\\nValueError: too many values to unpack\\nIn Python 3.0, \\nthough, we can use a single starred name in the target to match more\\ngenerally. In the following continuation of our interactive session, a matches the first\\nitem in the sequence, and b matches the rest:\\n>>> a, *b = seq\\n>>> a\\n1\\n>>> b\\n[2, 3, 4]\\nWhen a starred name is used, the number of items in the target on the left need not\\nmatch the length of the subject sequence. In fact, the starred name can appear anywhere\\nin the target. For instance, in the next interaction b matches the last item in the se-\\nquence, and a matches everything before the last:\\n>>> *a, b = seq\\n>>> a\\n[1, 2, 3]\\n>>> b\\n4\\nWhen the starred name appears in the middle, it collects everything between the other\\nnames listed. Thus, in the following interaction a and c are assigned the first and last\\nitems, and b gets everything in between them:\\n>>> a, *b, c = seq\\n>>> a\\n1\\n>>> b\\n[2, 3]\\n>>> c\\n4\\nMore generally, wherever the starred name shows up, it will be assigned a list that\\ncollects every unassigned name at that position:\\n>>> a, b, *c = seq\\n>>> a\\n1\\n>>> b\\n2\\n>>> c\\n[3, 4]\\nNaturally, like normal sequence assignment, extended sequence unpacking syntax\\nworks for any sequence types, not just lists. Here it is unpacking characters in a string:\\n>>> a, *b = 'spam'\\n>>> a, b\\n('s', ['p', 'a', 'm'])\\n>>> a, *b, c = 'spam'\\nAssignment Statements | 285\", metadata={'source': 'python.pdf', 'page': 335}),\n",
       " Document(page_content=\">>> a, b, c\\n('s', ['p', 'a'], 'm')\\nThis is similar \\nin spirit to slicing, but not exactly the same—a sequence unpacking\\nassignment always returns a list for multiple matched items, whereas slicing returns a\\nsequence of the same type as the object sliced:\\n>>> S = 'spam'\\n>>> S[0], S[1:]    # Slices are type-specific, * assignment always returns a list\\n('s', 'pam')\\n>>> S[0], S[1:3], S[3]\\n('s', 'pa', 'm')\\nGiven this extension in 3.0, as long as we’re processing a list the last example of the\\nprior section becomes even simpler, since we don’t have to manually slice to get the\\nfirst and rest of the items:\\n>>> L = [1, 2, 3, 4]\\n>>> while L:\\n...     front, *L = L                    # Get first, rest without slicing\\n...     print(front, L)\\n...\\n1 [2, 3, 4]\\n2 [3, 4]\\n3 [4]\\n4 []\\nBoundary cases\\nAlthough extended sequence unpacking is flexible, some boundary cases are worth\\nnoting. First, the starred name may match just a single item, but is always assigned a list:\\n>>> seq\\n[1, 2, 3, 4]\\n>>> a, b, c, *d = seq\\n>>> print(a, b, c, d)\\n1 2 3 [4]\\nSecond, if there is nothing left to match the starred name, it is assigned an empty list,\\nregardless of where it appears. In the following, a, b, c, and d have matched every item\\nin the sequence, but Python assigns e an empty list instead of treating this as an error\\ncase:\\n>>> a, b, c, d, *e = seq\\n>>> print(a, b, c, d, e)\\n1 2 3 4 []\\n>>> a, b, *e, c, d = seq\\n>>> print(a, b, c, d, e)\\n1 2 3 4 []\\n286 | Chapter 11: \\u2002Assignments, Expressions, and Prints\", metadata={'source': 'python.pdf', 'page': 336}),\n",
       " Document(page_content='Finally, errors can still be triggered if there is more than one starred name, if there are\\ntoo few values \\nand no star (as before), and if the starred name is not itself coded inside\\na sequence:\\n>>> a, *b, c, *d = seq\\nSyntaxError: two starred expressions in assignment\\n>>> a, b = seq\\nValueError: too many values to unpack\\n>>> *a = seq\\nSyntaxError: starred assignment target must be in a list or tuple\\n>>> *a, = seq\\n>>> a\\n[1, 2, 3, 4]\\nA useful convenience\\nKeep in mind that extended sequence unpacking assignment is just a convenience. We\\ncan usually achieve the same effects with explicit indexing and slicing (and in fact must\\nin Python 2.X), but extended unpacking is simpler to code. The common “first, rest”\\nsplitting coding pattern, for example, can be coded either way, but slicing involves extra\\nwork:\\n>>> seq\\n[1, 2, 3, 4]\\n>>> a, *b = seq                        # First, rest\\n>>> a, b\\n(1, [2, 3, 4])\\n>>> a, b = seq[0], seq[1:]             # First, rest: traditional\\n>>> a, b\\n(1, [2, 3, 4])\\nThe also common “rest, last” splitting pattern can similarly be coded either way, but\\nthe new extended unpacking syntax requires noticeably fewer keystrokes:\\n>>> *a, b = seq                        # Rest, last\\n>>> a, b\\n([1, 2, 3], 4)\\n>>> a, b = seq[:-1], seq[-1]           # Rest, last: traditional\\n>>> a, b\\n([1, 2, 3], 4)\\nBecause it is not only simpler but, arguably, more natural, extended sequence unpack-\\ning syntax will likely become widespread in Python code over time.\\nAssignment Statements | 287', metadata={'source': 'python.pdf', 'page': 337}),\n",
       " Document(page_content=\"Application to for loops\\nBecause the loop \\nvariable in the for loop statement can be any assignment target, ex-\\ntended sequence assignment works here too. We met the for loop iteration tool briefly\\nin Part II  and will study it formally in Chapter 13 . In Python 3.0, extended assignments\\nmay show up after the word for, where a simple variable name is more commonly used:\\nfor (a, *b, c) in [(1, 2, 3, 4), (5, 6, 7, 8)]:\\n    ...\\nWhen used in this context, on each iteration Python simply assigns the next tuple of\\nvalues to the tuple of names. On the first loop, for example, it’s as if we’d run the\\nfollowing assignment statement:\\na, *b, c = (1, 2, 3, 4)                            # b gets [2, 3]\\nThe names a, b, and c can be used within the loop’s code to reference the extracted\\ncomponents. In fact, this is really not a special case at all, but just an instance of general\\nassignment at work. As we saw earlier in this chapter, we can do the same thing with\\nsimple tuple assignment in both Python 2.X and 3.X:\\nfor (a, b, c) in [(1, 2, 3), (4, 5, 6)]:           # a, b, c = (1, 2, 3), ...\\nAnd we can always emulate 3.0’s extended assignment behavior in 2.6 by manually\\nslicing:\\nfor all in [(1, 2, 3, 4), (5, 6, 7, 8)]:\\n    a, b, c = all[0], all[1:3], all[3]\\nSince we haven’t learned enough to get more detailed about the syntax of for loops,\\nwe’ll return to this topic in Chapter 13.\\nMultiple-Target Assignments\\nA multiple-target assignment simply assigns all the given names to the object all the\\nway to the right. The following, for example, assigns the three variables a, b, and c to\\nthe string 'spam':\\n>>> a = b = c = 'spam'\\n>>> a, b, c\\n('spam', 'spam', 'spam')\\nThis form is equivalent to (but easier to code than) these three assignments:\\n>>> c = 'spam'\\n>>> b = c\\n>>> a = b\\nMultiple-target assignment and shared references\\nKeep in mind that there is just one object here, shared by all three variables (they all\\nwind up pointing to the same object in memory). This behavior is fine for immutable\\ntypes—for example, when initializing a set of counters to zero (recall that variables\\n288 | Chapter 11: \\u2002Assignments, Expressions, and Prints\", metadata={'source': 'python.pdf', 'page': 338}),\n",
       " Document(page_content='must be assigned before they can be used in Python, so you must initialize counters to\\nzero before you can start adding to them):\\n>>> a = b = 0\\n>>> b = b + 1\\n>>> a, b\\n(0, 1)\\nHere, changing b \\nonly changes b because numbers do not support in-place changes. As\\nlong as the object assigned is immutable, it’s irrelevant if more than one name references\\nit.\\nAs usual, though, we have to be more cautious when initializing variables to an empty\\nmutable object such as a list or dictionary:\\n>>> a = b = []\\n>>> b.append(42)\\n>>> a, b\\n([42], [42])\\nThis time, because a and b reference the same object, appending to it in-place through\\nb will impact what we see through a as well. This is really just another example of the\\nshared reference phenomenon we first met in Chapter 6 . To avoid the issue, initialize\\nmutable objects in separate statements instead, so that each creates a distinct empty\\nobject by running a distinct literal expression:\\n>>> a = []\\n>>> b = []\\n>>> b.append(42)\\n>>> a, b\\n([], [42])\\nAugmented Assignments\\nBeginning with Python 2.0, the set of additional assignment statement formats listed\\nin Table 11-2 became available. Known as augmented assignments, and borrowed from\\nthe C language, these formats are mostly just shorthand. They imply the combination\\nof a binary expression and an assignment. For instance, the following two formats are\\nnow roughly equivalent:\\nX = X + Y                       # Traditional form\\nX += Y                          # Newer augmented form\\nTable 11-2. Augmented assignment statements\\nX += Y X &= Y X -= Y X |= Y\\nX *= Y X ^= Y X /= Y X >>= Y\\nX %= Y X <<= Y X **= Y X //= Y\\nAugmented assignment works on any type that supports the implied binary expression.\\nFor example, here are two ways to add 1 to a name:\\nAssignment Statements | 289', metadata={'source': 'python.pdf', 'page': 339}),\n",
       " Document(page_content='>>> x = 1\\n>>> x = x + 1                   # Traditional\\n>>> x\\n2\\n>>> x += 1                      # Augmented\\n>>> x\\n3\\nWhen applied to \\na string, the augmented form performs concatenation instead. Thus,\\nthe second line here is equivalent to typing the longer S = S + \"SPAM\":\\n>>> S = \"spam\"\\n>>> S += \"SPAM\"                 # Implied concatenation\\n>>> S\\n\\'spamSPAM\\'\\nAs shown in Table 11-2 , there are analogous augmented assignment forms for every\\nPython binary expression operator (i.e., each operator with values on the left and right\\nside). For instance, X *= Y  multiplies and assigns, X >>= Y  shifts right and assigns, and\\nso on. X //= Y (for floor division) was added in version 2.2.\\nAugmented assignments have three advantages:*\\n• There’s less for you to type. Need I say more?\\n• The left side only has to be evaluated once. In X += Y, X may be a complicated object\\nexpression. In the augmented form, it only has to be evaluated once. However, in\\nthe long form, X = X + Y , X appears twice and must be run twice. Because of this,\\naugmented assignments usually run faster.\\n• The optimal technique is automatically chosen. That is, for objects that support\\nin-place changes, the augmented forms automatically perform in-place change op-\\nerations instead of slower copies.\\nThe last point here requires a bit more explanation. For augmented assignments, in-\\nplace operations may be applied for mutable objects as an optimization. Recall that\\nlists can be extended in a variety of ways. To add a single item to the end of a list, we\\ncan concatenate or call append:\\n>>> L = [1, 2]\\n>>> L = L + [3]                 # Concatenate: slower\\n>>> L\\n[1, 2, 3]\\n>>> L.append(4)                 # Faster, but in-place\\n>>> L\\n[1, 2, 3, 4]\\n* C/C++ programmers take note: although Python now supports statements like X += Y , it still does not have\\nC’s auto-increment/decrement operators (e.g., X++, −−X). These don’t quite map to the Python object model\\nbecause Python has no notion of in-place changes to immutable objects like numbers.\\n290 | Chapter 11: \\u2002Assignments, Expressions, and Prints', metadata={'source': 'python.pdf', 'page': 340}),\n",
       " Document(page_content='And to add a set of items to the end, we can either concatenate again or call the list\\nextend method:†\\n>>> L = L + [5, 6]              # Concatenate: slower\\n>>> L\\n[1, 2, 3, 4, 5, 6]\\n>>> L.extend([7, 8])            # Faster, but in-place\\n>>> L\\n[1, 2, 3, 4, 5, 6, 7, 8]\\nIn both cases, \\nconcatenation is less prone to the side effects of shared object references\\nbut will generally run slower than the in-place equivalent. Concatenation operations\\nmust create a new object, copy in the list on the left, and then copy in the list on the\\nright. By contrast, in-place method calls simply add items at the end of a memory block.\\nWhen we use augmented assignment to extend a list, we can forget these details—for\\nexample, Python automatically calls the quicker extend method instead of using the\\nslower concatenation operation implied by +:\\n>>> L += [9, 10]                # Mapped to L.extend([9, 10])\\n>>> L\\n[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\\nAugmented assignment and shared references\\nThis behavior is usually what we want, but notice that it implies that the += is an in-\\nplace change for lists; thus, it is not exactly like + concatenation, which always makes\\na new object. As for all shared reference cases, this difference might matter if other\\nnames reference the object being changed:\\n>>> L = [1, 2]\\n>>> M = L                       # L and M reference the same object\\n>>> L = L + [3, 4]              # Concatenation makes a new object\\n>>> L, M                        # Changes L but not M\\n([1, 2, 3, 4], [1, 2])\\n>>> L = [1, 2]\\n>>> M = L\\n>>> L += [3, 4]                 # But += really means extend\\n>>> L, M                        # M sees the in-place change too!\\n([1, 2, 3, 4], [1, 2, 3, 4])\\nThis only matters for mutables like lists and dictionaries, and it is a fairly obscure case\\n(at least, until it impacts your code!). As always, make copies of your mutable objects\\nif you need to break the shared reference structure.\\n† As suggested in Chapter 6 , we can also use slice assignment (e.g., L[len(L):] = [11,12,13] ), but this works\\nroughly the same as the simpler list extend method.\\nAssignment Statements | 291', metadata={'source': 'python.pdf', 'page': 341}),\n",
       " Document(page_content='Variable Name Rules\\nNow that we’ve \\nexplored assignment statements, it’s time to get more formal about the\\nuse of variable names. In Python, names come into existence when you assign values\\nto them, but there are a few rules to follow when picking names for things in your\\nprograms:\\nSyntax: (underscore or letter) + (any number of letters, digits, or underscores)\\nVariable names must start with an underscore or letter, which can be followed by\\nany number of letters, digits, or underscores. _spam, spam, and Spam_1 are legal\\nnames, but 1_Spam, spam$, and @#! are not.\\nCase matters: SPAM is not the same as spam\\nPython always pays attention to case in programs, both in names you create and\\nin reserved words. For instance, the names X and x refer to two different variables.\\nFor portability, case also matters in the names of imported module files, even on\\nplatforms where the filesystems are case-insensitive.\\nReserved words are off-limits\\nNames you define cannot be the same as words that mean special things in the\\nPython language. For instance, if you try to use a variable name like class, Python\\nwill raise a syntax error, but klass and Class work fine. Table 11-3  lists the words\\nthat are currently reserved (and hence off-limits for names of your own) in Python.\\nTable 11-3. Python 3.0 reserved words\\nFalse class finally is return\\nNone continue for lambda try\\nTrue def from nonlocal while\\nand del global not with\\nas elif if or yield\\nassert else import pass  \\nbreak except in raise  \\nTable 11-3  is specific to Python 3.0. In Python 2.6, the set of reserved words differs\\nslightly:\\n•print \\nis a reserved word, because printing is a statement, not a built-in (more on\\nthis later in this chapter).\\n•exec is a reserved word, because it is a statement, not a built-in function.\\n•nonlocal is not a reserved word because this statement is not available.\\nIn older Pythons the story is also more or less the same, with a few variations:\\n292 | Chapter 11: \\u2002Assignments, Expressions, and Prints', metadata={'source': 'python.pdf', 'page': 342}),\n",
       " Document(page_content='•with and as were not reserved until 2.6, when context managers were officially\\nenabled.\\n•yield was not reserved until Python 2.3, when generator functions were enabled.\\n•yield morphed from statement to expression in 2.5, but it’s still a reserved word,\\nnot a built-in function.\\nAs you can see, most of Python’s reserved words are all lowercase. They are also all\\ntruly reserved—unlike names in the built-in scope that you will meet in the next part\\nof this book, you cannot redefine reserved words by assignment (e.g., and = 1 results\\nin a syntax error).‡\\nBesides being of mixed case, the first three entries in Table 11-3, True, False, and\\nNone, are somewhat unusual in meaning—they also appear in the built-in scope of\\nPython described in Chapter 17 , and they are technically names assigned to objects.\\nThey are truly reserved in all other senses, though, and cannot be used for any other\\npurpose in your script other than that of the objects they represent. All the other re-\\nserved words are hardwired into Python’s syntax and can appear only in the specific\\ncontexts for which they are intended.\\nFurthermore, because module names in import statements become variables in your\\nscripts, variable name constraints extend to your module filenames too. For instance,\\nyou can code files called and.py and my-code.py and run them as top-level scripts, but\\nyou cannot import them: their names without the “.py” extension become variables in\\nyour code and so must follow all the variable rules just outlined. Reserved words are\\noff-limits, and dashes won’t work, though underscores will. We’ll revisit this idea in\\nPart V of this book.\\nPython’s Deprecation Protocol\\nIt is interesting \\nto note how reserved word changes are gradually phased into the lan-\\nguage. When a new feature might break existing code, Python normally makes it an\\noption and begins issuing “deprecation” warnings one or more releases before the fea-\\nture is officially enabled. The idea is that you should have ample time to notice the\\nwarnings and update your code before migrating to the new release. This is not true\\nfor major new releases like 3.0 (which breaks existing code freely), but it is generally\\ntrue in other cases.\\nFor example, yield was an optional extension in Python 2.2, but is a standard keyword\\nas of 2.3. It is used in conjunction with generator functions. This was one of a small\\nhandful of instances where Python broke with backward compatibility. Still, yield was\\nphased in over time: it began generating deprecation warnings in 2.2 and was not en-\\nabled until 2.3.\\n‡ In the Jython Java-based implementation of Python, though, user-defined variable names can sometimes be\\nthe same as Python reserved words. See Chapter 2\\n for an overview of the Jython system.\\nAssignment Statements | 293', metadata={'source': 'python.pdf', 'page': 343}),\n",
       " Document(page_content='Similarly, in Python 2.6, the words with and as become new reserved words for use in\\ncontext managers (a \\nnewer form of exception handling). These two words are not re-\\nserved in 2.5, unless the context manager feature is turned on manually with a\\nfrom__future__import (discussed later in this book). When used in 2.5, with and as\\ngenerate warnings about the upcoming change—except in the version of IDLE in Py-\\nthon 2.5, which appears to have enabled this feature for you (that is, using these words\\nas variable names does generate errors in 2.5, but only in its version of the IDLE GUI).\\nNaming conventions\\nBesides these rules, \\nthere is also a set of naming conventions—rules that are not required\\nbut are followed in normal practice. For instance, because names with two leading and\\ntrailing underscores (e.g., __name__) generally have special meaning to the Python in-\\nterpreter, you should avoid this pattern for your own names. Here is a list of the con-\\nventions Python follows:\\n• Names that begin with a single underscore ( _X) are not imported by a from module\\nimport * statement (described in Chapter 22).\\n• Names that have two leading and trailing underscores ( __X__) are system-defined\\nnames that have special meaning to the interpreter.\\n• Names that begin with two underscores and do not end with two more ( __X) are\\nlocalized (“mangled”) to enclosing classes (see the discussion of pseudoprivate\\nattributes in Chapter 30).\\n• The name that is just a single underscore ( _) retains the result of the last expression\\nwhen working interactively.\\nIn addition to these Python interpreter conventions, there are various other conventions\\nthat Python programmers usually follow. For instance, later in the book we’ll see that\\nclass names commonly start with an uppercase letter and module names with a low-\\nercase letter, and that the name self, though not reserved, usually has a special role in\\nclasses. In Chapter 17  we’ll also study another, larger category of names known as the\\nbuilt-ins, which are predefined but not reserved (and so can be reassigned: open = 42\\nworks, though sometimes you might wish it didn’t!).\\nNames have no type, but objects do\\nThis is mostly review, but remember that it’s crucial to keep Python’s distinction be-\\ntween names and objects clear. As described in Chapter 6, objects have a type (e.g.,\\ninteger, list) and may be mutable or not. Names (a.k.a. variables), on the other hand,\\nare always just references to objects; they have no notion of mutability and have no\\nassociated type information, apart from the type of the object they happen to reference\\nat a given point in time.\\n294 | Chapter 11: \\u2002Assignments, Expressions, and Prints', metadata={'source': 'python.pdf', 'page': 344}),\n",
       " Document(page_content='Thus, it’s OK to assign the same name to different kinds of objects at different times:\\n>>> x = 0               # x bound to an integer object\\n>>> x = \"Hello\"         # Now it\\'s a string\\n>>> x = [1, 2, 3]       # And now it\\'s a list\\nIn later examples, \\nyou’ll see that this generic nature of names can be a decided advantage\\nin Python programming. In Chapter 17 , you’ll also learn that names also live in some-\\nthing called a scope, which defines where they can be used; the place where you assign\\na name determines where it is visible.§\\nFor additional naming suggestions, see the previous section “Naming\\nconventions” of Python’s \\nsemi-official style guide, known as PEP 8 . This\\nguide is available at http://www.python.org/dev/peps/pep-0008, or via a\\nweb search for “Python PEP 8.” Technically, this document formalizes\\ncoding standards for Python library code.\\nThough useful, the usual caveats about coding standards apply here.\\nFor one thing, PEP 8 comes with more detail than you are probably ready\\nfor at this point in the book. And frankly, it has become more complex,\\nrigid, and subjective than it needs to be—some of its suggestions are not\\nat all universally accepted or followed by Python programmers doing\\nreal work. Moreover, some of the most prominent companies using Py-\\nthon today have adopted coding standards of their own that differ.\\nPEP 8 does codify useful rule-of-thumb Python knowledge, though, and\\nit’s a great read for Python beginners, as long as you take its recom-\\nmendations as guidelines, not gospel.\\nExpression Statements\\nIn Python, you can use an expression as a statement, too—that is, on a line by itself.\\nBut because the result of the expression won’t be saved, it usually makes sense to do\\nso only if the expression does something useful as a side effect. Expressions are com-\\nmonly used as statements in two situations:\\nFor calls to functions and methods\\nSome functions and methods do lots of work without returning a value. Such\\nfunctions are sometimes called procedures in other languages. Because they don’t\\nreturn values that you might be interested in retaining, you can call these functions\\nwith expression statements.\\n§ If you’ve used a more restrictive language like C++, you may be interested to know that there is no notion\\nof C++’s const  \\ndeclaration in Python; certain objects may be immutable, but names can always be assigned.\\nPython also has ways to hide names in classes and modules, but they’re not the same as C++’s declarations\\n(if hiding attributes matters to you, see the coverage of _X module names in Chapter 24 , __X class names in\\nChapter 30, and the Private and Public class decorators example in Chapter 38).\\nExpression Statements | 295', metadata={'source': 'python.pdf', 'page': 345}),\n",
       " Document(page_content=\"For printing values at the interactive prompt\\nPython echoes back \\nthe results of expressions typed at the interactive command\\nline. Technically, these are expression statements, too; they serve as a shorthand\\nfor typing print statements.\\nTable 11-4 lists some common expression statement forms in Python. Calls to functions\\nand methods are coded with zero or more argument objects (really, expressions that\\nevaluate to objects) in parentheses, after the function/method name.\\nTable 11-4. Common Python expression statements\\nOperation Interpretation\\nspam(eggs, ham) Function calls\\nspam.ham(eggs) Method calls\\nspam Printing variables in the interactive interpreter\\nprint(a, b, c, sep='') Printing operations in Python 3.0\\nyield x ** 2 Yielding expression statements\\nThe last two entries in Table 11-4  are somewhat special cases—as we’ll see later in this\\nchapter, printing in Python 3.0 is a function call usually coded on a line by itself, and\\nthe yield operation in generator functions (discussed in Chapter 20 ) is often coded as\\na statement as well. Both are really just instances of expression statements.\\nFor instance, though you normally run a print call on a line by itself as an expression\\nstatement, it returns a value like any other function call (its return value is None, the\\ndefault return value for functions that don’t return anything meaningful):\\n>>> x = print('spam')         # print is a function call expression in 3.0\\nspam\\n>>> print(x)                  # But it is coded as an expression statement\\nNone\\nAlso keep in mind that although expressions can appear as statements in Python, state-\\nments cannot be used as expressions. For example, Python doesn’t allow you to embed\\nassignment statements (=) in other expressions. The rationale for this is that it avoids\\ncommon coding mistakes; you can’t accidentally change a variable by typing = when\\nyou really mean to use the == equality test. You’ll see how to code around this when\\nyou meet the Python while loop in Chapter 13.\\nExpression Statements and In-Place Changes\\nThis brings up a mistake that is common in Python work. Expression statements are\\noften used to run list methods that change a list in-place:\\n>>> L = [1, 2]\\n>>> L.append(3)               # Append is an in-place change\\n>>> L\\n[1, 2, 3]\\n296 | Chapter 11: \\u2002Assignments, Expressions, and Prints\", metadata={'source': 'python.pdf', 'page': 346}),\n",
       " Document(page_content='However, it’s not unusual for Python newcomers to code such an operation as an as-\\nsignment statement instead, intending to assign L to the larger list:\\n>>> L = L.append(4)           # But append returns None, not L\\n>>> print(L)                  # So we lose our list!\\nNone\\nThis doesn’t quite \\nwork, though. Calling an in-place change operation such as append,\\nsort, or reverse on a list always changes the list in-place, but these methods do not\\nreturn the list they have changed; instead, they return the None object. Thus, if you\\nassign such an operation’s result back to the variable name, you effectively lose the list\\n(and it is probably garbage collected in the process!).\\nThe moral of the story is, don’t do this. We’ll revisit this phenomenon in the section\\n“Common Coding Gotchas” on page 387 at the end of this part of the book because\\nit can also appear in the context of some looping statements we’ll meet in later chapters.\\nPrint Operations\\nIn Python, print prints things—it’s simply a programmer-friendly interface to the\\nstandard output stream.\\nTechnically, printing converts one or more objects to their textual representations, adds\\nsome minor formatting, and sends the resulting text to either standard output or an-\\nother file-like stream. In a bit more detail, print is strongly bound up with the notions\\nof files and streams in Python:\\nFile object methods\\nIn Chapter 9, we learned about file object methods that write text (e.g.,\\nfile.write(str)). Printing operations are similar, but more focused—whereas file\\nwrite methods write strings to arbitrary files, print writes objects to the stdout\\nstream by default, with some automatic formatting added. Unlike with file meth-\\nods, there is no need to convert objects to strings when using print operations.\\nStandard output stream\\nThe standard output stream (often known as stdout) is simply a default place to\\nsend a program’s text output. Along with the standard input and error streams,\\nit’s one of three data connections created when your script starts. The standard\\noutput stream is usually mapped to the window where you started your Python\\nprogram, unless it’s been redirected to a file or pipe in your operating system’s shell.\\nBecause the standard output stream is available in Python as the stdout file object\\nin the built-in sys module (i.e., sys.stdout), it’s possible to emulate print with file\\nwrite method calls. However, print is noticeably easier to use and makes it easy to\\nprint text to other files and streams.\\nPrint Operations | 297', metadata={'source': 'python.pdf', 'page': 347}),\n",
       " Document(page_content=\"Printing is also one of the most visible places where Python 3.0 and 2.6 have diverged.\\nIn fact, this \\ndivergence is usually the first reason that most 2.X code won’t run un-\\nchanged under 3.X. Specifically, the way you code print operations depends on which\\nversion of Python you use:\\n• In Python 3.X, printing is a built-in function , with keyword arguments for special\\nmodes.\\n• In Python 2.X, printing is a statement with specific syntax all its own.\\nBecause this book covers both 3.0 and 2.6, we will look at each form in turn here. If\\nyou are fortunate enough to be able to work with code written for just one version of\\nPython, feel free to pick the section that is relevant to you; however, as your circum-\\nstances may change, it probably won’t hurt to be familiar with both cases.\\nThe Python 3.0 print Function\\nStrictly speaking, printing is not a separate statement form in 3.0. Instead, it is simply\\nan instance of the expression statement we studied in the preceding section.\\nThe print built-in function is normally called on a line of its own, because it doesn’t\\nreturn any value we care about (technically, it returns None). Because it is a normal\\nfunction, though, printing in 3.0 uses standard function-call syntax , rather than a special\\nstatement form. Because it provides special operation modes with keyword arguments,\\nthis form is both more general and supports future enhancements better.\\nBy comparison, Python 2.6 print statements have somewhat ad-hoc syntax to support\\nextensions such as end-of-line suppression and target files. Further, the 2.6 statement\\ndoes not support separator specification at all; in 2.6, you wind up building strings\\nahead of time more often than you do in 3.0.\\nCall format\\nSyntactically, calls to the 3.0 print function have the following form:\\nprint([object, ...][, sep=' '][, end='\\\\n'][, file=sys.stdout])\\nIn this formal notation, items in square brackets are optional and may be omitted in a\\ngiven call, and values after = give argument defaults. In English, this built-in function\\nprints the textual representation of one or more objects separated by the string sep and\\nfollowed by the string end to the stream file.\\nThe sep, end, and file parts, if present, must be given as keyword arguments —that is,\\nyou must use a special “name=value” syntax to pass the arguments by name instead of\\nposition. Keyword arguments are covered in depth in Chapter 18 , but they’re straight-\\nforward to use. The keyword arguments sent to this call may appear in any left-to-right\\norder following the objects to be printed, and they control the print operation:\\n298 | Chapter 11: \\u2002Assignments, Expressions, and Prints\", metadata={'source': 'python.pdf', 'page': 348}),\n",
       " Document(page_content=\"•sep is a string inserted between each object’s text, which defaults to a single space\\nif not passed; passing an empty string suppresses separators altogether.\\n•end \\nis a string added at the end of the printed text, which defaults to a \\\\n newline\\ncharacter if not passed. Passing an empty string avoids dropping down to the next\\noutput line at the end of the printed text—the next print will keep adding to the\\nend of the current output line.\\n•file specifies the file, standard stream, or other file-like object to which the text\\nwill be sent; it defaults to the sys.stdout standard output stream if not passed. Any\\nobject with a file-like write(string) method may be passed, but real files should\\nbe already opened for output.\\nThe textual representation of each object to be printed is obtained by passing the object\\nto the str built-in call; as we’ve seen, this built-in returns a “user friendly” display string\\nfor any object.‖ With no arguments at all, the print function simply prints a newline\\ncharacter to the standard output stream, which usually displays a blank line.\\nThe 3.0 print function in action\\nPrinting in 3.0 is probably simpler than some of its details may imply. To illustrate,\\nlet’s run some quick examples. The following prints a variety of object types to the\\ndefault standard output stream, with the default separator and end-of-line formatting\\nadded (these are the defaults because they are the most common use case):\\nC:\\\\misc> c:\\\\python30\\\\python\\n>>>\\n>>> print()                                      # Display a blank line\\n>>> x = 'spam'\\n>>> y = 99\\n>>> z = ['eggs']\\n>>>\\n>>> print(x, y, z)                               # Print 3 objects per defaults\\nspam 99 ['eggs']\\nThere’s no need to convert objects to strings here, as would be required for file write\\nmethods. By default, print calls add a space between the objects printed. To suppress\\nthis, send an empty string to the sep keyword argument, or send an alternative separator\\nof your choosing:\\n>>> print(x, y, z, sep='')                       # Suppress separator\\nspam99['eggs']\\n>>>\\n>>> print(x, y, z, sep=', ')                     # Custom separator\\nspam, 99, ['eggs']\\n‖Technically, printing uses the equivalent of str in the internal implementation of Python, but the effect is\\nthe same. Besides this to-string conversion role, str is also the name of the string data type and can be used\\nto decode Unicode strings from raw bytes with an extra encoding argument, as we’ll learn in Chapter 36 ; this\\nlatter role is an advanced usage that we can safely ignore here.\\nPrint Operations | 299\", metadata={'source': 'python.pdf', 'page': 349}),\n",
       " Document(page_content=\"Also by default, print adds an end-of-line character to terminate the output line. You\\ncan suppress this and avoid the line break altogether by passing an empty string to the\\nend keyword argument, or you can pass a different terminator of your own (include a\\n\\\\n character to break the line manually):\\n>>> print(x, y, z, end='')                        # Suppress line break\\nspam 99 ['eggs']>>>\\n>>>\\n>>> print(x, y, z, end=''); print(x, y, z)        # Two prints, same output line\\nspam 99 ['eggs']spam 99 ['eggs']\\n>>> print(x, y, z, end='...\\\\n')                   # Custom line end\\nspam 99 ['eggs']...\\n>>>\\nYou can also combine keyword arguments to specify both separators and end-of-line\\nstrings—they may appear in any order but must appear after all the objects being\\nprinted:\\n>>> print(x, y, z, sep='...', end='!\\\\n')          # Multiple keywords\\nspam...99...['eggs']!\\n>>> print(x, y, z, end='!\\\\n', sep='...')          # Order doesn't matter\\nspam...99...['eggs']!\\nHere is how the file keyword argument is used—it directs the printed text to an open\\noutput file or other compatible object for the duration of the single print (this is really\\na form of stream redirection, a topic we will revisit later in this section):\\n>>> print(x, y, z, sep='...', file=open('data.txt', 'w'))      # Print to a file\\n>>> print(x, y, z)                                             # Back to stdout\\nspam 99 ['eggs']\\n>>> print(open('data.txt').read())                             # Display file text\\nspam...99...['eggs']\\nFinally, keep in mind that the separator and end-of-line options provided by print op-\\nerations are just conveniences. If you need to display more specific formatting, don’t\\nprint this way, Instead, build up a more complex string ahead of time or within the\\nprint itself using the string tools we met in Chapter 7 , and print the string all at once:\\n>>> text = '%s: %-.4f, %05d' % ('Result', 3.14159, 42)\\n>>> print(text)\\nResult: 3.1416, 00042\\n>>> print('%s: %-.4f, %05d' % ('Result', 3.14159, 42))\\nResult: 3.1416, 00042\\nAs we’ll see in the next section, almost everything we’ve just seen about the 3.0 print\\nfunction also applies directly to 2.6 print statements—which makes sense, given that\\nthe function was intended to both emulate and improve upon 2.6 printing support.\\nThe Python 2.6 print Statement\\nAs mentioned earlier, printing in Python 2.6 uses a statement with unique and specific\\nsyntax, rather than a built-in function. In practice, though, 2.6 printing is mostly a\\nvariation on a theme; with the exception of separator strings (which are supported in\\n300 | Chapter 11: \\u2002Assignments, Expressions, and Prints\", metadata={'source': 'python.pdf', 'page': 350}),\n",
       " Document(page_content=\"3.0 but not 2.6), everything we can do with the 3.0 print function has a direct trans-\\nlation to the 2.6 print statement.\\nStatement forms\\nTable 11-5 lists the print statement’s forms in Python 2.6 and gives their Python 3.0\\nprint function equivalents for reference. Notice that the comma is significant in\\nprint statements—it separates objects to be printed, and a trailing comma suppresses\\nthe end-of-line character normally added at the end of the printed text (not to be con-\\nfused with tuple syntax!). The >> syntax, normally used as a bitwise right-shift opera-\\ntion, is used here as well, to specify a target output stream other than the sys.stdout\\ndefault.\\nTable 11-5. Python 2.6 print statement forms\\nPython 2.6 statement Python 3.0 equivalent Interpretation\\nprint x, y print(x, y) Print objects’ textual\\nforms to sys.stdout;\\nadd a space between the\\nitems and an end-of-line\\nat the end\\nprint x, y, print(x, y, end='') Same, but don’t add\\nend-of-line at end of text\\nprint >> afile, x, y print(x, y, file=afile) Send text to\\nmyfile.write, not to\\nsys.stdout.write\\nThe 2.6 print statement in action\\nAlthough the 2.6 print\\n statement has more unique syntax than the 3.0 function, it’s\\nsimilarly easy to use. Let’s turn to some basic examples again. By default, the 2.6\\nprint statement adds a space between the items separated by commas and adds a line\\nbreak at the end of the current output line:\\nC:\\\\misc> c:\\\\python26\\\\python\\n>>>\\n>>> x = 'a'\\n>>> y = 'b'\\n>>> print x, y\\na b\\nThis formatting is just a default; you can choose to use it or not. To suppress the line\\nbreak so you can add more text to the current line later, end your print statement with\\na comma, as shown in the second line of Table 11-5  (the following is two statements\\non one line, separated by a semicolon):\\n>>> print x, y,; print x, y\\na b a b\\nPrint Operations | 301\", metadata={'source': 'python.pdf', 'page': 351}),\n",
       " Document(page_content=\"To suppress the space between items, again, don’t print this way. Instead, build up an\\noutput string using \\nthe string concatenation and formatting tools covered in Chap-\\nter 7, and print the string all at once:\\n>>> print x + y\\nab\\n>>> print '%s...%s' % (x, y)\\na...b\\nAs you can see, apart from their special syntax for usage modes, 2.6 print statements\\nare roughly as simple to use as 3.0’s function. The next section uncovers the way that\\nfiles are specified in 2.6 prints.\\nPrint Stream Redirection\\nIn both Python 3.0 and 2.6, printing sends text to the standard output stream by default.\\nHowever, it’s often useful to send it elsewhere—to a text file, for example, to save results\\nfor later use or testing purposes. Although such redirection can be accomplished in\\nsystem shells outside Python itself, it turns out to be just as easy to redirect a script’s\\nstreams from within the script.\\nThe Python “hello world” program\\nLet’s start off with the usual (and largely pointless) language benchmark—the “hello\\nworld” program. To print a “hello world” message in Python, simply print the string\\nper your version’s print operation:\\n>>> print('hello world')               # Print a string object in 3.0\\nhello world\\n>>> print 'hello world'                # Print a string object in 2.6\\nhello world\\nBecause expression results are echoed on the interactive command line, you often don’t\\neven need to use a print statement there—simply type the expressions you’d like to\\nhave printed, and their results are echoed back:\\n>>> 'hello world'                      # Interactive echoes\\n'hello world'\\nThis code isn’t exactly an earth-shattering piece of software mastery, but it serves to\\nillustrate printing behavior. Really, the print operation is just an ergonomic feature of\\nPython—it provides a simple interface to the sys.stdout object, with a bit of default\\nformatting. In fact, if you enjoy working harder than you must, you can also code print\\noperations this way:\\n>>> import sys                         # Printing the hard way\\n>>> sys.stdout.write('hello world\\\\n')\\nhello world\\n302 | Chapter 11: \\u2002Assignments, Expressions, and Prints\", metadata={'source': 'python.pdf', 'page': 352}),\n",
       " Document(page_content=\"This code explicitly calls the write method of sys.stdout —an attribute preset when\\nPython starts up to an open file object connected to the output stream. The print\\noperation hides most of those details, providing a simple tool for simple printing tasks.\\nManual stream redirection\\nSo, why did I just show you the hard way to print? The sys.stdout print equivalent\\nturns out to be the basis of a common technique in Python. In general, print and\\nsys.stdout are directly related as follows. This statement:\\nprint(X, Y)                            # Or, in 2.6: print X, Y\\nis equivalent to the longer:\\nimport sys\\nsys.stdout.write(str(X) + ' ' + str(Y) + '\\\\n')\\nwhich manually performs a string conversion with str, adds a separator and newline\\nwith +, and calls the output stream’s write method. Which would you rather code? (He\\nsays, hoping to underscore the programmer-friendly nature of prints....)\\nObviously, the long form isn’t all that useful for printing by itself. However, it is useful\\nto know that this is exactly what print operations do because it is possible to reas-\\nsign sys.stdout to something different from the standard output stream. In other words,\\nthis equivalence provides a way of making your print operations send their text to other\\nplaces. For example:\\nimport sys\\nsys.stdout = open('log.txt', 'a')       # Redirects prints to a file\\n...\\nprint(x, y, x)                          # Shows up in log.txt\\nHere, we reset sys.stdout to a manually opened file named log.txt, located in the script’s\\nworking directory and opened in append mode (so we add to its current content). After\\nthe reset, every print operation anywhere in the program will write its text to the end\\nof the file log.txt instead of to the original output stream. The print operations are\\nhappy to keep calling sys.stdout’s write method, no matter what sys.stdout happens\\nto refer to. Because there is just one sys module in your process, assigning\\nsys.stdout this way will redirect every print anywhere in your program.\\nIn fact, as this chapter’s upcoming sidebar about print and stdout will explain, you\\ncan even reset sys.stdout to an object that isn’t a file at all, as long as it has the expected\\ninterface: a method named write to receive the printed text string argument. When that\\nobject is a class, printed text can be routed and processed arbitrarily per a write method\\nyou code yourself.\\nThis trick of resetting the output stream is primarily useful for programs originally\\ncoded with print statements. If you know that output should go to a file to begin with,\\nyou can always call file write methods instead. To redirect the output of a print-based\\nPrint Operations | 303\", metadata={'source': 'python.pdf', 'page': 353}),\n",
       " Document(page_content=\"program, though, resetting sys.stdout provides a convenient alternative to changing\\nevery print statement or using system shell-based redirection syntax.\\nAutomatic stream redirection\\nThis technique of redirecting printed text by assigning sys.stdout is commonly used\\nin practice. One potential problem with the last section’s code, though, is that there is\\nno direct way to restore the original output stream should you need to switch back after\\nprinting to a file. Because sys.stdout is just a normal file object, you can always save\\nit and restore it if needed:#\\nC:\\\\misc> c:\\\\python30\\\\python\\n>>> import sys\\n>>> temp = sys.stdout                   # Save for restoring later\\n>>> sys.stdout = open('log.txt', 'a')   # Redirect prints to a file\\n>>> print('spam')                       # Prints go to file, not here\\n>>> print(1, 2, 3)\\n>>> sys.stdout.close()                  # Flush output to disk\\n>>> sys.stdout = temp                   # Restore original stream\\n>>> print('back here')                  # Prints show up here again\\nback here\\n>>> print(open('log.txt').read())       # Result of earlier prints\\nspam\\n1 2 3\\nAs you can see, though, manual saving and restoring of the original output stream like\\nthis involves quite a bit of extra work. Because this crops up fairly often, a print ex-\\ntension is available to make it unnecessary.\\nIn 3.0, the file keyword allows a single print call to send its text to a file’s write method,\\nwithout actually resetting sys.stdout. Because the redirection is temporary, normal\\nprint calls keep printing to the original output stream. In 2.6, a print statement that\\nbegins with a >> followed by an output file object (or other compatible object) has the\\nsame effect. For example, the following again sends printed text to a file named log.txt:\\nlog =  open('log.txt', 'a')             # 3.0\\nprint(x, y, z, file=log)                # Print to a file-like object\\nprint(a, b, c)                          # Print to original stdout\\nlog =  open('log.txt', 'a')             # 2.6\\nprint >> log, x, y, z                   # Print to a file-like object\\nprint a, b, c                           # Print to original stdout\\nThese redirected forms of print are handy if you need to print to both files and the\\nstandard output stream in the same program. If you use these forms, however, be sure\\n#In both 2.6 and 3.0 you may also be able to use the __stdout__ attribute in the sys module, which refers to\\nthe original value sys.stdout had at program startup time. You still need to restore sys.stdout to\\nsys.__stdout__ to go back to this original stream value, though. See the sys module documentation for more\\ndetails.\\n304 | Chapter 11: \\u2002Assignments, Expressions, and Prints\", metadata={'source': 'python.pdf', 'page': 354}),\n",
       " Document(page_content=\"to give them a file object (or an object that has the same write method as a file object),\\nnot a file’s name string. Here is the technique in action:\\nC:\\\\misc> c:\\\\python30\\\\python\\n>>> log = open('log.txt', 'w')\\n>>> print(1, 2, 3, file=log)            # 2.6: print >> log, 1, 2, 3\\n>>> print(4, 5, 6, file=log)\\n>>> log.close()\\n>>> print(7, 8, 9)                      # 2.6: print 7, 8, 9\\n7 8 9\\n>>> print(open('log.txt').read())\\n1 2 3\\n4 5 6\\nThese extended forms of print are also commonly used to print error messages to the\\nstandard error stream, available to your script as the preopened file object\\nsys.stderr. You can either use its file write methods and format the output manually,\\nor print with redirection syntax:\\n>>> import sys\\n>>> sys.stderr.write(('Bad!' * 8) + '\\\\n')\\nBad!Bad!Bad!Bad!Bad!Bad!Bad!Bad!\\n>>> print('Bad!' * 8, file=sys.stderr)     # 2.6: print >> sys.stderr, 'Bad' * 8\\nBad!Bad!Bad!Bad!Bad!Bad!Bad!Bad!\\nNow that you know all about print redirections, the equivalence between printing and\\nfile write methods should be fairly obvious. The following interaction prints both ways\\nin 3.0, then redirects the output to an external file to verify that the same text is printed:\\n>>> X = 1; Y = 2\\n>>> print(X, Y)                                            # Print: the easy way\\n1 2\\n>>> import sys                                             # Print: the hard way\\n>>> sys.stdout.write(str(X) + ' ' + str(Y) + '\\\\n')\\n1 2\\n4\\n>>> print(X, Y, file=open('temp1', 'w'))                   # Redirect text to file\\n>>> open('temp2', 'w').write(str(X) + ' ' + str(Y) + '\\\\n') # Send to file manually\\n4\\n>>> print(open('temp1', 'rb').read())                      # Binary mode for bytes\\nb'1 2\\\\r\\\\n'\\n>>> print(open('temp2', 'rb').read())\\nb'1 2\\\\r\\\\n'\\nAs you can see, unless you happen to enjoy typing, print operations are usually the best\\noption for displaying text. For another example of the equivalence between prints and\\nfile writes, watch for a 3.0 print function emulation example in Chapter 18; it uses this\\ncode pattern to provide a general 3.0 print function equivalent for use in Python 2.6.\\nPrint Operations | 305\", metadata={'source': 'python.pdf', 'page': 355}),\n",
       " Document(page_content=\"Version-Neutral Printing\\nFinally, if you cannot \\nrestrict your work to Python 3.0 but still want your prints to be\\ncompatible with 3.0, you have some options. For one, you can code 2.6 print state-\\nments and let 3.0’s 2to3 conversion script translate them to 3.0 function calls auto-\\nmatically. See the Python 3.0 documentation for more details about this script; it\\nattempts to translate 2.X code to run under 3.0.\\nAlternatively, you can code 3.0 print function calls in your 2.6 code, by enabling the\\nfunction call variant with a statement like the following:\\nfrom __future__ import print_function\\nThis statement changes 2.6 to support 3.0’s print functions exactly. This way, you can\\nuse 3.0 print features and won’t have to change your prints if you later migrate to 3.0.\\nAlso keep in mind that simple prints, like those in the first row of Table 11-5 , work in\\neither version of Python—because any expression may be enclosed in parentheses, we\\ncan always pretend to be calling a 3.0 print function in 2.6 by adding outer parentheses.\\nThe only downside to this is that it makes a tuple out of your printed objects if there\\nare more than one—they will print with extra enclosing parentheses. In 3.0, for exam-\\nple, any number of objects may be listed in the call’s parentheses:\\nC:\\\\misc> c:\\\\python30\\\\python\\n>>> print('spam')                       # 3.0 print function call syntax\\nspam\\n>>> print('spam', 'ham', 'eggs')        # These are mutiple argments\\nspam ham eggs\\nThe first of these works the same in 2.6, but the second generates a tuple in the output:\\nC:\\\\misc> c:\\\\python26\\\\python\\n>>> print('spam')                       # 2.6 print statement, enclosing parens\\nspam\\n>>> print('spam', 'ham', 'eggs')        # This is really a tuple object!\\n('spam', 'ham', 'eggs')\\nTo be truly portable, you can format the print string as a single object, using the string\\nformatting expression or method call, or other string tools that we studied in Chapter 7:\\n>>> print('%s %s %s' % ('spam', 'ham', 'eggs'))\\nspam ham eggs\\n>>> print('{0} {1} {2}'.format('spam', 'ham', 'eggs'))\\nspam ham eggs\\nOf course, if you can use 3.0 exclusively you can forget such mappings entirely, but\\nmany Python programmers will at least encounter, if not write, 2.X code and systems\\nfor some time to come.\\n306 | Chapter 11: \\u2002Assignments, Expressions, and Prints\", metadata={'source': 'python.pdf', 'page': 356}),\n",
       " Document(page_content='I use Python 3.0 print function calls throughout this book. I’ll usually\\nwarn you that the results may have extra enclosing parentheses in 2.6\\nbecause multiple items are a tuple, but I sometimes don’t, so please\\nconsider this note a blanket warning—if you see extra parentheses in\\nyour printed text in 2.6, either drop the parentheses in your print state-\\nments, recode your prints using the version-neutral scheme outlined\\nhere, or learn to love superfluous text.\\nWhy You Will Care: print and stdout\\nThe equivalence between the print \\noperation and writing to sys.stdout is important.\\nIt makes it possible to reassign sys.stdout to any user-defined object that provides the\\nsame write method as files. Because the print statement just sends text to the\\nsys.stdout.write method, you can capture printed text in your programs by assigning\\nsys.stdout to an object whose write method processes the text in arbitrary ways.\\nFor instance, you can send printed text to a GUI window, or tee it off to multiple\\ndestinations, by defining an object with a write method that does the required routing.\\nYou’ll see an example of this trick when we study classes in Part VI  of this book, but\\nabstractly, it looks like this:\\nclass FileFaker:\\n    def write(self, string):\\n        # Do something with printed text in string\\nimport sys\\nsys.stdout = FileFaker()\\nprint(someObjects)              # Sends to class write method\\nThis works because print is what we will call in the next part of this book a polymor-\\nphic operation—it doesn’t care what sys.stdout is, only that it has a method (i.e.,\\ninterface) called write. This redirection to objects is made even simpler with the file\\nkeyword argument in 3.0 and the >> extended form of print in 2.6, because we don’t\\nneed to reset sys.stdout explicitly—normal prints will still be routed to the stdout\\nstream:\\nmyobj = FileFaker()             # 3.0: Redirect to object for one print\\nprint(someObjects, file=myobj)  # Does not reset sys.stdout\\nmyobj = FileFaker()             # 2.6: same effect\\nprint >> myobj, someObjects     # Does not reset sys.stdout\\nPython’s built-in input function reads from the sys.stdin file, so you can intercept read\\nrequests in a similar way, using classes that implement file-like read methods instead.\\nSee the input and while loop example in Chapter 10 for more background on this.\\nNotice that because printed text goes to the stdout stream, it’s the way to print HTML\\nin CGI scripts used on the Web. It also enables you to redirect Python script input and\\noutput at the operating system’s shell command line, as usual:\\nPrint Operations | 307', metadata={'source': 'python.pdf', 'page': 357}),\n",
       " Document(page_content='python script.py < inputfile > outputfile\\npython script.py | filterProgram\\nPython’s print operation \\nredirection tools are essentially pure-Python alternatives to\\nthese shell syntax forms.\\nChapter Summary\\nIn this chapter, \\nwe began our in-depth look at Python statements by exploring assign-\\nments, expressions, and print operations. Although these are generally simple to use,\\nthey have some alternative forms that, while optional, are often convenient in practice:\\naugmented assignment statements and the redirection form of print operations, for\\nexample, allow us to avoid some manual coding work. Along the way, we also studied\\nthe syntax of variable names, stream redirection techniques, and a variety of common\\nmistakes to avoid, such as assigning the result of an append method call back to a\\nvariable.\\nIn the next chapter, we’ll continue our statement tour by filling in details about the\\nif statement, Python’s main selection tool; there, we’ll also revisit Python’s syntax\\nmodel in more depth and look at the behavior of Boolean expressions. Before we move\\non, though, the end-of-chapter quiz will test your knowledge of what you’ve learned\\nhere.\\nTest Your Knowledge: Quiz\\n1. Name three ways that you can assign three variables to the same value.\\n2.Why might you need to care when assigning three variables to a mutable object?\\n3.\\nWhat’s wrong with saying L = L.sort()?\\n4. How might you use the print operation to send text to an external file?\\nTest Your Knowledge: Answers\\n1. You can use multiple-target assignments ( A = B = C = 0), sequence assignment\\n(A, B, C = 0, 0, 0), or multiple assignment statements on three separate lines\\n(A = 0 , B = 0 , and C = 0 ). With the latter technique, as introduced in Chapter 10 ,\\nyou can also string the three separate statements together on the same line by\\nseparating them with semicolons (A = 0; B = 0; C = 0).\\n308 | Chapter 11: \\u2002Assignments, Expressions, and Prints', metadata={'source': 'python.pdf', 'page': 358}),\n",
       " Document(page_content='2. If you assign them this way:\\nA = B = C = []\\nall three names \\nreference the same object, so changing it in-place from one (e.g.,\\nA.append(99)) will affect the others. This is true only for in-place changes to mu-\\ntable objects like lists and dictionaries; for immutable objects such as numbers and\\nstrings, this issue is irrelevant.\\n3. The list sort method is like append in that it makes an in-place change to the subject\\nlist—it returns None, not the list it changes. The assignment back to L sets L to\\nNone, not to the sorted list. As we’ll see later in this part of the book, a newer built-\\nin function, sorted, sorts any sequence and returns a new list with the sorting result;\\nbecause this is not an in-place change, its result can be meaningfully assigned to a\\nname.\\n4. To print to a file for a single print operation, you can use 3.0’s print(X, file=F)\\ncall form, use 2.6’s extended print >> file, X statement form, or assign\\nsys.stdout to a manually opened file before the print and restore the original after.\\nYou can also redirect all of a program’s printed text to a file with special syntax in\\nthe system shell, but this is outside Python’s scope.\\nTest Your Knowledge: Answers | 309', metadata={'source': 'python.pdf', 'page': 359}),\n",
       " Document(page_content='', metadata={'source': 'python.pdf', 'page': 360}),\n",
       " Document(page_content='CHAPTER 12\\nif Tests and Syntax Rules\\nThis chapter presents the Python if statement, which is the main statement used for\\nselecting from alternative actions based on test results. Because this is our first in-depth\\nlook at compound statements —statements that embed other statements—we will also\\nexplore the general concepts behind the Python statement syntax model here in more\\ndetail than we did in the introduction in Chapter 10 . Because the if statement intro-\\nduces the notion of tests, this chapter will also deal with Boolean expressions and fill\\nin some details on truth tests in general.\\nif Statements\\nIn simple terms, the Python if statement selects actions to perform. It’s the primary\\nselection tool in Python and represents much of the logic a Python program possesses.\\nIt’s also our first compound statement. Like all compound Python statements, the if\\nstatement may contain other statements, including other ifs. In fact, Python lets you\\ncombine statements in a program sequentially (so that they execute one after another),\\nand in an arbitrarily nested fashion (so that they execute only under certain conditions).\\nGeneral Format\\nThe Python if statement is typical of if statements in most procedural languages. It\\ntakes the form of an if test, followed by one or more optional elif (“else if”) tests and\\na final optional else block. The tests and the else part each have an associated block\\nof nested statements, indented under a header line. When the if statement runs, Python\\nexecutes the block of code associated with the first test that evaluates to true, or the\\nelse block if all tests prove false. The general form of an if statement looks like this:\\nif <test1>:               # if test\\n    <statements1>         # Associated block\\nelif <test2>:             # Optional elifs\\n    <statements2>\\nelse:                     # Optional else\\n    <statements3>\\n311', metadata={'source': 'python.pdf', 'page': 361}),\n",
       " Document(page_content='Basic Examples\\nTo demonstrate, let’s \\nlook at a few simple examples of the if statement at work. All\\nparts are optional, except the initial if test and its associated statements. Thus, in the\\nsimplest case, the other parts are omitted:\\n>>> if 1:\\n...     print(\\'true\\')\\n...\\ntrue\\nNotice how the prompt changes to ... for continuation lines when typing interactively\\nin the basic interface used here; in IDLE, you’ll simply drop down to an indented line\\ninstead (hit Backspace to back up). A blank line (which you can get by pressing Enter\\ntwice) terminates and runs the entire statement. Remember that 1 is Boolean true, so\\nthis statement’s test always succeeds. To handle a false result, code the else:\\n>>> if not 1:\\n...     print(\\'true\\')\\n... else:\\n...     print(\\'false\\')\\n...\\nfalse\\nMultiway Branching\\nNow here’s an example of a more complex if statement, with all its optional parts\\npresent:\\n>>> x = \\'killer rabbit\\'\\n>>> if x == \\'roger\\':\\n...     print(\"how\\'s jessica?\")\\n... elif x == \\'bugs\\':\\n...     print(\"what\\'s up doc?\")\\n... else:\\n...     print(\\'Run away! Run away!\\')\\n...\\nRun away! Run away!\\nThis multiline statement extends from the if line through the else block. When it’s\\nrun, Python executes the statements nested under the first test that is true, or the\\nelse part if all tests are false (in this example, they are). In practice, both the elif and\\nelse parts may be omitted, and there may be more than one statement nested in each\\nsection. Note that the words if, elif, and else are associated by the fact that they line\\nup vertically, with the same indentation.\\nIf you’ve used languages like C or Pascal, you might be interested to know that there\\nis no switch or case statement in Python that selects an action based on a variable’s\\nvalue. Instead, multiway branching  is coded either as a series of if/elif tests, as in the\\nprior example, or by indexing dictionaries or searching lists. Because dictionaries and\\nlists can be built at runtime, they’re sometimes more flexible than hardcoded if logic:\\n312 | Chapter 12: \\u2002if Tests and Syntax Rules', metadata={'source': 'python.pdf', 'page': 362}),\n",
       " Document(page_content=\">>> choice = 'ham'\\n>>> print({'spam':  1.25,         # A dictionary-based 'switch'\\n...        'ham':   1.99,         # Use has_key or get for default\\n...        'eggs':  0.99,\\n...        'bacon': 1.10}[choice])\\n1.99\\nAlthough it may \\ntake a few moments for this to sink in the first time you see it, this\\ndictionary is a multiway branch—indexing on the key choice branches to one of a set\\nof values, much like a switch in C. An almost equivalent but more verbose Python if\\nstatement might look like this:\\n>>> if choice == 'spam':\\n...     print(1.25)\\n... elif choice == 'ham':\\n...     print(1.99)\\n... elif choice == 'eggs':\\n...     print(0.99)\\n... elif choice == 'bacon':\\n...     print(1.10)\\n... else:\\n...     print('Bad choice')\\n...\\n1.99\\nNotice the else clause on the if here to handle the default case when no key matches.\\nAs we saw in Chapter 8, dictionary defaults can be coded with in expressions, get\\nmethod calls, or exception catching. All of the same techniques can be used here to\\ncode a default action in a dictionary-based multiway branch. Here’s the get scheme at\\nwork with defaults:\\n>>> branch = {'spam': 1.25,\\n...           'ham':  1.99,\\n...           'eggs': 0.99}\\n>>> print(branch.get('spam', 'Bad choice'))\\n1.25\\n>>> print(branch.get('bacon', 'Bad choice'))\\nBad choice\\nAn in membership test in an if statement can have the same default effect:\\n>>> choice = 'bacon'\\n>>> if choice in branch:\\n...     print(branch[choice])\\n... else:\\n...     print('Bad choice')\\n...\\nBad choice\\nDictionaries are good for associating values with keys, but what about the more com-\\nplicated actions you can code in the statement blocks associated with if statements?\\nIn Part IV , you’ll learn that dictionaries can also contain functions to represent more\\ncomplex branch actions and implement general jump tables. Such functions appear as\\nif Statements | 313\", metadata={'source': 'python.pdf', 'page': 363}),\n",
       " Document(page_content='dictionary values, may be coded as function names or lambdas, and are called by adding\\nparentheses to trigger their actions; stay tuned for more on this topic in Chapter 19.\\nAlthough dictionary-based multiway branching is useful in programs that deal with\\nmore dynamic data, most programmers will probably find that coding an if statement\\nis the most straightforward way to perform multiway branching. As a rule of thumb in\\ncoding, when in doubt, err on the side of simplicity and readability; it’s the “Pythonic”\\nway.\\nPython Syntax Rules\\nI introduced Python’s syntax model in Chapter 10. Now that we’re stepping up to larger\\nstatements like the if, this section reviews and expands on the syntax ideas introduced\\nearlier. In general, Python has a simple, statement-based syntax. However, there are a\\nfew properties you need to know about:\\n•Statements execute one after another, until you say otherwise . Python nor-\\nmally runs statements in a file or nested block in order from first to last, but state-\\nments like if (and, as you’ll see, loops) cause the interpreter to jump around in\\nyour code. Because Python’s path through a program is called the control flow,\\nstatements such as if that affect it are often called control-flow statements.\\n•Block and statement boundaries are detected automatically . As we’ve seen,\\nthere are no braces or “begin/end” delimiters around blocks of code in Python;\\ninstead, Python uses the indentation of statements under a header to group the\\nstatements in a nested block. Similarly, Python statements are not normally ter-\\nminated with semicolons; rather, the end of a line usually marks the end of the\\nstatement coded on that line.\\n•Compound statements = header + “:” + indented statements . All compound\\nstatements in Python follow the same pattern: a header line terminated with a\\ncolon, followed by one or more nested statements, usually indented under the\\nheader. The indented statements are called a block (or sometimes, a suite). In the\\nif statement, the elif and else clauses are part of the if, but they are also header\\nlines with nested blocks of their own.\\n•Blank lines, spaces, and comments are usually ignored . Blank lines are ignored\\nin files (but not at the interactive prompt, when they terminate compound state-\\nments). Spaces inside statements and expressions are almost always ignored\\n(except in string literals, and when used for indentation). Comments are always\\nignored: they start with a # character (not inside a string literal) and extend to the\\nend of the current line.\\n•Docstrings are ignored but are saved and displayed by tools . Python supports\\nan additional comment form called documentation strings ( docstrings for short),\\nwhich, unlike # comments, are retained at runtime for inspection. Docstrings are\\nsimply strings that show up at the top of program files and some statements. Python\\n314 | Chapter 12: \\u2002if Tests and Syntax Rules', metadata={'source': 'python.pdf', 'page': 364}),\n",
       " Document(page_content=\"ignores their contents, but they are automatically attached to objects at runtime\\nand may be \\ndisplayed with documentation tools. Docstrings are part of Python’s\\nlarger documentation strategy and are covered in the last chapter in this part of the\\nbook.\\nAs you’ve seen, there are no variable type declarations in Python; this fact alone makes\\nfor a much simpler language syntax than what you may be used to. However, for most\\nnew users the lack of the braces and semicolons used to mark blocks and statements\\nin many other languages seems to be the most novel syntactic feature of Python, so let’s\\nexplore what this means in more detail.\\nBlock Delimiters: Indentation Rules\\nPython detects block boundaries automatically, by line indentation—that is, the empty\\nspace to the left of your code. All statements indented the same distance to the right\\nbelong to the same block of code. In other words, the statements within a block line\\nup vertically, as in a column. The block ends when the end of the file or a lesser-indented\\nline is encountered, and more deeply nested blocks are simply indented further to the\\nright than the statements in the enclosing block.\\nFor instance, Figure 12-1 demonstrates the block structure of the following code:\\nx = 1\\nif x:\\n    y = 2\\n    if y:\\n        print('block2')\\n    print('block1')\\nprint('block0')\\nFigure 12-1. Nested blocks of code: a nested block starts with a statement indented further to the right\\nand ends with either a statement that is indented less, or the end of the file.\\nPython Syntax Rules | 315\", metadata={'source': 'python.pdf', 'page': 365}),\n",
       " Document(page_content='This code contains three blocks: the first (the top-level code of the file) is not indented\\nat all, the \\nsecond (within the outer if statement) is indented four spaces, and the third\\n(the print statement under the nested if) is indented eight spaces.\\nIn general, top-level (unnested) code must start in column 1. Nested blocks can start\\nin any column; indentation may consist of any number of spaces and tabs, as long as\\nit’s the same for all the statements in a given single block. That is, Python doesn’t care\\nhow you indent your code; it only cares that it’s done consistently. Four spaces or one\\ntab per indentation level are common conventions, but there is no absolute standard\\nin the Python world.\\nIndenting code is quite natural in practice. For example, the following (arguably silly)\\ncode snippet demonstrates common indentation errors in Python code:\\n  x = \\'SPAM\\'                        # Error: first line indented\\nif \\'rubbery\\' in \\'shrubbery\\':\\n    print(x * 8)\\n        x += \\'NI\\'                   # Error: unexpected indentation\\n        if x.endswith(\\'NI\\'):\\n                x *= 2\\n            print(x)                # Error: inconsistent indentation\\nThe properly indented version of this code looks like the following—even for an arti-\\nficial example like this, proper indentation makes the code’s intent much more\\napparent:\\nx = \\'SPAM\\'\\nif \\'rubbery\\' in \\'shrubbery\\':\\n    print(x * 8)\\n    x += \\'NI\\'\\n    if x.endswith(\\'NI\\'):\\n        x *= 2\\n        print(x)                    # Prints \"SPAMNISPAMNI\"\\nIt’s important to know that the only major place in Python where whitespace matters\\nis where it’s used to the left of your code, for indentation; in most other contexts, space\\ncan be coded or not. However, indentation is really part of Python syntax, not just a\\nstylistic suggestion: all the statements within any given single block must be indented\\nto the same level, or Python reports a syntax error. This is intentional—because you\\ndon’t need to explicitly mark the start and end of a nested block of code, some of the\\nsyntactic clutter found in other languages is unnecessary in Python.\\nAs described in Chapter 10 , making indentation part of the syntax model also enforces\\nconsistency, a crucial component of readability in structured programming languages\\nlike Python. Python’s syntax is sometimes described as “what you see is what you\\nget”—the indentation of each line of code unambiguously tells readers what it is asso-\\nciated with. This uniform and consistent appearance makes Python code easier to\\nmaintain and reuse.\\n316 | Chapter 12: \\u2002if Tests and Syntax Rules', metadata={'source': 'python.pdf', 'page': 366}),\n",
       " Document(page_content='Indentation is more natural than the details might imply, and it makes your code reflect\\nits logical structure. \\nConsistently indented code always satisfies Python’s rules.\\nMoreover, most text editors (including IDLE) make it easy to follow Python’s inden-\\ntation model by automatically indenting code as you type it.\\nAvoid mixing tabs and spaces: New error checking in 3.0\\nOne rule of thumb: although you can use spaces or tabs to indent, it’s usually not a\\ngood idea to mix the two within a block—use one or the other. Technically, tabs count\\nfor enough spaces to move the current column number up to a multiple of 8, and your\\ncode will work if you mix tabs and spaces consistently. However, such code can be\\ndifficult to change. Worse, mixing tabs and spaces makes your code difficult to read—\\ntabs may look very different in the next programmer’s editor than they do in yours.\\nIn fact, Python 3.0 now issues an error, for these very reasons, when a script mixes tabs\\nand spaces for indentation inconsistently within a block (that is, in a way that makes\\nit dependent on a tab’s equivalent in spaces). Python 2.6 allows such scripts to run, but\\nit has a -t command-line flag that will warn you about inconsistent tab usage and a\\n-tt flag that will issue errors for such code (you can use these switches in a command\\nline like python –t main.py in a system shell window). Python 3.0’s error case is equiv-\\nalent to 2.6’s -tt switch.\\nStatement Delimiters: Lines and Continuations\\nA statement in Python normally ends at the end of the line on which it appears. When\\na statement is too long to fit on a single line, though, a few special rules may be used\\nto make it span multiple lines:\\n•Statements may span multiple lines if you’re continuing an open syntactic\\npair. Python lets you continue typing a statement on the next line if you’re coding\\nsomething enclosed in a (), {}, or [] pair. For instance, expressions in parentheses\\nand dictionary and list literals can span any number of lines; your statement doesn’t\\nend until the Python interpreter reaches the line on which you type the closing part\\nof the pair (a ), }, or ]). Continuation lines (lines 2 and beyond of the statement)\\ncan start at any indentation level you like, but you should try to make them align\\nvertically for readability if possible. This open pairs rule also covers set and dic-\\ntionary comprehensions in Python 3.0.\\n•Statements may span multiple lines if they end in a backslash . This is a some-\\nwhat outdated feature, but if a statement needs to span multiple lines, you can also\\nadd a backslash (a \\\\ not embedded in a string literal or comment) at the end of the\\nprior line to indicate you’re continuing on the next line. Because you can also\\ncontinue by adding parentheses around most constructs, backslashes are almost\\nnever used. This approach is error-prone: accidentally forgetting a \\\\ usually gen-\\nerates a syntax error and might even cause the next line to be silently mistaken to\\nbe a new statement, with unexpected results.\\nPython Syntax Rules | 317', metadata={'source': 'python.pdf', 'page': 367}),\n",
       " Document(page_content='•Special rules for string literals. As we learned in Chapter 7 , triple-quoted string\\nblocks are designed to span multiple lines normally. We also learned in Chap-\\nter 7 that adjacent string literals are implicitly concatenated; when used in con-\\njunction with the open pairs rule mentioned earlier, wrapping this construct in\\nparentheses allows it to span multiple lines.\\n•Other rules . There are a few other points to mention with regard to statement\\ndelimiters. Although uncommon, you can terminate a statement with a\\nsemicolon—this convention is sometimes used to squeeze more than one simple\\n(noncompound) statement onto a single line. Also, comments and blank lines can\\nappear anywhere in a file; comments (which begin with a # character) terminate at\\nthe end of the line on which they appear.\\nA Few Special Cases\\nHere’s what a continuation line looks like using the open syntactic pairs rule. Delimited\\nconstructs, such as lists in square brackets, can span across any number of lines:\\nL = [\"Good\",\\n     \"Bad\",\\n     \"Ugly\"]                     # Open pairs may span lines\\nThis also works for anything in parentheses (expressions, function arguments, function\\nheaders, tuples, and generator expressions), as well as anything in curly braces (dic-\\ntionaries and, in 3.0, set literals and set and dictionary comprehensions). Some of these\\nare tools we’ll study in later chapters, but this rule naturally covers most constructs\\nthat span lines in practice.\\nIf you like using backslashes to continue lines, you can, but it’s not common practice\\nin Python:\\nif a == b and c == d and   \\\\\\n   d == e and f == g:\\n   print(\\'olde\\')                 # Backslashes allow continuations...\\nBecause any expression can be enclosed in parentheses, you can usually use the open\\npairs technique instead if you need your code to span multiple lines—simply wrap a\\npart of your statement in parentheses:\\nif (a == b and c == d and\\n    d == e and e == f):\\n    print(\\'new\\')                 # But parentheses usually do too\\nIn fact, backslashes are frowned on, because they’re too easy to not notice and too easy\\nto omit altogether. In the following, x is assigned 10 with the backslash, as intended; if\\nthe backslash is accidentally omitted, though, x is assigned 6 instead, and no error is\\nreported (the +4 is a valid expression statement by itself).\\n318 | Chapter 12: \\u2002if Tests and Syntax Rules', metadata={'source': 'python.pdf', 'page': 368}),\n",
       " Document(page_content='In a real program with a more complex assignment, this could be the source of a very\\nnasty bug:*\\nx = 1 + 2 + 3 \\\\                  # Omitting the \\\\ makes this very different\\n+4\\nAs another special \\ncase, Python allows you to write more than one noncompound\\nstatement (i.e., statements without nested statements) on the same line, separated by\\nsemicolons. Some coders use this form to save program file real estate, but it usually\\nmakes for more readable code if you stick to one statement per line for most of your\\nwork:\\nx = 1; y = 2; print(x)           # More than one simple statement\\nAs we learned in Chapter 7 , triple-quoted string literals span lines too. In addition, if\\ntwo string literals appear next to each other, they are concatenated as if a + had been\\nadded between them—when used in conjunction with the open pairs rule, wrapping\\nin parentheses allows this form to span multiple lines. For example, the first of the\\nfollowing inserts newline characters at line breaks and assigns S to \\'\\\\naaaa\\\\nbbbb\\n\\\\ncccc\\', and the second implicitly concatenates and assigns S to \\'aaaabbbbcccc\\'; com-\\nments are ignored in the second form, but included in the string in the first:\\nS = \"\"\"\\naaaa\\nbbbb\\ncccc\"\"\"\\nS = (\\'aaaa\\'\\n     \\'bbbb\\'                      # Comments here are ignored\\n     \\'cccc\\')\\nFinally, Python lets you move a compound statement’s body up to the header line,\\nprovided the body is just a simple (noncompound) statement. You’ll most often see\\nthis used for simple if statements with a single test and action:\\nif 1: print(\\'hello\\')             # Simple statement on header line\\nYou can combine some of these special cases to write code that is difficult to read, but\\nI don’t recommend it; as a rule of thumb, try to keep each statement on a line of its\\nown, and indent all but the simplest of blocks. Six months down the road, you’ll be\\nhappy you did.\\n* Frankly, it’s surprising that this wasn’t removed in Python 3.0, given some of its other changes! (See\\nTable P-2  \\nof the Preface for a list of 3.0 removals; some seem fairly innocuous in comparison with the dangers\\ninherent in backslash continuations.) Then again, this book’s goal is Python instruction, not populist outrage,\\nso the best advice I can give is simply: don’t do this.\\nPython Syntax Rules | 319', metadata={'source': 'python.pdf', 'page': 369}),\n",
       " Document(page_content='Truth Tests\\nThe notions of comparison, \\nequality, and truth values were introduced in Chapter 9 .\\nBecause the if statement is the first statement we’ve looked at that actually uses test\\nresults, we’ll expand on some of these ideas here. In particular, Python’s Boolean op-\\nerators are a bit different from their counterparts in languages like C. In Python:\\n• Any nonzero number or nonempty object is true.\\n• Zero numbers, empty objects, and the special object None are considered false.\\n• Comparisons and equality tests are applied recursively to data structures.\\n• Comparisons and equality tests return True or False (custom versions of 1 and 0).\\n• Boolean and and or operators return a true or false operand object.\\nIn short, Boolean operators are used to combine the results of other tests. There are\\nthree Boolean expression operators in Python:\\nX and Y\\nIs true if both X and Y are true\\nX or Y\\nIs true if either X or Y is true\\nnot X\\nIs true if X is false (the expression returns True or False)\\nHere, X and Y may be any truth value, or any expression that returns a truth value (e.g.,\\nan equality test, range comparison, and so on). Boolean operators are typed out as\\nwords in Python (instead of C’s &&, ||, and !). Also, Boolean and and or operators return\\na true or false object in Python, not the values True or False. Let’s look at a few examples\\nto see how this works:\\n>>> 2 < 3, 3 < 2        # Less-than: return True or False (1 or 0)\\n(True, False)\\nMagnitude comparisons such as these return True or False as their truth results, which,\\nas we learned in Chapters 5 and 9, are really just custom versions of the integers 1 and\\n0 (they print themselves differently but are otherwise the same).\\nOn the other hand, the and and or operators always return an object—either the object\\non the left side of the operator or the object on the right. If we test their results in if or\\nother statements, they will be as expected (remember, every object is inherently true\\nor false), but we won’t get back a simple True or False.\\n320 | Chapter 12: \\u2002if Tests and Syntax Rules', metadata={'source': 'python.pdf', 'page': 370}),\n",
       " Document(page_content='For or tests, Python evaluates the operand objects from left to right and returns the first\\none that \\nis true. Moreover, Python stops at the first true operand it finds. This is usually\\ncalled short-circuit evaluation , as determining a result short-circuits (terminates) the\\nrest of the expression:\\n>>> 2 or 3, 3 or 2      # Return left operand if true\\n(2, 3)                  # Else, return right operand (true or false)\\n>>> [] or 3\\n3\\n>>> [] or {}\\n{}\\nIn the first line of the preceding example, both operands ( 2 and 3) are true (i.e., are\\nnonzero), so Python always stops and returns the one on the left. In the other two tests,\\nthe left operand is false (an empty object), so Python simply evaluates and returns the\\nobject on the right (which may happen to have either a true or a false value when tested).\\nand operations also stop as soon as the result is known; however, in this case Python\\nevaluates the operands from left to right and stops at the first false object:\\n>>> 2 and 3, 3 and 2    # Return left operand if false\\n(3, 2)                  # Else, return right operand (true or false)\\n>>> [] and {}\\n[]\\n>>> 3 and []\\n[]\\nHere, both operands are true in the first line, so Python evaluates both sides and returns\\nthe object on the right. In the second test, the left operand is false ( []), so Python stops\\nand returns it as the test result. In the last test, the left side is true ( 3), so Python evaluates\\nand returns the object on the right (which happens to be a false []).\\nThe end result of all this is the same as in C and most other languages—you get a value\\nthat is logically true or false if tested in an if or while. However, in Python Booleans\\nreturn either the left or the right object, not a simple integer flag.\\nThis behavior of and and or may seem esoteric at first glance, but see this chapter’s\\nsidebar “Why You Will Care: Booleans” on page 323 for examples of how it is some-\\ntimes used to advantage in coding by Python programmers. The next section also shows\\na common way to leverage this behavior, and its replacement in more recent versions\\nof Python.\\nThe if/else Ternary Expression\\nOne common role for the prior section’s Boolean operators is to code an expression\\nthat runs the same as an if statement. Consider the following statement, which sets\\nA to either Y or Z, based on the truth value of X:\\nThe if/else Ternary Expression | 321', metadata={'source': 'python.pdf', 'page': 371}),\n",
       " Document(page_content=\"if X:\\n    A = Y\\nelse:\\n    A = Z\\nSometimes, though, the \\nitems involved in such a statement are so simple that it seems\\nlike overkill to spread them across four lines. At other times, we may want to nest such\\na construct in a larger statement instead of assigning its result to a variable. For these\\nreasons (and, frankly, because the C language has a similar tool†), Python 2.5 intro-\\nduced a new expression format that allows us to say the same thing in one expression:\\nA = Y if X else Z\\nThis expression has the exact same effect as the preceding four-line if statement, but\\nit’s simpler to code. As in the statement equivalent, Python runs expression Y only if\\nX turns out to be true, and runs expression Z only if X turns out to be false. That is, it\\nshort-circuits, just like the Boolean operators described in the prior section. Here are\\nsome examples of it in action:\\n>>> A = 't' if 'spam' else 'f'      # Nonempty is true\\n>>> A\\n't'\\n>>> A = 't' if '' else 'f'\\n>>> A\\n'f'\\nPrior to Python 2.5 (and after 2.5, if you insist), the same effect can often be achieved\\nby a careful combination of the and and or operators, because they return either the\\nobject on the left side or the object on the right:\\nA = ((X and Y) or Z)\\nThis works, but there is a catch—you have to be able to assume that Y will be Boolean\\ntrue. If that is the case, the effect is the same: the and runs first and returns Y if X is true;\\nif it’s not, the or simply returns Z. In other words, we get “if X then Y else Z.”\\nThis and/or combination also seems to require a “moment of great clarity” to under-\\nstand the first time you see it, and it’s no longer required as of 2.5—use the equivalent\\nand more robust and mnemonic Y if X else Z instead if you need this as an expression,\\nor use a full if statement if the parts are nontrivial.\\nAs a side note, using the following expression in Python is similar because the bool\\nfunction will translate X into the equivalent of integer 1 or 0, which can then be used to\\npick true and false values from a list:\\nA = [Z, Y][bool(X)]\\n† In fact, Python’s X if Y else Z  has a slightly different order than C’s Y ? X : Z. This was reportedly done\\nin response to analysis of common use patterns in Python code. According to rumor, this order was also\\nchosen in part to discourage ex-C programmers from overusing it! Remember, simple is better than complex,\\nin Python and elsewhere.\\n322 | Chapter 12: \\u2002if Tests and Syntax Rules\", metadata={'source': 'python.pdf', 'page': 372}),\n",
       " Document(page_content=\"For example:\\n>>> ['f', 't'][bool('')]\\n'f'\\n>>> ['f', 't'][bool('spam')]\\n't'\\nHowever, this isn’t \\nexactly the same, because Python will not short-circuit—it will\\nalways run both Z and Y, regardless of the value of X. Because of such complexities,\\nyou’re better off using the simpler and more easily understood if/else expression as\\nof Python 2.5 and later. Again, though, you should use even that sparingly, and only if\\nits parts are all fairly simple; otherwise, you’re better off coding the full if statement\\nform to make changes easier in the future. Your coworkers will be happy you did.\\nStill, you may see the and/or version in code written prior to 2.5 (and in code written\\nby C programmers who haven’t quite let go of their dark coding pasts...).\\nWhy You Will Care: Booleans\\nOne common way \\nto use the somewhat unusual behavior of Python Boolean operators\\nis to select from a set of objects with an or. A statement such as this:\\nX = A or B or C or None\\nsets X to the first nonempty (that is, true) object among A, B, and C, or to None if all of\\nthem are empty. This works because the or operator returns one of its two objects, and\\nit turns out to be a fairly common coding paradigm in Python: to select a nonempty\\nobject from among a fixed-size set, simply string them together in an or expression. In\\nsimpler form, this is also commonly used to designate a default—the following sets X\\nto A if A is true (or nonempty), and to default otherwise:\\nX = A or default\\nIt’s also important to understand short-circuit evaluation because expressions on the\\nright of a Boolean operator might call functions that perform substantial or important\\nwork, or have side effects that won’t happen if the short-circuit rule takes effect:\\nif f1() or f2(): ...\\nHere, if f1 returns a true (or nonempty) value, Python will never run f2. To guarantee\\nthat both functions will be run, call them before the or:\\ntmp1, tmp2 = f1(), f2()\\nif tmp1 or tmp2: ...\\nYou’ve already seen another application of this behavior in this chapter: because of the\\nway Booleans work, the expression ((A and B) or C) can be used to emulate an if/\\nelse statement—almost (see this chapter’s discussion of this form for details).\\nWe met additional Boolean use cases in prior chapters. As we saw in Chapter 9, because\\nall objects are inherently true or false, it’s common and easier in Python to test an object\\ndirectly ( if X: ) than to compare it to an empty value ( if X != '':). For a string, the\\ntwo tests are equivalent. As we also saw in Chapter 5, the preset Booleans values True\\nand False are the same as the integers 1 and 0 and are useful for initializing variables\\nThe if/else Ternary Expression | 323\", metadata={'source': 'python.pdf', 'page': 373}),\n",
       " Document(page_content='(X = False), for loop tests (while True:), and for displaying results at the interactive\\nprompt.\\nAlso watch for the discussion of operator overloading in Part VI : when we define new\\nobject types with classes, we can specify their Boolean nature with either the __bool__ or\\n__len__ methods ( __bool__ is named __nonzero__ in 2.6). The latter of these is tried if\\nthe former is absent and designates false by returning a length of zero—an empty object\\nis considered false.\\nChapter Summary\\nIn this chapter, \\nwe studied the Python if statement. Additionally, because this was our\\nfirst compound and logical statement, we reviewed Python’s general syntax rules and\\nexplored the operation of truth tests in more depth than we were able to previously.\\nAlong the way, we also looked at how to code multiway branching in Python and\\nlearned about the if/else expression introduced in Python 2.5.\\nThe next chapter continues our look at procedural statements by expanding on the\\nwhile and for loops. There, we’ll learn about alternative ways to code loops in Python,\\nsome of which may be better than others. Before that, though, here is the usual chapter \\nquiz.\\nTest Your Knowledge: Quiz\\n1. How might you code a multiway branch in Python?\\n2. How can you code an \\nif/else statement as an expression in Python?\\n3. How can you make a single statement span many lines?\\n4. What do the words True and False mean?\\nTest Your Knowledge: Answers\\n1. An if statement with multiple elif clauses is often the most straightforward way\\nto code a multiway branch, though not necessarily the most concise. Dictionary\\nindexing can often achieve the same result, especially if the dictionary contains\\ncallable functions coded with def statements or lambda expressions.\\n2. In Python 2.5 and later, the expression form Y if X else Z returns Y if X is true, or\\nZ otherwise; it’s the same as a four-line if statement. The and/or combination\\n(((X and Y) or Z)) can work the same way, but it’s more obscure and requires that\\nthe Y part be true.\\n324 | Chapter 12: \\u2002if Tests and Syntax Rules', metadata={'source': 'python.pdf', 'page': 374}),\n",
       " Document(page_content='3. Wrap up the statement in an open syntactic pair ( (), [] , or {}), and it can span as\\nmany lines as you like; the statement ends when Python sees the closing (right) half\\nof the pair, and lines 2 and beyond of the statement can begin at any indentation\\nlevel.\\n4.True and False are just custom versions of the integers 1 and 0, respectively: they\\nalways stand for Boolean true and false values in Python. They’re available for use\\nin truth tests and variable initialization and are printed for expression results at the\\ninteractive prompt.\\nTest Your Knowledge: Answers | 325', metadata={'source': 'python.pdf', 'page': 375}),\n",
       " Document(page_content='', metadata={'source': 'python.pdf', 'page': 376}),\n",
       " Document(page_content='CHAPTER 13\\nwhile and for Loops\\nThis chapter concludes our tour of Python procedural statements by presenting the\\nlanguage’s two main looping\\n constructs—statements that repeat an action over and\\nover. The first of these, the while statement, provides a way to code general loops. The\\nsecond, the for statement, is designed for stepping through the items in a sequence\\nobject and running a block of code for each.\\nWe’ve seen both of these informally already, but we’ll fill in additional usage details\\nhere. While we’re at it, we’ll also study a few less prominent statements used within\\nloops, such as break and continue, and cover some built-ins commonly used with loops,\\nsuch as range, zip, and map.\\nAlthough the while and for statements covered here are the primary syntax provided\\nfor coding repeated actions, there are additional looping operations and concepts in\\nPython. Because of that, the iteration story is continued in the next chapter, where we’ll\\nexplore the related ideas of Python’s iteration protocol  (used by the for loop) and list\\ncomprehensions (a close cousin to the for loop). Later chapters explore even more exotic\\niteration tools such as generators, filter, and reduce. For now, though, let’s keep things\\nsimple.\\nwhile Loops\\nPython’s while statement is the most general iteration construct in the language. In\\nsimple terms, it repeatedly executes a block of (normally indented) statements as long\\nas a test at the top keeps evaluating to a true value. It is called a “loop” because control\\nkeeps looping back to the start of the statement until the test becomes false. When the\\ntest becomes false, control passes to the statement that follows the while block. The\\nnet effect is that the loop’s body is executed repeatedly while the test at the top is true;\\nif the test is false to begin with, the body never runs.\\n327', metadata={'source': 'python.pdf', 'page': 377}),\n",
       " Document(page_content=\"General Format\\nIn its most \\ncomplex form, the while statement consists of a header line with a test\\nexpression, a body of one or more indented statements, and an optional else part that\\nis executed if control exits the loop without a break statement being encountered. Py-\\nthon keeps evaluating the test at the top and executing the statements nested in the\\nloop body until the test returns a false value:\\nwhile <test>:                   # Loop test\\n    <statements1>               # Loop body\\nelse:                           # Optional else\\n    <statements2>               # Run if didn't exit loop with break\\nExamples\\nTo illustrate, let’s look at a few simple while loops in action. The first, which consists\\nof a print statement nested in a while loop, just prints a message forever. Recall that\\nTrue is just a custom version of the integer 1 and always stands for a Boolean true value;\\nbecause the test is always true, Python keeps executing the body forever, or until you\\nstop its execution. This sort of behavior is usually called an infinite loop:\\n>>> while True:\\n...    print('Type Ctrl-C to stop me!')\\nThe next example keeps slicing off the first character of a string until the string is empty\\nand hence false. It’s typical to test an object directly like this instead of using the more\\nverbose equivalent ( while x != '':). Later in this chapter, we’ll see other ways to step\\nmore directly through the items in a string with a for loop.\\n>>> x = 'spam'\\n>>> while x:                  # While x is not empty\\n...     print(x, end=' ')\\n...     x = x[1:]             # Strip first character off x\\n...\\nspam pam am m\\nNote the end=' ' keyword argument used here to place all outputs on the same line\\nseparated by a space; see Chapter 11  if you’ve forgotten why this works as it does. The\\nfollowing code counts from the value of a up to, but not including, b. We’ll see an easier\\nway to do this with a Python for loop and the built-in range function later:\\n>>> a=0; b=10\\n>>> while a < b:              # One way to code counter loops\\n...     print(a, end=' ')\\n...     a += 1                # Or, a = a + 1\\n...\\n0 1 2 3 4 5 6 7 8 9\\nFinally, notice that Python doesn’t have what some languages call a “do until” loop\\nstatement. However, we can simulate one with a test and break at the bottom of the\\nloop body:\\n328 | Chapter 13: \\u2002while and for Loops\", metadata={'source': 'python.pdf', 'page': 378}),\n",
       " Document(page_content=\"while True:\\n    ...loop body...\\n    if exitTest(): break\\nTo fully understand \\nhow this structure works, we need to move on to the next section\\nand learn more about the break statement.\\nbreak, continue, pass, and the Loop else\\nNow that we’ve seen a few Python loops in action, it’s time to take a look at two simple\\nstatements that have a purpose only when nested inside loops—the break and\\ncontinue statements. While we’re looking at oddballs, we will also study the loop\\nelse clause here, because it is intertwined with break, and Python’s empty placeholder\\nstatement, the pass (which is not tied to loops per se, but falls into the general category\\nof simple one-word statements). In Python:\\nbreak\\nJumps out of the closest enclosing loop (past the entire loop statement)\\ncontinue\\nJumps to the top of the closest enclosing loop (to the loop’s header line)\\npass\\nDoes nothing at all: it’s an empty statement placeholder\\nLoop else block\\nRuns if and only if the loop is exited normally (i.e., without hitting a break)\\nGeneral Loop Format\\nFactoring in break and continue statements, the general format of the while loop looks\\nlike this:\\nwhile <test1>:\\n    <statements1>\\n    if <test2>: break              # Exit loop now, skip else\\n    if <test3>: continue           # Go to top of loop now, to test1\\nelse:\\n    <statements2>                  # Run if we didn't hit a 'break'\\nbreak and continue statements can appear anywhere inside the while (or for) loop’s\\nbody, but they are usually coded further nested in an if test to take action in response\\nto some condition.\\nLet’s turn to a few simple examples to see how these statements come together in\\npractice.\\nbreak, continue, pass, and the Loop else | 329\", metadata={'source': 'python.pdf', 'page': 379}),\n",
       " Document(page_content='pass\\nSimple things first: \\nthe pass statement is a no-operation placeholder that is used when\\nthe syntax requires a statement, but you have nothing useful to say. It is often used to\\ncode an empty body for a compound statement. For instance, if you want to code an\\ninfinite loop that does nothing each time through, do it with a pass:\\nwhile True: pass                   # Type Ctrl-C to stop me!\\nBecause the body is just an empty statement, Python gets stuck in this loop. pass is\\nroughly to statements as None is to objects—an explicit nothing. Notice that here the\\nwhile loop’s body is on the same line as the header, after the colon; as with if state-\\nments, this only works if the body isn’t a compound statement.\\nThis example does nothing forever. It probably isn’t the most useful Python program\\never written (unless you want to warm up your laptop computer on a cold winter’s\\nday!); frankly, though, I couldn’t think of a better pass example at this point in the book.\\nWe’ll see other places where pass makes more sense later—for instance, to ignore ex-\\nceptions caught by try statements, and to define empty class objects with attributes\\nthat behave like “structs” and “records” in other languages. A pass is also sometime\\ncoded to mean “to be filled in later,” to stub out the bodies of functions temporarily:\\ndef func1():\\n    pass                           # Add real code here later\\ndef func2():\\n    pass\\nWe can’t leave the body empty without getting a syntax error, so we say pass instead.\\nVersion skew note : Python 3.0 (but not 2.6) allows ellipses coded\\nas ... (literally, three consecutive dots) to appear any place an expres-\\nsion can. Because ellipses do nothing by themselves, this can serve as\\nan alternative to the pass statement, especially for code to be filled in\\nlater—a sort of Python “TBD”:\\ndef func1():\\n    ...                   # Alternative to pass\\ndef func2():\\n    ...\\nfunc1()                   # Does nothing if called\\nEllipses can also appear on the same line as a statement header and may\\nbe used to initialize variable names if no specific type is required:\\ndef func1(): ...          # Works on same line too\\ndef func2(): ...\\n>>> X = ...               # Alternative to None\\n330 | Chapter 13: \\u2002while and for Loops', metadata={'source': 'python.pdf', 'page': 380}),\n",
       " Document(page_content=\">>> X\\nEllipsis\\nThis notation is \\nnew in Python 3.0 (and goes well beyond the original\\nintent of ... in slicing extensions), so time will tell if it becomes wide-\\nspread enough to challenge pass and None in these roles.\\ncontinue\\nThe continue statement causes an immediate jump to the top of a loop. It also some-\\ntimes lets you avoid statement nesting. The next example uses continue to skip odd\\nnumbers. This code prints all even numbers less than 10 and greater than or equal to\\n0. Remember, 0 means false and % is the remainder of division operator, so this loop\\ncounts down to 0, skipping numbers that aren’t multiples of 2 (it prints 8 6 4 2 0):\\nx = 10\\nwhile x:\\n    x = x−1                        # Or, x -= 1\\n    if x % 2 != 0: continue        # Odd? -- skip print\\n    print(x, end=' ')\\nBecause continue jumps to the top of the loop, you don’t need to nest the print state-\\nment inside an if test; the print is only reached if the continue is not run. If this sounds\\nsimilar to a “goto” in other languages, it should. Python has no “goto” statement, but\\nbecause continue lets you jump about in a program, many of the warnings about read-\\nability and maintainability you may have heard about goto apply. continue should\\nprobably be used sparingly, especially when you’re first getting started with Python.\\nFor instance, the last example might be clearer if the print were nested under the if:\\nx = 10\\nwhile x:\\n    x = x−1\\n    if x % 2 == 0:                 # Even? -- print\\n        print(x, end=' ')\\nbreak\\nThe break statement causes an immediate exit from a loop. Because the code that fol-\\nlows it in the loop is not executed if the break is reached, you can also sometimes avoid\\nnesting by including a break. For example, here is a simple interactive loop (a variant\\nof a larger example we studied in Chapter 10 ) that inputs data with input (known as\\nraw_input in Python 2.6) and exits when the user enters “stop” for the name request:\\n>>> while True:\\n...     name = input('Enter name:')\\n...     if name == 'stop': break\\n...     age  = input('Enter age: ')\\n...     print('Hello', name, '=>', int(age) ** 2)\\n...\\nEnter name:mel\\nEnter age: 40\\nbreak, continue, pass, and the Loop else | 331\", metadata={'source': 'python.pdf', 'page': 381}),\n",
       " Document(page_content=\"Hello mel => 1600\\nEnter name:bob\\nEnter age: 30\\nHello bob => 900\\nEnter name:stop\\nNotice how this \\ncode converts the age input to an integer with int before raising it to\\nthe second power; as you’ll recall, this is necessary because input returns user input as\\na string. In Chapter 35 , you’ll see that input also raises an exception at end-of-file (e.g.,\\nif the user types Ctrl-Z or Ctrl-D); if this matters, wrap input in try statements.\\nLoop else\\nWhen combined with the loop else clause, the break statement can often eliminate the\\nneed for the search status flags used in other languages. For instance, the following\\npiece of code determines whether a positive integer y is prime by searching for factors\\ngreater than 1:\\nx = y // 2                                # For some y > 1\\nwhile x > 1:\\n    if y % x == 0:                        # Remainder\\n        print(y, 'has factor', x)\\n        break                             # Skip else\\n    x -= 1\\nelse:                                     # Normal exit\\n    print(y, 'is prime')\\nRather than setting a flag to be tested when the loop is exited, it inserts a break where\\na factor is found. This way, the loop else clause can assume that it will be executed\\nonly if no factor is found; if you don’t hit the break, the number is prime.\\nThe loop else clause is also run if the body of the loop is never executed, as you don’t\\nrun a break in that event either; in a while loop, this happens if the test in the header\\nis false to begin with. Thus, in the preceding example you still get the “is prime” message\\nif x is initially less than or equal to 1 (for instance, if y is 2).\\nThis example determines primes, but only informally so. Numbers less\\nthan 2 are \\nnot considered prime by the strict mathematical definition.\\nTo be really picky, this code also fails for negative numbers and succeeds\\nfor floating-point numbers with no decimal digits. Also note that its\\ncode must use // instead of / in Python 3.0 because of the migration\\nof / to “true division,” as described in Chapter 5  (we need the initial\\ndivision to truncate remainders, not retain them!). If you want to ex-\\nperiment with this code, be sure to see the exercise at the end of\\nPart IV, which wraps it in a function for reuse.\\n332 | Chapter 13: \\u2002while and for Loops\", metadata={'source': 'python.pdf', 'page': 382}),\n",
       " Document(page_content=\"More on the loop else\\nBecause the loop else\\n clause is unique to Python, it tends to perplex some newcomers.\\nIn general terms, the loop else provides explicit syntax for a common coding scenario—\\nit is a coding structure that lets us catch the “other” way out of a loop, without setting\\nand checking flags or conditions.\\nSuppose, for instance, that we are writing a loop to search a list for a value, and we\\nneed to know whether the value was found after we exit the loop. We might code such\\na task this way:\\nfound = False\\nwhile x and not found:\\n    if match(x[0]):                  # Value at front?\\n        print('Ni')\\n        found = True\\n    else:\\n        x = x[1:]                    # Slice off front and repeat\\nif not found:\\n    print('not found')\\nHere, we initialize, set, and later test a flag to determine whether the search succeeded\\nor not. This is valid Python code, and it does work; however, this is exactly the sort of\\nstructure that the loop else clause is there to handle. Here’s an else equivalent:\\nwhile x:                             # Exit when x empty\\n    if match(x[0]):\\n        print('Ni')\\n        break                        # Exit, go around else\\n    x = x[1:]\\nelse:\\n    print('Not found')               # Only here if exhausted x\\nThis version is more concise. The flag is gone, and we’ve replaced the if test at the loop\\nend with an else (lined up vertically with the word while). Because the break inside the\\nmain part of the while exits the loop and goes around the else, this serves as a more\\nstructured way to catch the search-failure case.\\nSome readers might have noticed that the prior example’s else clause could be replaced\\nwith a test for an empty x after the loop (e.g., if not x:). Although that’s true in this\\nexample, the else provides explicit syntax for this coding pattern (it’s more obviously\\na search-failure clause here), and such an explicit empty test may not apply in some\\ncases. The loop else becomes even more useful when used in conjunction with the\\nfor loop—the topic of the next section—because sequence iteration is not under your\\ncontrol.\\nbreak, continue, pass, and the Loop else | 333\", metadata={'source': 'python.pdf', 'page': 383}),\n",
       " Document(page_content='Why You Will Care: Emulating C while Loops\\nThe section on \\nexpression statements in Chapter 11  stated that Python doesn’t allow\\nstatements such as assignments to appear in places where it expects an expression. That\\nmeans this common C language coding pattern won’t work in Python:\\nwhile ((x = next()) != NULL) {...process x...}\\nC assignments return the value assigned, but Python assignments are just statements,\\nnot expressions. This eliminates a notorious class of C errors (you can’t accidentally\\ntype = in Python when you mean ==). If you need similar behavior, though, there are at\\nleast three ways to get the same effect in Python while loops without embedding as-\\nsignments in loop tests. You can move the assignment into the loop body with a break:\\nwhile True:\\n    x = next()\\n    if not x: break\\n    ...process x...\\nor move the assignment into the loop with tests:\\nx = True\\nwhile x:\\n    x = next()\\n    if x:\\n        ...process x...\\nor move the first assignment outside the loop:\\nx = next()\\nwhile x:\\n    ...process x...\\n    x = next()\\nOf these three coding patterns, the first may be considered by some to be the least\\nstructured, but it also seems to be the simplest and is the most commonly used. A simple\\nPython for loop may replace some C loops as well.\\nfor Loops\\nThe for loop is a generic sequence iterator \\nin Python: it can step through the items in\\nany ordered sequence object. The for statement works on strings, lists, tuples, other\\nbuilt-in iterables, and new objects that we’ll see how to create later with classes. We\\nmet it in brief when studying sequence object types; let’s expand on its usage more\\nformally here.\\nGeneral Format\\nThe Python for loop begins with a header line that specifies an assignment target (or\\ntargets), along with the object you want to step through. The header is followed by a\\nblock of (normally indented) statements that you want to repeat:\\n334 | Chapter 13: \\u2002while and for Loops', metadata={'source': 'python.pdf', 'page': 384}),\n",
       " Document(page_content='for <target> in <object>:             # Assign object items to target\\n    <statements>                      # Repeated loop body: use target\\nelse:\\n    <statements>                      # If we didn\\'t hit a \\'break\\'\\nWhen Python runs a for loop, it assigns the items in the sequence object to the target\\none by one \\nand executes the loop body for each. The loop body typically uses the\\nassignment target to refer to the current item in the sequence as though it were a cursor\\nstepping through the sequence.\\nThe name used as the assignment target in a for header line is usually a (possibly new)\\nvariable in the scope where the for statement is coded. There’s not much special about\\nit; it can even be changed inside the loop’s body, but it will automatically be set to the\\nnext item in the sequence when control returns to the top of the loop again. After the\\nloop this variable normally still refers to the last item visited, which is the last item in\\nthe sequence unless the loop exits with a break statement.\\nThe for statement also supports an optional else block, which works exactly as it does\\nin a while loop—it’s executed if the loop exits without running into a break statement\\n(i.e., if all items in the sequence have been visited). The break and continue statements\\nintroduced earlier also work the same in a for loop as they do in a while. The for loop’s\\ncomplete format can be described this way:\\nfor <target> in <object>:             # Assign object items to target\\n    <statements>\\n    if <test>: break                  # Exit loop now, skip else\\n    if <test>: continue               # Go to top of loop now\\nelse:\\n    <statements>                      # If we didn\\'t hit a \\'break\\'\\nExamples\\nLet’s type a few for loops interactively now, so you can see how they are used in practice.\\nBasic usage\\nAs mentioned earlier, a for loop can step across any kind of sequence object. In our\\nfirst example, for instance, we’ll assign the name x to each of the three items in a list in\\nturn, from left to right, and the print statement will be executed for each. Inside the\\nprint statement (the loop body), the name x refers to the current item in the list:\\n>>> for x in [\"spam\", \"eggs\", \"ham\"]:\\n...     print(x, end=\\' \\')\\n...\\nspam eggs ham\\nThe next two examples compute the sum and product of all the items in a list. Later in\\nthis chapter and later in the book we’ll meet tools that apply operations such as + and\\n* to items in a list automatically, but it’s usually just as easy to use a for:\\nfor Loops | 335', metadata={'source': 'python.pdf', 'page': 385}),\n",
       " Document(page_content='>>> sum = 0\\n>>> for x in [1, 2, 3, 4]:\\n...     sum = sum + x\\n...\\n>>> sum\\n10\\n>>> prod = 1\\n>>> for item in [1, 2, 3, 4]: prod *= item\\n...\\n>>> prod\\n24\\nOther data types\\nAny sequence works \\nin a for, as it’s a generic tool. For example, for loops work on\\nstrings and tuples:\\n>>> S = \"lumberjack\"\\n>>> T = (\"and\", \"I\\'m\", \"okay\")\\n>>> for x in S: print(x, end=\\' \\')     # Iterate over a string\\n...\\nl u m b e r j a c k\\n>>> for x in T: print(x, end=\\' \\')     # Iterate over a tuple\\n...\\nand I\\'m okay\\nIn fact, as we’ll in the next chapter when we explore the notion of “iterables,” for loops\\ncan even work on some objects that are not sequences—files and dictionaries work, too!\\nTuple assignment in for loops\\nIf you’re iterating through a sequence of tuples, the loop target itself can actually be a\\ntuple of targets. This is just another case of the tuple-unpacking assignment we studied\\nin Chapter 11 at work. Remember, the for loop assigns items in the sequence object\\nto the target, and assignment works the same everywhere:\\n>>> T = [(1, 2), (3, 4), (5, 6)]\\n>>> for (a, b) in T:                   # Tuple assignment at work\\n...     print(a, b)\\n...\\n1 2\\n3 4\\n5 6\\nHere, the first time through the loop is like writing (a,b) = (1,2), the second time is\\nlike writing (a,b) = (3,4), and so on. The net effect is to automatically unpack the\\ncurrent tuple on each iteration.\\nThis form is commonly used in conjunction with the zip call we’ll meet later in this\\nchapter to implement parallel traversals. It also makes regular appearances in conjunc-\\ntion with SQL databases in Python, where query result tables are returned as sequences\\n336 | Chapter 13: \\u2002while and for Loops', metadata={'source': 'python.pdf', 'page': 386}),\n",
       " Document(page_content=\"of sequences like the list used here—the outer list is the database table, the nested tuples\\nare the rows within the table, and tuple assignment extracts columns.\\nTuples in for \\nloops also come in handy to iterate through both keys and values in\\ndictionaries using the items method, rather than looping through the keys and indexing\\nto fetch the values manually:\\n>>> D = {'a': 1, 'b': 2, 'c': 3}\\n>>> for key in D:\\n...    print(key, '=>', D[key])             # Use dict keys iterator and index\\n...\\na => 1\\nc => 3\\nb => 2\\n>>> list(D.items())\\n[('a', 1), ('c', 3), ('b', 2)]\\n>>> for (key, value) in D.items():\\n...    print(key, '=>', value)              # Iterate over both keys and values\\n...\\na => 1\\nc => 3\\nb => 2\\nIt’s important to note that tuple assignment in for loops isn’t a special case; any as-\\nsignment target works syntactically after the word for. Although we can always assign\\nmanually within the loop to unpack:\\n>>> T\\n[(1, 2), (3, 4), (5, 6)]\\n>>> for both in T:\\n...     a, b = both                         # Manual assignment equivalent\\n...     print(a, b)\\n...\\n1 2\\n3 4\\n5 6\\nTuples in the loop header save us an extra step when iterating through sequences of\\nsequences. As suggested in Chapter 11, even nested structures may be automatically\\nunpacked this way in a for:\\n>>> ((a, b), c) = ((1, 2), 3)               # Nested sequences work too\\n>>> a, b, c\\n(1, 2, 3)\\n>>> for ((a, b), c) in [((1, 2), 3), ((4, 5), 6)]: print(a, b, c)\\n...\\n1 2 3\\n4 5 6\\nfor Loops | 337\", metadata={'source': 'python.pdf', 'page': 387}),\n",
       " Document(page_content=\"But this is no special case—the for loop simply runs the sort of assignment we ran just\\nbefore it, on each iteration. Any nested sequence structure may be unpacked this way,\\njust because sequence assignment is so generic:\\n>>> for ((a, b), c) in [([1, 2], 3), ['XY', 6]]: print(a, b, c)\\n...\\n1 2 3\\nX Y 6\\nPython 3.0 extended sequence assignment in for loops\\nIn fact, because the loop variable in a for loop can really be any assignment target, we\\ncan also use Python 3.0’s extended sequence-unpacking assignment syntax here to\\nextract items and sections of sequences within sequences. Really, this isn’t a special\\ncase either, but simply a new assignment form in 3.0 (as discussed in Chapter 11);\\nbecause it works in assignment statements, it automatically works in for loops.\\nConsider the tuple assignment form introduced in the prior section. A tuple of values\\nis assigned to a tuple of names on each iteration, exactly like a simple assignment\\nstatement:\\n>>> a, b, c = (1, 2, 3)                               # Tuple assignment\\n>>> a, b, c\\n(1, 2, 3)\\n>>> for (a, b, c) in [(1, 2, 3), (4, 5, 6)]:          # Used in for loop\\n...     print(a, b, c)\\n...\\n1 2 3\\n4 5 6\\nIn Python 3.0, because a sequence can be assigned to a more general set of names with\\na starred name to collect multiple items, we can use the same syntax to extract parts of\\nnested sequences in the for loop:\\n>>> a, *b, c = (1, 2, 3, 4)                           # Extended seq assignment\\n>>> a, b, c\\n(1, [2, 3], 4)\\n>>> for (a, *b, c) in [(1, 2, 3, 4), (5, 6, 7, 8)]:\\n...     print(a, b, c)\\n...\\n1 [2, 3] 4\\n5 [6, 7] 8\\nIn practice, this approach might be used to pick out multiple columns from rows of\\ndata represented as nested sequences. In Python 2.X starred names aren’t allowed, but\\nyou can achieve similar effects by slicing. The only difference is that slicing returns a\\ntype-specific result, whereas starred names always are assigned lists:\\n>>> for all in [(1, 2, 3, 4), (5, 6, 7, 8)]:          # Manual slicing in 2.6\\n...     a, b, c = all[0], all[1:3], all[3]\\n...     print(a, b, c)\\n338 | Chapter 13: \\u2002while and for Loops\", metadata={'source': 'python.pdf', 'page': 388}),\n",
       " Document(page_content='...\\n1 (2, 3) 4\\n5 (6, 7) 8\\nSee Chapter 11 for more on this assignment form.\\nNested for loops\\nNow let’s look \\nat a for loop that’s a bit more sophisticated than those we’ve seen so\\nfar. The next example illustrates statement nesting and the loop else clause in a for.\\nGiven a list of objects (items) and a list of keys (tests), this code searches for each key\\nin the objects list and reports on the search’s outcome:\\n>>> items = [\"aaa\", 111, (4, 5), 2.01]   # A set of objects\\n>>> tests = [(4, 5), 3.14]               # Keys to search for\\n>>>\\n>>> for key in tests:                    # For all keys\\n...     for item in items:               # For all items\\n...         if item == key:              # Check for match\\n...             print(key, \"was found\")\\n...             break\\n...     else:\\n...         print(key, \"not found!\")\\n...\\n(4, 5) was found\\n3.14 not found!\\nBecause the nested if runs a break when a match is found, the loop else clause can\\nassume that if it is reached, the search has failed. Notice the nesting here. When this\\ncode runs, there are two loops going at the same time: the outer loop scans the keys\\nlist, and the inner loop scans the items list for each key. The nesting of the loop else\\nclause is critical; it’s indented to the same level as the header line of the inner for loop,\\nso it’s associated with the inner loop, not the if or the outer for.\\nNote that this example is easier to code if we employ the in operator to test membership.\\nBecause in implicitly scans an object looking for a match (at least logically), it replaces\\nthe inner loop:\\n>>> for key in tests:                    # For all keys\\n...     if key in items:                 # Let Python check for a match\\n...         print(key, \"was found\")\\n...     else:\\n...         print(key, \"not found!\")\\n...\\n(4, 5) was found\\n3.14 not found!\\nIn general, it’s a good idea to let Python do as much of the work as possible (as in this\\nsolution) for the sake of brevity and performance.\\nThe next example performs a typical data-structure task with a for—collecting com-\\nmon items in two sequences (strings). It’s roughly a simple set intersection routine;\\nafter the loop runs, res refers to a list that contains all the items found in seq1 and seq2:\\nfor Loops | 339', metadata={'source': 'python.pdf', 'page': 389}),\n",
       " Document(page_content='>>> seq1 = \"spam\"\\n>>> seq2 = \"scam\"\\n>>>\\n>>> res = []                             # Start empty\\n>>> for x in seq1:                       # Scan first sequence\\n...     if x in seq2:                    # Common item?\\n...         res.append(x)                # Add to result end\\n...\\n>>> res\\n[\\'s\\', \\'a\\', \\'m\\']\\nUnfortunately, this code \\nis equipped to work only on two specific variables: seq1 and\\nseq2. It would be nice if this loop could somehow be generalized into a tool you could\\nuse more than once. As you’ll see, that simple idea leads us to functions, the topic of\\nthe next part of the book.\\nWhy You Will Care: File Scanners\\nIn general, loops \\ncome in handy anywhere you need to repeat an operation or process\\nsomething more than once. Because files contain multiple characters and lines, they\\nare one of the more typical use cases for loops. To load a file’s contents into a string all\\nat once, you simply call the file object’s read method:\\nfile = open(\\'test.txt\\', \\'r\\')   # Read contents into a string\\nprint(file.read())\\nBut to load a file in smaller pieces, it’s common to code either a while loop with breaks\\non end-of-file, or a for loop. To read by characters, either of the following codings will\\nsuffice:\\nfile = open(\\'test.txt\\')\\nwhile True:\\n    char = file.read(1)         # Read by character\\n    if not char: break\\n    print(char)\\nfor char in open(\\'test.txt\\').read():\\n    print(char)\\nThe for loop here also processes each character, but it loads the file into memory all at\\nonce (and assumes it fits!). To read by lines or blocks instead, you can use while loop\\ncode like this:\\nfile = open(\\'test.txt\\')\\nwhile True:\\n    line = file.readline()      # Read line by line\\n    if not line: break\\n    print(line, end=\\'\\')         # Line already has a \\\\n\\nfile = open(\\'test.txt\\', \\'rb\\')\\nwhile True:\\n    chunk = file.read(10)       # Read byte chunks: up to 10 bytes\\n    if not chunk: break\\n    print(chunk)\\n340 | Chapter 13: \\u2002while and for Loops', metadata={'source': 'python.pdf', 'page': 390}),\n",
       " Document(page_content=\"You typically read binary data in blocks. To read text files line by line, though, the\\nfor loop tends to be easiest to code and the quickest to run:\\nfor line in open('test.txt').readlines():\\n    print(line, end='')\\nfor line in open('test.txt'):   # Use iterators: best text input mode\\n    print(line, end='')\\nThe file readlines \\nmethod loads a file all at once into a line-string list, and the last\\nexample here relies on file iterators to automatically read one line on each loop iteration\\n(iterators are covered in detail in Chapter 14 ). See the library manual for more on the\\ncalls used here. The last example here is generally the best option for text files—besides\\nits simplicity, it works for arbitrarily large files and doesn’t load the entire file into\\nmemory all at once. The iterator version may be the quickest, but I/O performance is\\nless clear-cut in Python 3.0.\\nIn some 2.X Python code, you may also see the name open replaced with file and the\\nfile object’s older xreadlines method used to achieve the same effect as the file’s auto-\\nmatic line iterator (it’s like readlines but doesn’t load the file into memory all at once).\\nBoth file and xreadlines are removed in Python 3.0, because they are redundant; you\\nshouldn’t use them in 2.6 either, but they may pop up in older code and resources.\\nWatch for more on reading files in Chapter 36; as we’ll see there, text and binary files\\nhave slightly different semantics in 3.0.\\nLoop Coding Techniques\\nThe for loop subsumes \\nmost counter-style loops. It’s generally simpler to code and\\nquicker to run than a while, so it’s the first tool you should reach for whenever you\\nneed to step through a sequence. But there are also situations where you will need to\\niterate in more specialized ways. For example, what if you need to visit every second\\nor third item in a list, or change the list along the way? How about traversing more than\\none sequence in parallel, in the same for loop?\\nYou can always code such unique iterations with a while loop and manual indexing,\\nbut Python provides two built-ins that allow you to specialize the iteration in a for:\\n• The built-in range function produces a series of successively higher integers, which\\ncan be used as indexes in a for.\\n• The built-in zip function returns a series of parallel-item tuples, which can be used\\nto traverse multiple sequences in a for.\\nBecause for loops typically run quicker than while-based counter loops, it’s to your\\nadvantage to use tools like these that allow you to use for when possible. Let’s look at\\neach of these built-ins in turn.\\nLoop Coding Techniques | 341\", metadata={'source': 'python.pdf', 'page': 391}),\n",
       " Document(page_content=\"Counter Loops: while and range\\nThe range function is \\nreally a general tool that can be used in a variety of contexts. \\nAlthough it’s used most often to generate indexes in a for, you can use it anywhere you\\nneed a list of integers. In Python 3.0, range is an iterator that generates items on demand,\\nso we need to wrap it in a list call to display its results all at once (more on iterators\\nin Chapter 14):\\n>>> list(range(5)), list(range(2, 5)), list(range(0, 10, 2))\\n([0, 1, 2, 3, 4], [2, 3, 4], [0, 2, 4, 6, 8])\\nWith one argument, range generates a list of integers from zero up to but not including\\nthe argument’s value. If you pass in two arguments, the first is taken as the lower bound.\\nAn optional third argument can give a step; if it is used, Python adds the step to each\\nsuccessive integer in the result (the step defaults to 1). Ranges can also be nonpositive\\nand nonascending, if you want them to be:\\n>>> list(range(−5, 5))\\n[−5, −4, −3, −2, −1, 0, 1, 2, 3, 4]\\n>>> list(range(5, −5, −1))\\n[5, 4, 3, 2, 1, 0, −1, −2, −3, −4]\\nAlthough such range results may be useful all by themselves, they tend to come in most\\nhandy within for loops. For one thing, they provide a simple way to repeat an action\\na specific number of times. To print three lines, for example, use a range to generate\\nthe appropriate number of integers; for loops force results from range automatically in\\n3.0, so we don’t need list here:\\n>>> for i in range(3):\\n...     print(i, 'Pythons')\\n...\\n0 Pythons\\n1 Pythons\\n2 Pythons\\nrange is also commonly used to iterate over a sequence indirectly. The easiest and fastest\\nway to step through a sequence exhaustively is always with a simple for, as Python\\nhandles most of the details for you:\\n>>> X = 'spam'\\n>>> for item in X: print(item, end=' ')           # Simple iteration\\n...\\ns p a m\\nInternally, the for loop handles the details of the iteration automatically when used\\nthis way. If you really need to take over the indexing logic explicitly, you can do it with\\na while loop:\\n>>> i = 0\\n>>> while i < len(X):                             # while loop iteration\\n...     print(X[i], end=' ')\\n...     i += 1\\n342 | Chapter 13: \\u2002while and for Loops\", metadata={'source': 'python.pdf', 'page': 392}),\n",
       " Document(page_content=\"...\\ns p a m\\nYou can also \\ndo manual indexing with a for, though, if you use range to generate a list\\nof indexes to iterate through. It’s a multistep process, but it’s sufficient to generate\\noffsets, rather than the items at those offsets:\\n>>> X\\n'spam'\\n>>> len(X)                                        # Length of string\\n4\\n>>> list(range(len(X)))                           # All legal offsets into X\\n[0, 1, 2, 3]\\n>>>\\n>>> for i in range(len(X)): print(X[i], end=' ')  # Manual for indexing\\n...\\ns p a m\\nNote that because this example is stepping over a list of offsets into X, not the actual\\nitems of X, we need to index back into X within the loop to fetch each item.\\nNonexhaustive Traversals: range and Slices\\nThe last example in the prior section works, but it’s not the fastest option. It’s also\\nmore work than we need to do. Unless you have a special indexing requirement, you’re\\nalways better off using the simple for loop form in Python—as a general rule, use for\\ninstead of while whenever possible, and don’t use range calls in for loops except as a\\nlast resort. This simpler solution is better:\\n>>> for item in X: print(item)                    # Simple iteration\\n...\\nHowever, the coding pattern used in the prior example does allow us to do more spe-\\ncialized sorts of traversals. For instance, we can skip items as we go:\\n>>> S = 'abcdefghijk'\\n>>> list(range(0, len(S), 2))\\n[0, 2, 4, 6, 8, 10]\\n>>> for i in range(0, len(S), 2): print(S[i], end=' ')\\n...\\na c e g i k\\nHere, we visit every second item in the string S by stepping over the generated range\\nlist. To visit every third item, change the third range argument to be 3, and so on. In\\neffect, using range this way lets you skip items in loops while still retaining the simplicity\\nof the for loop construct.\\nStill, this is probably not the ideal best-practice technique in Python today. If you really\\nwant to skip items in a sequence, the extended three-limit form of the slice expres-\\nsion, presented in Chapter 7 , provides a simpler route to the same goal. To visit every\\nsecond character in S, for example, slice with a stride of 2:\\nLoop Coding Techniques | 343\", metadata={'source': 'python.pdf', 'page': 393}),\n",
       " Document(page_content=\">>> S = 'abcdefghijk'\\n>>> for c in S[::2]: print(c, end=' ')\\n...\\na c e g i k\\nThe result is \\nthe same, but substantially easier for you to write and for others to read.\\nThe only real advantage to using range here instead is that it does not copy the string\\nand does not create a list in 3.0; for very large strings, it may save memory.\\nChanging Lists: range\\nAnother common place where you may use the range and for combination is in loops\\nthat change a list as it is being traversed. Suppose, for example, that you need to add 1\\nto every item in a list. You can try this with a simple for loop, but the result probably\\nwon’t be exactly what you want:\\n>>> L = [1, 2, 3, 4, 5]\\n>>> for x in L:\\n...     x += 1\\n...\\n>>> L\\n[1, 2, 3, 4, 5]\\n>>> x\\n6\\nThis doesn’t quite work—it changes the loop variable x, not the list L. The reason is\\nsomewhat subtle. Each time through the loop, x refers to the next integer already pulled\\nout of the list. In the first iteration, for example, x is integer 1. In the next iteration, the\\nloop body sets x to a different object, integer 2, but it does not update the list where 1\\noriginally came from.\\nTo really change the list as we march across it, we need to use indexes so we can assign\\nan updated value to each position as we go. The range/len combination can produce\\nthe required indexes for us:\\n>>> L = [1, 2, 3, 4, 5]\\n>>> for i in range(len(L)):          # Add one to each item in L\\n...     L[i] += 1                    # Or L[i] = L[i] + 1\\n...\\n>>> L\\n[2, 3, 4, 5, 6]\\nWhen coded this way, the list is changed as we proceed through the loop. There is no\\nway to do the same with a simple for x in L: -style loop, because such a loop iterates\\nthrough actual items, not list positions. But what about the equivalent while loop? Such\\na loop requires a bit more work on our part, and likely runs more slowly:\\n>>> i = 0\\n>>> while i < len(L):\\n...     L[i] += 1\\n344 | Chapter 13: \\u2002while and for Loops\", metadata={'source': 'python.pdf', 'page': 394}),\n",
       " Document(page_content=\"...     i += 1\\n...\\n>>> L\\n[3, 4, 5, 6, 7]\\nHere again, though, \\nthe range solution may not be ideal either. A list comprehension\\nexpression of the form:\\n[x+1 for x in L]\\nwould do similar work, albeit without changing the original list in-place (we could\\nassign the expression’s new list object result back to L, but this would not update any\\nother references to the original list). Because this is such a central looping concept, we’ll\\nsave a complete exploration of list comprehensions for the next chapter.\\nParallel Traversals: zip and map\\nAs we’ve seen, the range built-in allows us to traverse sequences with for in a nonex-\\nhaustive fashion. In the same spirit, the built-in zip function allows us to use for loops\\nto visit multiple sequences in parallel. In basic operation, zip takes one or more se-\\nquences as arguments and returns a series of tuples that pair up parallel items taken\\nfrom those sequences. For example, suppose we’re working with two lists:\\n>>> L1 = [1,2,3,4]\\n>>> L2 = [5,6,7,8]\\nTo combine the items in these lists, we can use zip to create a list of tuple pairs (like\\nrange, zip is an iterable object in 3.0, so we must wrap it in a list call to display all its\\nresults at once—more on iterators in the next chapter):\\n>>> zip(L1, L2)\\n<zip object at 0x026523C8>\\n>>> list(zip(L1, L2))                       # list() required in 3.0, not 2.6\\n[(1, 5), (2, 6), (3, 7), (4, 8)]\\nSuch a result may be useful in other contexts as well, but when wedded with the for\\nloop, it supports parallel iterations:\\n>>> for (x, y) in zip(L1, L2):\\n...     print(x, y, '--', x+y)\\n...\\n1 5 -- 6\\n2 6 -- 8\\n3 7 -- 10\\n4 8 -- 12\\nHere, we step over the result of the zip call—that is, the pairs of items pulled from the\\ntwo lists. Notice that this for loop again uses the tuple assignment form we met earlier\\nto unpack each tuple in the zip result. The first time through, it’s as though we ran the\\nassignment statement (x, y) = (1, 5).\\nLoop Coding Techniques | 345\", metadata={'source': 'python.pdf', 'page': 395}),\n",
       " Document(page_content=\"The net effect is that we scan both L1 and L2 in our loop. We could achieve a similar\\neffect with a while loop that handles indexing manually, but it would require more\\ntyping and would likely run more slowly than the for/zip approach.\\nStrictly speaking, the zip function is more general than this example suggests. For in-\\nstance, it accepts any type of sequence (really, any iterable object, including files), and\\nit accepts more than two arguments. With three arguments, as in the following exam-\\nple, it builds a list of three-item tuples with items from each sequence, essentially pro-\\njecting by columns (technically, we get an N-ary tuple for N arguments):\\n>>> T1, T2, T3 = (1,2,3), (4,5,6), (7,8,9)\\n>>> T3\\n(7, 8, 9)\\n>>> list(zip(T1, T2, T3))\\n[(1, 4, 7), (2, 5, 8), (3, 6, 9)]\\nMoreover, zip truncates result tuples at the length of the shortest sequence when the\\nargument lengths differ. In the following, we zip together two strings to pick out char-\\nacters in parallel, but the result has only as many tuples as the length of the shortest\\nsequence:\\n>>> S1 = 'abc'\\n>>> S2 = 'xyz123'\\n>>>\\n>>> list(zip(S1, S2))\\n[('a', 'x'), ('b', 'y'), ('c', 'z')]\\nmap equivalence in Python 2.6\\nIn Python 2.X, the related built-in map function pairs items from sequences in a similar\\nfashion, but it pads shorter sequences with None if the argument lengths differ instead\\nof truncating to the shortest length:\\n>>> S1 = 'abc'\\n>>> S2 = 'xyz123'\\n>>> map(None, S1, S2)                        # 2.X only\\n[('a', 'x'), ('b', 'y'), ('c', 'z'), (None, '1'), (None, '2'), (None,'3')]\\nThis example is using a degenerate form of the map built-in, which is no longer supported\\nin 3.0. Normally, map takes a function and one or more sequence arguments and collects\\nthe results of calling the function with parallel items taken from the sequence(s). We’ll\\nstudy map in detail in Chapters 19 and 20, but as a brief example, the following maps\\nthe built-in ord function across each item in a string and collects the results (like zip,\\nmap is a value generator in 3.0 and so must be passed to list to collect all its results at\\nonce):\\n>>> list(map(ord, 'spam'))\\n[115, 112, 97, 109]\\n346 | Chapter 13: \\u2002while and for Loops\", metadata={'source': 'python.pdf', 'page': 396}),\n",
       " Document(page_content=\"This works the same as the following loop statement, but is often quicker:\\n>>> res = []\\n>>> for c in 'spam': res.append(ord(c))\\n>>> res\\n[115, 112, 97, 109]\\nVersion skew note : The degenerate form of map using a function argu-\\nment of None is no longer supported in Python 3.0, because it largely\\noverlaps with zip (and was, frankly, a bit at odds with map’s function-\\napplication purpose). In 3.0, either use zip or write loop code to pad\\nresults yourself. We’ll see how to do this in Chapter 20, after we’ve had\\na chance to study some additional iteration concepts.\\nDictionary construction with zip\\nIn Chapter 8 , I suggested that the zip call used here can also be handy for generating\\ndictionaries when the sets of keys and values must be computed at runtime. Now that\\nwe’re becoming proficient with zip, I’ll explain how it relates to dictionary construc-\\ntion. As you’ve learned, you can always create a dictionary by coding a dictionary literal,\\nor by assigning to keys over time:\\n>>> D1 = {'spam':1, 'eggs':3, 'toast':5}\\n>>> D1\\n{'toast': 5, 'eggs': 3, 'spam': 1}\\n>>> D1 = {}\\n>>> D1['spam']  = 1\\n>>> D1['eggs']  = 3\\n>>> D1['toast'] = 5\\nWhat to do, though, if your program obtains dictionary keys and values in lists at\\nruntime, after you’ve coded your script? For example, say you had the following keys\\nand values lists:\\n>>> keys = ['spam', 'eggs', 'toast']\\n>>> vals = [1, 3, 5]\\nOne solution for turning those lists into a dictionary would be to zip the lists and step\\nthrough them in parallel with a for loop:\\n>>> list(zip(keys, vals))\\n[('spam', 1), ('eggs', 3), ('toast', 5)]\\n>>> D2 = {}\\n>>> for (k, v) in zip(keys, vals): D2[k] = v\\n...\\n>>> D2\\n{'toast': 5, 'eggs': 3, 'spam': 1}\\nLoop Coding Techniques | 347\", metadata={'source': 'python.pdf', 'page': 397}),\n",
       " Document(page_content=\"It turns out, though, that in Python 2.2 and later you can skip the for loop altogether\\nand simply pass the zipped keys/values lists to the built-in dict constructor call:\\n>>> keys = ['spam', 'eggs', 'toast']\\n>>> vals = [1, 3, 5]\\n>>> D3 = dict(zip(keys, vals))\\n>>> D3\\n{'toast': 5, 'eggs': 3, 'spam': 1}\\nThe built-in name dict\\n is really a type name in Python (you’ll learn more about type\\nnames, and subclassing them, in Chapter 31 ). Calling it achieves something like a list-\\nto-dictionary conversion, but it’s really an object construction request. In the next\\nchapter we’ll explore a related but richer concept, the list comprehension , which builds\\nlists in a single expression; we’ll also revisit 3.0 dictionary comprehensions  an alternative\\nto the dict cal for zipped key/value pairs.\\nGenerating Both Offsets and Items: enumerate\\nEarlier, we discussed using range to generate the offsets of items in a string, rather than\\nthe items at those offsets. In some programs, though, we need both: the item to use,\\nplus an offset as we go. Traditionally, this was coded with a simple for loop that also\\nkept a counter of the current offset:\\n>>> S = 'spam'\\n>>> offset = 0\\n>>> for item in S:\\n...     print(item, 'appears at offset', offset)\\n...     offset += 1\\n...\\ns appears at offset 0\\np appears at offset 1\\na appears at offset 2\\nm appears at offset 3\\nThis works, but in recent Python releases a new built-in named enumerate does the job\\nfor us:\\n>>> S = 'spam'\\n>>> for (offset, item) in enumerate(S):\\n...     print(item, 'appears at offset', offset)\\n...\\ns appears at offset 0\\np appears at offset 1\\na appears at offset 2\\nm appears at offset 3\\nThe enumerate function returns a generator object —a kind of object that supports the\\niteration protocol that we will study in the next chapter and will discuss in more detail\\nin the next part of the book. In short, it has a __next__ method called by the next built-\\nin function, which returns an (index, value) tuple each time through the loop. We can\\nunpack these tuples with tuple assignment in the for loop (much like using zip):\\n348 | Chapter 13: \\u2002while and for Loops\", metadata={'source': 'python.pdf', 'page': 398}),\n",
       " Document(page_content=\">>> E = enumerate(S)\\n>>> E\\n<enumerate object at 0x02765AA8>\\n>>> next(E)\\n(0, 's')\\n>>> next(E)\\n(1, 'p')\\n>>> next(E)\\n(2, 'a')\\nAs usual, we \\ndon’t normally see this machinery because iteration contexts—\\nincluding list comprehensions, the subject of Chapter 14 —run the iteration protocol\\nautomatically:\\n>>> [c * i for (i, c) in enumerate(S)]\\n['', 'p', 'aa', 'mmm']\\nTo fully understand iteration concepts like enumerate, zip, and list comprehensions,\\nwe need to move on to the next chapter for a more formal dissection.\\nChapter Summary\\nIn this chapter, we explored Python’s looping statements as well as some concepts\\nrelated to looping in Python. We looked at the while and for loop statements in depth,\\nand we learned about their associated else clauses. We also studied the break and\\ncontinue statements, which have meaning only inside loops, and met several built-in\\ntools commonly used in for loops, including range, zip, map, and enumerate (although\\ntheir roles as iterators in Python 3.0 won’t be fully uncovered until the next chapter).\\nIn the next chapter, we continue the iteration story by discussing list comprehensions\\nand the iteration protocol in Python—concepts strongly related to for loops. There,\\nwe’ll also explain some of the subtleties of iterable tools we met here, such as range and\\nzip. As always, though, before moving on let’s exercise what you’ve picked up here\\nwith a quiz.\\nTest Your Knowledge: Quiz\\n1. What are the main functional differences between a while\\n and a for?\\n2. What’s the difference between break and continue?\\n3. When is a loop’s else clause executed?\\n4. How can you code a counter-based loop in Python?\\n5. What can a range be used for in a for loop?\\nTest Your Knowledge: Quiz | 349\", metadata={'source': 'python.pdf', 'page': 399}),\n",
       " Document(page_content='Test Your Knowledge: Answers\\n1. The while loop is \\na general looping statement, but the for is designed to iterate\\nacross items in a sequence (really, iterable). Although the while can imitate the\\nfor with counter loops, it takes more code and might run slower.\\n2. The break statement exits a loop immediately (you wind up below the entire\\nwhile or for loop statement), and continue jumps back to the top of the loop (you\\nwind up positioned just before the test in while or the next item fetch in for).\\n3. The else clause in a while or for loop will be run once as the loop is exiting, if the\\nloop exits normally (without running into a break statement). A break exits the\\nloop immediately, skipping the else part on the way out (if there is one).\\n4. Counter loops can be coded with a while statement that keeps track of the index\\nmanually, or with a for loop that uses the range built-in function to generate suc-\\ncessive integer offsets. Neither is the preferred way to work in Python, if you need\\nto simply step across all the items in a sequence. Instead, use a simple for loop\\ninstead, without range or counters, whenever possible; it will be easier to code and\\nusually quicker to run.\\n5. The range built-in can be used in a for to implement a fixed number of repetitions,\\nto scan by offsets instead of items at offsets, to skip successive items as you go, and\\nto change a list while stepping across it. None of these roles requires range, and\\nmost have alternatives—scanning actual items, three-limit slices, and list compre-\\nhensions are often better solutions today (despite the natural inclinations of ex-C\\nprogrammers to want to count things!).\\n350 | Chapter 13: \\u2002while and for Loops', metadata={'source': 'python.pdf', 'page': 400}),\n",
       " Document(page_content=\"CHAPTER 14\\nIterations and Comprehensions, Part 1\\nIn the prior chapter we met Python’s two looping statements, while and for. Although\\nthey can handle most repetitive tasks programs need to perform, the need to iterate\\nover sequences is so common and pervasive that Python provides additional tools to\\nmake it simpler and more efficient. This chapter begins our exploration of these tools.\\nSpecifically, it presents the related concepts of Python’s iteration protocol —a method-\\ncall model used by the for loop—and fills in some details on list comprehensions—a\\nclose cousin to the for loop that applies an expression to items in an iterable.\\nBecause both of these tools are related to both the for loop and functions, we’ll take a\\ntwo-pass approach to covering them in this book: this chapter introduces the basics in\\nthe context of looping tools, serving as something of continuation of the prior chapter,\\nand a later chapter (Chapter 20) revisits them in the context of function-based tools.\\nIn this chapter, we’ll also sample additional iteration tools in Python and touch on the\\nnew iterators available in Python 3.0.\\nOne note up front: some of the concepts presented in these chapters may seem ad-\\nvanced at first glance. With practice, though, you’ll find that these tools are useful and\\npowerful. Although never strictly required, because they’ve become commonplace in\\nPython code, a basic understanding can also help if you must read programs written\\nby others.\\nIterators: A First Look\\nIn the preceding chapter, I mentioned that the for loop can work on any sequence type\\nin Python, including lists, tuples, and strings, like this:\\n>>> for x in [1, 2, 3, 4]: print(x ** 2, end=' ')\\n...\\n1 4 9 16\\n>>> for x in (1, 2, 3, 4): print(x ** 3, end=' ')\\n...\\n1 8 27 64\\n351\", metadata={'source': 'python.pdf', 'page': 401}),\n",
       " Document(page_content=\">>> for x in 'spam': print(x * 2, end=' ')\\n...\\nss pp aa mm\\nActually, the for \\nloop turns out to be even more generic than this—it works on any\\niterable object . In fact, this is true of all iteration tools that scan objects from left to right\\nin Python, including for loops, the list comprehensions we’ll study in this chapter, in\\nmembership tests, the map built-in function, and more.\\nThe concept of “iterable objects” is relatively recent in Python, but it has come to\\npermeate the language’s design. It’s essentially a generalization of the notion of se-\\nquences—an object is considered iterable if it is either a physically stored sequence or\\nan object that produces one result at a time in the context of an iteration tool like a\\nfor loop. In a sense, iterable objects include both physical sequences and virtual\\nsequences computed on demand.*\\nThe Iteration Protocol: File Iterators\\nOne of the easiest ways to understand what this means is to look at how it works with\\na built-in type such as the file. Recall from Chapter 9 that open file objects have a\\nmethod called readline, which reads one line of text from a file at a time—each time\\nwe call the readline method, we advance to the next line. At the end of the file, an\\nempty string is returned, which we can detect to break out of the loop:\\n>>> f = open('script1.py')     # Read a 4-line script file in this directory\\n>>> f.readline()               # readline loads one line on each call\\n'import sys\\\\n'\\n>>> f.readline()\\n'print(sys.path)\\\\n'\\n>>> f.readline()\\n'x = 2\\\\n'\\n>>> f.readline()\\n'print(2 ** 33)\\\\n'\\n>>> f.readline()               # Returns empty string at end-of-file\\n''\\nHowever, files also have a method named __next__ that has a nearly identical effect—\\nit returns the next line from a file each time it is called. The only noticeable difference\\nis that __next__ raises a built-in StopIteration exception at end-of-file instead of re-\\nturning an empty string:\\n>>> f = open('script1.py')     # __next__ loads one line on each call too\\n>>> f.__next__()               # But raises an exception at end-of-file\\n'import sys\\\\n'\\n>>> f.__next__()\\n'print(sys.path)\\\\n'\\n* Terminology in this topic tends to be a bit loose. This text uses the terms “iterable” and “iterator”\\ninterchangeably to refer to an object that supports iteration in general. Sometimes the term “iterable” refers\\nto an object that supports iter and “iterator” refers to an object return by iter that supports next(I), but\\nthat convention is not universal in either the Python world or this book.\\n352 | Chapter 14: \\u2002Iterations and Comprehensions, Part 1\", metadata={'source': 'python.pdf', 'page': 402}),\n",
       " Document(page_content=\">>> f.__next__()\\n'x = 2\\\\n'\\n>>> f.__next__()\\n'print(2 ** 33)\\\\n'\\n>>> f.__next__()\\nTraceback (most recent call last):\\n...more exception text omitted...\\nStopIteration\\nThis interface is exactly what we call the iteration protocol  in Python. Any object with\\na __next__ method to \\nadvance to a next result, which raises StopIteration at the end\\nof the series of results, is considered iterable in Python. Any such object may also be\\nstepped through with a for loop or other iteration tool, because all iteration tools nor-\\nmally work internally by calling __next__ on each iteration and catching the\\nStopIteration exception to determine when to exit.\\nThe net effect of this magic is that, as mentioned in Chapter 9 , the best way to read a\\ntext file line by line today is to not read it at all —instead, allow the for loop to auto-\\nmatically call __next__ to advance to the next line on each iteration. The file object’s\\niterator will do the work of automatically loading lines as you go. The following, for\\nexample, reads a file line by line, printing the uppercase version of each line along the\\nway, without ever explicitly reading from the file at all:\\n>>> for line in open('script1.py'):       # Use file iterators to read by lines\\n...     print(line.upper(), end='')       # Calls __next__, catches StopIteration\\n...\\nIMPORT SYS\\nPRINT(SYS.PATH)\\nX = 2\\nPRINT(2 ** 33)\\nNotice that the print uses end='' here to suppress adding a \\\\n, because line strings\\nalready have one (without this, our output would be double-spaced). This is considered\\nthe best way to read text files line by line today, for three reasons: it’s the simplest to\\ncode, might be the quickest to run, and is the best in terms of memory usage. The older,\\noriginal way to achieve the same effect with a for loop is to call the file readlines method\\nto load the file’s content into memory as a list of line strings:\\n>>> for line in open('script1.py').readlines():\\n...     print(line.upper(), end='')\\n...\\nIMPORT SYS\\nPRINT(SYS.PATH)\\nX = 2\\nPRINT(2 ** 33)\\nThis readlines technique still works, but it is not considered the best practice today\\nand performs poorly in terms of memory usage. In fact, because this version really does\\nload the entire file into memory all at once, it will not even work for files too big to fit\\ninto the memory space available on your computer. By contrast, because it reads one\\nline at a time, the iterator-based version is immune to such memory-explosion issues.\\nIterators: A First Look | 353\", metadata={'source': 'python.pdf', 'page': 403}),\n",
       " Document(page_content=\"The iterator version might run quicker too, though this can vary per release (Python\\n3.0 made this \\nadvantage less clear-cut by rewriting I/O libraries to support Unicode\\ntext and be less system-dependent).\\nAs mentioned in the prior chapter’s sidebar, “Why You Will Care: File Scan-\\nners” on page 340, it’s also possible to read a file line by line with a while loop:\\n>>> f = open('script1.py')\\n>>> while True:\\n...     line = f.readline()\\n...     if not line: break\\n...     print(line.upper(), end='')\\n...\\n...same output...\\nHowever, this may run slower than the iterator-based for loop version, because itera-\\ntors run at C language speed inside Python, whereas the while loop version runs Python\\nbyte code through the Python virtual machine. Any time we trade Python code for C\\ncode, speed tends to increase. This is not an absolute truth, though, especially in Python\\n3.0; we’ll see timing techniques later in this book for measuring the relative speed of\\nalternatives like these.\\nManual Iteration: iter and next\\nTo support manual iteration code (with less typing), Python 3.0 also provides a built-\\nin function, next, that automatically calls an object’s __next__ method. Given an itera-\\nble object X, the call next(X) is the same as X.__next__(), but noticeably simpler. With\\nfiles, for instance, either form may be used:\\n>>> f = open('script1.py')\\n>>> f.__next__()                   # Call iteration method directly\\n'import sys\\\\n'\\n>>> f.__next__()\\n'print(sys.path)\\\\n'\\n>>> f = open('script1.py')\\n>>> next(f)                        # next built-in calls __next__\\n'import sys\\\\n'\\n>>> next(f)\\n'print(sys.path)\\\\n'\\nTechnically, there is one more piece to the iteration protocol. When the for loop begins,\\nit obtains an iterator from the iterable object by passing it to the iter built-in function;\\nthe object returned by iter has the required next method. This becomes obvious if we\\nlook at how for loops internally process built-in sequence types such as lists:\\n>>> L = [1, 2, 3]\\n>>> I = iter(L)                    # Obtain an iterator object\\n>>> I.next()                       # Call next to advance to next item\\n1\\n>>> I.next()\\n2\\n354 | Chapter 14: \\u2002Iterations and Comprehensions, Part 1\", metadata={'source': 'python.pdf', 'page': 404}),\n",
       " Document(page_content=\">>> I.next()\\n3\\n>>> I.next()\\nTraceback (most recent call last):\\n...more omitted...\\nStopIteration\\nThis initial step \\nis not required for files, because a file object is its own iterator. That\\nis, files have their own __next__ method and so do not need to return a different object\\nthat does:\\n>>> f = open('script1.py')\\n>>> iter(f) is f\\nTrue\\n>>> f.__next__()\\n'import sys\\\\n'\\nLists, and many other built-in objects, are not their own iterators because they support\\nmultiple open iterations. For such objects, we must call iter to start iterating:\\n>>> L = [1, 2, 3]\\n>>> iter(L) is L\\nFalse\\n>>> L.__next__()\\nAttributeError: 'list' object has no attribute '__next__'\\n>>> I = iter(L)\\n>>> I.__next__()\\n1\\n>>> next(I)                # Same as I.__next__()\\n2\\nAlthough Python iteration tools call these functions automatically, we can use them to\\napply the iteration protocol manually, too. The following interaction demonstrates the\\nequivalence between automatic and manual iteration:†\\n>>> L = [1, 2, 3]\\n>>>\\n>>> for X in L:                 # Automatic iteration\\n...     print(X ** 2, end=' ')  # Obtains iter, calls __next__, catches exceptions\\n...\\n1 4 9\\n>>> I = iter(L)                 # Manual iteration: what for loops usually do\\n† Technically speaking, the for  loop calls the internal equivalent of I.__next__, instead of the next(I) used\\nhere. There is rarely any difference between the two, but as we’ll see in the next section, there are some built-\\nin objects in 3.0 (such as os.popen results) that support the former and not the latter, but may be still be\\niterated across in for loops. Your manual iterations can generally use either call scheme. If you care for the\\nfull story, in 3.0 os.popen results have been reimplemented with the subprocess module and a wrapper class,\\nwhose __getattr__ method is no longer called in 3.0 for implicit __next__ fetches made by the next built-in,\\nbut is called for explicit fetches by name—a 3.0 change issue we’ll confront in Chapters 37 and 38, which\\napparently burns some standard library code too! Also in 3.0, the related 2.6 calls os.popen2/3/4 are no longer\\navailable; use subprocess.Popen with appropriate arguments instead (see the Python 3.0 library manual for\\nthe new required code).\\nIterators: A First Look | 355\", metadata={'source': 'python.pdf', 'page': 405}),\n",
       " Document(page_content=\">>> while True:\\n...     try:                    # try statement catches exceptions\\n...         X = next(I)         # Or call I.__next__\\n...     except StopIteration:\\n...         break\\n...     print(X ** 2, end=' ')\\n...\\n1 4 9\\nTo understand this \\ncode, you need to know that try statements run an action and catch\\nexceptions that occur while the action runs (we’ll explore exceptions in depth in\\nPart VII ). I should also note that for loops and other iteration contexts can sometimes\\nwork differently for user-defined classes, repeatedly indexing an object instead of run-\\nning the iteration protocol. We’ll defer that story until we study class operator over-\\nloading in Chapter 29.\\nVersion skew note : In Python 2.6, the iteration method is named\\nX.next() instead of X.__next__(). For portability, the next(X) built-in\\nfunction is available in Python 2.6 too (but not earlier), and calls 2.6’s\\nX.next() instead of 3.0’s X.__next__(). Iteration works the same in 2.6\\nin all other ways, though; simply use X.next() or next(X) for manual\\niterations, instead of 3.0’s X.__next__(). Prior to 2.6, use manual\\nX.next() calls instead of next(X).\\nOther Built-in Type Iterators\\nBesides files and physical sequences like lists, other types have useful iterators as well.\\nThe classic way to step through the keys of a dictionary, for example, is to request its\\nkeys list explicitly:\\n>>> D = {'a':1, 'b':2, 'c':3}\\n>>> for key in D.keys():\\n...     print(key, D[key])\\n...\\na 1\\nc 3\\nb 2\\nIn recent versions of Python, though, dictionaries have an iterator that automatically\\nreturns one key at a time in an iteration context:\\n>>> I = iter(D)\\n>>> next(I)\\n'a'\\n>>> next(I)\\n'c'\\n>>> next(I)\\n'b'\\n>>> next(I)\\nTraceback (most recent call last):\\n356 | Chapter 14: \\u2002Iterations and Comprehensions, Part 1\", metadata={'source': 'python.pdf', 'page': 406}),\n",
       " Document(page_content=\"...more omitted...\\nStopIteration\\nThe net effect \\nis that we no longer need to call the keys method to step through dic-\\ntionary keys—the for loop will use the iteration protocol to grab one key each time\\nthrough:\\n>>> for key in D:\\n...     print(key, D[key])\\n...\\na 1\\nc 3\\nb 2\\nWe can’t delve into their details here, but other Python object types also support the\\niterator protocol and thus may be used in for loops too. For instance, shelves (an access-\\nby-key filesystem for Python objects) and the results from os.popen (a tool for reading\\nthe output of shell commands) are iterable as well:\\n>>> import os\\n>>> P = os.popen('dir')\\n>>> P.__next__()\\n' Volume in drive C is SQ004828V03\\\\n'\\n>>> P.__next__()\\n' Volume Serial Number is 08BE-3CD4\\\\n'\\n>>> next(P)\\nTypeError: _wrap_close object is not an iterator\\nNotice that popen objects support a P.next() method in Python 2.6. In 3.0, they support\\nthe P.__next__() method, but not the next(P) built-in; since the latter is defined to call\\nthe former, it’s not clear if this behavior will endure in future releases (as described in\\nan earlier footnote, this appears to be an implementation issue). This is only an issue\\nfor manual iteration, though; if you iterate over these objects automatically with for\\nloops and other iteration contexts (described in the next sections), they return succes-\\nsive lines in either Python version.\\nThe iteration protocol also is the reason that we’ve had to wrap some results in a\\nlist call to see their values all at once. Objects that are iterable return results one at a\\ntime, not in a physical list:\\n>>> R = range(5)\\n>>> R                            # Ranges are iterables in 3.0\\nrange(0, 5)\\n>>> I = iter(R)                  # Use iteration protocol to produce results\\n>>> next(I)\\n0\\n>>> next(I)\\n1\\n>>> list(range(5))               # Or use list to collect all results at once\\n[0, 1, 2, 3, 4]\\nIterators: A First Look | 357\", metadata={'source': 'python.pdf', 'page': 407}),\n",
       " Document(page_content=\"Now that you have a better understanding of this protocol, you should be able to see\\nhow it explains why the enumerate tool introduced \\nin the prior chapter works the way\\nit does:\\n>>> E = enumerate('spam')        # enumerate is an iterable too\\n>>> E\\n<enumerate object at 0x0253F508>\\n>>> I = iter(E)\\n>>> next(I)                      # Generate results with iteration protocol\\n(0, 's')\\n>>> next(I)                      # Or use list to force generation to run\\n(1, 'p')\\n>>> list(enumerate('spam'))\\n[(0, 's'), (1, 'p'), (2, 'a'), (3, 'm')]\\nWe don’t normally see this machinery because for loops run it for us automatically to\\nstep through results. In fact, everything that scans left-to-right in Python employs the\\niteration protocol in the same way—including the topic of the next section.\\nList Comprehensions: A First Look\\nNow that we’ve seen how the iteration protocol works, let’s turn to a very common use\\ncase. Together with for loops, list comprehensions are one of the most prominent\\ncontexts in which the iteration protocol is applied.\\nIn the previous chapter, we learned how to use range to change a list as we step across\\nit:\\n>>> L = [1, 2, 3, 4, 5]\\n>>> for i in range(len(L)):\\n...     L[i] += 10\\n...\\n>>> L\\n[11, 12, 13, 14, 15]\\nThis works, but as I mentioned there, it may not be the optimal “best-practice” ap-\\nproach in Python. Today, the list comprehension expression makes many such prior\\nuse cases obsolete. Here, for example, we can replace the loop with a single expression\\nthat produces the desired result list:\\n>>> L = [x + 10 for x in L]\\n>>> L\\n[21, 22, 23, 24, 25]\\nThe net result is the same, but it requires less coding on our part and is likely to run\\nsubstantially faster. The list comprehension isn’t exactly the same as the for loop state-\\nment version because it makes a new list object (which might matter if there are multiple\\nreferences to the original list), but it’s close enough for most applications and is a com-\\nmon and convenient enough approach to merit a closer look here.\\n358 | Chapter 14: \\u2002Iterations and Comprehensions, Part 1\", metadata={'source': 'python.pdf', 'page': 408}),\n",
       " Document(page_content=\"List Comprehension Basics\\nWe met the \\nlist comprehension briefly in Chapter 4 . Syntactically, its syntax is derived\\nfrom a construct in set theory notation that applies an operation to each item in a set,\\nbut you don’t have to know set theory to use this tool. In Python, most people find that\\na list comprehension simply looks like a backward for loop.\\nTo get a handle on the syntax, let’s dissect the prior section’s example in more detail:\\n>>> L = [x + 10 for x in L]\\nList comprehensions are written in square brackets because they are ultimately a way\\nto construct a new list. They begin with an arbitrary expression that we make up, which\\nuses a loop variable that we make up ( x + 10). That is followed by what you should\\nnow recognize as the header of a for loop, which names the loop variable, and an\\niterable object (for x in L).\\nTo run the expression, Python executes an iteration across L inside the interpreter,\\nassigning x to each item in turn, and collects the results of running the items through\\nthe expression on the left side. The result list we get back is exactly what the list com-\\nprehension says—a new list containing x + 10, for every x in L.\\nTechnically speaking, list comprehensions are never really required because we can\\nalways build up a list of expression results manually with for loops that append results\\nas we go:\\n>>> res = []\\n>>> for x in L:\\n...     res.append(x + 10)\\n...\\n>>> res\\n[21, 22, 23, 24, 25]\\nIn fact, this is exactly what the list comprehension does internally.\\nHowever, list comprehensions are more concise to write, and because this code pattern\\nof building up result lists is so common in Python work, they turn out to be very handy\\nin many contexts. Moreover, list comprehensions can run much faster than manual\\nfor loop statements (often roughly twice as fast) because their iterations are performed\\nat C language speed inside the interpreter, rather than with manual Python code; es-\\npecially for larger data sets, there is a major performance advantage to using them.\\nUsing List Comprehensions on Files\\nLet’s work through another common use case for list comprehensions to explore them\\nin more detail. Recall that the file object has a readlines method that loads the file into\\na list of line strings all at once:\\n>>> f = open('script1.py')\\n>>> lines = f.readlines()\\nList Comprehensions: A First Look | 359\", metadata={'source': 'python.pdf', 'page': 409}),\n",
       " Document(page_content=\">>> lines\\n['import sys\\\\n', 'print(sys.path)\\\\n', 'x = 2\\\\n', 'print(2 ** 33)\\\\n']\\nThis works, but \\nthe lines in the result all include the newline character ( \\\\n) at the end.\\nFor many programs, the newline character gets in the way—we have to be careful to\\navoid double-spacing when printing, and so on. It would be nice if we could get rid of\\nthese newlines all at once, wouldn’t it?\\nAny time we start thinking about performing an operation on each item in a sequence,\\nwe’re in the realm of list comprehensions. For example, assuming the variable lines is\\nas it was in the prior interaction, the following code does the job by running each line\\nin the list through the string rstrip method to remove whitespace on the right side (a\\nline[:−1] slice would work, too, but only if we can be sure all lines are properly\\nterminated):\\n>>> lines = [line.rstrip() for line in lines]\\n>>> lines\\n['import sys', 'print(sys.path)', 'x = 2', 'print(2 ** 33)']\\nThis works as planned. Because list comprehensions are an iteration context just like\\nfor loop statements, though, we don’t even have to open the file ahead of time. If we\\nopen it inside the expression, the list comprehension will automatically use the iteration\\nprotocol we met earlier in this chapter. That is, it will read one line from the file at a\\ntime by calling the file’s next method, run the line through the rstrip expression, and\\nadd it to the result list. Again, we get what we ask for—the rstrip result of a line, for\\nevery line in the file:\\n>>> lines = [line.rstrip() for line in open('script1.py')]\\n>>> lines\\n['import sys', 'print(sys.path)', 'x = 2', 'print(2 ** 33)']\\nThis expression does a lot implicitly, but we’re getting a lot of work for free here—\\nPython scans the file and builds a list of operation results automatically. It’s also an\\nefficient way to code this operation: because most of this work is done inside the Python\\ninterpreter, it is likely much faster than an equivalent for statement. Again, especially\\nfor large files, the speed advantages of list comprehensions can be significant.\\nBesides their efficiency, list comprehensions are also remarkably expressive. In our\\nexample, we can run any string operation on a file’s lines as we iterate. Here’s the list\\ncomprehension equivalent to the file iterator uppercase example we met earlier, along\\nwith a few others (the method chaining in the second of these examples works because\\nstring methods return a new string, to which we can apply another string method):\\n>>> [line.upper() for line in open('script1.py')]\\n['IMPORT SYS\\\\n', 'PRINT(SYS.PATH)\\\\n', 'X = 2\\\\n', 'PRINT(2 ** 33)\\\\n']\\n>>> [line.rstrip().upper() for line in open('script1.py')]\\n['IMPORT SYS', 'PRINT(SYS.PATH)', 'X = 2', 'PRINT(2 ** 33)']\\n>>> [line.split() for line in open('script1.py')]\\n[['import', 'sys'], ['print(sys.path)'], ['x', '=', '2'], ['print(2', '**','33)']]\\n360 | Chapter 14: \\u2002Iterations and Comprehensions, Part 1\", metadata={'source': 'python.pdf', 'page': 410}),\n",
       " Document(page_content=\">>> [line.replace(' ', '!') for line in open('script1.py')]\\n['import!sys\\\\n', 'print(sys.path)\\\\n', 'x!=!2\\\\n', 'print(2!**!33)\\\\n']\\n>>> [('sys' in line, line[0]) for line in open('script1.py')]\\n[(True, 'i'), (True, 'p'), (False, 'x'), (False, 'p')]\\nExtended List Comprehension Syntax\\nIn fact, list \\ncomprehensions can be even more advanced in practice. As one particularly\\nuseful extension, the for loop nested in the expression can have an associated if clause\\nto filter out of the result items for which the test is not true.\\nFor example, suppose we want to repeat the prior section’s file-scanning example, but\\nwe need to collect only lines that begin with the letter p (perhaps the first character on\\neach line is an action code of some sort). Adding an if filter clause to our expression\\ndoes the trick:\\n>>> lines = [line.rstrip() for line in open('script1.py') if line[0] == 'p']\\n>>> lines\\n['print(sys.path)', 'print(2 ** 33)']\\nHere, the if clause checks each line read from the file to see whether its first character\\nis p; if not, the line is omitted from the result list. This is a fairly big expression, but it’s\\neasy to understand if we translate it to its simple for loop statement equivalent. In\\ngeneral, we can always translate a list comprehension to a for statement by appending\\nas we go and further indenting each successive part:\\n>>> res = []\\n>>> for line in open('script1.py'):\\n...     if line[0] == 'p':\\n...         res.append(line.rstrip())\\n...\\n>>> res\\n['print(sys.path)', 'print(2 ** 33)']\\nThis for statement equivalent works, but it takes up four lines instead of one and\\nprobably runs substantially slower.\\nList comprehensions can become even more complex if we need them to—for instance,\\nthey may contain nested loops, coded as a series of for clauses. In fact, their full syntax\\nallows for any number of for clauses, each of which can have an optional associated\\nif clause (we’ll be more formal about their syntax in Chapter 20).\\nFor example, the following builds a list of the concatenation of x + y for every x in one\\nstring and every y in another. It effectively collects the permutation of the characters in\\ntwo strings:\\n>>> [x + y for x in 'abc' for y in 'lmn']\\n['al', 'am', 'an', 'bl', 'bm', 'bn', 'cl', 'cm', 'cn']\\nList Comprehensions: A First Look | 361\", metadata={'source': 'python.pdf', 'page': 411}),\n",
       " Document(page_content=\"Again, one way to understand this expression is to convert it to statement form by\\nindenting its parts. \\nThe following is an equivalent, but likely slower, alternative way to\\nachieve the same effect:\\n>>> res = []\\n>>> for x in 'abc':\\n...     for y in 'lmn':\\n...         res.append(x + y)\\n...\\n>>> res\\n['al', 'am', 'an', 'bl', 'bm', 'bn', 'cl', 'cm', 'cn']\\nBeyond this complexity level, though, list comprehension expressions can often be-\\ncome too compact for their own good. In general, they are intended for simple types\\nof iterations; for more involved work, a simpler for statement structure will probably\\nbe easier to understand and modify in the future. As usual in programming, if something\\nis difficult for you to understand, it’s probably not a good idea.\\nWe’ll revisit list comprehensions in Chapter 20 , in the context of functional program-\\nming tools; as we’ll see, they turn out to be just as related to functions as they are to\\nlooping statements.\\nOther Iteration Contexts\\nLater in the book, we’ll see that user-defined classes can implement the iteration pro-\\ntocol too. Because of this, it’s sometimes important to know which built-in tools make\\nuse of it—any tool that employs the iteration protocol will automatically work on any\\nbuilt-in type or user-defined class that provides it.\\nSo far, I’ve been demonstrating iterators in the context of the for loop statement, be-\\ncause this part of the book is focused on statements. Keep in mind, though, that every\\ntool that scans from left to right across objects uses the iteration protocol. This includes\\nthe for loops we’ve seen:\\n>>> for line in open('script1.py'):         # Use file iterators\\n...     print(line.upper(), end='')\\n...\\nIMPORT SYS\\nPRINT(SYS.PATH)\\nX = 2\\nPRINT(2 ** 33)\\nHowever, list comprehensions, the in membership test, the map built-in function, and\\nother built-ins such as the sorted and zip calls also leverage the iteration protocol.\\nWhen applied to a file, all of these use the file object’s iterator automatically to scan\\nline by line:\\n>>> uppers = [line.upper() for line in open('script1.py')]\\n>>> uppers\\n['IMPORT SYS\\\\n', 'PRINT(SYS.PATH)\\\\n', 'X = 2\\\\n', 'PRINT(2 ** 33)\\\\n']\\n362 | Chapter 14: \\u2002Iterations and Comprehensions, Part 1\", metadata={'source': 'python.pdf', 'page': 412}),\n",
       " Document(page_content=\">>> map(str.upper, open('script1.py'))      # map is an iterable in 3.0\\n<map object at 0x02660710>\\n>>> list( map(str.upper, open('script1.py')) )\\n['IMPORT SYS\\\\n', 'PRINT(SYS.PATH)\\\\n', 'X = 2\\\\n', 'PRINT(2 ** 33)\\\\n']\\n>>> 'y = 2\\\\n' in open('script1.py')\\nFalse\\n>>> 'x = 2\\\\n' in open('script1.py')\\nTrue\\nWe introduced the map\\n call used here in the preceding chapter; it’s a built-in that applies\\na function call to each item in the passed-in iterable object. map is similar to a list com-\\nprehension but is more limited because it requires a function instead of an arbitrary\\nexpression. It also returns an iterable object itself in Python 3.0, so we must wrap it in\\na list call to force it to give us all its values at once; more on this change later in this\\nchapter. Because map, like the list comprehension, is related to both for loops and\\nfunctions, we’ll also explore both again in Chapters 19 and 20.\\nPython includes various additional built-ins that process iterables, too: sorted sorts\\nitems in an iterable, zip combines items from iterables, enumerate pairs items in an\\niterable with relative positions, filter selects items for which a function is true, and \\nreduce runs pairs of items in an iterable through a function. All of these accept iterables,\\nand zip, enumerate, and filter also return an iterable in Python 3.0, like map. Here they\\nare in action running the file’s iterator automatically to scan line by line:\\n>>> sorted(open('script1.py'))\\n['import sys\\\\n', 'print(2 ** 33)\\\\n', 'print(sys.path)\\\\n', 'x = 2\\\\n']\\n>>> list(zip(open('script1.py'), open('script1.py')))\\n[('import sys\\\\n', 'import sys\\\\n'), ('print(sys.path)\\\\n', 'print(sys.path)\\\\n'),\\n('x = 2\\\\n', 'x = 2\\\\n'), ('print(2 ** 33)\\\\n', 'print(2 ** 33)\\\\n')]\\n>>> list(enumerate(open('script1.py')))\\n[(0, 'import sys\\\\n'), (1, 'print(sys.path)\\\\n'), (2, 'x = 2\\\\n'),\\n(3, 'print(2 ** 33)\\\\n')]\\n>>> list(filter(bool, open('script1.py')))\\n['import sys\\\\n', 'print(sys.path)\\\\n', 'x = 2\\\\n', 'print(2 ** 33)\\\\n']\\n>>> import functools, operator\\n>>> functools.reduce(operator.add, open('script1.py'))\\n'import sys\\\\nprint(sys.path)\\\\nx = 2\\\\nprint(2 ** 33)\\\\n'\\nAll of these are iteration tools, but they have unique roles. We met zip and enumerate\\nin the prior chapter; filter and reduce are in Chapter 19 ’s functional programming\\ndomain, so we’ll defer details for now.\\nWe first saw the sorted function used here at work in Chapter 4, and we used it for\\ndictionaries in Chapter 8 . sorted is a built-in that employs the iteration protocol—it’s\\nlike the original list sort method, but it returns the new sorted list as a result and runs\\nOther Iteration Contexts | 363\", metadata={'source': 'python.pdf', 'page': 413}),\n",
       " Document(page_content=\"on any iterable object. Notice that, unlike map and others, sorted  returns an actual\\nlist in Python 3.0 instead of an iterable.\\nOther built-in functions support the iteration protocol as well (but frankly, are harder\\nto cast in interesting examples related to files). For example, the sum call computes the\\nsum of all the numbers in any iterable; the any and all built-ins return True if any or\\nall items in an iterable are True, respectively; and max and min return the largest and\\nsmallest item in an iterable, respectively. Like reduce, all of the tools in the following\\nexamples accept any iterable as an argument and use the iteration protocol to scan it,\\nbut return a single result:\\n>>> sum([3, 2, 4, 1, 5, 0])                  # sum expects numbers only\\n15\\n>>> any(['spam', '', 'ni'])\\nTrue\\n>>> all(['spam', '', 'ni'])\\nFalse\\n>>> max([3, 2, 5, 1, 4])\\n5\\n>>> min([3, 2, 5, 1, 4])\\n1\\nStrictly speaking, the max and min functions can be applied to files as well—they auto-\\nmatically use the iteration protocol to scan the file and pick out the lines with the highest\\nand lowest string values, respectively (though I’ll leave valid use cases to your\\nimagination):\\n>>> max(open('script1.py'))                  # Line with max/min string value\\n'x = 2\\\\n'\\n>>> min(open('script1.py'))\\n'import sys\\\\n'\\nInterestingly, the iteration protocol is even more pervasive in Python today than the\\nexamples so far have demonstrated— everything in Python’s built-in toolset that scans\\nan object from left to right is defined to use the iteration protocol on the subject object.\\nThis even includes more esoteric tools such as the list and tuple built-in functions\\n(which build new objects from iterables), the string join method (which puts a sub-\\nstring between strings contained in an iterable), and even sequence assignments. Con-\\nsequently, all of these will also work on an open file and automatically read one line at\\na time:\\n>>> list(open('script1.py'))\\n['import sys\\\\n', 'print(sys.path)\\\\n', 'x = 2\\\\n', 'print(2 ** 33)\\\\n']\\n>>> tuple(open('script1.py'))\\n('import sys\\\\n', 'print(sys.path)\\\\n', 'x = 2\\\\n', 'print(2 ** 33)\\\\n')\\n>>> '&&'.join(open('script1.py'))\\n'import sys\\\\n&&print(sys.path)\\\\n&&x = 2\\\\n&&print(2 ** 33)\\\\n'\\n>>> a, b, c, d = open('script1.py')\\n>>> a, d\\n364 | Chapter 14: \\u2002Iterations and Comprehensions, Part 1\", metadata={'source': 'python.pdf', 'page': 414}),\n",
       " Document(page_content=\"('import sys\\\\n', 'print(2 ** 33)\\\\n')\\n>>> a, *b = open('script1.py')                # 3.0 extended form\\n>>> a, b\\n('import sys\\\\n', ['print(sys.path)\\\\n', 'x = 2\\\\n', 'print(2 ** 33)\\\\n'])\\nEarlier, we saw \\nthat the built-in dict call accepts an iterable zip result, too. For that\\nmatter, so does the set call, as well as the new set and dictionary comprehension ex-\\npressions in Python 3.0, which we met in Chapters 4, 5, and 8:\\n>>> set(open('script1.py'))\\n{'print(sys.path)\\\\n', 'x = 2\\\\n', 'print(2 ** 33)\\\\n', 'import sys\\\\n'}\\n>>> {line for line in open('script1.py')}\\n{'print(sys.path)\\\\n', 'x = 2\\\\n', 'print(2 ** 33)\\\\n', 'import sys\\\\n'}\\n>>> {ix: line for ix, line in enumerate(open('script1.py'))}\\n{0: 'import sys\\\\n', 1: 'print(sys.path)\\\\n', 2: 'x = 2\\\\n', 3: 'print(2 ** 33)\\\\n'}\\nIn fact, both set and dictionary comprehensions support the extended syntax of list\\ncomprehensions we met earlier in this chapter, including if tests:\\n>>> {line for line in open('script1.py') if line[0] == 'p'}\\n{'print(sys.path)\\\\n', 'print(2 ** 33)\\\\n'}\\n>>> {ix: line for (ix, line) in enumerate(open('script1.py')) if line[0] == 'p'}\\n{1: 'print(sys.path)\\\\n', 3: 'print(2 ** 33)\\\\n'}\\nLike the list comprehension, both of these scan the file line by line and pick out lines\\nthat begin with the letter “p.” They also happen to build sets and dictionaries in the\\nend, but we get a lot of work “for free” by combining file iteration and comprehension\\nsyntax.\\nThere’s one last iteration context that’s worth mentioning, although it’s a bit of a pre-\\nview: in Chapter 18 , we’ll learn that a special *arg form can be used in function calls\\nto unpack a collection of values into individual arguments. As you can probably predict\\nby now, this accepts any iterable, too, including files (see Chapter 18  for more details\\non the call syntax):\\n>>> def f(a, b, c, d): print(a, b, c, d, sep='&')\\n...\\n>>> f(1, 2, 3, 4)\\n1&2&3&4\\n>>> f(*[1, 2, 3, 4])                   # Unpacks into arguments\\n1&2&3&4\\n>>> f(*open('script1.py'))             # Iterates by lines too!\\nimport sys\\n&print(sys.path)\\n&x = 2\\n&print(2 ** 33)\\nIn fact, because this argument-unpacking syntax in calls accepts iterables, it’s also pos-\\nsible to use the zip built-in to unzip zipped tuples, by making prior or nested zip results\\nOther Iteration Contexts | 365\", metadata={'source': 'python.pdf', 'page': 415}),\n",
       " Document(page_content=\"arguments for another zip call (warning: you probably shouldn’t read the following\\nexample if you plan to operate heavy machinery anytime soon!):\\n>>> X = (1, 2)\\n>>> Y = (3, 4)\\n>>>\\n>>> list(zip(X, Y))                    # Zip tuples: returns an iterable\\n[(1, 3), (2, 4)]\\n>>>\\n>>> A, B = zip(*zip(X, Y))             # Unzip a zip!\\n>>> A\\n(1, 2)\\n>>> B\\n(3, 4)\\nStill other tools in Python, such as the range built-in and dictionary view objects, return\\niterables instead of processing them. To see how these have been absorbed into the\\niteration protocol in Python 3.0 as well, we need to move on to the next section.\\nNew Iterables in Python 3.0\\nOne of the fundamental changes in Python 3.0 is that it has a stronger emphasis on \\niterators than 2.X. In addition to the iterators associated with built-in types such as files\\nand dictionaries, the dictionary methods keys, values, and items return iterable objects\\nin Python 3.0, as do the built-in functions range, map, zip, and filter. As shown in the\\nprior section, the last three of these functions both return iterators and process them.\\nAll of these tools produce results on demand in Python 3.0, instead of constructing\\nresult lists as they do in 2.6.\\nAlthough this saves memory space, it can impact your coding styles in some contexts.\\nIn various places in this book so far, for example, we’ve had to wrap up various function\\nand method call results in a list(...) call in order to force them to produce all their\\nresults at once:\\n>>> zip('abc', 'xyz')                  # An iterable in Python 3.0 (a list in 2.6)\\n<zip object at 0x02E66710>\\n>>> list(zip('abc', 'xyz'))            # Force list of results in 3.0 to display\\n[('a', 'x'), ('b', 'y'), ('c', 'z')]\\nThis isn’t required in 2.6, because functions like zip return lists of results. In 3.0,\\nthough, they return iterable objects, producing results on demand. This means extra\\ntyping is required to display the results at the interactive prompt (and possibly in some\\nother contexts), but it’s an asset in larger programs—delayed evaluation like this con-\\nserves memory and avoids pauses while large result lists are computed. Let’s take a\\nquick look at some of the new 3.0 iterables in action.\\n366 | Chapter 14: \\u2002Iterations and Comprehensions, Part 1\", metadata={'source': 'python.pdf', 'page': 416}),\n",
       " Document(page_content='The range Iterator\\nWe studied the range\\n built-in’s basic behavior in the prior chapter. In 3.0, it returns an\\niterator that generates numbers in the range on demand, instead of building the result\\nlist in memory. This subsumes the older 2.X xrange (see the upcoming version skew\\nnote), and you must use list(range(...)) to force an actual range list if one is needed\\n(e.g., to display results):\\nC:\\\\\\\\misc> c:\\\\python30\\\\python\\n>>> R = range(10)                # range returns an iterator, not a list\\n>>> R\\nrange(0, 10)\\n>>> I = iter(R)                  # Make an iterator from the range\\n>>> next(I)                      # Advance to next result\\n0                                # What happens in for loops, comprehensions, etc.\\n>>> next(I)\\n1\\n>>> next(I)\\n2\\n>>> list(range(10))              # To force a list if required\\n[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\\nUnlike the list returned by this call in 2.X, range objects in 3.0 support only iteration,\\nindexing, and the len function. They do not support any other sequence operations\\n(use list(...) if you require more list tools):\\n>>> len(R)                       # range also does len and indexing, but no others\\n10\\n>>> R[0]\\n0\\n>>> R[-1]\\n9\\n>>> next(I)                      # Continue taking from iterator, where left off\\n3\\n>>> I.__next__()                 # .next() becomes .__next__(), but use new next()\\n4\\nVersion skew note: Python 2.X also has a built-in called xrange, which\\nis like range but produces items on demand instead of building a list of\\nresults in memory all at once. Since this is exactly what the new iterator-\\nbased range does in Python 3.0, xrange is no longer available in 3.0—it\\nhas been subsumed. You may still see it in 2.X code, though, especially\\nsince range builds result lists there and so is not as efficient in its memory\\nusage. As noted in a sidebar in the prior chapter, the file.xread\\nlines() method used to minimize memory use in 2.X has been dropped\\nin Python 3.0 for similar reasons, in favor of file iterators.\\nNew Iterables in Python 3.0 | 367', metadata={'source': 'python.pdf', 'page': 417}),\n",
       " Document(page_content='The map, zip, and filter Iterators\\nLike range, the map, zip\\n, and filter built-ins also become iterators in 3.0 to conserve\\nspace, rather than producing a result list all at once in memory. All three not only\\nprocess iterables, as in 2.X, but also return iterable results in 3.0. Unlike range, though,\\nthey are their own iterators—after you step through their results once, they are ex-\\nhausted. In other words, you can’t have multiple iterators on their results that maintain\\ndifferent positions in those results.\\nHere is the case for the map built-in we met in the prior chapter. As with other iterators,\\nyou can force a list with list(...) if you really need one, but the default behavior can\\nsave substantial space in memory for large result sets:\\n>>> M = map(abs, (-1, 0, 1))            # map returns an iterator, not a list\\n>>> M\\n<map object at 0x0276B890>\\n>>> next(M)                             # Use iterator manually: exhausts results\\n1                                       # These do not support len() or indexing\\n>>> next(M)\\n0\\n>>> next(M)\\n1\\n>>> next(M)\\nStopIteration\\n>>> for x in M: print(x)                # map iterator is now empty: one pass only\\n...\\n>>> M = map(abs, (-1, 0, 1))            # Make a new iterator to scan again\\n>>> for x in M: print(x)                # Iteration contexts auto call next()\\n...\\n1\\n0\\n1\\n>>> list(map(abs, (-1, 0, 1)))          # Can force a real list if needed\\n[1, 0, 1]\\nThe zip built-in, introduced in the prior chapter, returns iterators that work the same\\nway:\\n>>> Z = zip((1, 2, 3), (10, 20, 30))    # zip is the same: a one-pass iterator\\n>>> Z\\n<zip object at 0x02770EE0>\\n>>> list(Z)\\n[(1, 10), (2, 20), (3, 30)]\\n>>> for pair in Z: print(pair)          # Exhausted after one pass\\n...\\n>>> Z = zip((1, 2, 3), (10, 20, 30))\\n>>> for pair in Z: print(pair)          # Iterator used automatically or manually\\n...\\n(1, 10)\\n368 | Chapter 14: \\u2002Iterations and Comprehensions, Part 1', metadata={'source': 'python.pdf', 'page': 418}),\n",
       " Document(page_content=\"(2, 20)\\n(3, 30)\\n>>> Z = zip((1, 2, 3), (10, 20, 30))\\n>>> next(Z)\\n(1, 10)\\n>>> next(Z)\\n(2, 20)\\nThe filter built-in, which we’ll study in the next part of this book, is also analogous.\\nIt returns items \\nin an iterable for which a passed-in function returns True (as we’ve\\nlearned, in Python True includes nonempty objects):\\n>>> filter(bool, ['spam', '', 'ni'])\\n<filter object at 0x0269C6D0>\\n>>> list(filter(bool, ['spam', '', 'ni']))\\n['spam', 'ni']\\nLike most of the tools discussed in this section, filter both accepts an iterable to\\nprocess and returns an iterable to generate results in 3.0.\\nMultiple Versus Single Iterators\\nIt’s interesting to see how the range object differs from the built-ins described in this\\nsection—it supports len and indexing, it is not its own iterator (you make one with\\niter when iterating manually), and it supports multiple iterators over its result that\\nremember their positions independently:\\n>>> R = range(3)                           # range allows multiple iterators\\n>>> next(R)\\nTypeError: range object is not an iterator\\n>>> I1 = iter(R)\\n>>> next(I1)\\n0\\n>>> next(I1)\\n1\\n>>> I2 = iter(R)                           # Two iterators on one range\\n>>> next(I2)\\n0\\n>>> next(I1)                               # I1 is at a different spot than I2\\n2\\nBy contrast, zip, map, and filter do not support multiple active iterators on the same\\nresult:\\n>>> Z = zip((1, 2, 3), (10, 11, 12))\\n>>> I1 = iter(Z)\\n>>> I2 = iter(Z)                           # Two iterators on one zip\\n>>> next(I1)\\n(1, 10)\\n>>> next(I1)\\n(2, 11)\\n>>> next(I2)                               # I2 is at same spot as I1!\\nNew Iterables in Python 3.0 | 369\", metadata={'source': 'python.pdf', 'page': 419}),\n",
       " Document(page_content=\"(3, 12)\\n>>> M = map(abs, (-1, 0, 1))                # Ditto for map (and filter)\\n>>> I1 = iter(M); I2 = iter(M)\\n>>> print(next(I1), next(I1), next(I1))\\n1 0 1\\n>>> next(I2)\\nStopIteration\\n>>> R = range(3)                            # But range allows many iterators\\n>>> I1, I2 = iter(R), iter(R)\\n>>> [next(I1), next(I1), next(I1)]\\n[0 1 2]\\n>>> next(I2)\\n0\\nWhen we code \\nour own iterable objects with classes later in the book ( Chapter 29),\\nwe’ll see that multiple iterators are usually supported by returning new objects for the\\niter call; a single iterator generally means an object returns itself. In Chapter 20 , we’ll\\nalso find that generator functions and expressions behave like map and zip instead of\\nrange in this regard, supporting a single active iteration. In that chapter, we’ll see some\\nsubtle implications of one-shot iterators in loops that attempt to scan multiple times.\\nDictionary View Iterators\\nAs we saw briefly in Chapter 8 , in Python 3.0 the dictionary keys, values, and items\\nmethods return iterable view objects that generate result items one at a time, instead\\nof producing result lists all at once in memory. View items maintain the same physical\\nordering as that of the dictionary and reflect changes made to the underlying dictionary.\\nNow that we know more about iterators, here’s the rest of the story:\\n>>> D = dict(a=1, b=2, c=3)\\n>>> D\\n{'a': 1, 'c': 3, 'b': 2}\\n>>> K = D.keys()                              # A view object in 3.0, not a list\\n>>> K\\n<dict_keys object at 0x026D83C0>\\n>>> next(K)                                   # Views are not iterators themselves\\nTypeError: dict_keys object is not an iterator\\n>>> I = iter(K)                               # Views have an iterator,\\n>>> next(I)                                   # which can be used manually\\n'a'                                           # but does not support len(), index\\n>>> next(I)\\n'c'\\n>>> for k in D.keys(): print(k, end=' ')      # All iteration contexts use auto\\n...\\na c b\\n370 | Chapter 14: \\u2002Iterations and Comprehensions, Part 1\", metadata={'source': 'python.pdf', 'page': 420}),\n",
       " Document(page_content=\"As for all iterators, you can always force a 3.0 dictionary view to build a real list by\\npassing it to \\nthe list built-in. However, this usually isn’t required except to display\\nresults interactively or to apply list operations like indexing:\\n>>> K = D.keys()\\n>>> list(K)                              # Can still force a real list if needed\\n['a', 'c', 'b']\\n>>> V = D.values()                       # Ditto for values() and items() views\\n>>> V\\n<dict_values object at 0x026D8260>\\n>>> list(V)\\n[1, 3, 2]\\n>>> list(D.items())\\n[('a', 1), ('c', 3), ('b', 2)]\\n>>> for (k, v) in D.items(): print(k, v, end=' ')\\n...\\na 1 c 3 b 2\\nIn addition, 3.0 dictionaries still have iterators themselves, which return successive\\nkeys. Thus, it’s not often necessary to call keys directly in this context:\\n>>> D                                    # Dictionaries still have own iterator\\n{'a': 1, 'c': 3, 'b': 2}                 # Returns next key on each iteration\\n>>> I = iter(D)\\n>>> next(I)\\n'a'\\n>>> next(I)\\n'c'\\n>>> for key in D: print(key, end=' ')    # Still no need to call keys() to iterate\\n...                                      # But keys is an iterator in 3.0 too!\\na c b\\nFinally, remember again that because keys no longer returns a list, the traditional coding\\npattern for scanning a dictionary by sorted keys won’t work in 3.0. Instead, convert\\nkeys views first with a list call, or use the sorted call on either a keys view or the\\ndictionary itself, as follows:\\n>>> D\\n{'a': 1, 'c': 3, 'b': 2}\\n>>> for k in sorted(D.keys())): print(k, D[k], end=' ')\\n...\\na 1 b 2 c 3\\n>>> D\\n{'a': 1, 'c': 3, 'b': 2}\\n>>> for k in sorted(D): print(k, D[k], end=' ')    # Best practice key sorting\\n...\\na 1 b 2 c 3\\nNew Iterables in Python 3.0 | 371\", metadata={'source': 'python.pdf', 'page': 421}),\n",
       " Document(page_content='Other Iterator Topics\\nWe’ll learn more \\nabout both list comprehensions and iterators in Chapter 20 , in con-\\njunction with functions, and again in Chapter 29  when we study classes. As you’ll see\\nlater:\\n• User-defined functions can be turned into iterable generator functions, with\\nyield statements.\\n• List comprehensions morph into iterable generator expressions when coded in\\nparentheses.\\n• User-defined classes are made iterable with __iter__ or __getitem__ operator\\noverloading.\\nIn particular, user-defined iterators defined with classes allow arbitrary objects and\\noperations to be used in any of the iteration contexts we’ve met here.\\nChapter Summary\\nIn this chapter, we explored concepts related to looping in Python. We took our first\\nsubstantial look at the iteration protocol  in Python—a way for nonsequence objects to\\ntake part in iteration loops—and at list comprehensions . As we saw, a list comprehen-\\nsion is an expression similar to a for loop that applies another expression to all the\\nitems in any iterable object. Along the way, we also saw other built-in iteration tools\\nat work and studied recent iteration additions in Python 3.0.\\nThis wraps up our tour of specific procedural statements and related tools. The next\\nchapter closes out this part of the book by discussing documentation options for Python\\ncode; documentation is also part of the general syntax model, and it’s an important\\ncomponent of well-written programs. In the next chapter, we’ll also dig into a set of\\nexercises for this part of the book before we turn our attention to larger structures such\\nas functions. As usual, though, let’s first exercise what we’ve learned here with a quiz.\\nTest Your Knowledge: Quiz\\n1. How are for\\n loops and iterators related?\\n2. How are for loops and list comprehensions related?\\n3. Name four iteration contexts in the Python language.\\n4. What is the best way to read line by line from a text file today?\\n5. What sort of weapons would you expect to see employed by the Spanish\\nInquisition?\\n372 | Chapter 14: \\u2002Iterations and Comprehensions, Part 1', metadata={'source': 'python.pdf', 'page': 422}),\n",
       " Document(page_content='Test Your Knowledge: Answers\\n1. The for loop uses the iteration protocol  \\nto step through items in the object across\\nwhich it is iterating. It calls the object’s __next__ method (run by the next built-in)\\non each iteration and catches the StopIteration exception to determine when to\\nstop looping. Any object that supports this model works in a for loop and in other\\niteration contexts.\\n2. Both are iteration tools. List comprehensions are a concise and efficient way to\\nperform a common for loop task: collecting the results of applying an expression\\nto all items in an iterable object. It’s always possible to translate a list comprehen-\\nsion to a for loop, and part of the list comprehension expression looks like the\\nheader of a for loop syntactically.\\n3. Iteration contexts in Python include the for loop; list comprehensions; the map\\nbuilt-in function; the in membership test expression; and the built-in functions\\nsorted, sum, any, and all. This category also includes the list and tuple built-ins,\\nstring join methods, and sequence assignments, all of which use the iteration pro-\\ntocol (the __next__ method) to step across iterable objects one item at a time.\\n4. The best way to read lines from a text file today is to not read it explicitly at all:\\ninstead, open the file within an iteration context such as a for loop or list com-\\nprehension, and let the iteration tool automatically scan one line at a time by\\nrunning the file’s next method on each iteration. This approach is generally best\\nin terms of coding simplicity, execution speed, and memory space requirements.\\n5. I’ll accept any of the following as correct answers: fear, intimidation, nice red uni-\\nforms, a comfy chair, and soft pillows.\\nTest Your Knowledge: Answers | 373', metadata={'source': 'python.pdf', 'page': 423}),\n",
       " Document(page_content='', metadata={'source': 'python.pdf', 'page': 424}),\n",
       " Document(page_content='CHAPTER 15\\nThe Documentation Interlude\\nThis part of the book concludes with a look at techniques and tools used for\\ndocumenting Python code. \\nAlthough Python code is designed to be readable, a few\\nwell-placed human-readable comments can do much to help others understand the\\nworkings of your programs. Python includes syntax and tools to make documentation\\neasier.\\nAlthough this is something of a tools-related concept, the topic is presented here partly\\nbecause it involves Python’s syntax model, and partly as a resource for readers strug-\\ngling to understand Python’s toolset. For the latter purpose, I’ll expand here on docu-\\nmentation pointers first given in Chapter 4 . As usual, in addition to the chapter quiz\\nthis concluding chapter ends with some warnings about common pitfalls and a set of\\nexercises for this part of the text.\\nPython Documentation Sources\\nBy this point in the book, you’re probably starting to realize that Python comes with\\nan amazing amount of prebuilt functionality—built-in functions and exceptions, pre-\\ndefined object attributes and methods, standard library modules, and more. And we’ve\\nreally only scratched the surface of each of these categories.\\nOne of the first questions that bewildered beginners often ask is: how do I find infor-\\nmation on all the built-in tools? This section provides hints on the various documen-\\ntation sources available in Python. It also presents documentation strings  (docstrings)\\nand the PyDoc system that makes use of them. These topics are somewhat peripheral\\nto the core language itself, but they become essential knowledge as soon as your code\\nreaches the level of the examples and exercises in this part of the book.\\nAs summarized in Table 15-1 , there are a variety of places to look for information on\\nPython, with generally increasing verbosity. Because documentation is such a crucial\\ntool in practical programming, we’ll explore each of these categories in the sections\\nthat follow.\\n375', metadata={'source': 'python.pdf', 'page': 425}),\n",
       " Document(page_content=\"Table 15-1. Python documentation sources\\nForm Role\\n# comments In-file documentation\\nThe dir function Lists of attributes available in objects\\nDocstrings: __doc__ In-file documentation attached to objects\\nPyDoc: The help function Interactive help for objects\\nPyDoc: HTML reports Module documentation in a browser\\nThe standard manual set Official language and library descriptions\\nWeb resources Online tutorials, examples, and so on\\nPublished books Commercially available reference texts\\n# Comments\\nHash-mark comments are the \\nmost basic way to document your code. Python simply\\nignores all the text following a # (as long as it’s not inside a string literal), so you can\\nfollow this character with words and descriptions meaningful to programmers. Such\\ncomments are accessible only in your source files, though; to code comments that are\\nmore widely available, you’ll need to use docstrings.\\nIn fact, current best practice generally dictates that docstrings are best for larger func-\\ntional documentation (e.g., “my file does this”), and # comments are best limited to\\nsmaller code documentation (e.g., “this strange expression does that”). More on doc-\\nstrings in a moment.\\nThe dir Function\\nThe built-in dir function is an easy way to grab a list of all the attributes available inside\\nan object (i.e., its methods and simpler data items). It can be called on any object that\\nhas attributes. For example, to find out what’s available in the standard library’s sys\\nmodule, import it and pass it to dir (these results are from Python 3.0; they might vary\\nslightly on 2.6):\\n>>> import sys\\n>>> dir(sys)\\n['__displayhook__', '__doc__', '__excepthook__', '__name__', '__package__',\\n'__stderr__', '__stdin__', '__stdout__', '_clear_type_cache', '_current_frames',\\n'_getframe', 'api_version', 'argv', 'builtin_module_names', 'byteorder',\\n'call_tracing', 'callstats', 'copyright', 'displayhook', 'dllhandle',\\n'dont_write_bytecode', 'exc_info', 'excepthook', 'exec_prefix', 'executable',\\n'exit', 'flags', 'float_info', 'getcheckinterval', 'getdefaultencoding',\\n...more names omitted...]\\nOnly some of the many names are displayed here; run these statements on your machine\\nto see the full list.\\n376 | Chapter 15: \\u2002The Documentation Interlude\", metadata={'source': 'python.pdf', 'page': 426}),\n",
       " Document(page_content=\"To find out what attributes are provided in built-in object types, run dir on a literal (or\\nexisting instance) of the desired type. For example, to see list and string attributes, you\\ncan pass empty objects:\\n>>> dir([])\\n['__add__', '__class__', '__contains__', ...more...\\n'append', 'count', 'extend', 'index', 'insert', 'pop', 'remove',\\n'reverse', 'sort']\\n>>> dir('')\\n['__add__', '__class__', '__contains__', ...more...\\n'capitalize', 'center', 'count', 'encode', 'endswith', 'expandtabs',\\n'find', 'format', 'index', 'isalnum', 'isalpha', 'isdecimal',\\n'isdigit', 'isidentifier', 'islower', 'isnumeric', 'isprintable',\\n'isspace', 'istitle', 'isupper', 'join', 'ljust', 'lower', 'lstrip', '\\nmaketrans', 'partition', 'replace', 'rfind', 'rindex', 'rjust',\\n...more names omitted...]\\ndir results for any built-in type include a set of attributes that are related to the imple-\\nmentation of that type (technically, operator overloading methods); they all begin and\\nend with double underscores to make them distinct, and you can safely ignore them at\\nthis point in the book.\\nIncidentally, you can achieve the same effect by passing a type name to dir instead of\\na literal:\\n>>> dir(str) == dir('')           # Same result as prior example\\nTrue\\n>>> dir(list) == dir([])\\nTrue\\nThis works because names like str and list that were once type converter functions\\nare actually names of types in Python today; calling one of these invokes its constructor\\nto generate an instance of that type. I’ll have more to say about constructors and op-\\nerator overloading methods when we discuss classes in Part VI.\\nThe dir function serves as a sort of memory-jogger—it provides a list of attribute names,\\nbut it does not tell you anything about what those names mean. For such extra infor-\\nmation, we need to move on to the next documentation source.\\nDocstrings: __doc__\\nBesides # comments, Python supports documentation that is automatically attached to\\nobjects and retained at runtime for inspection. Syntactically, such comments are coded\\nas strings at the tops of module files and function and class statements, before any other\\nexecutable code ( # comments are OK before them). Python automatically stuffs the\\nstrings, known as docstrings, into the __doc__ attributes of the corresponding objects.\\nPython Documentation Sources | 377\", metadata={'source': 'python.pdf', 'page': 427}),\n",
       " Document(page_content='User-defined docstrings\\nFor example, consider \\nthe following file, docstrings.py. Its docstrings appear at the\\nbeginning of the file and at the start of a function and a class within it. Here, I’ve used\\ntriple-quoted block strings for multiline comments in the file and the function, but any\\nsort of string will work. We haven’t studied the def or class statements in detail yet,\\nso ignore everything about them except the strings at their tops:\\n\"\"\"\\nModule documentation\\nWords Go Here\\n\"\"\"\\nspam = 40\\ndef square(x):\\n    \"\"\"\\n    function documentation\\n    can we have your liver then?\\n    \"\"\"\\n    return x ** 2          # square\\nclass Employee:\\n    \"class documentation\"\\n    pass\\nprint(square(4))\\nprint(square.__doc__)\\nThe whole point of this documentation protocol is that your comments are retained\\nfor inspection in __doc__ attributes after the file is imported. Thus, to display the doc-\\nstrings associated with the module and its objects, we simply import the file and print\\ntheir __doc__ attributes, where Python has saved the text:\\n>>> import docstrings\\n16\\n    function documentation\\n    can we have your liver then?\\n>>> print(docstrings.__doc__)\\nModule documentation\\nWords Go Here\\n>>> print(docstrings.square.__doc__)\\n    function documentation\\n    can we have your liver then?\\n>>> print(docstrings.Employee.__doc__)\\n    class documentation\\n378 | Chapter 15: \\u2002The Documentation Interlude', metadata={'source': 'python.pdf', 'page': 428}),\n",
       " Document(page_content=\"Note that you will generally want to use print to print docstrings; otherwise, you’ll get\\na single string with embedded newline characters.\\nYou can also attach docstrings to methods of classes (covered in Part VI ), but because\\nthese are just def statements nested in class statements, they’re not a special case. To\\nfetch the docstring of a method function inside a class within a module, you would\\nsimply extend the path to go through the class: module.class.method.__doc__ (we’ll see\\nan example of method docstrings in Chapter 28).\\nDocstring standards\\nThere is no broad standard about what should go into the text of a docstring (although\\nsome companies have internal standards). There have been various markup language\\nand template proposals (e.g., HTML or XML), but they don’t seem to have caught on\\nin the Python world. And frankly, convincing Python programmers to document their\\ncode using handcoded HTML is probably not going to happen in our lifetimes!\\nDocumentation tends to have a low priority amongst programmers in general. Usually,\\nif you get any comments in a file at all, you count yourself lucky. I strongly encourage\\nyou to document your code liberally, though—it really is an important part of well-\\nwritten programs. The point here is that there is presently no standard on the structure\\nof docstrings; if you want to use them, anything goes today.\\nBuilt-in docstrings\\nAs it turns out, built-in modules and objects in Python use similar techniques to attach\\ndocumentation above and beyond the attribute lists returned by dir. For example, to\\nsee an actual human-readable description of a built-in module, import it and print its\\n__doc__ string:\\n>>> import sys\\n>>> print(sys.__doc__)\\nThis module provides access to some objects used or maintained by the\\ninterpreter and to functions that interact strongly with the interpreter.\\nDynamic objects:\\nargv -- command line arguments; argv[0] is the script pathname if known\\npath -- module search path; path[0] is the script directory, else ''\\nmodules -- dictionary of loaded modules\\n...more text omitted...\\nFunctions, classes, and methods within built-in modules have attached descriptions in\\ntheir __doc__ attributes as well:\\n>>> print(sys.getrefcount.__doc__)\\ngetrefcount(object) -> integer\\nReturn the reference count of object.  The count returned is generally\\none higher than you might expect, because it includes the (temporary)\\n...more text omitted...\\nPython Documentation Sources | 379\", metadata={'source': 'python.pdf', 'page': 429}),\n",
       " Document(page_content='You can also read about built-in functions via their docstrings:\\n>>> print(int.__doc__)\\nint(x[, base]) -> integer\\nConvert a string or number to an integer, if possible.  A floating\\npoint argument will be truncated towards zero (this does not include a\\n...more text omitted...\\n>>> print(map.__doc__)\\nmap(func, *iterables) --> map object\\nMake an iterator that computes the function using arguments from\\neach of the iterables.  Stops when the shortest iterable is exhausted.\\nYou can get \\na wealth of information about built-in tools by inspecting their docstrings\\nthis way, but you don’t have to—the help function, the topic of the next section, does\\nthis automatically for you.\\nPyDoc: The help Function\\nThe docstring technique proved to be so useful that Python now ships with a tool that\\nmakes docstrings even easier to display. The standard PyDoc tool is Python code that\\nknows how to extract docstrings and associated structural information and format\\nthem into nicely arranged reports of various types. Additional tools for extracting and\\nformatting docstrings are available in the open source domain (including tools that may\\nsupport structured text—search the Web for pointers), but Python ships with PyDoc\\nin its standard library.\\nThere are a variety of ways to launch PyDoc, including command-line script options\\n(see the Python library manual for details). Perhaps the two most prominent PyDoc\\ninterfaces are the built-in help function and the PyDoc GUI/HTML interface. The\\nhelp function invokes PyDoc to generate a simple textual report (which looks much\\nlike a “manpage” on Unix-like systems):\\n>>> import sys\\n>>> help(sys.getrefcount)\\nHelp on built-in function getrefcount in module sys:\\ngetrefcount(...)\\n    getrefcount(object) -> integer\\n    Return the reference count of object.  The count returned is generally\\n    one higher than you might expect, because it includes the (temporary)\\n    ...more omitted...\\nNote that you do not have to import sys in order to call help, but you do have to import\\nsys to get help on sys; it expects an object reference to be passed in. For larger objects\\nsuch as modules and classes, the help display is broken down into multiple sections, a\\nfew of which are shown here. Run this interactively to see the full report:\\n380 | Chapter 15: \\u2002The Documentation Interlude', metadata={'source': 'python.pdf', 'page': 430}),\n",
       " Document(page_content=\">>> help(sys)\\nHelp on built-in module sys:\\nNAME\\n    sys\\nFILE\\n    (built-in)\\nMODULE DOCS\\n    http://docs.python.org/library/sys\\nDESCRIPTION\\n    This module provides access to some objects used or maintained by the\\n    interpreter and to functions that interact strongly with the interpreter.\\n    ...more omitted...\\nFUNCTIONS\\n    __displayhook__ = displayhook(...)\\n        displayhook(object) -> None\\n        Print an object to sys.stdout and also save it in builtins.\\n        ...more omitted...\\nDATA\\n    __stderr__ = <io.TextIOWrapper object at 0x0236E950>\\n    __stdin__ = <io.TextIOWrapper object at 0x02366550>\\n    __stdout__ = <io.TextIOWrapper object at 0x02366E30>\\n    ...more omitted...\\nSome of the information in this report is docstrings, and some of it (e.g., function call\\npatterns) is structural \\ninformation that PyDoc gleans automatically by inspecting ob-\\njects’ internals, when available. You can also use help on built-in functions, methods,\\nand types. To get help for a built-in type, use the type name (e.g., dict for dictionary,\\nstr for string, list for list). You’ll get a large display that describes all the methods\\navailable for that type:\\n>>> help(dict)\\nHelp on class dict in module builtins:\\nclass dict(object)\\n |  dict() -> new empty dictionary.\\n |  dict(mapping) -> new dictionary initialized from a mapping object's\\n ...more omitted...\\n>>> help(str.replace)\\nHelp on method_descriptor:\\nreplace(...)\\n    S.replace (old, new[, count]) -> str\\n    Return a copy of S with all occurrences of substring\\n    ...more omitted...\\n>>> help(ord)\\nPython Documentation Sources | 381\", metadata={'source': 'python.pdf', 'page': 431}),\n",
       " Document(page_content='Help on built-in function ord in module builtins:\\nord(...)\\n    ord(c) -> integer\\n    Return the integer ordinal of a one-character string.\\nFinally, the help \\nfunction works just as well on your modules as it does on built-ins.\\nHere it is reporting on the docstrings.py file we coded earlier. Again, some of this is\\ndocstrings, and some is information automatically extracted by inspecting objects’\\nstructures:\\n>>> import docstrings\\n>>> help(docstrings.square)\\nHelp on function square in module docstrings:\\nsquare(x)\\n    function documentation\\n    can we have your liver then?\\n>>> help(docstrings.Employee)\\nHelp on class Employee in module docstrings:\\nclass Employee(builtins.object)\\n |  class documentation\\n |\\n |  Data descriptors defined here:\\n ...more omitted...\\n>>> help(docstrings)\\nHelp on module docstrings:\\nNAME\\n    docstrings\\nFILE\\n    c:\\\\misc\\\\docstrings.py\\nDESCRIPTION\\n    Module documentation\\n    Words Go Here\\nCLASSES\\n    builtins.object\\n        Employee\\n    class Employee(builtins.object)\\n     |  class documentation\\n     |\\n     |  Data descriptors defined here:\\n     ...more omitted...\\nFUNCTIONS\\n    square(x)\\n        function documentation\\n382 | Chapter 15: \\u2002The Documentation Interlude', metadata={'source': 'python.pdf', 'page': 432}),\n",
       " Document(page_content='        can we have your liver then?\\nDATA\\n    spam = 40\\nPyDoc: HTML Reports\\nThe help function is nice \\nfor grabbing documentation when working interactively. For\\na more grandiose display, however, PyDoc also provides a GUI interface (a simple but\\nportable Python/tkinter script) and can render its report in HTML page format, view-\\nable in any web browser. In this mode, PyDoc can run locally or as a remote server in\\nclient/server mode; reports contain automatically created hyperlinks that allow you to\\nclick your way through the documentation of related components in your application.\\nTo start PyDoc in this mode, you generally first launch the search engine GUI captured\\nin Figure 15-1 . You can start this either by selecting the “Module Docs” item in Python’s\\nStart button menu on Windows, or by launching the pydoc.py script in Python’s stand-\\nard library directory: Lib on Windows (run pydoc.py with a -g command-line argu-\\nment). Enter the name of a module you’re interested in, and press the Enter key; PyDoc\\nwill march down your module import search path ( sys.path) looking for references to\\nthe requested module.\\nFigure 15-1. The Pydoc top-level search engine GUI: type the name of a module you want\\ndocumentation for, press \\nEnter, select the module, and then press “go to selected” (or omit the module\\nname and press “open browser” to see all available modules).\\nOnce you’ve found a promising entry, select it and click “go to selected.” PyDoc will\\nspawn a web browser on your machine to display the report rendered in HTML format.\\nFigure 15-2 shows the information PyDoc displays for the built-in glob module.\\nNotice the hyperlinks in the Modules section of this page—you can click these to jump\\nto the PyDoc pages for related (imported) modules. For larger pages, PyDoc also gen-\\nerates hyperlinks to sections within the page.\\nPython Documentation Sources | 383', metadata={'source': 'python.pdf', 'page': 433}),\n",
       " Document(page_content='Like the help function interface, the GUI interface works on user-defined modules as\\nwell as built-ins. Figure 15-3  shows the page generated for our docstrings.py module file.\\nPyDoc can be customized and launched in various ways we won’t cover here; see its\\nentry in Python’s standard library manual for more details. The main thing to take away\\nfrom this section is that PyDoc essentially gives you implementation reports “for\\nfree”—if you are good about using docstrings in your files, PyDoc does all the work of\\ncollecting and formatting them for display. PyDoc only helps for objects like functions\\nand modules, but it provides an easy way to access a middle level of documentation for\\nsuch tools—its reports are more useful than raw attribute lists, and less exhaustive than\\nthe standard manuals.\\nCool PyDoc trick of the day : If you leave the module name empty in the top input field\\nof the window in Figure 15-1  and press the “open browser” button, PyDoc will produce\\na web page containing a hyperlink to every module you can possibly import on your\\ncomputer. This includes Python standard library modules, modules of third-party\\nFigure 15-2. When you find a module in the Figure 15-1  GUI (such as this built-in standard library\\nmodule) and press “go to selected,” the module’s documentation is rendered in HTML and displayed\\nin a web browser window like this one.\\n384 | Chapter 15: \\u2002The Documentation Interlude', metadata={'source': 'python.pdf', 'page': 434}),\n",
       " Document(page_content='extensions you may have installed, user-defined modules on your import search path,\\nand even \\nstatically or dynamically linked-in C-coded modules. Such information is hard\\nto come by otherwise without writing code that inspects a set of module sources.\\nPyDoc can also be run to save the HTML documentation for a module in a file for later\\nviewing or printing; see its documentation for pointers. Also, note that PyDoc might\\nnot work well if run on scripts that read from standard input—PyDoc imports the target\\nmodule to inspect its contents, and there may be no connection for standard input text\\nwhen it is run in GUI mode. Modules that can be imported without immediate input\\nrequirements will always work under PyDoc, though.\\nFigure 15-3. PyDoc can serve up documentation pages for both built-in and user-coded modules. Here\\nis the page \\nfor a user-defined module, showing all its documentation strings (docstrings) extracted\\nfrom the source file.\\nPython Documentation Sources | 385', metadata={'source': 'python.pdf', 'page': 435}),\n",
       " Document(page_content='The Standard Manual Set\\nFor the complete \\nand most up-to-date description of the language and its toolset, Py-\\nthon’s standard manuals stand ready to serve. Python’s manuals ship in HTML and\\nother formats, and they are installed with the Python system on Windows—they are\\navailable in your Start button’s menu for Python, and they can also be opened from the\\nHelp menu within IDLE. You can also fetch the manual set separately from http://www\\n.python.org in a variety of formats, or read them online at that site (follow the Docu-\\nmentation link). On Windows, the manuals are a compiled help file to support\\nsearches, and the online versions at the Python website include a web-based search\\npage.\\nWhen opened, the Windows format of the manuals displays a root page like that in\\nFigure 15-4. The two most important entries here are most likely the Library Reference\\n(which documents built-in types, functions, exceptions, and standard library modules)\\nand the Language Reference (which provides a formal description of language-level\\ndetails). The tutorial listed on this page also provides a brief introduction for\\nnewcomers.\\nFigure 15-4. Python’s standard manual set, available online at http://www.python.org, from IDLE’s\\nHelp menu, and \\nin the Windows Start button menu. It’s a searchable help file on Windows, and there\\nis a search engine for the online version. Of these, the Library Reference is the one you’ll want to use\\nmost of the time.\\n386 | Chapter 15: \\u2002The Documentation Interlude', metadata={'source': 'python.pdf', 'page': 436}),\n",
       " Document(page_content='Web Resources\\nAt the official Python website ( http://www.python.org), you’ll find links to various Py-\\nthon \\nresources, some of which cover special topics or domains. Click the Documen-\\ntation link to access an online tutorial and the Beginners Guide to Python. The site also\\nlists non-English Python resources.\\nYou will find numerous Python wikis, blogs, websites, and a host of other resources\\non the Web today. To sample the online community, try searching for a term like\\n“Python programming” in Google.\\nPublished Books\\nAs a final resource, you can choose from a large collection of reference books for Python.\\nBear in mind that books tend to lag behind the cutting edge of Python changes, partly\\nbecause of the work involved in writing, and partly because of the natural delays built\\ninto the publishing cycle. Usually, by the time a book comes out, it’s three or more\\nmonths behind the current Python state. Unlike standard manuals, books are also gen-\\nerally not free.\\nStill, for many, the convenience and quality of a professionally published text is worth\\nthe cost. Moreover, Python changes so slowly that books are usually still relevant years\\nafter they are published, especially if their authors post updates on the Web. See the\\nPreface for pointers to other Python books.\\nCommon Coding Gotchas\\nBefore the programming exercises for this part of the book, let’s run through some of\\nthe most common mistakes beginners make when coding Python statements and pro-\\ngrams. Many of these are warnings I’ve thrown out earlier in this part of the book,\\ncollected here for ease of reference. You’ll learn to avoid these pitfalls once you’ve\\ngained a bit of Python coding experience, but a few words now might help you avoid\\nfalling into some of these traps initially:\\n•Don’t forget the colons. Always remember to type a : at the end of compound\\nstatement headers (the first line of an if, while, for, etc.). You’ll probably forget\\nat first (I did, and so have most of my 3,000 Python students over the years), but\\nyou can take some comfort from the fact that it will soon become an unconscious\\nhabit.\\n•Start in column 1 . Be sure to start top-level (unnested) code in column 1. That\\nincludes unnested code typed into module files, as well as unnested code typed at\\nthe interactive prompt.\\nCommon Coding Gotchas | 387', metadata={'source': 'python.pdf', 'page': 437}),\n",
       " Document(page_content='•Blank lines matter at the interactive prompt . Blank lines in compound state-\\nments are always ignored in module files, but when you’re typing code at the\\ninteractive prompt, they end the statement. In other words, blank lines tell the\\ninteractive command line that you’ve finished a compound statement; if you want\\nto continue, don’t hit the Enter key at the ... prompt (or in IDLE) until you’re\\nreally done.\\n•Indent consistently . Avoid mixing tabs and spaces in the indentation of a block,\\nunless you know what your text editor does with tabs. Otherwise, what you see in\\nyour editor may not be what Python sees when it counts tabs as a number of spaces.\\nThis is true in any block-structured language, not just Python—if the next pro-\\ngrammer has her tabs set differently, she will not understand the structure of your\\ncode. It’s safer to use all tabs or all spaces for each block.\\n•Don’t code C in Python . A reminder for C/C++ programmers: you don’t need to\\ntype parentheses around tests in if and while headers (e.g., if (X==1): ). You can,\\nif you like (any expression can be enclosed in parentheses), but they are fully su-\\nperfluous in this context. Also, do not terminate all your statements with semico-\\nlons; it’s technically legal to do this in Python as well, but it’s totally useless unless\\nyou’re placing more than one statement on a single line (the end of a line normally\\nterminates a statement). And remember, don’t embed assignment statements in\\nwhile loop tests, and don’t use {} around blocks (indent your nested code blocks\\nconsistently instead).\\n•Use simple  for loops instead of  while or range. Another reminder: a simple\\nfor loop (e.g., for x in seq:) is almost always simpler to code and quicker to run\\nthan a while- or range-based counter loop. Because Python handles indexing in-\\nternally for a simple for, it can sometimes be twice as fast as the equivalent\\nwhile. Avoid the temptation to count things in Python!\\n•Beware of mutables in assignments . I mentioned this in Chapter 11 : you need\\nto be careful about using mutables in a multiple-target assignment ( a = b = []),\\nas well as in an augmented assignment ( a += [1, 2]). In both cases, in-place\\nchanges may impact other variables. See Chapter 11 for details.\\n•Don’t expect results from functions that change objects in-place. We en-\\ncountered this one earlier, too: in-place change operations like the list.append and \\nlist.sort methods introduced in Chapter 8  do not return values (other than\\nNone), so you should call them without assigning the result. It’s not uncommon for\\nbeginners to say something like mylist = mylist.append(X)  to try to get the result\\nof an append, but what this actually does is assign mylist to None, not to the modified\\nlist (in fact, you’ll lose your reference to the list altogether).\\nA more devious example of this pops up in Python 2.X code when trying to step\\nthrough dictionary items in a sorted fashion. It’s fairly common to see code like\\nfor k in D.keys().sort():. This almost works—the keys method builds a keys\\nlist, and the sort method orders it—but because the sort method returns None, the\\nloop fails because it is ultimately a loop over None (a nonsequence). This fails even\\n388 | Chapter 15: \\u2002The Documentation Interlude', metadata={'source': 'python.pdf', 'page': 438}),\n",
       " Document(page_content='sooner in Python 3.0, because dictionary keys are views, not lists! To code this\\ncorrectly, either use \\nthe newer sorted built-in function, which returns the sorted\\nlist, or split the method calls out to statements: Ks = list(D.keys()), then\\nKs.sort(), and finally, for k in Ks:. This, by the way, is one case where you’ll still\\nwant to call the keys method explicitly for looping, instead of relying on the dic-\\ntionary iterators—iterators do not sort.\\n•Always use parentheses to call a function . You must add parentheses after a \\nfunction name to call it, whether it takes arguments or not (e.g., use function(),\\nnot function). In Part IV, we’ll see that functions are simply objects that have a\\nspecial operation—a call that you trigger with the parentheses.\\nIn classes, this problem seems to occur most often with files; it’s common to see\\nbeginners type file.close to close a file, rather than file.close(). Because it’s\\nlegal to reference a function without calling it, the first version with no parentheses\\nsucceeds silently, but it does not close the file!\\n•Don’t use extensions or paths in imports and reloads . Omit directory paths\\nand file suffixes in import statements (e.g., say import mod, not import mod.py). (We\\ndiscussed module basics in Chapter 3 and will continue studying modules in\\nPart V .) Because modules may have other suffixes besides .py (.pyc, for instance),\\nhardcoding a particular suffix is not only illegal syntax, but doesn’t make sense.\\nAny platform-specific directory path syntax comes from module search path set-\\ntings, not the import statement.\\nChapter Summary\\nThis chapter took us on a tour of program documentation—both documentation we\\nwrite ourselves for our own programs, and documentation available for built-in tools.\\nWe met docstrings, explored the online and manual resources for Python reference,\\nand learned how PyDoc’s help function and web page interface provide extra sources\\nof documentation. Because this is the last chapter in this part of the book, we also\\nreviewed common coding mistakes to help you avoid them.\\nIn the next part of this book, we’ll start applying what we already know to larger pro-\\ngram constructs: functions. Before moving on, however, be sure to work through the\\nset of lab exercises for this part of the book that appear at the end of this chapter. And\\neven before that, let’s run through this chapter’s quiz.\\nTest Your Knowledge: Quiz\\n1. When should you use documentation strings instead of hash-mark comments?\\n2. Name three ways you can view documentation strings.\\nTest Your Knowledge: Quiz | 389', metadata={'source': 'python.pdf', 'page': 439}),\n",
       " Document(page_content='3. How can you obtain a list of the available attributes in an object?\\n4. How can you get a list of all available modules on your computer?\\n5. Which Python book should you purchase after this one?\\nTest Your Knowledge: Answers\\n1.\\nDocumentation strings (docstrings) are considered best for larger, functional doc-\\numentation, describing the use of modules, functions, classes, and methods in your\\ncode. Hash-mark comments are today best limited to micro-documentation about\\narcane expressions or statements. This is partly because docstrings are easier to\\nfind in a source file, but also because they can be extracted and displayed by the\\nPyDoc system.\\n2. You can see docstrings by printing an object’s __doc__ attribute, by passing it to\\nPyDoc’s help function, and by selecting modules in PyDoc’s GUI search engine in\\nclient/server mode. Additionally, PyDoc can be run to save a module’s documen-\\ntation in an HTML file for later viewing or printing.\\n3. The built-in dir(X) function returns a list of all the attributes attached to any object.\\n4. Run the PyDoc GUI interface, leave the module name blank, and select “open\\nbrowser”; this opens a web page containing a link to every module available to\\nyour programs.\\n5. Mine, of course. (Seriously, the Preface lists a few recommended follow-up books,\\nboth for reference and for application tutorials.)\\nTest Your Knowledge: Part III Exercises\\nNow that you know how to code basic program logic, the following exercises will ask\\nyou to implement some simple tasks with statements. Most of the work is in exercise\\n4, which lets you explore coding alternatives. There are always many ways to arrange\\nstatements, and part of learning Python is learning which arrangements work better\\nthan others.\\nSee Part III in Appendix B for the solutions.\\n1.Coding basic loops.\\na. Write a for loop that prints the ASCII code of each character in a string named\\nS. Use the built-in function ord(character) to convert each character to an\\nASCII integer. (Test it interactively to see how it works.)\\nb. Next, change your loop to compute the sum of the ASCII codes of all the\\ncharacters in a string.\\n390 | Chapter 15: \\u2002The Documentation Interlude', metadata={'source': 'python.pdf', 'page': 440}),\n",
       " Document(page_content=\"c. Finally, modify your code again to return a new list that contains the ASCII\\ncodes of each character in the string. Does the expression map(ord, S)  have a\\nsimilar effect? (Hint: see Chapter 14\\n.)\\n2.Backslash characters . What happens on your machine when you type the following\\ncode interactively?\\nfor i in range(50):\\n    print('hello %d\\\\n\\\\a' % i)\\nBeware that if it’s run outside of the IDLE interface this example may beep at you,\\nso you may not want to run it in a crowded lab. IDLE prints odd characters instead\\nof beeping (see the backslash escape characters in Table 7-2).\\n3.Sorting dictionaries. In Chapter 8, we saw that dictionaries are unordered collec-\\ntions. Write a for loop that prints a dictionary’s items in sorted (ascending) order.\\n(Hint: use the dictionary keys and list sort methods, or the newer sorted built-in\\nfunction.)\\n4.Program logic alternatives. Consider the following code, which uses a while loop\\nand found flag to search a list of powers of 2 for the value of 2 raised to the fifth\\npower (32). It’s stored in a module file called power.py.\\nL = [1, 2, 4, 8, 16, 32, 64]\\nX = 5\\nfound = False\\ni = 0\\nwhile not found and i < len(L):\\n   if 2 ** X == L[i]:\\n       found = True\\n   else:\\n       i = i+1\\nif found:\\n    print('at index', i)\\nelse:\\n    print(X, 'not found')\\nC:\\\\book\\\\tests> python power.py\\nat index 5\\nAs is, the example doesn’t follow normal Python coding techniques. Follow the\\nsteps outlined here to improve it (for all the transformations, you may either type\\nyour code interactively or store it in a script file run from the system command\\nline—using a file makes this exercise much easier):\\na. First, rewrite this code with a while loop else clause to eliminate the found flag\\nand final if statement.\\nb. Next, rewrite the example to use a for loop with an else clause, to eliminate\\nthe explicit list-indexing logic. (Hint: to get the index of an item, use the list\\nindex method—L.index(X) returns the offset of the first X in list L.)\\nTest Your Knowledge: Part III Exercises | 391\", metadata={'source': 'python.pdf', 'page': 441}),\n",
       " Document(page_content='c. Next, remove the loop completely by rewriting the example with a simple in\\noperator membership \\nexpression. (See Chapter 8  for more details, or type this\\nto test: 2 in [1,2,3].)\\nd. Finally, use a for loop and the list append method to generate the powers-of-2\\nlist (L) instead of hardcoding a list literal.\\nDeeper thoughts:\\ne. Do you think it would improve performance to move the 2 ** X expression\\noutside the loops? How would you code that?\\nf. As we saw in exercise 1, Python includes a map(function, list)  tool that can\\ngenerate a powers-of-2 list, too: map(lambda x: 2 ** x, range(7)). Try typing\\nthis code interactively; we’ll meet lambda more formally in Chapter 19.\\n392 | Chapter 15: \\u2002The Documentation Interlude', metadata={'source': 'python.pdf', 'page': 442}),\n",
       " Document(page_content='PART IV\\nFunctions', metadata={'source': 'python.pdf', 'page': 443}),\n",
       " Document(page_content='', metadata={'source': 'python.pdf', 'page': 444}),\n",
       " Document(page_content=\"CHAPTER 16\\nFunction Basics\\nIn Part III, we looked at basic procedural statements in Python. Here, we’ll move on to\\nexplore a set of additional statements that we can use to create functions of our own.\\nIn \\nsimple terms, a function is a device that groups a set of statements so they can be run\\nmore than once in a program. Functions also can compute a result value and let us\\nspecify parameters that serve as function inputs, which may differ each time the code\\nis run. Coding an operation as a function makes it a generally useful tool, which we\\ncan use in a variety of contexts.\\nMore fundamentally, functions are the alternative to programming by cutting and\\npasting—rather than having multiple redundant copies of an operation’s code, we can\\nfactor it into a single function. In so doing, we reduce our future work radically: if the\\noperation must be changed later, we only have one copy to update, not many.\\nFunctions are the most basic program structure Python provides for maximizing code\\nreuse and minimizing code redundancy . As we’ll see, functions are also a design tool\\nthat lets us split complex systems into manageable parts. Table 16-1  summarizes the\\nprimary function-related tools we’ll study in this part of the book.\\nTable 16-1. Function-related statements and expressions\\nStatement Examples\\nCallsmyfunc('spam', 'eggs', meat=ham)\\ndef, \\nreturndef adder(a, b=1, *c):\\n    return a + b + c[0]\\nglobal def changer():\\n    global x; x = 'new'\\nnonlocal def changer():\\n    nonlocal x; x = 'new'\\nyield def squares(x):\\n    for i in range(x): yield i ** 2\\nlambda funcs = [lambda x: x**2, lambda x: x*3]\\n395\", metadata={'source': 'python.pdf', 'page': 445}),\n",
       " Document(page_content='Why Use Functions?\\nBefore we get \\ninto the details, let’s establish a clear picture of what functions are all\\nabout. Functions are a nearly universal program-structuring device. You may have\\ncome across them before in other languages, where they may have been called subrou-\\ntines or procedures. As a brief introduction, functions serve two primary development\\nroles:\\nMaximizing code reuse and minimizing redundancy\\nAs in most programming languages, Python functions are the simplest way to\\npackage logic you may wish to use in more than one place and more than one time.\\nUp until now, all the code we’ve been writing has run immediately. Functions allow\\nus to group and generalize code to be used arbitrarily many times later. Because\\nthey allow us to code an operation in a single place and use it in many places,\\nPython functions are the most basic factoring tool in the language: they allow us\\nto reduce code redundancy in our programs, and thereby reduce maintenance\\neffort.\\nProcedural decomposition\\nFunctions also provide a tool for splitting systems into pieces that have well-defined\\nroles. For instance, to make a pizza from scratch, you would start by mixing the\\ndough, rolling it out, adding toppings, baking it, and so on. If you were program-\\nming a pizza-making robot, functions would help you divide the overall “make\\npizza” task into chunks—one function for each subtask in the process. It’s easier\\nto implement the smaller tasks in isolation than it is to implement the entire process\\nat once. In general, functions are about procedure—how to do something, rather\\nthan what you’re doing it to. We’ll see why this distinction matters in Part VI , when\\nwe start making new object with classes.\\nIn this part of the book, we’ll explore the tools used to code functions in Python: func-\\ntion basics, scope rules, and argument passing, along with a few related concepts such\\nas generators and functional tools. Because its importance begins to become more ap-\\nparent at this level of coding, we’ll also revisit the notion of polymorphism introduced\\nearlier in the book. As you’ll see, functions don’t imply much new syntax, but they do\\nlead us to some bigger programming ideas.\\nCoding Functions\\nAlthough it wasn’t made very formal, we’ve already used some functions in earlier\\nchapters. For instance, to make a file object, we called the built-in open function; sim-\\nilarly, we used the len built-in function to ask for the number of items in a collection\\nobject.\\nIn this chapter, we will explore how to write new functions in Python. Functions we\\nwrite behave the same way as the built-ins we’ve already seen: they are called in\\n396 | Chapter 16: \\u2002Function Basics', metadata={'source': 'python.pdf', 'page': 446}),\n",
       " Document(page_content='expressions, are passed values, and return results. But writing new functions requires\\nthe application of a few additional ideas that haven’t yet been introduced. Moreover,\\nfunctions behave very differently in Python than they do in compiled languages like C.\\nHere is a brief introduction to the main concepts behind Python functions, all of which\\nwe will study in this part of the book:\\n•def is executable code . Python functions are written with a new statement, the\\ndef. Unlike functions in compiled languages such as C, def is an executable state-\\nment—your function does not exist until Python reaches and runs the def. In fact,\\nit’s legal (and even occasionally useful) to nest def statements inside if statements,\\nwhile loops, and even other defs. In typical operation, def statements are coded in\\nmodule files and are naturally run to generate functions when a module file is first\\nimported.\\n•def creates an object and assigns it to a name . When Python reaches and runs\\na def statement, it generates a new function object and assigns it to the function’s\\nname. As with all assignments, the function name becomes a reference to the func-\\ntion object. There’s nothing magic about the name of a function—as you’ll see,\\nthe function object can be assigned to other names, stored in a list, and so on.\\nFunction objects may also have arbitrary user-defined attributes attached to them\\nto record data.\\n•lambda creates an object but returns it as a result. Functions may also be created\\nwith the lambda expression, a feature that allows us to in-line function definitions\\nin places where a def statement won’t work syntactically (this is a more advanced\\nconcept that we’ll defer until Chapter 19).\\n•return sends a result object back to the caller . When a function is called, the\\ncaller stops until the function finishes its work and returns control to the caller.\\nFunctions that compute a value send it back to the caller with a return statement;\\nthe returned value becomes the result of the function call.\\n•yield sends a result object back to the caller, but remembers where it left\\noff. Functions known as generators may also use the yield statement to send back\\na value and suspend their state such that they may be resumed later, to produce a\\nseries of results over time. This is another advanced topic covered later in this part\\nof the book.\\n•global declares module-level variables that are to be assigned . By default, all\\nnames assigned in a function are local to that function and exist only while the\\nfunction runs. To assign a name in the enclosing module, functions need to list it\\nin a global statement. More generally, names are always looked up in scopes—\\nplaces where variables are stored—and assignments bind names to scopes.\\n•nonlocal declares enclosing function variables that are to be assigned . Simi-\\nlarly, the nonlocal statement added in Python 3.0 allows a function to assign a\\nname that exists in the scope of a syntactically enclosing def statement. This allows\\nCoding Functions | 397', metadata={'source': 'python.pdf', 'page': 447}),\n",
       " Document(page_content='enclosing functions to serve as a place to retain state—information remembered\\nwhen a function is called—without using shared global names.\\n•Arguments are \\npassed by assignment (object reference). In Python, arguments\\nare passed to functions by assignment (which, as we’ve learned, means by object\\nreference). As you’ll see, in Python’s model the caller and function share objects\\nby references, but there is no name aliasing. Changing an argument name within\\na function does not also change the corresponding name in the caller, but changing\\npassed-in mutable objects can change objects shared by the caller.\\n•Arguments, return values, and variables are not declared . As with everything\\nin Python, there are no type constraints on functions. In fact, nothing about a\\nfunction needs to be declared ahead of time: you can pass in arguments of any type,\\nreturn any kind of object, and so on. As one consequence, a single function can\\noften be applied to a variety of object types—any objects that sport a compatible\\ninterface (methods and expressions) will do, regardless of their specific types.\\nIf some of the preceding words didn’t sink in, don’t worry—we’ll explore all of these\\nconcepts with real code in this part of the book. Let’s get started by expanding on some\\nof these ideas and looking at a few examples.\\ndef Statements\\nThe def statement creates a function object and assigns it to a name. Its general format\\nis as follows:\\ndef <name>(arg1, arg2,... argN):\\n    <statements>\\nAs with all compound Python statements, def consists of a header line followed by a\\nblock of statements, usually indented (or a simple statement after the colon). The\\nstatement block becomes the function’s body—that is, the code Python executes each\\ntime the function is called.\\nThe def header line specifies a function name that is assigned the function object, along\\nwith a list of zero or more arguments (sometimes called parameters) in parentheses.\\nThe argument names in the header are assigned to the objects passed in parentheses at\\nthe point of call.\\nFunction bodies often contain a return statement:\\ndef <name>(arg1, arg2,... argN):\\n    ...\\n    return <value>\\nThe Python return statement can show up anywhere in a function body; it ends the\\nfunction call and sends a result back to the caller. The return statement consists of an\\nobject expression that gives the function’s result. The return statement is optional; if\\nit’s not present, the function exits when the control flow falls off the end of the function\\n398 | Chapter 16: \\u2002Function Basics', metadata={'source': 'python.pdf', 'page': 448}),\n",
       " Document(page_content='body. Technically, a function without a return statement returns the None object au-\\ntomatically, but this return value is usually ignored.\\nFunctions may also contain yield statements, which are designed to produce a series\\nof values over time, but we’ll defer discussion of these until we survey generator topics\\nin Chapter 20.\\ndef Executes at Runtime\\nThe Python def is a true executable statement: when it runs, it creates a new function\\nobject and assigns it to a name. (Remember, all we have in Python is runtime; there is\\nno such thing as a separate compile time.) Because it’s a statement, a def can appear\\nanywhere a statement can—even nested in other statements. For instance, although\\ndefs normally are run when the module enclosing them is imported, it’s also completely\\nlegal to nest a function def inside an if statement to select between alternative\\ndefinitions:\\nif test:\\n    def func():            # Define func this way\\n        ...\\nelse:\\n    def func():            # Or else this way\\n        ...\\n...\\nfunc()                     # Call the version selected and built\\nOne way to understand this code is to realize that the def is much like an = statement:\\nit simply assigns a name at runtime. Unlike in compiled languages such as C, Python\\nfunctions do not need to be fully defined before the program runs. More generally,\\ndefs are not evaluated until they are reached and run, and the code inside defs is not\\nevaluated until the functions are later called.\\nBecause function definition happens at runtime, there’s nothing special about the\\nfunction name. What’s important is the object to which it refers:\\nothername = func           # Assign function object\\nothername()                # Call func again\\nHere, the function was assigned to a different name and called through the new name.\\nLike everything else in Python, functions are just objects; they are recorded explicitly\\nin memory at program execution time. In fact, besides calls, functions allow arbitrary\\nattributes to be attached to record information for later use:\\ndef func(): ...            # Create function object\\nfunc()                     # Call object\\nfunc.attr = value          # Attach attributes\\nCoding Functions | 399', metadata={'source': 'python.pdf', 'page': 449}),\n",
       " Document(page_content='A First Example: Definitions and Calls\\nApart from such runtime \\nconcepts (which tend to seem most unique to programmers\\nwith backgrounds in traditional compiled languages), Python functions are straight-\\nforward to use. Let’s code a first real example to demonstrate the basics. As you’ll see,\\nthere are two sides to the function picture: a definition (the def that creates a function)\\nand a call (an expression that tells Python to run the function’s body).\\nDefinition\\nHere’s a definition typed interactively that defines a function called times, which re-\\nturns the product of its two arguments:\\n>>> def times(x, y):       # Create and assign function\\n...     return x * y       # Body executed when called\\n...\\nWhen Python reaches and runs this def, it creates a new function object that packages\\nthe function’s code and assigns the object to the name times. Typically, such a state-\\nment is coded in a module file and runs when the enclosing file is imported; for some-\\nthing this small, though, the interactive prompt suffices.\\nCalls\\nAfter the def has run, you can call (run) the function in your program by adding\\nparentheses after the function’s name. The parentheses may optionally contain one or\\nmore object arguments, to be passed (assigned) to the names in the function’s header:\\n>>> times(2, 4)            # Arguments in parentheses\\n8\\nThis expression passes two arguments to times. As mentioned previously, arguments\\nare passed by assignment, so in this case the name x in the function header is assigned\\nthe value 2, y is assigned the value 4, and the function’s body is run. For this function,\\nthe body is just a return statement that sends back the result as the value of the call\\nexpression. The returned object was printed here interactively (as in most languages,\\n2 * 4 is 8 in Python), but if we needed to use it later we could instead assign it to a\\nvariable. For example:\\n>>> x = times(3.14, 4)     # Save the result object\\n>>> x\\n12.56\\nNow, watch what happens when the function is called a third time, with very different\\nkinds of objects passed in:\\n>>> times(\\'Ni\\', 4)         # Functions are \"typeless\"\\n\\'NiNiNiNi\\'\\n400 | Chapter 16: \\u2002Function Basics', metadata={'source': 'python.pdf', 'page': 450}),\n",
       " Document(page_content='This time, our function means something completely different (Monty Python reference\\nagain intended). In \\nthis third call, a string and an integer are passed to x and y, instead\\nof two numbers. Recall that * works on both numbers and sequences; because we never\\ndeclare the types of variables, arguments, or return values in Python, we can use\\ntimes to either multiply numbers or repeat sequences.\\nIn other words, what our times function means and does depends on what we pass into\\nit. This is a core idea in Python (and perhaps the key to using the language well), which\\nwe’ll explore in the next section.\\nPolymorphism in Python\\nAs we just saw, the very meaning of the expression x * y  in our simple times function\\ndepends completely upon the kinds of objects that x and y are—thus, the same function\\ncan perform multiplication in one instance and repetition in another. Python leaves it\\nup to the objects to do something reasonable for the syntax. Really, * is just a dispatch\\nmechanism that routes control to the objects being processed.\\nThis sort of type-dependent behavior is known as polymorphism, a term we first met\\nin Chapter 4  that essentially means that the meaning of an operation depends on the\\nobjects being operated upon. Because it’s a dynamically typed language, polymorphism\\nruns rampant in Python. In fact, every operation is a polymorphic operation in Python:\\nprinting, indexing, the * operator, and much more.\\nThis is deliberate, and it accounts for much of the language’s conciseness and flexibility.\\nA single function, for instance, can generally be applied to a whole category of object\\ntypes automatically. As long as those objects support the expected interface (a.k.a.\\nprotocol), the function can process them. That is, if the objects passed into a function\\nhave the expected methods and expression operators, they are plug-and-play compat-\\nible with the function’s logic.\\nEven in our simple times function, this means that any two objects that support a * will\\nwork, no matter what they may be, and no matter when they are coded. This function\\nwill work on two numbers (performing multiplication), or a string and a number (per-\\nforming repetition), or any other combination of objects supporting the expected\\ninterface—even class-based objects we have not even coded yet.\\nMoreover, if the objects passed in do not support this expected interface, Python will\\ndetect the error when the * expression is run and raise an exception automatically. It’s\\ntherefore pointless to code error checking ourselves. In fact, doing so would limit our\\nfunction’s utility, as it would be restricted to work only on objects whose types we test\\nfor.\\nThis turns out to be a crucial philosophical difference between Python and statically\\ntyped languages like C++ and Java: in Python, your code is not supposed to care  about\\nspecific data types. If it does, it will be limited to working on just the types you antici-\\npated when you wrote it, and it will not support other compatible object types that\\nA First Example: Definitions and Calls | 401', metadata={'source': 'python.pdf', 'page': 451}),\n",
       " Document(page_content='may be coded in the future. Although it is possible to test for types with tools like the\\ntype built-in function, \\ndoing so breaks your code’s flexibility. By and large, we code to\\nobject interfaces in Python, not data types.\\nOf course, this polymorphic model of programming means we have to test our code to\\ndetect errors, rather than providing type declarations a compiler can use to detect some\\ntypes of errors for us ahead of time. In exchange for an initial bit of testing, though, we\\nradically reduce the amount of code we have to write and radically increase our code’s\\nflexibility. As you’ll learn, it’s a net win in practice.\\nA Second Example: Intersecting Sequences\\nLet’s look at a second function example that does something a bit more useful than\\nmultiplying arguments and further illustrates function basics.\\nIn Chapter 13 , we coded a for loop that collected items held in common in two strings.\\nWe noted there that the code wasn’t as useful as it could be because it was set up to\\nwork only on specific variables and could not be rerun later. Of course, we could copy\\nthe code and paste it into each place where it needs to be run, but this solution is neither\\ngood nor general—we’d still have to edit each copy to support different sequence\\nnames, and changing the algorithm would then require changing multiple copies.\\nDefinition\\nBy now, you can probably guess that the solution to this dilemma is to package the\\nfor loop inside a function. Doing so offers a number of advantages:\\n• Putting the code in a function makes it a tool that you can run as many times as\\nyou like.\\n• Because callers can pass in arbitrary arguments, functions are general enough to\\nwork on any two sequences (or other iterables) you wish to intersect.\\n• When the logic is packaged in a function, you only have to change code in one\\nplace if you ever need to change the way the intersection works.\\n• Coding the function in a module file means it can be imported and reused by any\\nprogram run on your machine.\\nIn effect, wrapping the code in a function makes it a general intersection utility:\\ndef intersect(seq1, seq2):\\n    res = []                     # Start empty\\n    for x in seq1:               # Scan seq1\\n        if x in seq2:            # Common item?\\n            res.append(x)        # Add to end\\n    return res\\nThe transformation from the simple code of Chapter 13  to this function is straightfor-\\nward; we’ve just nested the original logic under a def header and made the objects on\\n402 | Chapter 16: \\u2002Function Basics', metadata={'source': 'python.pdf', 'page': 452}),\n",
       " Document(page_content='which it operates passed-in parameter names. Because this function computes a result,\\nwe’ve also added a return statement to send a result object back to the caller.\\nCalls\\nBefore you can call \\na function, you have to make it. To do this, run its def statement,\\neither by typing it interactively or by coding it in a module file and importing the file.\\nOnce you’ve run the def, you can call the function by passing any two sequence objects\\nin parentheses:\\n>>> s1 = \"SPAM\"\\n>>> s2 = \"SCAM\"\\n>>> intersect(s1, s2)            # Strings\\n[\\'S\\', \\'A\\', \\'M\\']\\nHere, we’ve passed in two strings, and we get back a list containing the characters in\\ncommon. The algorithm the function uses is simple: “for every item in the first argu-\\nment, if that item is also in the second argument, append the item to the result.” It’s a\\nlittle shorter to say that in Python than in English, but it works out the same.\\nTo be fair, our intersect function is fairly slow (it executes nested loops), isn’t really\\nmathematical intersection (there may be duplicates in the result), and isn’t required at\\nall (as we’ve seen, Python’s set data type provides a built-in intersection operation).\\nIndeed, the function could be replaced with a single list comprehension expression, as\\nit exhibits the classic loop collector code pattern:\\n>>> [x for x in s1 if x in s2]\\n[\\'S\\', \\'A\\', \\'M\\']\\nAs a function basics example, though, it does the job—this single piece of code can\\napply to an entire range of object types, as the next section explains.\\nPolymorphism Revisited\\nLike all functions in Python, intersect is polymorphic. That is, it works on arbitrary\\ntypes, as long as they support the expected object interface:\\n>>> x = intersect([1, 2, 3], (1, 4))      # Mixed types\\n>>> x                                     # Saved result object\\n[1]\\nThis time, we passed in different types of objects to our function—a list and a tuple\\n(mixed types)—and it still picked out the common items. Because you don’t have to\\nspecify the types of arguments ahead of time, the intersect function happily iterates\\nthrough any kind of sequence objects you send it, as long as they support the expected\\ninterfaces.\\nFor intersect, this means that the first argument has to support the for loop, and the\\nsecond has to support the in membership test. Any two such objects will work, re-\\ngardless of their specific types—that includes physically stored sequences like strings\\nA Second Example: Intersecting Sequences | 403', metadata={'source': 'python.pdf', 'page': 453}),\n",
       " Document(page_content='and lists; all the iterable objects we met in Chapter 14 , including files and dictionaries;\\nand even any class-based objects we code that apply operator overloading techniques\\n(we’ll discuss these later in the book).*\\nHere again, if we pass in objects that do not support these interfaces (e.g., numbers),\\nPython will automatically detect the mismatch and raise an exception for us—which\\nis exactly what we want, and the best we could do on our own if we coded explicit type\\ntests. By not coding type tests and allowing Python to detect the mismatches for us, we\\nboth reduce the amount of code we need to write and increase our code’s flexibility.\\nLocal Variables\\nProbably the most interesting part of this example is its names. It turns out that the\\nvariable res inside intersect is what in Python is called a local variable —a name that\\nis visible only to code inside the function def and that exists only while the function\\nruns. In fact, because all names assigned in any way inside a function are classified as\\nlocal variables by default, nearly all the names in intersect are local variables:\\n•res is obviously assigned, so it is a local variable.\\n• Arguments are passed by assignment, so seq1 and seq2 are, too.\\n• The for loop assigns items to a variable, so the name x is also local.\\nAll these local variables appear when the function is called and disappear when the\\nfunction exits—the return statement at the end of intersect sends back the result\\nobject, but the name res goes away. To fully explore the notion of locals, though, we\\nneed to move on to Chapter 17.\\nChapter Summary\\nThis chapter introduced the core ideas behind function definition—the syntax and\\noperation of the def and return statements, the behavior of function call expressions,\\nand the notion and benefits of polymorphism in Python functions. As we saw, a def\\nstatement is executable code that creates a function object at runtime; when the func-\\ntion is later called, objects are passed into it by assignment (recall that assignment\\nmeans object reference in Python, which, as we learned in Chapter 6 , really means\\npointer internally), and computed values are sent back by return. We also began\\n* This code will always work if we intersect files’ contents obtained with file.readlines(). It may not work\\nto intersect lines in open input files directly, though, depending on the file object’s implementation of the\\nin operator or general iteration. Files must generally be rewound (e.g., with a file.seek(0) or another\\nopen) after they have been read to end-of-file once. As we’ll see in Chapter 29  when we study operator\\noverloading, classes implement the in operator either by providing the specific __contains__ method or by\\nsupporting the general iteration protocol with the __iter__ or older __getitem__ methods; if coded, classes\\ncan define what iteration means for their data.\\n404 | Chapter 16: \\u2002Function Basics', metadata={'source': 'python.pdf', 'page': 454}),\n",
       " Document(page_content='exploring the concepts of local variables and scopes in this chapter, but we’ll save all\\nthe details on those topics for Chapter 17\\n. First, though, a quick quiz.\\nTest Your Knowledge: Quiz\\n1. What is the point of coding functions?\\n2. At what time does Python create a function?\\n3.\\nWhat does a function return if it has no return statement in it?\\n4. When does the code nested inside the function definition statement run?\\n5. What’s wrong with checking the types of objects passed into a function?\\nTest Your Knowledge: Answers\\n1. Functions are the most basic way of avoiding code redundancy in Python—factor-\\ning code into functions means that we have only one copy of an operation’s code\\nto update in the future. Functions are also the basic unit of code reuse in Python—\\nwrapping code in functions makes it a reusable tool, callable in a variety of pro-\\ngrams. Finally, functions allow us to divide a complex system into manageable\\nparts, each of which may be developed individually.\\n2. A function is created when Python reaches and runs the def statement; this state-\\nment creates a function object and assigns it the function’s name. This normally\\nhappens when the enclosing module file is imported by another module (recall that\\nimports run the code in a file from top to bottom, including any defs), but it can\\nalso occur when a def is typed interactively or nested in other statements, such as\\nifs.\\n3. A function returns the None object by default if the control flow falls off the end of\\nthe function body without running into a return statement. Such functions are\\nusually called with expression statements, as assigning their None results to varia-\\nbles is generally pointless.\\n4. The function body (the code nested inside the function definition statement) is run\\nwhen the function is later called with a call expression. The body runs anew each\\ntime the function is called.\\n5. Checking the types of objects passed into a function effectively breaks the func-\\ntion’s flexibility, constraining the function to work on specific types only. Without\\nsuch checks, the function would likely be able to process an entire range of object\\ntypes—any objects that support the interface expected by the function will work.\\n(The term interface means the set of methods and expression operators the func-\\ntion’s code runs.)\\nTest Your Knowledge: Answers | 405', metadata={'source': 'python.pdf', 'page': 455}),\n",
       " Document(page_content='', metadata={'source': 'python.pdf', 'page': 456}),\n",
       " Document(page_content='CHAPTER 17\\nScopes\\nChapter 16  introduced basic function definitions and calls. As we saw, Python’s basic\\nfunction model \\nis simple to use, but even simple function examples quickly led us to\\nquestions about the meaning of variables in our code. This chapter moves on to present\\nthe details behind Python’s scopes—the places where variables are defined and looked\\nup. As we’ll see, the place where a name is assigned in our code is crucial to determining\\nwhat the name means. We’ll also find that scope usage can have a major impact on\\nprogram maintenance effort; overuse of globals, for example, is a generally bad thing.\\nPython Scope Basics\\nNow that you’re ready to start writing your own functions, we need to get more formal\\nabout what names mean in Python. When you use a name in a program, Python creates,\\nchanges, or looks up the name in what is known as a namespace—a place where names\\nlive. When we talk about the search for a name’s value in relation to code, the term \\nscope refers to a namespace: that is, the location of a name’s assignment in your code\\ndetermines the scope of the name’s visibility to your code.\\nJust about everything related to names, including scope classification, happens at as-\\nsignment time in Python. As we’ve seen, names in Python spring into existence when\\nthey are first assigned values, and they must be assigned before they are used. Because\\nnames are not declared ahead of time, Python uses the location of the assignment of a\\nname to associate it with (i.e., bind it to) a particular namespace. In other words, the\\nplace where you assign a name in your source code determines the namespace it will\\nlive in, and hence its scope of visibility.\\nBesides packaging code, functions add an extra namespace layer to your programs—\\nby default, all names assigned inside a function are associated with that function’s\\nnamespace, and no other. This means that:\\n• Names defined inside a def can only be seen by the code within that def. You cannot\\neven refer to such names from outside the function.\\n407', metadata={'source': 'python.pdf', 'page': 457}),\n",
       " Document(page_content='• Names defined inside a def do not clash with variables outside the def, even if the\\nsame names are used elsewhere. A name X assigned outside a given def (i.e., in a\\ndifferent def or at the top level of a module file) is a completely different variable\\nfrom a name X assigned inside that def.\\nIn all cases, the scope of a variable (where it can be used) is always determined by where\\nit is assigned in your source code and has nothing to do with which functions call which.\\nIn fact, as we’ll learn in this chapter, variables may be assigned in three different places,\\ncorresponding to three different scopes:\\n• If a variable is assigned inside a def, it is local to that function.\\n• If a variable is assigned in an enclosing def, it is nonlocal to nested functions.\\n• If a variable is assigned outside all defs, it is global to the entire file.\\nWe call this lexical scoping  because variable scopes are determined entirely by the lo-\\ncations of the variables in the source code of your program files, not by function calls.\\nFor example, in the following module file, the X = 99  assignment creates a global var-\\niable named X (visible everywhere in this file), but the X = 88 assignment creates a\\nlocal variable X (visible only within the def statement):\\nX = 99\\ndef func():\\n    X = 88\\nEven though both variables are named X, their scopes make them different. The net\\neffect is that function scopes help to avoid name clashes in your programs and help to\\nmake functions more self-contained program units.\\nScope Rules\\nBefore we started writing functions, all the code we wrote was at the top level of a\\nmodule (i.e., not nested in a def), so the names we used either lived in the module itself\\nor were built-ins predefined by Python (e.g., open). Functions provide nested name-\\nspaces (scopes) that localize the names they use, such that names inside a function\\nwon’t clash with those outside it (in a module or another function). Again, functions\\ndefine a local scope , and modules define a global scope . The two scopes are related as\\nfollows:\\n•The enclosing module is a global scope . Each module is a global scope—that\\nis, a namespace in which variables created (assigned) at the top level of the module\\nfile live. Global variables become attributes of a module object to the outside world\\nbut can be used as simple variables within a module file.\\n•The global scope spans a single file only . Don’t be fooled by the word “global”\\nhere—names at the top level of a file are only global to code within that single file.\\nThere is really no notion of a single, all-encompassing global file-based scope in\\n408 | Chapter 17: \\u2002Scopes', metadata={'source': 'python.pdf', 'page': 458}),\n",
       " Document(page_content='Python. Instead, names are partitioned into modules, and you must always import\\na module explicitly \\nif you want to be able to use the names its file defines. When\\nyou hear “global” in Python, think “module.”\\n•Each call to a function creates a new local scope . Every time you call a function,\\nyou create a new local scope—that is, a namespace in which the names created\\ninside that function will usually live. You can think of each def statement (and\\nlambda expression) as defining a new local scope, but because Python allows func-\\ntions to call themselves to loop (an advanced technique known as recursion), the\\nlocal scope in fact technically corresponds to a function call—in other words, each\\ncall creates a new local namespace. Recursion is useful when processing structures\\nwhose shapes can’t be predicted ahead of time.\\n•Assigned names are local unless declared global or nonlocal . By default, all\\nthe names assigned inside a function definition are put in the local scope (the\\nnamespace associated with the function call). If you need to assign a name that\\nlives at the top level of the module enclosing the function, you can do so by de-\\nclaring it in a global statement inside the function. If you need to assign a name\\nthat lives in an enclosing def, as of Python 3.0 you can do so by declaring it in a \\nnonlocal statement.\\n•All other names are enclosing function locals, globals, or built-ins . Names\\nnot assigned a value in the function definition are assumed to be enclosing scope\\nlocals (in an enclosing def), globals (in the enclosing module’s namespace), or built-\\nins (in the predefined __builtin__ module Python provides).\\nThere are a few subtleties to note here. First, keep in mind that code typed at the\\ninteractive command prompt follows these same rules. You may not know it yet, but\\ncode run interactively is really entered into a built-in module called __main__; this\\nmodule works just like a module file, but results are echoed as you go. Because of this,\\ninteractively created names live in a module, too, and thus follow the normal scope\\nrules: they are global to the interactive session. You’ll learn more about modules in the\\nnext part of this book.\\nAlso note that any type of assignment  within a function classifies a name as local. This\\nincludes = statements, module names in import, function names in def, function argu-\\nment names, and so on. If you assign a name in any way within a def, it will become a\\nlocal to that function.\\nConversely, in-place changes  to objects do not classify names as locals; only actual name\\nassignments do. For instance, if the name L is assigned to a list at the top level of a\\nmodule, a statement L = X  within a function will classify L as a local, but L.append(X)\\nwill not. In the latter case, we are changing the list object that L references, not L itself—\\nL is found in the global scope as usual, and Python happily modifies it without requiring\\na global (or nonlocal) declaration. As usual, it helps to keep the distinction between\\nnames and objects clear: changing an object is not an assignment to a name.\\nPython Scope Basics | 409', metadata={'source': 'python.pdf', 'page': 459}),\n",
       " Document(page_content='Name Resolution: The LEGB Rule\\nIf the prior section \\nsounds confusing, it really boils down to three simple rules. With a\\ndef statement:\\n• Name references search at most four scopes: local, then enclosing functions (if\\nany), then global, then built-in.\\n• Name assignments create or change local names by default.\\n•global and nonlocal declarations map assigned names to enclosing module and\\nfunction scopes.\\nIn other words, all names assigned inside a function def statement (or a lambda, an\\nexpression we’ll meet later) are locals by default. Functions can freely use names as-\\nsigned in syntactically enclosing functions and the global scope, but they must declare\\nsuch nonlocals and globals in order to change them.\\nPython’s name-resolution scheme is sometimes called the LEGB rule, after the scope\\nnames:\\n• When you use an unqualified name inside a function, Python searches up to four\\nscopes—the local (L) scope, then the local scopes of any enclosing (E) defs and\\nlambdas, then the global ( G) scope, and then the built-in ( B) scope—and stops at\\nthe first place the name is found. If the name is not found during this search, Python\\nreports an error. As we learned in Chapter 6 , names must be assigned before they\\ncan be used.\\n• When you assign a name in a function (instead of just referring to it in an expres-\\nsion), Python always creates or changes the name in the local scope, unless it’s\\ndeclared to be global or nonlocal in that function.\\n• When you assign a name outside any function (i.e., at the top level of a module\\nfile, or at the interactive prompt), the local scope is the same as the global scope—\\nthe module’s namespace.\\nFigure 17-1  illustrates Python’s four scopes. Note that the second scope lookup layer,\\nE—the scopes of enclosing defs or lambdas—can technically correspond to more than\\none lookup layer. This case only comes into play when you nest functions within func-\\ntions, and it is addressed by the nonlocal statement.*\\nAlso keep in mind that these rules apply only to simple variable names (e.g., spam). In\\nParts V and VI, we’ll see that qualified attribute names (e.g., object.spam) live in par-\\nticular objects and follow a completely different set of lookup rules than those\\n* The scope lookup rule was called the “LGB rule” in the first edition of this book. The enclosing def “E” layer\\nwas added later in Python to obviate the task of passing in enclosing scope names explicitly with default\\narguments—a topic usually of marginal interest to Python beginners that we’ll defer until later in this chapter.\\nSince this scope is addressed by the nonlocal statement in Python 3.0, I suppose the lookup rule might now\\nbe better named “LNGB,” but backward compatibility matters in books, too!\\n410 | Chapter 17: \\u2002Scopes', metadata={'source': 'python.pdf', 'page': 460}),\n",
       " Document(page_content='covered here. References to attribute names following periods ( .) search one or more\\nobjects, not scopes, and may invoke something called “inheritance”; more on this in\\nPart VI of this book.\\nScope Example\\nLet’s look at a larger example that demonstrates scope ideas. Suppose we wrote the\\nfollowing code in a module file:\\n# Global scope\\nX = 99                # X and func assigned in module: global\\ndef func(Y):          # Y and Z assigned in function: locals\\n    # Local scope\\n    Z = X + Y         # X is a global\\n    return Z\\nfunc(1)               # func in module: result=100\\nThis module and the function it contains use a number of names to do their business.\\nUsing Python’s scope rules, we can classify the names as follows:\\nGlobal names: X, func\\nX is global because it’s assigned at the top level of the module file; it can be refer-\\nenced inside the function without being declared global. func is global for the same\\nreason; the def statement assigns a function object to the name func at the top level\\nof the module.\\nFigure 17-1. The LEGB scope lookup rule. When a variable is referenced, Python searches for it in\\nthis order: in \\nthe local scope, in any enclosing functions’ local scopes, in the global scope, and finally\\nin the built-in scope. The first occurrence wins. The place in your code where a variable is assigned\\nusually determines its scope. In Python 3, nonlocal declarations can also force names to be mapped\\nto enclosing function scopes, whether assigned or not.\\nPython Scope Basics | 411', metadata={'source': 'python.pdf', 'page': 461}),\n",
       " Document(page_content=\"Local names: Y, Z\\nY and Z \\nare local to the function (and exist only while the function runs) because\\nthey are both assigned values in the function definition: Z by virtue of the = state-\\nment, and Y because arguments are always passed by assignment.\\nThe whole point behind this name-segregation scheme is that local variables serve as\\ntemporary names that you need only while a function is running. For instance, in the\\npreceding example, the argument Y and the addition result Z exist only inside the func-\\ntion; these names don’t interfere with the enclosing module’s namespace (or any other\\nfunction, for that matter).\\nThe local/global distinction also makes functions easier to understand, as most of the\\nnames a function uses appear in the function itself, not at some arbitrary place in a\\nmodule. Also, because you can be sure that local names will not be changed by some\\nremote function in your program, they tend to make programs easier to debug and\\nmodify.\\nThe Built-in Scope\\nWe’ve been talking about the built-in scope in the abstract, but it’s a bit simpler than\\nyou may think. Really, the built-in scope is just a built-in module called builtins, but\\nyou have to import builtins to query built-ins because the name builtins is not itself\\nbuilt-in....\\nNo, I’m serious! The built-in scope is implemented as a standard library module named\\nbuiltins, but that name itself is not placed in the built-in scope, so you have to import\\nit in order to inspect it. Once you do, you can run a dir call to see which names are\\npredefined. In Python 3.0:\\n>>> import builtins\\n>>> dir(builtins)\\n['ArithmeticError', 'AssertionError', 'AttributeError', 'BaseException',\\n'BufferError', 'BytesWarning', 'DeprecationWarning', 'EOFError', 'Ellipsis',\\n    ...many more names omitted...\\n'print', 'property', 'quit', 'range', 'repr', 'reversed', 'round', 'set',\\n'setattr', 'slice', 'sorted', 'staticmethod', 'str', 'sum', 'super', 'tuple',\\n'type', 'vars', 'zip']\\nThe names in this list constitute the built-in scope in Python; roughly the first half are\\nbuilt-in exceptions, and the second half are built-in functions. Also in this list are the\\nspecial names None, True, and False, though they are treated as reserved words. Because\\nPython automatically searches this module last in its LEGB lookup, you get all the\\nnames in this list “for free;” that is, you can use them without importing any modules.\\nThus, there are really two ways to refer to a built-in function—by taking advantage of\\nthe LEGB rule, or by manually importing the builtins module:\\n>>> zip                         # The normal way\\n<class 'zip'>\\n412 | Chapter 17: \\u2002Scopes\", metadata={'source': 'python.pdf', 'page': 462}),\n",
       " Document(page_content=\">>> import builtins             # The hard way\\n>>> builtins.zip\\n<class 'zip'>\\nThe second of \\nthese approaches is sometimes useful in advanced work. The careful\\nreader might also notice that because the LEGB lookup procedure takes the first oc-\\ncurrence of a name that it finds, names in the local scope may override variables of the\\nsame name in both the global and built-in scopes, and global names may override built-\\nins. A function can, for instance, create a local variable called open by assigning to it:\\ndef hider():\\n    open = 'spam'              # Local variable, hides built-in\\n    ...\\n    open('data.txt')           # This won't open a file now in this scope!\\nHowever, this will hide the built-in function called open that lives in the built-in (outer)\\nscope. It’s also usually a bug, and a nasty one at that, because Python will not issue a\\nwarning message about it (there are times in advanced programming where you may\\nreally want to replace a built-in name by redefining it in your code).\\nFunctions can similarly hide global variables of the same name with locals:\\nX = 88                         # Global X\\ndef func():\\n    X = 99                     # Local X: hides global\\nfunc()\\nprint(X)                       # Prints 88: unchanged\\nHere, the assignment within the function creates a local X that is a completely different\\nvariable from the global X in the module outside the function. Because of this, there is\\nno way to change a name outside a function without adding a global (or nonlocal)\\ndeclaration to the def, as described in the next section.\\nVersion skew note: Actually, the tongue twisting gets a bit worse. The\\nPython 3.0 builtins module used here is named __builtin__ in Python\\n2.6. And just for fun, the name __builtins__ (with the “s”) is preset in\\nmost global scopes, including the interactive session, to reference the\\nmodule known as builtins (a.k.a. __builtin__ in 2.6).\\nThat is, after importing builtins, __builtins__ is builtins is True in\\n3.0, and __builtins__ is __builtin__ is True in 2.6. The net effect is\\nthat we can inspect the built-in scope by simply running\\ndir(__builtins__) with no import in both 3.0 and 2.6, but we are ad-\\nvised to use builtins for real work in 3.0. Who said documenting this\\nstuff was easy?\\nPython Scope Basics | 413\", metadata={'source': 'python.pdf', 'page': 463}),\n",
       " Document(page_content='Breaking the Universe in Python 2.6\\nHere’s another thing you can do in Python that you probably shouldn’t—because the\\nnames True and False \\nin 2.6 are just variables in the built-in scope and are not reserved,\\nit’s possible to reassign them with a statement like True = False. Don’t worry, you\\nwon’t actually break the logical consistency of the universe in so doing! This statement\\nmerely redefines the word True for the single scope in which it appears. All other scopes\\nstill find the originals in the built-in scope.\\nFor more fun, though, in Python 2.6 you could say __builtin__.True = False, to reset\\nTrue to False for the entire Python process. Alas, this type of assignment has been\\ndisallowed in Python 3.0, because True and False are treated as actual reserved words,\\njust like None. In 2.6, though, it sends IDLE into a strange panic state that resets the\\nuser code process.\\nThis technique can be useful, however, both to illustrate the underlying namespace\\nmodel and for tool writers who must change built-ins such as open to customized func-\\ntions. Also, note that third-party tools such as PyChecker will warn about common\\nprogramming mistakes, including accidental assignment to built-in names (this is\\nknown as “shadowing” a built-in in PyChecker).\\nThe global Statement\\nThe global statement and \\nits nonlocal cousin are the only things that are remotely like\\ndeclaration statements in Python. They are not type or size declarations, though; they\\nare namespace declarations . The global statement tells Python that a function plans to\\nchange one or more global names—i.e., names that live in the enclosing module’s scope\\n(namespace).\\nWe’ve talked about global in passing already. Here’s a summary:\\n• Global names are variables assigned at the top level of the enclosing module file.\\n• Global names must be declared only if they are assigned within a function.\\n• Global names may be referenced within a function without being declared.\\nIn other words, global allows us to change names that live outside a def at the top level\\nof a module file. As we’ll see later, the nonlocal statement is almost identical but applies\\nto names in the enclosing def’s local scope, rather than names in the enclosing module.\\nThe global statement consists of the keyword global, followed by one or more names\\nseparated by commas. All the listed names will be mapped to the enclosing module’s\\nscope when assigned or referenced within the function body. For instance:\\nX = 88                         # Global X\\ndef func():\\n    global X\\n    X = 99                     # Global X: outside def\\n414 | Chapter 17: \\u2002Scopes', metadata={'source': 'python.pdf', 'page': 464}),\n",
       " Document(page_content='func()\\nprint(X)                       # Prints 99\\nWe’ve added a global\\n declaration to the example here, such that the X inside the def\\nnow refers to the X outside the def; they are the same variable this time. Here is a slightly\\nmore involved example of global at work:\\ny, z = 1, 2                    # Global variables in module\\ndef all_global():\\n    global x                   # Declare globals assigned\\n    x = y + z                  # No need to declare y, z: LEGB rule\\nHere, x, y, and z are all globals inside the function all_global. y and z are global because\\nthey aren’t assigned in the function; x is global because it was listed in a global statement\\nto map it to the module’s scope explicitly. Without the global here, x would be con-\\nsidered local by virtue of the assignment.\\nNotice that y and z are not declared global; Python’s LEGB lookup rule finds them in\\nthe module automatically. Also, notice that x might not exist in the enclosing module\\nbefore the function runs; in this case, the assignment in the function creates x in the\\nmodule.\\nMinimize Global Variables\\nBy default, names assigned in functions are locals, so if you want to change names\\noutside functions you have to write extra code (e.g., global statements). This is by\\ndesign—as is common in Python, you have to say more to do the potentially “wrong”\\nthing. Although there are times when globals are useful, variables assigned in a def are\\nlocal by default because that is normally the best policy. Changing globals can lead to\\nwell-known software engineering problems: because the variables’ values are\\ndependent on the order of calls to arbitrarily distant functions, programs can become\\ndifficult to debug.\\nConsider this module file, for example:\\nX = 99\\ndef func1():\\n    global X\\n    X = 88\\ndef func2():\\n    global X\\n    X = 77\\nNow, imagine that it is your job to modify or reuse this module file. What will the value\\nof X be here? Really, that question has no meaning unless it’s qualified with a point of\\nreference in time—the value of X is timing-dependent, as it depends on which function\\nwas called last (something we can’t tell from this file alone).\\nThe global Statement | 415', metadata={'source': 'python.pdf', 'page': 465}),\n",
       " Document(page_content=\"The net effect is that to understand this code, you have to trace the flow of control\\nthrough the entire program . And, if \\nyou need to reuse or modify the code, you have to\\nkeep the entire program in your head all at once. In this case, you can’t really use one\\nof these functions without bringing along the other. They are dependent on (that is,\\ncoupled with) the global variable. This is the problem with globals—they generally\\nmake code more difficult to understand and use than code consisting of self-contained\\nfunctions that rely on locals.\\nOn the other hand, short of using object-oriented programming and classes, global\\nvariables are probably the most straightforward way to retain shared state information\\n(information that a function needs to remember for use the next time it is called) in\\nPython—local variables disappear when the function returns, but globals do not. Other\\ntechniques, such as default mutable arguments and enclosing function scopes, can\\nachieve this, too, but they are more complex than pushing values out to the global scope\\nfor retention.\\nSome programs designate a single module to collect globals; as long as this is expected,\\nit is not as harmful. In addition, programs that use multithreading to do parallel pro-\\ncessing in Python commonly depend on global variables—they become shared memory\\nbetween functions running in parallel threads, and so act as a communication device.†\\nFor now, though, especially if you are relatively new to programming, avoid the temp-\\ntation to use globals whenever you can—try to communicate with passed-in arguments\\nand return values instead. Six months from now, both you and your coworkers will be\\nhappy you did.\\nMinimize Cross-File Changes\\nHere’s another scope-related issue: although we can change variables in another file\\ndirectly, we usually shouldn’t. Module files were introduced in Chapter 3  and are cov-\\nered in more depth in the next part of this book. To illustrate their relationship to\\nscopes, consider these two module files:\\n# first.py\\nX = 99                    # This code doesn't know about second.py\\n# second.py\\nimport first\\nprint(first.X)            # Okay: references a name in another file\\nfirst.X = 88              # But changing it can be too subtle and implicit\\n†Multithreading runs function calls in parallel with the rest of the program and is supported by Python’s\\nstandard library modules _thread, threading, and queue (thread, threading, and Queue in Python 2.6). Because\\nall threaded functions run in the same process, global scopes often serve as shared memory between them.\\nThreading is commonly used for long-running tasks in GUIs, to implement nonblocking operations in general\\nand to leverage CPU capacity. It is also beyond this book’s scope; see the Python library manual, as well as\\nthe follow-up texts listed in the Preface (such as O’Reilly’s Programming Python), for more details.\\n416 | Chapter 17: \\u2002Scopes\", metadata={'source': 'python.pdf', 'page': 466}),\n",
       " Document(page_content='The first defines a variable X, which the second prints and then changes by assignment.\\nNotice that we must import the first module into the second file to get to its variable\\nat all—as we’ve learned, each module is a self-contained namespace (package of vari-\\nables), and we must import one module to see inside it from another. That’s the main\\npoint about modules: by segregating variables on a per-file basis, they avoid name\\ncollisions across files.\\nReally, though, in terms of this chapter’s topic, the global scope of a module file be-\\ncomes the attribute namespace of the module object once it is imported—importers\\nautomatically have access to all of the file’s global variables, because a file’s global scope\\nmorphs into an object’s attribute namespace when it is imported.\\nAfter importing the first module, the second module prints its variable and then assigns\\nit a new value. Referencing the module’s variable to print it is fine—this is how modules\\nare linked together into a larger system normally. The problem with the assignment,\\nhowever, is that it is far too implicit: whoever’s charged with maintaining or reusing\\nthe first module probably has no clue that some arbitrarily far-removed module on the\\nimport chain can change X out from under him at runtime. In fact, the second module\\nmay be in a completely different directory, and so difficult to notice at all.\\nAlthough such cross-file variable changes are always possible in Python, they are usually\\nmuch more subtle than you will want. Again, this sets up too strong a coupling between\\nthe two files—because they are both dependent on the value of the variable X, it’s\\ndifficult to understand or reuse one file without the other. Such implicit cross-file de-\\npendencies can lead to inflexible code at best, and outright bugs at worst.\\nHere again, the best prescription is generally to not do this—the best way to commu-\\nnicate across file boundaries is to call functions, passing in arguments and getting back\\nreturn values. In this specific case, we would probably be better off coding an accessor\\nfunction to manage the change:\\n# first.py\\nX = 99\\ndef setX(new):\\n    global X\\n    X = new\\n# second.py\\nimport first\\nfirst.setX(88)\\nThis requires more code and may seem like a trivial change, but it makes a huge dif-\\nference in terms of readability and maintainability—when a person reading the first\\nmodule by itself sees a function, that person will know that it is a point of interface and\\nwill expect the change to the X. In other words, it removes the element of surprise that\\nis rarely a good thing in software projects. Although we cannot prevent cross-file\\nchanges from happening, common sense dictates that they should be minimized unless\\nwidely accepted across the program.\\nThe global Statement | 417', metadata={'source': 'python.pdf', 'page': 467}),\n",
       " Document(page_content=\"Other Ways to Access Globals\\nInterestingly, because global-scope \\nvariables morph into the attributes of a loaded\\nmodule object, we can emulate the global statement by importing the enclosing module\\nand assigning to its attributes, as in the following example module file. Code in this file\\nimports the enclosing module, first by name, and then by indexing the sys.modules\\nloaded modules table (more on this table in Chapter 21):\\n# thismod.py\\nvar = 99                              # Global variable == module attribute\\ndef local():\\n    var = 0                           # Change local var\\ndef glob1():\\n    global var                        # Declare global (normal)\\n    var += 1                          # Change global var\\ndef glob2():\\n    var = 0                           # Change local var\\n    import thismod                    # Import myself\\n    thismod.var += 1                  # Change global var\\ndef glob3():\\n    var = 0                           # Change local var\\n    import sys                        # Import system table\\n    glob = sys.modules['thismod']     # Get module object (or use __name__)\\n    glob.var += 1                     # Change global var\\ndef test():\\n    print(var)\\n    local(); glob1(); glob2(); glob3()\\n    print(var)\\nWhen run, this adds 3 to the global variable (only the first function does not impact it):\\n>>> import thismod\\n>>> thismod.test()\\n99\\n102\\n>>> thismod.var\\n102\\nThis works, and it illustrates the equivalence of globals to module attributes, but it’s\\nmuch more work than using the global statement to make your intentions explicit.\\nAs we’ve seen, global allows us to change names in a module outside a function. It has\\na cousin named nonlocal that can be used to change names in enclosing functions, too,\\nbut to understand how that can be useful, we first need to explore enclosing functions\\nin general.\\n418 | Chapter 17: \\u2002Scopes\", metadata={'source': 'python.pdf', 'page': 468}),\n",
       " Document(page_content='Scopes and Nested Functions\\nSo far, I’ve \\nomitted one part of Python’s scope rules on purpose, because it’s relatively\\nrare to encounter it in practice. However, it’s time to take a deeper look at the letter\\nE in the LEGB lookup rule. The E layer is fairly new (it was added in Python 2.2); it\\ntakes the form of the local scopes of any and all enclosing function defs. Enclosing\\nscopes are sometimes also called statically nested scopes . Really, the nesting is a lexical\\none—nested scopes correspond to physically and syntactically nested code structures\\nin your program’s source code.\\nNested Scope Details\\nWith the addition of nested function scopes, variable lookup rules become slightly more\\ncomplex. Within a function:\\n• A reference (X) looks for the name X first in the current local scope (function); then\\nin the local scopes of any lexically enclosing functions in your source code, from\\ninner to outer; then in the current global scope (the module file); and finally in the\\nbuilt-in scope (the module builtins). global declarations make the search begin\\nin the global (module file) scope instead.\\n• An assignment (X = value) creates or changes the name X in the current local scope,\\nby default. If X is declared global within the function, the assignment creates or\\nchanges the name X in the enclosing module’s scope instead. If, on the other hand,\\nX is declared nonlocal within the function, the assignment changes the name X in\\nthe closest enclosing function’s local scope.\\nNotice that the global declaration still maps variables to the enclosing module. When\\nnested functions are present, variables in enclosing functions may be referenced, but\\nthey require nonlocal declarations to be changed.\\nNested Scope Examples\\nTo clarify the prior section’s points, let’s illustrate with some real code. Here is what\\nan enclosing function scope looks like:\\nX = 99                   # Global scope name: not used\\ndef f1():\\n    X = 88               # Enclosing def local\\n    def f2():\\n        print(X)         # Reference made in nested def\\n    f2()\\nf1()                     # Prints 88: enclosing def local\\nFirst off, this is legal Python code: the def is simply an executable statement, which can\\nappear anywhere any other statement can—including nested in another def. Here, the\\nScopes and Nested Functions | 419', metadata={'source': 'python.pdf', 'page': 469}),\n",
       " Document(page_content=\"nested def runs while a call to the function f1 is running; it generates a function and\\nassigns it to the name f2, a local variable within f1’s local scope. In a sense, f2 is a\\ntemporary function that lives only during the execution of (and is visible only to code\\nin) the enclosing f1.\\nBut notice what happens inside f2: when it prints the variable X, it refers to the X that\\nlives in the enclosing f1 function’s local scope. Because functions can access names in\\nall physically enclosing def statements, the X in f2 is automatically mapped to the X in\\nf1, by the LEGB lookup rule.\\nThis enclosing scope lookup works even if the enclosing function has already returned.\\nFor example, the following code defines a function that makes and returns another\\nfunction:\\ndef f1():\\n    X = 88\\n    def f2():\\n        print(X)         # Remembers X in enclosing def scope\\n    return f2            # Return f2 but don't call it\\naction = f1()            # Make, return function\\naction()                 # Call it now: prints 88\\nIn this code, the call to action is really running the function we named f2 when f1 ran.\\nf2 remembers the enclosing scope’s X in f1, even though f1 is no longer active.\\nFactory functions\\nDepending on whom you ask, this sort of behavior is also sometimes called a closure\\nor factory function. These terms refer to a function object that remembers values in\\nenclosing scopes regardless of whether those scopes are still present in memory. Al-\\nthough classes (described in Part VI  of this book) are usually best at remembering state\\nbecause they make it explicit with attribute assignments, such functions provide an\\nalternative.\\nFor instance, factory functions are sometimes used by programs that need to generate\\nevent handlers on the fly in response to conditions at runtime (e.g., user inputs that\\ncannot be anticipated). Look at the following function, for example:\\n>>> def maker(N):\\n...     def action(X):                    # Make and return action\\n...         return X ** N                 # action retains N from enclosing scope\\n...     return action\\n...\\nThis defines an outer function that simply generates and returns a nested function,\\nwithout calling it. If we call the outer function:\\n>>> f = maker(2)                          # Pass 2 to N\\n>>> f\\n<function action at 0x014720B0>\\n420 | Chapter 17: \\u2002Scopes\", metadata={'source': 'python.pdf', 'page': 470}),\n",
       " Document(page_content='what we get back is a reference to the generated nested function—the one created by\\nrunning the nested def. If we now call what we got back from the outer function:\\n>>> f(3)                                  # Pass 3 to X, N remembers 2: 3 ** 2\\n9\\n>>> f(4)                                  # 4 ** 2\\n16\\nit invokes the \\nnested function—the one called action within maker. The most unusual\\npart of this is that the nested function remembers integer 2, the value of the variable N\\nin maker, even though maker has returned and exited by the time we call action. In effect,\\nN from the enclosing local scope is retained as state information attached to action, and\\nwe get back its argument squared.\\nIf we now call the outer function again, we get back a new nested function with different\\nstate information attached. That is, we get the argument cubed instead of squared, but\\nthe original still squares as before:\\n>>> g = maker(3)                          # g remembers 3, f remembers 2\\n>>> g(3)                                  # 3 ** 3\\n27\\n>>> f(3)                                  # 3 ** 2\\n9\\nThis works because each call to a factory function like this gets its own set of state\\ninformation. In our case, the function we assign to name g remembers 3, and f remem-\\nbers 2, because each has its own state information retained by the variable N in maker.\\nThis is an advanced technique that you’re unlikely to see very often in most code, except\\namong programmers with backgrounds in functional programming languages. On the\\nother hand, enclosing scopes are often employed by lambda function-creation expres-\\nsions (discussed later in this chapter)—because they are expressions, they are almost\\nalways nested within a def. Moreover, function nesting is commonly used for decora-\\ntors (explored in Chapter 38 )—in some cases, it’s the most reasonable coding pattern.\\nAs a general rule, classes are better at “memory” like this because they make the state\\nretention explicit in attributes. Short of using classes, though, globals, enclosing scope\\nreferences like these, and default arguments are the main ways that Python functions\\ncan retain state information. To see how they compete, Chapter 18  provides complete\\ncoverage of defaults, but the next section gives enough of an introduction to get us\\nstarted.\\nRetaining enclosing scopes’ state with defaults\\nIn earlier versions of Python, the sort of code in the prior section failed because nested\\ndefs did not do anything about scopes—a reference to a variable within f2 would search\\nonly the local ( f2), then global (the code outside f1), and then built-in scopes. Because\\nit skipped the scopes of enclosing functions, an error would result. To work around\\nthis, programmers typically used default argument values  to pass in and remember the\\nobjects in an enclosing scope:\\nScopes and Nested Functions | 421', metadata={'source': 'python.pdf', 'page': 471}),\n",
       " Document(page_content='def f1():\\n    x = 88\\n    def f2(x=x):                # Remember enclosing scope X with defaults\\n        print(x)\\n    f2()\\nf1()                            # Prints 88\\nThis code works \\nin all Python releases, and you’ll still see this pattern in some existing\\nPython code. In short, the syntax arg = val in a def header means that the argument\\narg will default to the value val if no real value is passed to arg in a call.\\nIn the modified f2 here, the x=x means that the argument x will default to the value of\\nx in the enclosing scope—because the second x is evaluated before Python steps into\\nthe nested def, it still refers to the x in f1. In effect, the default remembers what x was\\nin f1 (i.e., the object 88).\\nThat’s fairly complex, and it depends entirely on the timing of default value evaluations.\\nIn fact, the nested scope lookup rule was added to Python to make defaults unnecessary\\nfor this role—today, Python automatically remembers any values required in the en-\\nclosing scope for use in nested defs.\\nOf course, the best prescription for most code is simply to avoid nesting defs within\\ndefs, as it will make your programs much simpler. The following is an equivalent of\\nthe prior example that banishes the notion of nesting. Notice the forward reference in\\nthis code—it’s OK to call a function defined after the function that calls it, as long as\\nthe second def runs before the first function is actually called. Code inside a def is never\\nevaluated until the function is actually called:\\n>>> def f1():\\n...     x = 88                  # Pass x along instead of nesting\\n...     f2(x)                   # Forward reference okay\\n...\\n>>> def f2(x):\\n...     print(x)\\n...\\n>>> f1()\\n88\\nIf you avoid nesting this way, you can almost forget about the nested scopes concept\\nin Python, unless you need to code in the factory function style discussed earlier—at\\nleast, for def statements. lambdas, which almost naturally appear nested in defs, often\\nrely on nested scopes, as the next section explains.\\nNested scopes and lambdas\\nWhile they’re rarely used in practice for defs themselves, you are more likely to care\\nabout nested function scopes when you start coding lambda expressions. We won’t\\ncover lambda in depth until Chapter 19 , but in short, it’s an expression that generates\\na new function to be called later, much like a def statement. Because it’s an expression,\\n422 | Chapter 17: \\u2002Scopes', metadata={'source': 'python.pdf', 'page': 472}),\n",
       " Document(page_content='though, it can be used in places that def cannot, such as within list and dictionary\\nliterals.\\nLike a def, a lambda expression introduces a new local scope for the function it creates.\\nThanks to the enclosing scopes lookup layer, lambdas can see all the variables that live\\nin the functions in which they are coded. Thus, the following code works, but only\\nbecause the nested scope rules are applied:\\ndef func():\\n    x = 4\\n    action = (lambda n: x ** n)          # x remembered from enclosing def\\n    return action\\nx = func()\\nprint(x(2))                              # Prints 16, 4 ** 2\\nPrior to the introduction of nested function scopes, programmers used defaults to pass\\nvalues from an enclosing scope into lambdas, just as for defs. For instance, the following\\nworks on all Python releases:\\ndef func():\\n    x = 4\\n    action = (lambda n, x=x: x ** n)     # Pass x in manually\\n    return action\\nBecause lambdas are expressions, they naturally (and even normally) nest inside en-\\nclosing defs. Hence, they are perhaps the biggest beneficiaries of the addition of en-\\nclosing function scopes in the lookup rules; in most cases, it is no longer necessary to\\npass values into lambdas with defaults.\\nScopes versus defaults with loop variables\\nThere is one notable exception to the rule I just gave: if a lambda or def defined within\\na function is nested inside a loop, and the nested function references an enclosing scope\\nvariable that is changed by that loop, all functions generated within the loop will have\\nthe same value—the value the referenced variable had in the last loop iteration.\\nFor instance, the following attempts to build up a list of functions that each remember\\nthe current variable i from the enclosing scope:\\n>>> def makeActions():\\n...     acts = []\\n...     for i in range(5):                       # Tries to remember each i\\n...         acts.append(lambda x: i ** x)        # All remember same last i!\\n...     return acts\\n...\\n>>> acts = makeActions()\\n>>> acts[0]\\n<function <lambda> at 0x012B16B0>\\nThis doesn’t quite work, though—because the enclosing scope variable is looked up\\nwhen the nested functions are later called, they all effectively remember the same value\\nScopes and Nested Functions | 423', metadata={'source': 'python.pdf', 'page': 473}),\n",
       " Document(page_content=\"(the value the loop variable had on the last loop iteration). That is, we get back 4 to the\\npower of 2 for each function in the list, because i is the same in all of them:\\n>>> acts[0](2)                                   # All are 4 ** 2, value of last i\\n16\\n>>> acts[2](2)                                   # This should be 2 ** 2\\n16\\n>>> acts[4](2)                                   # This should be 4 ** 2\\n16\\nThis is the one case where we still have to explicitly retain enclosing scope values with\\ndefault arguments, rather than enclosing scope references. That is, to make this sort of\\ncode work, we must pass in the current value of the enclosing scope’s variable with a\\ndefault. Because defaults are evaluated when the nested function is created (not when\\nit’s later called), each remembers its own value for i:\\n>>> def makeActions():\\n...     acts = []\\n...     for i in range(5):                       # Use defaults instead\\n...         acts.append(lambda x, i=i: i ** x)   # Remember current i\\n...     return acts\\n...\\n>>> acts = makeActions()\\n>>> acts[0](2)                                   # 0 ** 2\\n0\\n>>> acts[2](2)                                   # 2 ** 2\\n4\\n>>> acts[4](2)                                   # 4 ** 2\\n16\\nThis is a fairly obscure case, but it can come up in practice, especially in code that\\ngenerates callback handler functions for a number of widgets in a GUI (e.g., button-\\npress handlers). We’ll talk more about defaults in Chapter 18  and lambdas in Chap-\\nter 19, so you may want to return and review this section later.‡\\nArbitrary scope nesting\\nBefore ending this discussion, I should note that scopes may nest arbitrarily, but only\\nenclosing function def statements (not classes, described in Part VI) are searched:\\n>>> def f1():\\n...     x = 99\\n...     def f2():\\n...         def f3():\\n...             print(x)        # Found in f1's local scope!\\n...         f3()\\n‡ In the section “Function Gotchas” on page 518 at the end of this part of the book, we’ll also see that there\\nis an issue with using mutable objects like lists and dictionaries for default arguments (e.g., def f(a=[]) )—\\nbecause defaults are implemented as single objects attached to functions, mutable defaults retain state from\\ncall to call, rather then being initialized anew on each call. Depending on whom you ask, this is either\\nconsidered a feature that supports state retention, or a strange wart on the language. More on this at the end\\nof Chapter 20.\\n424 | Chapter 17: \\u2002Scopes\", metadata={'source': 'python.pdf', 'page': 474}),\n",
       " Document(page_content='...     f2()\\n...\\n>>> f1()\\n99\\nPython will search the local scopes of all enclosing defs, from inner to outer, after the\\nreferencing function’s local \\nscope and before the module’s global scope or built-ins.\\nHowever, this sort of code is even less likely to pop up in practice. In Python, we say\\nflat is better than nested —except in very limited contexts, your life (and the lives of your\\ncoworkers) will generally be better if you minimize nested function definitions.\\nThe nonlocal Statement\\nIn the prior section we explored the way that nested functions can reference variables\\nin an enclosing function’s scope, even if that function has already returned. It turns out\\nthat, as of Python 3.0, we can also change such enclosing scope variables, as long as we\\ndeclare them in nonlocal statements. With this statement, nested defs can have both\\nread and write access to names in enclosing functions.\\nThe nonlocal statement is a close cousin to global, covered earlier. Like global,\\nnonlocal declares that a name will be changed in an enclosing scope. Unlike global,\\nthough, nonlocal applies to a name in an enclosing function’s scope, not the global\\nmodule scope outside all defs. Also unlike global, nonlocal names must already exist\\nin the enclosing function’s scope when declared—they can exist only in enclosing\\nfunctions and cannot be created by a first assignment in a nested def.\\nIn other words, nonlocal both allows assignment to names in enclosing function scopes\\nand limits scope lookups for such names to enclosing defs. The net effect is a more\\ndirect and reliable implementation of changeable scope information, for programs that\\ndo not desire or need classes with attributes.\\nnonlocal Basics\\nPython 3.0 introduces a new nonlocal statement, which has meaning only inside a\\nfunction:\\ndef func():\\n    nonlocal name1, name2, ...\\nThis statement allows a nested function to change one or more names defined in a\\nsyntactically enclosing function’s scope. In Python 2.X (including 2.6), when one func-\\ntion def is nested in another, the nested function can reference any of the names defined\\nby assignment in the enclosing def’s scope, but it cannot change them. In 3.0, declaring\\nthe enclosing scopes’ names in a nonlocal statement enables nested functions to assign\\nand thus change such names as well.\\nThis provides a way for enclosing functions to provide writeable state information,\\nremembered when the nested function is later called. Allowing the state to change\\nThe nonlocal Statement | 425', metadata={'source': 'python.pdf', 'page': 475}),\n",
       " Document(page_content='makes it more useful to the nested function (imagine a counter in the enclosing scope,\\nfor instance). In \\n2.X, programmers usually achieve similar goals by using classes or\\nother schemes. Because nested functions have become a more common coding pattern\\nfor state retention, though, nonlocal makes it more generally applicable.\\nBesides allowing names in enclosing defs to be changed, the nonlocal statement also\\nforces the issue for references—just like the global statement, nonlocal causes searches\\nfor the names listed in the statement to begin in the enclosing defs’ scopes, not in the\\nlocal scope of the declaring function. That is, nonlocal also means “skip my local scope\\nentirely.”\\nIn fact, the names listed in a nonlocal must have been previously defined in an enclosing\\ndef when the nonlocal is reached, or an error is raised. The net effect is much like global:\\nglobal means the names reside in the enclosing module, and nonlocal means they reside\\nin an enclosing def. nonlocal is even more strict, though—scope search is restricted to\\nonly enclosing defs. That is, nonlocal names can appear only in enclosing defs, not in\\nthe module’s global scope or built-in scopes outside the defs.\\nThe addition of nonlocal does not alter name reference scope rules in general; they still\\nwork as before, per the “LEGB” rule described earlier. The nonlocal statement mostly\\nserves to allow names in enclosing scopes to be changed rather than just referenced.\\nHowever, global and nonlocal statements do both restrict the lookup rules somewhat,\\nwhen coded in a function:\\n•global makes scope lookup begin in the enclosing module’s scope and allows\\nnames there to be assigned. Scope lookup continues on to the built-in scope if the\\nname does not exist in the module, but assignments to global names always create\\nor change them in the module’s scope.\\n•nonlocal restricts scope lookup to just enclosing defs, requires that the names al-\\nready exist there, and allows them to be assigned. Scope lookup does not continue\\non to the global or built-in scopes.\\nIn Python 2.6, references to enclosing def scope names are allowed, but not assignment.\\nHowever, you can still use classes with explicit attributes to achieve the same change-\\nable state information effect as nonlocals (and you may be better off doing so in some\\ncontexts); globals and function attributes can sometimes accomplish similar goals as\\nwell. More on this in a moment; first, let’s turn to some working code to make this\\nmore concrete.\\nnonlocal in Action\\nOn to some examples, all run in 3.0. References to enclosing def scopes work as they\\ndo in 2.6. In the following, tester builds and returns the function nested, to be called\\nlater, and the state reference in nested maps the local scope of tester using the normal\\nscope lookup rules:\\n426 | Chapter 17: \\u2002Scopes', metadata={'source': 'python.pdf', 'page': 476}),\n",
       " Document(page_content=\"C:\\\\\\\\misc>c:\\\\python30\\\\python\\n>>> def tester(start):\\n...     state = start             # Referencing nonlocals works normally\\n...     def nested(label):\\n...         print(label, state)   # Remembers state in enclosing scope\\n...     return nested\\n...\\n>>> F = tester(0)\\n>>> F('spam')\\nspam 0\\n>>> F('ham')\\nham 0\\nChanging a name \\nin an enclosing def’s scope is not allowed by default, though; this is\\nthe normal case in 2.6 as well:\\n>>> def tester(start):\\n...     state = start\\n...     def nested(label):\\n...         print(label, state)\\n...         state += 1            # Cannot change by default (or in 2.6)\\n...     return nested\\n...\\n>>> F = tester(0)\\n>>> F('spam')\\nUnboundLocalError: local variable 'state' referenced before assignment\\nUsing nonlocal for changes\\nNow, under 3.0, if we declare state in the tester scope as nonlocal within nested, we\\nget to change it inside the nested function, too. This works even though tester has\\nreturned and exited by the time we call the returned nested function through the name\\nF:\\n>>> def tester(start):\\n...     state = start             # Each call gets its own state\\n...     def nested(label):\\n...         nonlocal state        # Remembers state in enclosing scope\\n...         print(label, state)\\n...         state += 1            # Allowed to change it if nonlocal\\n...     return nested\\n...\\n>>> F = tester(0)\\n>>> F('spam')                     # Increments state on each call\\nspam 0\\n>>> F('ham')\\nham 1\\n>>> F('eggs')\\neggs 2\\nAs usual with enclosing scope references, we can call the tester factory function mul-\\ntiple times to get multiple copies of its state in memory. The state object in the enclosing\\nscope is essentially attached to the nested function object returned; each call makes a\\nThe nonlocal Statement | 427\", metadata={'source': 'python.pdf', 'page': 477}),\n",
       " Document(page_content=\"new, distinct state object, such that updating one function’s state won’t impact the\\nother. The following continues the prior listing’s interaction:\\n>>> G = tester(42)                # Make a new tester that starts at 42\\n>>> G('spam')\\nspam 42\\n>>> G('eggs')                     # My state information updated to 43\\neggs 43\\n>>> F('bacon')                    # But F's is where it left off: at 3\\nbacon 3                           # Each call has different state information\\nBoundary cases\\nThere are a few things to watch out for. First, unlike the global statement, nonlocal\\nnames really must have previously been assigned in an enclosing def’s scope when a\\nnonlocal is evaluated, or else you’ll get an error—you cannot create them dynamically\\nby assigning them anew in the enclosing scope:\\n>>> def tester(start):\\n...     def nested(label):\\n...         nonlocal state        # Nonlocals must already exist in enclosing def!\\n...         state = 0\\n...         print(label, state)\\n...     return nested\\n...\\nSyntaxError: no binding for nonlocal 'state' found\\n>>> def tester(start):\\n...     def nested(label):\\n...         global state          # Globals don't have to exist yet when declared\\n...         state = 0             # This creates the name in the module now\\n...         print(label, state)\\n...     return nested\\n...\\n>>> F = tester(0)\\n>>> F('abc')\\nabc 0\\n>>> state\\n0\\nSecond, nonlocal restricts the scope lookup to just enclosing defs; nonlocals are not\\nlooked up in the enclosing module’s global scope or the built-in scope outside all\\ndefs, even if they are already there:\\n>>> spam = 99\\n>>> def tester():\\n...     def nested():\\n...         nonlocal spam         # Must be in a def, not the module!\\n...         print('Current=', spam)\\n...         spam += 1\\n...     return nested\\n...\\nSyntaxError: no binding for nonlocal 'spam' found\\n428 | Chapter 17: \\u2002Scopes\", metadata={'source': 'python.pdf', 'page': 478}),\n",
       " Document(page_content=\"These restrictions make sense once you realize that Python would not otherwise gen-\\nerally know which \\nenclosing scope to create a brand new name in. In the prior listing,\\nshould spam be assigned in tester, or the module outside? Because this is ambiguous,\\nPython must resolve nonlocals at function creation time, not function call time.\\nWhy nonlocal?\\nGiven the extra complexity of nested functions, you might wonder what the fuss is\\nabout. Although it’s difficult to see in our small examples, state information becomes\\ncrucial in many programs. There are a variety of ways to “remember” information\\nacross function and method calls in Python. While there are tradeoffs for all,\\nnonlocal does improve this story for enclosing scope references—the nonlocal state-\\nment allows multiple copies of changeable state to be retained in memory and addresses\\nsimple state-retention needs where classes may not be warranted.\\nAs we saw in the prior section, the following code allows state to be retained and\\nmodified in an enclosing scope. Each call to tester creates a little self-contained package\\nof changeable information, whose names do not clash with any other part of the\\nprogram:\\ndef tester(start):\\n    state = start                      # Each call gets its own state\\n    def nested(label):\\n        nonlocal state                 # Remembers state in enclosing scope\\n        print(label, state)\\n        state += 1                     # Allowed to change it if nonlocal\\n    return nested\\nF = tester(0)\\nF('spam')\\nUnfortunately, this code only works in Python 3.0. If you are using Python 2.6, other\\noptions are available, depending on your goals. The next two sections present some\\nalternatives.\\nShared state with globals\\nOne usual prescription for achieving the nonlocal effect in 2.6 and earlier is to simply\\nmove the state out to the global scope (the enclosing module):\\n>>> def tester(start):\\n...     global state                   # Move it out to the module to change it\\n...     state = start                  # global allows changes in module scope\\n...     def nested(label):\\n...         global state\\n...         print(label, state)\\n...         state += 1\\n...     return nested\\n...\\n>>> F = tester(0)\\n>>> F('spam')                          # Each call increments shared global state\\nThe nonlocal Statement | 429\", metadata={'source': 'python.pdf', 'page': 479}),\n",
       " Document(page_content=\"spam 0\\n>>> F('eggs')\\neggs 1\\nThis works in \\nthis case, but it requires global declarations in both functions and is\\nprone to name collisions in the global scope (what if “state” is already being used?). A\\nworse, and more subtle, problem is that it only allows for a single shared copy of the\\nstate information in the module scope—if we call tester again, we’ll wind up resetting\\nthe module’s state variable, such that prior calls will see their state overwritten:\\n>>> G = tester(42)                     # Resets state's single copy in global scope\\n>>> G('toast')\\ntoast 42\\n>>> G('bacon')\\nbacon 43\\n>>> F('ham')                           # Oops -- my counter has been overwritten!\\nham 44\\nAs shown earlier, when using nonlocal instead of global, each call to tester remembers\\nits own unique copy of the state object.\\nState with classes (preview)\\nThe other prescription for changeable state information in 2.6 and earlier is to use\\nclasses with attributes  to make state information access more explicit than the implicit\\nmagic of scope lookup rules. As an added benefit, each instance of a class gets a fresh\\ncopy of the state information, as a natural byproduct of Python’s object model.\\nWe haven’t explored classes in detail yet, but as a brief preview, here is a reformulation\\nof the tester/nested functions used earlier as a class—state is recorded in objects ex-\\nplicitly as they are created. To make sense of this code, you need to know that a def\\nwithin a class like this works exactly like a def outside of a class, except that the\\nfunction’s self argument automatically receives the implied subject of the call (an in-\\nstance object created by calling the class itself):\\n>>> class tester:                          # Class-based alternative (see Part VI)\\n...     def __init__(self, start):         # On object construction,\\n...         self.state = start             # save state explicitly in new object\\n...     def nested(self, label):\\n...         print(label, self.state)       # Reference state explicitly\\n...         self.state += 1                # Changes are always allowed\\n...\\n>>> F = tester(0)                          # Create instance, invoke __init__\\n>>> F.nested('spam')                       # F is passed to self\\nspam 0\\n>>> F.nested('ham')\\nham 1\\n>>> G = tester(42)                         # Each instance gets new copy of state\\n>>> G.nested('toast')                      # Changing one does not impact others\\ntoast 42\\n430 | Chapter 17: \\u2002Scopes\", metadata={'source': 'python.pdf', 'page': 480}),\n",
       " Document(page_content=\">>> G.nested('bacon')\\nbacon 43\\n>>> F.nested('eggs')                       # F's state is where it left off\\neggs 2\\n>>> F.state                                # State may be accessed outside class\\n3\\nWith just slightly more magic, which we’ll delve into later in this book, we could also\\nmake our class \\nlook like a callable function using operator overloading. __call__ in-\\ntercepts direct calls on an instance, so we don’t need to call a named method:\\n>>> class tester:\\n...     def __init__(self, start):\\n...         self.state = start\\n...     def __call__(self, label):         # Intercept direct instance calls\\n...         print(label, self.state)       # So .nested() not required\\n...         self.state += 1\\n...\\n>>> H = tester(99)\\n>>> H('juice')                             # Invokes __call__\\njuice 99\\n>>> H('pancakes')\\npancakes 100\\nDon’t sweat the details in this code too much at this point in the book; we’ll explore\\nclasses in depth in Part VI and will look at specific operator overloading tools like\\n__call__ in Chapter 29, so you may wish to file this code away for future reference.\\nThe point here is that classes can make state information more obvious, by leveraging\\nexplicit attribute assignment instead of scope lookups.\\nWhile using classes for state information is generally a good rule of thumb to follow,\\nthey might be overkill in cases like this, where state is a single counter. Such trivial state\\ncases are more common than you might think; in such contexts, nested defs are some-\\ntimes more lightweight than coding classes, especially if you’re not familiar with OOP\\nyet. Moreover, there are some scenarios in which nested defs may actually work better\\nthan classes (see the description of method decorators in Chapter 38 for an example\\nthat is far beyond this chapter’s scope).\\nState with function attributes\\nAs a final state-retention option, we can also sometimes achieve the same effect as\\nnonlocals with function attributes —user-defined names attached to functions directly.\\nHere’s a final version of our example based on this technique—it replaces a nonlocal\\nwith an attribute attached to the nested function. Although this scheme may not be as\\nintuitive to some, it also allows the state variable to be accessed outside the nested\\nfunction (with nonlocals, we can only see state variables within the nested def):\\n>>> def tester(start):\\n...     def nested(label):\\n...         print(label, nested.state)     # nested is in enclosing scope\\n...         nested.state += 1              # Change attr, not nested itself\\nThe nonlocal Statement | 431\", metadata={'source': 'python.pdf', 'page': 481}),\n",
       " Document(page_content=\"...     nested.state = start               # Initial state after func defined\\n...     return nested\\n...\\n>>> F = tester(0)\\n>>> F('spam')                              # F is a 'nested' with state attached\\nspam 0\\n>>> F('ham')\\nham 1\\n>>> F.state                                # Can access state outside functions too\\n2\\n>>>\\n>>> G = tester(42)                         # G has own state, doesn't overwrite F's\\n>>> G('eggs')\\neggs 42\\n>>> F('ham')\\nham 2\\nThis code relies \\non the fact that the function name nested is a local variable in the\\ntester scope enclosing nested; as such, it can be referenced freely inside nested. This\\ncode also relies on the fact that changing an object in-place is not an assignment to a\\nname; when it increments nested.state, it is changing part of the object nested refer-\\nences, not the name nested itself. Because we’re not really assigning a name in the\\nenclosing scope, no nonlocal is needed.\\nAs you can see, globals, nonlocals, classes, and function attributes all offer\\nstate-retention options. Globals only support shared data, classes require a basic\\nknowledge of OOP, and both classes and function attributes allow state to be accessed\\noutside the nested function itself. As usual, the best tool for your program depends\\nupon your program’s goals.\\nChapter Summary\\nIn this chapter, we studied one of two key concepts related to functions: scopes (how\\nvariables are looked up when they are used). As we learned, variables are considered\\nlocal to the function definitions in which they are assigned, unless they are specifically\\ndeclared to be global or nonlocal. We also studied some more advanced scope concepts\\nhere, including nested function scopes and function attributes. Finally, we looked at\\nsome general design ideas, such as the need to avoid globals and cross-file changes.\\nIn the next chapter, we’re going to continue our function tour with the second key\\nfunction-related concept: argument passing. As we’ll find, arguments are passed into\\na function by assignment, but Python also provides tools that allow functions to be\\nflexible in how items are passed. Before we move on, let’s take this chapter’s quiz to\\nreview the scope concepts we’ve covered here.\\n432 | Chapter 17: \\u2002Scopes\", metadata={'source': 'python.pdf', 'page': 482}),\n",
       " Document(page_content=\"Test Your Knowledge: Quiz\\n1. What is the output of the following code, and why?\\n>>> X = 'Spam'\\n>>> \\ndef func():\\n...     print(X)\\n...\\n>>> func()\\n2. What is the output of this code, and why?\\n>>> X = 'Spam'\\n>>> def func():\\n...     X = 'NI!'\\n...\\n>>> func()\\n>>> print(X)\\n3. What does this code print, and why?\\n>>> X = 'Spam'\\n>>> def func():\\n...     X = 'NI'\\n...     print(X)\\n...\\n>>> func()\\n>>> print(X)\\n4. What output does this code produce? Why?\\n>>> X = 'Spam'\\n>>> def func():\\n...     global X\\n...     X = 'NI'\\n...\\n>>> func()\\n>>> print(X)\\n5. What about this code—what’s the output, and why?\\n>>> X = 'Spam'\\n>>> def func():\\n...     X = 'NI'\\n...     def nested():\\n...         print(X)\\n...     nested()\\n...\\n>>> func()\\n>>> X\\nTest Your Knowledge: Quiz | 433\", metadata={'source': 'python.pdf', 'page': 483}),\n",
       " Document(page_content=\"6. How about this example: what is its output in Python 3.0, and why?\\n>>> def func():\\n...     X = 'NI'\\n...     def nested():\\n...         nonlocal X\\n...         X = 'Spam'\\n...     nested()\\n...     print(X)\\n...\\n>>> func()\\n7.Name three or more ways to retain state information in a Python function.\\nTest Your Knowledge: Answers\\n1. The \\noutput here is 'Spam', because the function references a global variable in the\\nenclosing module (because it is not assigned in the function, it is considered global).\\n2. The output here is 'Spam' again because assigning the variable inside the function\\nmakes it a local and effectively hides the global of the same name. The print state-\\nment finds the variable unchanged in the global (module) scope.\\n3. It prints 'NI' on one line and 'Spam' on another, because the reference to the var-\\niable within the function finds the assigned local and the reference in the print\\nstatement finds the global.\\n4. This time it just prints 'NI' because the global declaration forces the variable as-\\nsigned inside the function to refer to the variable in the enclosing global scope.\\n5. The output in this case is again 'NI' on one line and 'Spam' on another, because\\nthe print statement in the nested function finds the name in the enclosing func-\\ntion’s local scope, and the print at the end finds the variable in the global scope.\\n6. This example prints 'Spam', because the nonlocal statement (available in Python\\n3.0 but not 2.6) means that the assignment to X inside the nested function changes\\nX in the enclosing function’s local scope. Without this statement, this assignment\\nwould classify X as local to the nested function, making it a different variable; the\\ncode would then print 'NI' instead.\\n7. Although the values of local variables go away when a function returns, you can\\nmake a Python function retain state information by using shared global variables,\\nenclosing function scope references within nested functions, or using default ar-\\ngument values. Function attributes can sometimes allow state to be attached to the\\nfunction itself, instead of looked up in scopes. Another alternative, using OOP with\\nclasses, sometimes supports state retention better than any of the scope-based\\ntechniques because it makes it explicit with attribute assignments; we’ll explore\\nthis option in Part VI.\\n434 | Chapter 17: \\u2002Scopes\", metadata={'source': 'python.pdf', 'page': 484}),\n",
       " Document(page_content='CHAPTER 18\\nArguments\\nChapter 17 explored the details behind Python’s scopes—the places where variables\\nare defined and looked up. As we learned, the place where a name is defined in our\\ncode determines much of its meaning. This chapter continues the function story by\\nstudying the concepts in Python argument passing—the way that objects are sent to\\nfunctions as inputs. As we’ll see, arguments (a.k.a. parameters) are assigned to names\\nin a function, but they have more to do with object references than with variable scopes.\\nWe’ll also find that Python provides extra tools, such as keywords, defaults, and arbi-\\ntrary argument collectors, that allow for wide flexibility in the way arguments are sent\\nto a function.\\nArgument-Passing Basics\\nEarlier in this part of the book, I noted that arguments are passed by assignment. This\\nhas a few ramifications that aren’t always obvious to beginners, which I’ll expand on\\nin this section. Here is a rundown of the key points in passing arguments to functions:\\n•Arguments are passed by automatically assigning objects to local variable\\nnames. Function arguments—references to (possibly) shared objects sent by the\\ncaller—are just another instance of Python assignment at work. Because references\\nare implemented as pointers, all arguments are, in effect, passed by pointer. Objects\\npassed as arguments are never automatically copied.\\n•Assigning to argument names inside a function does not affect the caller .\\nArgument names in the function header become new, local names when the func-\\ntion runs, in the scope of the function. There is no aliasing between function ar-\\ngument names and variable names in the scope of the caller.\\n•Changing a mutable object argument in a function may impact the caller .\\nOn the other hand, as arguments are simply assigned to passed-in objects, func-\\ntions can change passed-in mutable objects in place, and the results may affect the\\ncaller. Mutable arguments can be input and output for functions.\\n435', metadata={'source': 'python.pdf', 'page': 485}),\n",
       " Document(page_content='For more details on references, see Chapter 6 ; everything we learned there also applies\\nto function arguments, though the assignment to argument names is automatic and\\nimplicit.\\nPython’s pass-by-assignment scheme isn’t quite the same as C++’s reference parame-\\nters option, but it turns out to be very similar to the C language’s argument-passing\\nmodel in practice:\\n•Immutable arguments are effectively passed “by value.” Objects such as in-\\ntegers and strings are passed by object reference instead of by copying, but because\\nyou can’t change immutable objects in-place anyhow, the effect is much like mak-\\ning a copy.\\n•Mutable arguments are effectively passed “by pointer.”  Objects such as lists\\nand dictionaries are also passed by object reference, which is similar to the way C\\npasses arrays as pointers—mutable objects can be changed in-place in the function,\\nmuch like C arrays.\\nOf course, if you’ve never used C, Python’s argument-passing mode will seem simpler\\nstill—it involves just the assignment of objects to names, and it works the same whether\\nthe objects are mutable or not.\\nArguments and Shared References\\nTo illustrate argument-passing properties at work, consider the following code:\\n>>> def f(a):                 # a is assigned to (references) passed object\\n...     a = 99                # Changes local variable a only\\n...\\n>>> b = 88\\n>>> f(b)                      # a and b both reference same 88 initially\\n>>> print(b)                  # b is not changed\\n88\\nIn this example the variable a is assigned the object 88 at the moment the function is\\ncalled with f(b), but a lives only within the called function. Changing a inside the\\nfunction has no effect on the place where the function is called; it simply resets the local\\nvariable a to a completely different object.\\nThat’s what is meant by a lack of name aliasing—assignment to an argument name\\ninside a function (e.g., a=99) does not magically change a variable like b in the scope of\\nthe function call. Argument names may share passed objects initially (they are essen-\\ntially pointers to those objects), but only temporarily, when the function is first called.\\nAs soon as an argument name is reassigned, this relationship ends.\\nAt least, that’s the case for assignment to argument names themselves. When arguments\\nare passed mutable objects like lists and dictionaries, we also need to be aware that in-\\nplace changes to such objects may live on after a function exits, and hence impact callers.\\nHere’s an example that demonstrates this behavior:\\n436 | Chapter 18: \\u2002Arguments', metadata={'source': 'python.pdf', 'page': 486}),\n",
       " Document(page_content=\">>> def changer(a, b):        # Arguments assigned references to objects\\n...     a = 2                 # Changes local name's value only\\n...     b[0] = 'spam'         # Changes shared object in-place\\n...\\n>>> X = 1\\n>>> L = [1, 2]                # Caller\\n>>> changer(X, L)             # Pass immutable and mutable objects\\n>>> X, L                      # X is unchanged, L is different!\\n(1, ['spam', 2])\\nIn this code, the changer function assigns values to argument a itself, and to a compo-\\nnent of the \\nobject referenced by argument b. These two assignments within the function\\nare only slightly different in syntax but have radically different results:\\n• Because a is a local variable name in the function’s scope, the first assignment has\\nno effect on the caller—it simply changes the local variable a to reference a com-\\npletely different object, and does not change the binding of the name X in the caller’s\\nscope. This is the same as in the prior example.\\n• Argument b is a local variable name, too, but it is passed a mutable object (the list\\nthat L references in the caller’s scope). As the second assignment is an in-place\\nobject change, the result of the assignment to b[0] in the function impacts the value\\nof L after the function returns.\\nReally, the second assignment statement in changer doesn’t change b—it changes part\\nof the object that b currently references. This in-place change impacts the caller only\\nbecause the changed object outlives the function call. The name L hasn’t changed\\neither—it still references the same, changed object—but it seems as though L differs\\nafter the call because the value it references has been modified within the function.\\nFigure 18-1  illustrates the name/object bindings that exist immediately after the func-\\ntion has been called, and before its code has run.\\nIf this example is still confusing, it may help to notice that the effect of the automatic\\nassignments of the passed-in arguments is the same as running a series of simple as-\\nsignment statements. In terms of the first argument, the assignment has no effect on\\nthe caller:\\n>>> X = 1\\n>>> a = X               # They share the same object\\n>>> a = 2               # Resets 'a' only, 'X' is still 1\\n>>> print(X)\\n1\\nThe assignment through the second argument does affect a variable at the call, though,\\nbecause it is an in-place object change:\\n>>> L = [1, 2]\\n>>> b = L               # They share the same object\\n>>> b[0] = 'spam'       # In-place change: 'L' sees the change too\\n>>> print(L)\\n['spam', 2]\\nArgument-Passing Basics | 437\", metadata={'source': 'python.pdf', 'page': 487}),\n",
       " Document(page_content=\"If you recall our discussions about shared mutable objects in Chapters 6 and 9, you’ll\\nrecognize the phenomenon \\nat work: changing a mutable object in-place can impact\\nother references to that object. Here, the effect is to make one of the arguments work\\nlike both an input and an output of the function.\\nAvoiding Mutable Argument Changes\\nThis behavior of in-place changes to mutable arguments isn’t a bug—it’s simply the\\nway argument passing works in Python. Arguments are passed to functions by reference\\n(a.k.a. pointer) by default because that is what we normally want. It means we can pass\\nlarge objects around our programs without making multiple copies along the way, and\\nwe can easily update these objects as we go. In fact, as we’ll see in Part VI, Python’s\\nclass model depends upon changing a passed-in “self” argument in-place, to update\\nobject state.\\nIf we don’t want in-place changes within functions to impact objects we pass to them,\\nthough, we can simply make explicit copies of mutable objects, as we learned in Chap-\\nter 6. For function arguments, we can always copy the list at the point of call:\\nL = [1, 2]\\nchanger(X, L[:])        # Pass a copy, so our 'L' does not change\\nWe can also copy within the function itself, if we never want to change passed-in ob-\\njects, regardless of how the function is called:\\ndef changer(a, b):\\n   b = b[:]             # Copy input list so we don't impact caller\\nFigure 18-1. References: arguments. Because arguments are passed by assignment, argument names\\nin the function \\nmay share objects with variables in the scope of the call. Hence, in-place changes to\\nmutable arguments in a function can impact the caller. Here, a and b in the function initially reference\\nthe objects referenced by variables X and L when the function is first called. Changing the list through\\nvariable b makes L appear different after the call returns.\\n438 | Chapter 18: \\u2002Arguments\", metadata={'source': 'python.pdf', 'page': 488}),\n",
       " Document(page_content=\"   a = 2\\n   b[0] = 'spam'        # Changes our list copy only\\nBoth of these \\ncopying schemes don’t stop the function from changing the object—they\\njust prevent those changes from impacting the caller. To really prevent changes, we can\\nalways convert to immutable objects to force the issue. Tuples, for example, throw an\\nexception when changes are attempted:\\nL = [1, 2]\\nchanger(X, tuple(L))    # Pass a tuple, so changes are errors\\nThis scheme uses the built-in tuple function, which builds a new tuple out of all the\\nitems in a sequence (really, any iterable). It’s also something of an extreme—because\\nit forces the function to be written to never change passed-in arguments, this solution\\nmight impose more limitations on the function than it should, and so should generally\\nbe avoided (you never know when changing arguments might come in handy for other\\ncalls in the future). Using this technique will also make the function lose the ability to\\ncall any list-specific methods on the argument, including methods that do not change\\nthe object in-place.\\nThe main point to remember here is that functions might update mutable objects like\\nlists and dictionaries passed into them. This isn’t necessarily a problem if it’s expected,\\nand often serves useful purposes. Moreover, functions that change passed-in mutable\\nobjects in place are probably designed and intended to do so—the change is likely part\\nof a well-defined API that you shouldn’t violate by making copies.\\nHowever, you do have to be aware of this property—if objects change out from under\\nyou unexpectedly, check whether a called function might be responsible, and make\\ncopies when objects are passed if needed.\\nSimulating Output Parameters\\nWe’ve already discussed the return statement and used it in a few examples. Here’s\\nanother way to use this statement: because return can send back any sort of object, it\\ncan return multiple values by packaging them in a tuple or other collection type. In fact,\\nalthough Python doesn’t support what some languages label “call-by-reference” argu-\\nment passing, we can usually simulate it by returning tuples and assigning the results\\nback to the original argument names in the caller:\\n>>> def multiple(x, y):\\n...     x = 2               # Changes local names only\\n...     y = [3, 4]\\n...     return x, y         # Return new values in a tuple\\n...\\n>>> X = 1\\n>>> L = [1, 2]\\n>>> X, L = multiple(X, L)   # Assign results to caller's names\\n>>> X, L\\n(2, [3, 4])\\nArgument-Passing Basics | 439\", metadata={'source': 'python.pdf', 'page': 489}),\n",
       " Document(page_content='It looks like the code is returning two values here, but it’s really just one—a two-item\\ntuple with the \\noptional surrounding parentheses omitted. After the call returns, we can\\nuse tuple assignment to unpack the parts of the returned tuple. (If you’ve forgotten why\\nthis works, flip back to “Tuples” on page 225 in Chapter 4, Chapter 9 , and “Assignment\\nStatements” on page 279 in Chapter 11 .) The net effect of this coding pattern is to\\nsimulate the output parameters of other languages by explicit assignments. X and L\\nchange after the call, but only because the code said so.\\nUnpacking arguments in Python 2.X: The preceding example unpacks a\\ntuple returned by the function with tuple assignment. In Python 2.6, it’s\\nalso possible to automatically unpack tuples in arguments passed to a\\nfunction. In 2.6, a function defined by this header:\\ndef f((a, (b, c))):\\ncan be called with tuples that match the expected structure:\\nf((1, (2, 3))) assigns a, b, and c to 1, 2, and 3, respectively. Naturally,\\nthe passed tuple can also be an object created before the call ( f(T)). This\\ndef syntax is no longer supported in Python 3.0. Instead, code this\\nfunction as:\\ndef f(T): (a, (b, c)) = T\\nto unpack in an explicit assignment statement. This explicit form works\\nin both 3.0 and 2.6. Argument unpacking is an obscure and rarely used\\nfeature in Python 2.X. Moreover, a function header in 2.6 supports only\\nthe tuple form of sequence assignment; more general sequence assign-\\nments (e.g., def f((a, [b, c])):) fail on syntax errors in 2.6 as well and\\nrequire the explicit assignment form.\\nTuple unpacking argument syntax is also disallowed by 3.0 in lambda\\nfunction argument lists: see the sidebar “Why You Will Care: List Com-\\nprehensions and map” on page 491 for an example. Somewhat asym-\\nmetrically, tuple unpacking assignment is still automatic in 3.0 for loops\\ntargets, though; see Chapter 13 for examples.\\nSpecial Argument-Matching Modes\\nAs we’ve just seen, arguments are always passed by assignment in Python; names in the\\ndef header are assigned to passed-in objects. On top of this model, though, Python\\nprovides additional tools that alter the way the argument objects in a call are\\nmatched with argument names in the header prior to assignment. These tools are all\\noptional, but they allow us to write functions that support more flexible calling pat-\\nterns, and you may encounter some libraries that require them.\\n440 | Chapter 18: \\u2002Arguments', metadata={'source': 'python.pdf', 'page': 490}),\n",
       " Document(page_content='By default, arguments are matched by position, from left to right, and you must pass\\nexactly as many \\narguments as there are argument names in the function header.\\nHowever, you can also specify matching by name, default values, and collectors for\\nextra arguments.\\nThe Basics\\nBefore we go into the syntactic details, I want to stress that these special modes are\\noptional and only have to do with matching objects to names; the underlying passing\\nmechanism after the matching takes place is still assignment. In fact, some of these\\ntools are intended more for people writing libraries than for application developers.\\nBut because you may stumble across these modes even if you don’t code them yourself,\\nhere’s a synopsis of the available tools:\\nPositionals: matched from left to right\\nThe normal case, which we’ve mostly been using so far, is to match passed argu-\\nment values to argument names in a function header by position, from left to right.\\nKeywords: matched by argument name\\nAlternatively, callers can specify which argument in the function is to receive a\\nvalue by using the argument’s name in the call, with the name=value syntax.\\nDefaults: specify values for arguments that aren’t passed\\nFunctions themselves can specify default values for arguments to receive if the call\\npasses too few values, again using the name=value syntax.\\nVarargs collecting: collect arbitrarily many positional or keyword arguments\\nFunctions can use special arguments preceded with one or two * characters to\\ncollect an arbitrary number of extra arguments (this feature is often referred to as\\nvarargs, after the varargs feature in the C language, which also supports variable-\\nlength argument lists).\\nVarargs unpacking: pass arbitrarily many positional or keyword arguments\\nCallers can also use the * syntax to unpack argument collections into discrete,\\nseparate arguments. This is the inverse of a * in a function header—in the header\\nit means collect arbitrarily many arguments, while in the call it means pass arbi-\\ntrarily many arguments.\\nKeyword-only arguments: arguments that must be passed by name\\nIn Python 3.0 (but not 2.6), functions can also specify arguments that must be\\npassed by name with keyword arguments, not by position. Such arguments are\\ntypically used to define configuration options in addition to actual arguments.\\nSpecial Argument-Matching Modes | 441', metadata={'source': 'python.pdf', 'page': 491}),\n",
       " Document(page_content='Matching Syntax\\nTable 18-1 \\nsummarizes the syntax that invokes the special argument-matching modes.\\nTable 18-1. Function argument-matching forms\\nSyntax Location Interpretation\\nfunc(value) Caller Normal argument: matched by position\\nfunc(name=value) Caller Keyword argument: matched by name\\nfunc(*sequence) Caller Pass all objects in sequence as individual positional arguments\\nfunc(**dict) Caller Pass all key/value pairs in dict as individual keyword arguments\\ndef func(name) Function Normal argument: matches any passed value by position or name\\ndef func(name=value) Function Default argument value, if not passed in the call\\ndef func(*name) Function Matches and collects remaining positional arguments in a tuple\\ndef func(**name) Function Matches and collects remaining keyword arguments in a dictionary\\ndef func(*args, name)\\ndef func(*, name=value)Function Arguments that must be passed by keyword only in calls (3.0)\\nThese special matching modes break down into function calls and definitions as\\nfollows:\\n• In a function call\\n (the first four rows of the table), simple values are matched by\\nposition, but using the name=value form tells Python to match by name to argu-\\nments instead; these are called keyword arguments . Using a *sequence or **dict in\\na call allows us to package up arbitrarily many positional or keyword objects in\\nsequences and dictionaries, respectively, and unpack them as separate, individual\\narguments when they are passed to the function.\\n• In a function header  (the rest of the table), a simple name is matched by position or\\nname depending on how the caller passes it, but the name=value form specifies a\\ndefault value . The *name form collects any extra unmatched positional arguments\\nin a tuple, and the **name form collects extra keyword arguments in a dictionary.\\nIn Python 3.0 and later, any normal or defaulted argument names following a\\n*name or a bare * are keyword-only arguments and must be passed by keyword in\\ncalls.\\nOf these, keyword arguments and defaults are probably the most commonly used in\\nPython code. We’ve informally used both of these earlier in this book:\\n• We’ve already used keywords to specify options to the 3.0 print function, but they\\nare more general—keywords allow us to label any argument with its name, to make\\ncalls more informational.\\n442 | Chapter 18: \\u2002Arguments', metadata={'source': 'python.pdf', 'page': 492}),\n",
       " Document(page_content='• We met defaults earlier, too, as a way to pass in values from the enclosing function’s\\nscope, but they are also more general—they allow us to make any argument op-\\ntional, providing its default value in a function definition.\\nAs we’ll see, the combination of defaults in a function header and keywords in a call\\nfurther allows us to pick and choose which defaults to override.\\nIn short, special \\nargument-matching modes let you be fairly liberal about how many\\narguments must be passed to a function. If a function specifies defaults, they are used\\nif you pass too few  arguments. If a function uses the * variable argument list forms, you\\ncan pass too many  arguments; the * names collect the extra arguments in data structures\\nfor processing in the function.\\nThe Gritty Details\\nIf you choose to use and combine the special argument-matching modes, Python will\\nask you to follow these ordering rules:\\n• In a function call, arguments must appear in this order: any positional arguments\\n(value), followed by a combination of any keyword arguments ( name=value) and\\nthe *sequence form, followed by the **dict form.\\n• In a function header, arguments must appear in this order: any normal arguments\\n(name), followed by any default arguments ( name=value), followed by the *name (or\\n* in 3.0) form if present, followed by any name or name=value keyword-only argu-\\nments (in 3.0), followed by the **name form.\\nIn both the call and header, the **arg form must appear last if present. If you mix\\narguments in any other order, you will get a syntax error because the combinations can\\nbe ambiguous. The steps that Python internally carries out to match arguments before\\nassignment can roughly be described as follows:\\n1. Assign nonkeyword arguments by position.\\n2. Assign keyword arguments by matching names.\\n3. Assign extra nonkeyword arguments to *name tuple.\\n4. Assign extra keyword arguments to **name dictionary.\\n5. Assign default values to unassigned arguments in header.\\nAfter this, Python checks to make sure each argument is passed just one value; if not,\\nan error is raised. When all matching is complete, Python assigns argument names to\\nthe objects passed to them.\\nSpecial Argument-Matching Modes | 443', metadata={'source': 'python.pdf', 'page': 493}),\n",
       " Document(page_content='The actual matching algorithm Python uses is a bit more complex (it must also account\\nfor keyword-only arguments \\nin 3.0, for instance), so we’ll defer to Python’s standard\\nlanguage manual for a more exact description. It’s not required reading, but tracing\\nPython’s matching algorithm may help you to understand some convoluted cases, es-\\npecially when modes are mixed.\\nIn Python 3.0, argument names in a function header can also have an-\\nnotation values, specified \\nas name:value (or name:value=default when\\ndefaults are present). This is simply additional syntax for arguments and\\ndoes not augment or change the argument-ordering rules described\\nhere. The function itself can also have an annotation value, given as\\ndef f()->value. See the discussion of function annotation in Chap-\\nter 19 for more details.\\nKeyword and Default Examples\\nThis is all simpler in code than the preceding descriptions may imply. If you don’t use\\nany special matching syntax, Python matches names by position from left to right, like\\nmost other languages. For instance, if you define a function that requires three argu-\\nments, you must call it with three arguments:\\n>>> def f(a, b, c): print(a, b, c)\\n...\\nHere, we pass them by position— a is matched to 1, b is matched to 2, and so on (this\\nworks the same in Python 3.0 and 2.6, but extra tuple parentheses are displayed in 2.6\\nbecause we’re using 3.0 print calls):\\n>>> f(1, 2, 3)\\n1 2 3\\nKeywords\\nIn Python, though, you can be more specific about what goes where when you call a\\nfunction. Keyword arguments allow us to match by name, instead of by position:\\n>>> f(c=3, b=2, a=1)\\n1 2 3\\nThe c=3 in this call, for example, means send 3 to the argument named c. More formally,\\nPython matches the name c in the call to the argument named c in the function defi-\\nnition’s header, and then passes the value 3 to that argument. The net effect of this call\\nis the same as that of the prior call, but notice that the left-to-right order of the argu-\\nments no longer matters when keywords are used because arguments are matched by\\nname, not by position. It’s even possible to combine positional and keyword arguments\\nin a single call. In this case, all positionals are matched first from left to right in the\\nheader, before keywords are matched by name:\\n444 | Chapter 18: \\u2002Arguments', metadata={'source': 'python.pdf', 'page': 494}),\n",
       " Document(page_content=\">>> f(1, c=3, b=2)\\n1 2 3\\nWhen most people \\nsee this the first time, they wonder why one would use such a tool.\\nKeywords typically have two roles in Python. First, they make your calls a bit more self-\\ndocumenting (assuming that you use better argument names than a, b, and c). For\\nexample, a call of this form:\\nfunc(name='Bob', age=40, job='dev')\\nis much more meaningful than a call with three naked values separated by commas—\\nthe keywords serve as labels for the data in the call. The second major use of keywords\\noccurs in conjunction with defaults, which we turn to next.\\nDefaults\\nWe talked about defaults in brief earlier, when discussing nested function scopes. In\\nshort, defaults allow us to make selected function arguments optional; if not passed a\\nvalue, the argument is assigned its default before the function runs. For example, here\\nis a function that requires one argument and defaults two:\\n>>> def f(a, b=2, c=3): print(a, b, c)\\n...\\nWhen we call this function, we must provide a value for a, either by position or by\\nkeyword; however, providing values for b and c is optional. If we don’t pass values to\\nb and c, they default to 2 and 3, respectively:\\n>>> f(1)\\n1 2 3\\n>>> f(a=1)\\n1 2 3\\nIf we pass two values, only c gets its default, and with three values, no defaults are used:\\n>>> f(1, 4)\\n1 4 3\\n>>> f(1, 4, 5)\\n1 4 5\\nFinally, here is how the keyword and default features interact. Because they subvert the\\nnormal left-to-right positional mapping, keywords allow us to essentially skip over\\narguments with defaults:\\n>>> f(1, c=6)\\n1 2 6\\nHere, a gets 1 by position, c gets 6 by keyword, and b, in between, defaults to 2.\\nBe careful not to confuse the special name=value syntax in a function header and a\\nfunction call; in the call it means a match-by-name keyword argument, while in the\\nheader it specifies a default for an optional argument. In both cases, this is not an\\nassignment statement (despite its appearance); it is special syntax for these two con-\\ntexts, which modifies the default argument-matching mechanics.\\nSpecial Argument-Matching Modes | 445\", metadata={'source': 'python.pdf', 'page': 495}),\n",
       " Document(page_content='Combining keywords and defaults\\nHere is a \\nslightly larger example that demonstrates keywords and defaults in action. In\\nthe following, the caller must always pass at least two arguments (to match spam and\\neggs), but the other two are optional. If they are omitted, Python assigns toast and\\nham to the defaults specified in the header:\\ndef func(spam, eggs, toast=0, ham=0):   # First 2 required\\n    print((spam, eggs, toast, ham))\\nfunc(1, 2)                              # Output: (1, 2, 0, 0)\\nfunc(1, ham=1, eggs=0)                  # Output: (1, 0, 0, 1)\\nfunc(spam=1, eggs=0)                    # Output: (1, 0, 0, 0)\\nfunc(toast=1, eggs=2, spam=3)           # Output: (3, 2, 1, 0)\\nfunc(1, 2, 3, 4)                        # Output: (1, 2, 3, 4)\\nNotice again that when keyword arguments are used in the call, the order in which the\\narguments are listed doesn’t matter; Python matches by name, not by position. The\\ncaller must supply values for spam and eggs, but they can be matched by position or by\\nname. Again, keep in mind that the form name=value means different things in the call\\nand the def: a keyword in the call and a default in the header.\\nArbitrary Arguments Examples\\nThe last two matching extensions, * and **, are designed to support functions that take\\nany number of arguments. Both can appear in either the function definition or a func-\\ntion call, and they have related purposes in the two locations.\\nCollecting arguments\\nThe first use, in the function definition, collects unmatched positional arguments into\\na tuple:\\n>>> def f(*args): print(args)\\n...\\nWhen this function is called, Python collects all the positional arguments into a new\\ntuple and assigns the variable args to that tuple. Because it is a normal tuple object, it\\ncan be indexed, stepped through with a for loop, and so on:\\n>>> f()\\n()\\n>>> f(1)\\n(1,)\\n>>> f(1, 2, 3, 4)\\n(1, 2, 3, 4)\\nThe ** feature is similar, but it only works for keyword arguments—it collects them\\ninto a new dictionary, which can then be processed with normal dictionary tools. In a\\nsense, the ** form allows you to convert from keywords to dictionaries, which you can\\nthen step through with keys calls, dictionary iterators, and the like:\\n446 | Chapter 18: \\u2002Arguments', metadata={'source': 'python.pdf', 'page': 496}),\n",
       " Document(page_content=\">>> def f(**args): print(args)\\n...\\n>>> f()\\n{}\\n>>> f(a=1, b=2)\\n{'a': 1, 'b': 2}\\nFinally, function headers \\ncan combine normal arguments, the *, and the ** to imple-\\nment wildly flexible call signatures. For instance, in the following, 1 is passed to a by\\nposition, 2 and 3 are collected into the pargs positional tuple, and x and y wind up in\\nthe kargs keyword dictionary:\\n>>> def f(a, *pargs, **kargs): print(a, pargs, kargs)\\n...\\n>>> f(1, 2, 3, x=1, y=2)\\n1 (2, 3) {'y': 2, 'x': 1}\\nIn fact, these features can be combined in even more complex ways that may seem\\nambiguous at first glance—an idea we will revisit later in this chapter. First, though,\\nlet’s see what happens when * and ** are coded in function calls instead of definitions.\\nUnpacking arguments\\nIn recent Python releases, we can use the * syntax when we call a function, too. In this\\ncontext, its meaning is the inverse of its meaning in the function definition—it unpacks\\na collection of arguments, rather than building a collection of arguments. For example,\\nwe can pass four arguments to a function in a tuple and let Python unpack them into\\nindividual arguments:\\n>>> def func(a, b, c, d): print(a, b, c, d)\\n...\\n>>> args = (1, 2)\\n>>> args += (3, 4)\\n>>> func(*args)\\n1 2 3 4\\nSimilarly, the ** syntax in a function call unpacks a dictionary of key/value pairs into\\nseparate keyword arguments:\\n>>> args = {'a': 1, 'b': 2, 'c': 3}\\n>>> args['d'] = 4\\n>>> func(**args)\\n1 2 3 4\\nAgain, we can combine normal, positional, and keyword arguments in the call in very\\nflexible ways:\\n>>> func(*(1, 2), **{'d': 4, 'c': 4})\\n1 2 4 4\\n>>> func(1, *(2, 3), **{'d': 4})\\n1 2 3 4\\n>>> func(1, c=3, *(2,), **{'d': 4})\\nSpecial Argument-Matching Modes | 447\", metadata={'source': 'python.pdf', 'page': 497}),\n",
       " Document(page_content=\"1 2 3 4\\n>>> func(1, *(2, 3), d=4)\\n1 2 3 4\\n>>> f(1, *(2,), c=3, **{'d':4})\\n1 2 3 4\\nThis sort of \\ncode is convenient when you cannot predict the number of arguments that\\nwill be passed to a function when you write your script; you can build up a collection\\nof arguments at runtime instead and call the function generically this way. Again, don’t\\nconfuse the */** syntax in the function header and the function call—in the header it\\ncollects any number of arguments, while in the call it unpacks any number of\\narguments.\\nAs we saw in Chapter 14 , the *pargs  form in a call is an iteration con-\\ntext, so technically it accepts any iterable object, not just tuples or other\\nsequences as shown in the examples here. For instance, a file object\\nworks after the *, and unpacks its lines into individual arguments (e.g.,\\nfunc(*open('fname')).\\nThis generality is supported in both Python 3.0 and 2.6, but it holds true\\nonly for calls—a *pargs in a call allows any iterable, but the same form\\nin a def header always bundles extra arguments into a tuple. This header\\nbehavior is similar in spirit and syntax to the * in Python 3.0 extended\\nsequence unpacking assignment forms we met in Chapter 11 (e.g., x,\\n*y = z), though that feature always creates lists, not tuples.\\nApplying functions generically\\nThe prior section’s examples may seem obtuse, but they are used more often than you\\nmight expect. Some programs need to call arbitrary functions in a generic fashion,\\nwithout knowing their names or arguments ahead of time. In fact, the real power of\\nthe special “varargs” call syntax is that you don’t need to know how many arguments\\na function call requires before you write a script. For example, you can use if logic to\\nselect from a set of functions and argument lists, and call any of them generically:\\nif <test>:\\n    action, args = func1, (1,)             # Call func1 with 1 arg in this case\\nelse:\\n    action, args = func2, (1, 2, 3)        # Call func2 with 3 args here\\n...\\naction(*args)                              # Dispatch generically\\nMore generally, this varargs call syntax is useful any time you cannot predict the argu-\\nments list. If your user selects an arbitrary function via a user interface, for instance,\\nyou may be unable to hardcode a function call when writing your script. To work\\naround this, simply build up the arguments list with sequence operations, and call it\\nwith starred names to unpack the arguments:\\n448 | Chapter 18: \\u2002Arguments\", metadata={'source': 'python.pdf', 'page': 498}),\n",
       " Document(page_content=\">>> args = (2,3)\\n>>> args += (4,)\\n>>> args\\n(2, 3, 4)\\n>>> func(*args)\\nBecause the arguments \\nlist is passed in as a tuple here, the program can build it at\\nruntime. This technique also comes in handy for functions that test or time other func-\\ntions. For instance, in the following code we support any function with any arguments\\nby passing along whatever arguments were sent in:\\ndef tracer(func, *pargs, **kargs):         # Accept arbitrary arguments\\n    print('calling:', func.__name__)\\n    return func(*pargs, **kargs)           # Pass along arbitrary arguments\\ndef func(a, b, c, d):\\n    return a + b + c + d\\nprint(tracer(func, 1, 2, c=3, d=4))\\nWhen this code is run, arguments are collected by the tracer and then propagated with\\nvarargs call syntax:\\ncalling: func\\n10\\nWe’ll see larger examples of such roles later in this book; see especially the sequence\\ntiming example in Chapter 20 and the various decorator tools we will code in Chap-\\nter 38.\\nThe defunct apply built-in (Python 2.6)\\nPrior to Python 3.0, the effect of the *args and **args varargs call syntax could be\\nachieved with a built-in function named apply. This original technique has been re-\\nmoved in 3.0 because it is now redundant (3.0 cleans up many such dusty tools that\\nhave been subsumed over the years). It’s still available in Python 2.6, though, and you\\nmay come across it in older 2.X code.\\nIn short, the following are equivalent prior to Python 3.0:\\nfunc(*pargs, **kargs)             # Newer call syntax: func(*sequence, **dict)\\napply(func, pargs, kargs)         # Defunct built-in:  apply(func, sequence, dict)\\nFor example, consider the following function, which accepts any number of positional\\nor keyword arguments:\\n>>> def echo(*args, **kwargs): print(args, kwargs)\\n...\\n>>> echo(1, 2, a=3, b=4)\\n(1, 2) {'a': 3, 'b': 4}\\nSpecial Argument-Matching Modes | 449\", metadata={'source': 'python.pdf', 'page': 499}),\n",
       " Document(page_content=\"In Python 2.6, we can call it generically with apply, or with the call syntax that is now\\nrequired in 3.0:\\n>>> pargs = (1, 2)\\n>>> kargs = {'a':3, 'b':4}\\n>>> apply(echo, pargs, kargs)\\n(1, 2) {'a': 3, 'b': 4}\\n>>> echo(*pargs, **kargs)\\n(1, 2) {'a': 3, 'b': 4}\\nThe unpacking call \\nsyntax form is newer than the apply function, is preferred in general,\\nand is required in 3.0. Apart from its symmetry with the *pargs and **kargs collector\\nforms in def headers, and the fact that it requires fewer keystrokes overall, the newer\\ncall syntax also allows us to pass along additional arguments without having to man-\\nually extend argument sequences or dictionaries:\\n>>> echo(0, c=5, *pargs, **kargs)      # Normal, keyword, *sequence, **dictionary\\n(0, 1, 2) {'a': 3, 'c': 5, 'b': 4}\\nThat is, the call syntax form is more general . Since it’s required in 3.0, you should now\\ndisavow all knowledge of apply (unless, of course, it appears in 2.X code you must use\\nor maintain...).\\nPython 3.0 Keyword-Only Arguments\\nPython 3.0 generalizes the ordering rules in function headers to allow us to specify \\nkeyword-only arguments —arguments that must be passed by keyword only and will\\nnever be filled in by a positional argument. This is useful if we want a function to both\\nprocess any number of arguments and accept possibly optional configuration options.\\nSyntactically, keyword-only arguments are coded as named arguments that appear after\\n*args in the arguments list. All such arguments must be passed using keyword syntax\\nin the call. For example, in the following, a may be passed by name or position, b collects\\nany extra positional arguments, and c must be passed by keyword only:\\n>>> def kwonly(a, *b, c):\\n...     print(a, b, c)\\n...\\n>>> kwonly(1, 2, c=3)\\n1 (2,) 3\\n>>> kwonly(a=1, c=3)\\n1 () 3\\n>>> kwonly(1, 2, 3)\\nTypeError: kwonly() needs keyword-only argument c\\nWe can also use a * character by itself in the arguments list to indicate that a function\\ndoes not accept a variable-length argument list but still expects all arguments following\\nthe * to be passed as keywords. In the next function, a may be passed by position or\\nname again, but b and c must be keywords, and no extra positionals are allowed:\\n450 | Chapter 18: \\u2002Arguments\", metadata={'source': 'python.pdf', 'page': 500}),\n",
       " Document(page_content=\">>> def kwonly(a, *, b, c):\\n...     print(a, b, c)\\n...\\n>>> kwonly(1, c=3, b=2)\\n1 2 3\\n>>> kwonly(c=3, b=2, a=1)\\n1 2 3\\n>>> kwonly(1, 2, 3)\\nTypeError: kwonly() takes exactly 1 positional argument (3 given)\\n>>> kwonly(1)\\nTypeError: kwonly() needs keyword-only argument b\\nYou can still \\nuse defaults for keyword-only arguments, even though they appear after\\nthe * in the function header. In the following code, a may be passed by name or position,\\nand b and c are optional but must be passed by keyword if used:\\n>>> def kwonly(a, *, b='spam', c='ham'):\\n...     print(a, b, c)\\n...\\n>>> kwonly(1)\\n1 spam ham\\n>>> kwonly(1, c=3)\\n1 spam 3\\n>>> kwonly(a=1)\\n1 spam ham\\n>>> kwonly(c=3, b=2, a=1)\\n1 2 3\\n>>> kwonly(1, 2)\\nTypeError: kwonly() takes exactly 1 positional argument (2 given)\\nIn fact, keyword-only arguments with defaults are optional, but those without defaults\\neffectively become required keywords for the function:\\n>>> def kwonly(a, *, b, c='spam'):\\n...     print(a, b, c)\\n...\\n>>> kwonly(1, b='eggs')\\n1 eggs spam\\n>>> kwonly(1, c='eggs')\\nTypeError: kwonly() needs keyword-only argument b\\n>>> kwonly(1, 2)\\nTypeError: kwonly() takes exactly 1 positional argument (2 given)\\n>>> def kwonly(a, *, b=1, c, d=2):\\n...     print(a, b, c, d)\\n...\\n>>> kwonly(3, c=4)\\n3 1 4 2\\n>>> kwonly(3, c=4, b=5)\\n3 5 4 2\\n>>> kwonly(3)\\nTypeError: kwonly() needs keyword-only argument c\\n>>> kwonly(1, 2, 3)\\nTypeError: kwonly() takes exactly 1 positional argument (3 given)\\nSpecial Argument-Matching Modes | 451\", metadata={'source': 'python.pdf', 'page': 501}),\n",
       " Document(page_content=\"Ordering rules\\nFinally, note that \\nkeyword-only arguments must be specified after a single star, not\\ntwo—named arguments cannot appear after the **args arbitrary keywords form, and\\na ** can’t appear by itself in the arguments list. Both attempts generate a syntax error:\\n>>> def kwonly(a, **pargs, b, c):\\nSyntaxError: invalid syntax\\n>>> def kwonly(a, **, b, c):\\nSyntaxError: invalid syntax\\nThis means that in a function header, keyword-only arguments must be coded before\\nthe **args arbitrary keywords form and after the *args arbitrary positional form, when\\nboth are present. Whenever an argument name appears before *args, it is a possibly\\ndefault positional argument, not keyword-only:\\n>>> def f(a, *b, **d, c=6): print(a, b, c, d)          # Keyword-only before **!\\nSyntaxError: invalid syntax\\n>>> def f(a, *b, c=6, **d): print(a, b, c, d)          # Collect args in header\\n...\\n>>> f(1, 2, 3, x=4, y=5)                               # Default used\\n1 (2, 3) 6 {'y': 5, 'x': 4}\\n>>> f(1, 2, 3, x=4, y=5, c=7)                          # Override default\\n1 (2, 3) 7 {'y': 5, 'x': 4}\\n>>> f(1, 2, 3, c=7, x=4, y=5)                          # Anywhere in keywords\\n1 (2, 3) 7 {'y': 5, 'x': 4}\\n>>> def f(a, c=6, *b, **d): print(a, b, c, d)          # c is not keyword-only!\\n...\\n>>> f(1, 2, 3, x=4)\\n1 (3,) 2 {'x': 4}\\nIn fact, similar ordering rules hold true in function calls: when keyword-only arguments\\nare passed, they must appear before a **args form. The keyword-only argument can\\nbe coded either before or after the *args, though, and may be included in **args:\\n>>> def f(a, *b, c=6, **d): print(a, b, c, d)          # KW-only between * and **\\n...\\n>>> f(1, *(2, 3), **dict(x=4, y=5))                    # Unpack args at call\\n1 (2, 3) 6 {'y': 5, 'x': 4}\\n>>> f(1, *(2, 3), **dict(x=4, y=5), c=7)               # Keywords before **args!\\nSyntaxError: invalid syntax\\n>>> f(1, *(2, 3), c=7, **dict(x=4, y=5))               # Override default\\n1 (2, 3) 7 {'y': 5, 'x': 4}\\n>>> f(1, c=7, *(2, 3), **dict(x=4, y=5))               # After or before *\\n1 (2, 3) 7 {'y': 5, 'x': 4}\\n>>> f(1, *(2, 3), **dict(x=4, y=5, c=7))               # Keyword-only in **\\n1 (2, 3) 7 {'y': 5, 'x': 4}\\n452 | Chapter 18: \\u2002Arguments\", metadata={'source': 'python.pdf', 'page': 502}),\n",
       " Document(page_content=\"Trace through these cases on your own, in conjunction with the general argument-\\nordering rules described \\nformally earlier. They may appear to be worst cases in the\\nartificial examples here, but they can come up in real practice, especially for people\\nwho write libraries and tools for other Python programmers to use.\\nWhy keyword-only arguments?\\nSo why care about keyword-only arguments? In short, they make it easier to allow a\\nfunction to accept both any number of positional arguments to be processed, and con-\\nfiguration options passed as keywords. While their use is optional, without keyword-\\nonly arguments extra work may be required to provide defaults for such options and\\nto verify that no superfluous keywords were passed.\\nImagine a function that processes a set of passed-in objects and allows a tracing flag to\\nbe passed:\\nprocess(X, Y, Z)                    # use flag's default\\nprocess(X, Y, notify=True)          # override flag default\\nWithout keyword-only arguments we have to use both *args and **args and manually\\ninspect the keywords, but with keyword-only arguments less code is required. The\\nfollowing guarantees that no positional argument will be incorrectly matched against\\nnotify and requires that it be a keyword if passed:\\ndef process(*args, notify=False): ...\\nSince we’re going to see a more realistic example of this later in this chapter, in “Em-\\nulating the Python 3.0 print Function” on page 457, I’ll postpone the rest of this story\\nuntil then. For an additional example of keyword-only arguments in action, see the\\niteration options timing case study in Chapter 20. And for additional function definition\\nenhancements in Python 3.0, stay tuned for the discussion of function annotation syn-\\ntax in Chapter 19.\\nThe min Wakeup Call!\\nTime for something more realistic. To make this chapter’s concepts more concrete,\\nlet’s work through an exercise that demonstrates a practical application of argument-\\nmatching tools.\\nSuppose you want to code a function that is able to compute the minimum value from\\nan arbitrary set of arguments and an arbitrary set of object data types. That is, the\\nfunction should accept zero or more arguments, as many as you wish to pass. Moreover,\\nthe function should work for all kinds of Python object types: numbers, strings, lists,\\nlists of dictionaries, files, and even None.\\nThe first requirement provides a natural example of how the * feature can be put to\\ngood use—we can collect arguments into a tuple and step over each of them in turn\\nwith a simple for loop. The second part of the problem definition is easy: because every\\nThe min Wakeup Call! | 453\", metadata={'source': 'python.pdf', 'page': 503}),\n",
       " Document(page_content='object type supports comparisons, we don’t have to specialize the function per type (an\\napplication of polymorphism); \\nwe can simply compare objects blindly and let Python\\nworry about what sort of comparison to perform.\\nFull Credit\\nThe following file shows three ways to code this operation, at least one of which was\\nsuggested by a student in one of my courses:\\n• The first function fetches the first argument ( args is a tuple) and traverses the rest\\nby slicing off the first (there’s no point in comparing an object to itself, especially\\nif it might be a large structure).\\n• The second version lets Python pick off the first and rest of the arguments auto-\\nmatically, and so avoids an index and slice.\\n• The third converts from a tuple to a list with the built-in list call and employs the\\nlist sort method.\\nThe sort method is coded in C, so it can be quicker than the other approaches at times,\\nbut the linear scans of the first two techniques will make them faster most of the\\ntime.* The file mins.py contains the code for all three solutions:\\ndef min1(*args):\\n    res = args[0]\\n    for arg in args[1:]:\\n        if arg < res:\\n            res = arg\\n    return res\\ndef min2(first, *rest):\\n    for arg in rest:\\n        if arg < first:\\n            first = arg\\n    return first\\ndef min3(*args):\\n    tmp = list(args)            # Or, in Python 2.4+: return sorted(args)[0]\\n    tmp.sort()\\n    return tmp[0]\\nprint(min1(3,4,1,2))\\n* Actually, this is fairly complicated. The Python sort routine is coded in C and uses a highly optimized\\nalgorithm that attempts to take advantage of partial ordering in the items to be sorted. It’s named “timsort”\\nafter Tim Peters, its creator, and in its documentation it claims to have “supernatural performance” at times\\n(pretty good, for a sort!). Still, sorting is an inherently exponential operation (it must chop up the sequence\\nand put it back together many times), and the other versions simply perform one linear left-to-right scan.\\nThe net effect is that sorting is quicker if the arguments are partially ordered, but is likely to be slower\\notherwise. Even so, Python performance can change over time, and the fact that sorting is implemented in\\nthe C language can help greatly; for an exact analysis, you should time the alternatives with the time or\\ntimeit modules we’ll meet in Chapter 20.\\n454 | Chapter 18: \\u2002Arguments', metadata={'source': 'python.pdf', 'page': 504}),\n",
       " Document(page_content='print(min2(\"bb\", \"aa\"))\\nprint(min3([2,2], [1,1], [3,3]))\\nAll three solutions \\nproduce the same result when the file is run. Try typing a few calls\\ninteractively to experiment with these on your own:\\n% python mins.py\\n1\\naa\\n[1, 1]\\nNotice that none of these three variants tests for the case where no arguments are passed\\nin. They could, but there’s no point in doing so here—in all three solutions, Python\\nwill automatically raise an exception if no arguments are passed in. The first variant\\nraises an exception when we try to fetch item 0, the second when Python detects an\\nargument list mismatch, and the third when we try to return item 0 at the end.\\nThis is exactly what we want to happen—because these functions support any data\\ntype, there is no valid sentinel value that we could pass back to designate an error. There\\nare exceptions to this rule (e.g., if you have to run expensive actions before you reach\\nthe error), but in general it’s better to assume that arguments will work in your func-\\ntions’ code and let Python raise errors for you when they do not.\\nBonus Points\\nYou can get can get bonus points here for changing these functions to compute the\\nmaximum, rather than minimum, values. This one’s easy: the first two versions only\\nrequire changing < to >, and the third simply requires that we return tmp[−1] instead of\\ntmp[0]. For an extra point, be sure to set the function name to “max” as well (though\\nthis part is strictly optional).\\nIt’s also possible to generalize a single function to compute either a minimum or a\\nmaximum value, by evaluating comparison expression strings with a tool like the\\neval built-in function (see the library manual) or passing in an arbitrary comparison\\nfunction. The file minmax.py shows how to implement the latter scheme:\\ndef minmax(test, *args):\\n    res = args[0]\\n    for arg in args[1:]:\\n        if test(arg, res):\\n            res = arg\\n    return res\\ndef lessthan(x, y): return x < y                # See also: lambda\\ndef grtrthan(x, y): return x > y\\nprint(minmax(lessthan, 4, 2, 1, 5, 6, 3))       # Self-test code\\nprint(minmax(grtrthan, 4, 2, 1, 5, 6, 3))\\n% python minmax.py\\nThe min Wakeup Call! | 455', metadata={'source': 'python.pdf', 'page': 505}),\n",
       " Document(page_content='1\\n6\\nFunctions are another \\nkind of object that can be passed into a function like this one.\\nTo make this a max (or other) function, for example, we could simply pass in the right\\nsort of test function. This may seem like extra work, but the main point of generalizing\\nfunctions this way (instead of cutting and pasting to change just a single character) is\\nthat we’ll only have one version to change in the future, not two.\\nThe Punch Line...\\nOf course, all this was just a coding exercise. There’s really no reason to code min or\\nmax functions, because both are built-ins in Python! We met them briefly in Chap-\\nter 5  in conjunction with numeric tools, and again in Chapter 14  when exploring iter-\\nation contexts. The built-in versions work almost exactly like ours, but they’re coded\\nin C for optimal speed and accept either a single iterable or multiple arguments. Still,\\nthough it’s superfluous in this context, the general coding pattern we used here might\\nbe useful in other scenarios.\\nGeneralized Set Functions\\nLet’s look at a more useful example of special argument-matching modes at work. At\\nthe end of Chapter 16 , we wrote a function that returned the intersection of two se-\\nquences (it picked out items that appeared in both). Here is a version that intersects an\\narbitrary number of sequences (one or more) by using the varargs matching form\\n*args to collect all the passed-in arguments. Because the arguments come in as a tuple,\\nwe can process them in a simple for loop. Just for fun, we’ll code a union function that\\nalso accepts an arbitrary number of arguments to collect items that appear in any of\\nthe operands:\\ndef intersect(*args):\\n    res = []\\n    for x in args[0]:                  # Scan first sequence\\n        for other in args[1:]:         # For all other args\\n            if x not in other: break   # Item in each one?\\n        else:                          # No: break out of loop\\n            res.append(x)              # Yes: add items to end\\n    return res\\ndef union(*args):\\n    res = []\\n    for seq in args:                   # For all args\\n        for x in seq:                  # For all nodes\\n            if not x in res:\\n                res.append(x)          # Add new items to result\\n    return res\\n456 | Chapter 18: \\u2002Arguments', metadata={'source': 'python.pdf', 'page': 506}),\n",
       " Document(page_content='Because these are tools worth reusing (and they’re too big to retype interactively), we’ll\\nstore the functions \\nin a module file called inter2.py (if you’ve forgotten how modules\\nand imports work, see the introduction in Chapter 3 , or stay tuned for in-depth coverage\\nin Part V ). In both functions, the arguments passed in at the call come in as the args\\ntuple. As in the original intersect, both work on any kind of sequence. Here, they are\\nprocessing strings, mixed types, and more than two sequences:\\n% python\\n>>> from inter2 import intersect, union\\n>>> s1, s2, s3 = \"SPAM\", \"SCAM\", \"SLAM\"\\n>>> intersect(s1, s2), union(s1, s2)           # Two operands\\n([\\'S\\', \\'A\\', \\'M\\'], [\\'S\\', \\'P\\', \\'A\\', \\'M\\', \\'C\\'])\\n>>> intersect([1,2,3], (1,4))                  # Mixed types\\n[1]\\n>>> intersect(s1, s2, s3)                      # Three operands\\n[\\'S\\', \\'A\\', \\'M\\']\\n>>> union(s1, s2, s3)\\n[\\'S\\', \\'P\\', \\'A\\', \\'M\\', \\'C\\', \\'L\\']\\nI should note that because Python now has a set object type  (described\\nin Chapter 5), \\nnone of the set-processing examples in this book are\\nstrictly required anymore; they are included only as demonstrations of\\ncoding techniques. Because it’s constantly improving, Python has an\\nuncanny way of conspiring to make my book examples obsolete over\\ntime!\\nEmulating the Python 3.0 print Function\\nTo round out the chapter, let’s look at one last example of argument matching at work. \\nThe code you’ll see here is intended for use in Python 2.6 or earlier (it works in 3.0,\\ntoo, but is pointless there): it uses both the *args arbitrary positional tuple and the\\n**args arbitrary keyword-arguments dictionary to simulate most of what the Python\\n3.0 print function does.\\nAs we learned in Chapter 11, this isn’t actually required, because 2.6 programmers can\\nalways enable the 3.0 print function with an import of this form:\\nfrom __future__ import print_function\\nTo demonstrate argument matching in general, though, the following file, print30.py,\\ndoes the same job in a small amount of reusable code:\\nEmulating the Python 3.0 print Function | 457', metadata={'source': 'python.pdf', 'page': 507}),\n",
       " Document(page_content='\"\"\"\\nEmulate most of the 3.0 print function for use in 2.X\\ncall signature: print30(*args, sep=\\' \\', end=\\'\\\\n\\', file=None)\\n\"\"\"\\nimport sys\\ndef print30(*args, **kargs):\\n    sep  = kargs.get(\\'sep\\', \\' \\')             # Keyword arg defaults\\n    end  = kargs.get(\\'end\\', \\'\\\\n\\')\\n    file = kargs.get(\\'file\\', sys.stdout)\\n    output = \\'\\'\\n    first  = True\\n    for arg in args:\\n        output += (\\'\\' if first else sep) + str(arg)\\n        first = False\\n    file.write(output + end)\\nTo test it, \\nimport this into another file or the interactive prompt, and use it like the 3.0\\nprint function. Here is a test script, testprint30.py (notice that the function must be\\ncalled “print30”, because “print” is a reserved word in 2.6):\\nfrom print30 import print30\\nprint30(1, 2, 3)\\nprint30(1, 2, 3, sep=\\'\\')                     # Suppress separator\\nprint30(1, 2, 3, sep=\\'...\\')\\nprint30(1, [2], (3,), sep=\\'...\\')             # Various object types\\nprint30(4, 5, 6, sep=\\'\\', end=\\'\\')             # Suppress newline\\nprint30(7, 8, 9)\\nprint30()                                    # Add newline (or blank line)\\nimport sys\\nprint30(1, 2, 3, sep=\\'??\\', end=\\'.\\\\n\\', file=sys.stderr)    # Redirect to file\\nWhen run under 2.6, we get the same results as 3.0’s print function:\\nC:\\\\misc> c:\\\\python26\\\\python testprint30.py\\n1 2 3\\n123\\n1...2...3\\n1...[2]...(3,)\\n4567 8 9\\n1??2??3.\\nAlthough pointless in 3.0, the results are the same when run there. As usual, the gen-\\nerality of Python’s design allows us to prototype or develop concepts in the Python\\nlanguage itself. In this case, argument-matching tools are as flexible in Python code as\\nthey are in Python’s internal implementation.\\n458 | Chapter 18: \\u2002Arguments', metadata={'source': 'python.pdf', 'page': 508}),\n",
       " Document(page_content=\"Using Keyword-Only Arguments\\nIt’s interesting to \\nnotice that this example could be coded with Python 3.0\\nkeyword-only arguments, described earlier in this chapter, to automatically validate\\nconfiguration arguments:\\n# Use keyword-only args\\ndef print30(*args, sep=' ', end='\\\\n', file=sys.stdout):\\n    output = ''\\n    first  = True\\n    for arg in args:\\n        output += ('' if first else sep) + str(arg)\\n        first = False\\n    file.write(output + end)\\nThis version works the same as the original, and it’s a prime example of how keyword-\\nonly arguments come in handy. The original version assumes that all positional\\narguments are to be printed, and all keywords are for options only. That’s almost suf-\\nficient, but any extra keyword arguments are silently ignored. A call like the following,\\nfor instance, will generate an exception with the keyword-only form:\\n>>> print30(99, name='bob')\\nTypeError: print30() got an unexpected keyword argument 'name'\\nbut will silently ignore the name argument in the original version. To detect superfluous\\nkeywords manually, we could use dict.pop() to delete fetched entries, and check if the\\ndictionary is not empty. Here is an equivalent to the keyword-only version:\\n# Use keyword args deletion with defaults\\ndef print30(*args, **kargs):\\n    sep  = kargs.pop('sep', ' ')\\n    end  = kargs.pop('end', '\\\\n')\\n    file = kargs.pop('file', sys.stdout)\\n    if kargs: raise TypeError('extra keywords: %s' % kargs)\\n    output = ''\\n    first  = True\\n    for arg in args:\\n        output += ('' if first else sep) + str(arg)\\n        first = False\\n    file.write(output + end)\\nThis works as before, but it now catches extraneous keyword arguments, too:\\n>>> print30(99, name='bob')\\nTypeError: extra keywords: {'name': 'bob'}\\nEmulating the Python 3.0 print Function | 459\", metadata={'source': 'python.pdf', 'page': 509}),\n",
       " Document(page_content='This version of the function runs under Python 2.6, but it requires four more lines of\\ncode than the \\nkeyword-only version. Unfortunately, the extra code is required in this\\ncase—the keyword-only version only works on 3.0, which negates most of the reason\\nthat I wrote this example in the first place (a 3.0 emulator that only works on 3.0 isn’t\\nincredibly useful!). In programs written to run on 3.0, though, keyword-only arguments\\ncan simplify a specific category of functions that accept both arguments and options.\\nFor another example of 3.0 keyword-only arguments, be sure to see the upcoming\\niteration timing case study in Chapter 20.\\nWhy You Will Care: Keyword Arguments\\nAs you can \\nprobably tell, advanced argument-matching modes can be complex. They\\nare also entirely optional; you can get by with just simple positional matching, and it’s\\nprobably a good idea to do so when you’re starting out. However, because some Python\\ntools make use of them, some general knowledge of these modes is important.\\nFor example, keyword arguments play an important role in tkinter, the de facto stand-\\nard GUI API for Python (this module’s name is Tkinter in Python 2.6). We touch on\\ntkinter only briefly at various points in this book, but in terms of its call patterns,\\nkeyword arguments set configuration options when GUI components are built. For\\ninstance, a call of the form:\\nfrom tkinter import *\\nwidget = Button(text=\"Press me\", command=someFunction)\\ncreates a new button and specifies its text and callback function, using the text and\\ncommand keyword arguments. Since the number of configuration options for a widget\\ncan be large, keyword arguments let you pick and choose which to apply. Without\\nthem, you might have to either list all the possible options by position or hope for a\\njudicious positional argument defaults protocol that would handle every possible op-\\ntion arrangement.\\nMany built-in functions in Python expect us to use keywords for usage-mode options\\nas well, which may or may not have defaults. As we learned in Chapter 8 , for instance,\\nthe sorted built-in:\\nsorted(iterable, key=None, reverse=False)\\nexpects us to pass an iterable object to be sorted, but also allows us to pass in optional\\nkeyword arguments to specify a dictionary sort key and a reversal flag, which default\\nto None and False, respectively. Since we normally don’t use these options, they may\\nbe omitted to use defaults.\\nChapter Summary\\nIn this chapter, \\nwe studied the second of two key concepts related to functions: argu-\\nments (how objects are passed into a function). As we learned, arguments are passed\\ninto a function by assignment, which means by object reference, which really means\\n460 | Chapter 18: \\u2002Arguments', metadata={'source': 'python.pdf', 'page': 510}),\n",
       " Document(page_content='by pointer. We also studied some more advanced extensions, including default and\\nkeyword arguments, tools \\nfor using arbitrarily many arguments, and keyword-only\\narguments in 3.0. Finally, we saw how mutable arguments can exhibit the same be-\\nhavior as other shared references to objects—unless the object is explicitly copied when\\nit’s sent in, changing a passed-in mutable in a function can impact the caller.\\nThe next chapter continues our look at functions by exploring some more advanced\\nfunction-related ideas: function annotations, lambdas, and functional tools such as\\nmap and filter. Many of these concepts stem from the fact that functions are normal\\nobjects in Python, and so support some advanced and very flexible processing modes.\\nBefore diving into those topics, however, take this chapter’s quiz to review the argument\\nideas we’ve studied here.\\nTest Your Knowledge: Quiz\\n1. What is the output of the following code, and why?\\n>>> def func(a, b=4, c=5):\\n...     \\nprint(a, b, c)\\n...\\n>>> func(1, 2)\\n2. What is the output of this code, and why?\\n>>> def func(a, b, c=5):\\n...     print(a, b, c)\\n...\\n>>> func(1, c=3, b=2)\\n3. How about this code: what is its output, and why?\\n>>> def func(a, *pargs):\\n...     print(a, pargs)\\n...\\n>>> func(1, 2, 3)\\n4. What does this code print, and why?\\n>>> def func(a, **kargs):\\n...     print(a, kargs)\\n...\\n>>> func(a=1, c=3, b=2)\\n5. One last time: what is the output of this code, and why?\\n>>> def func(a, b, c=3, d=4): print(a, b, c, d)\\n...\\n>>> func(1, *(5,6))\\n6. Name three or more ways that functions can communicate results to a caller.\\nTest Your Knowledge: Quiz | 461', metadata={'source': 'python.pdf', 'page': 511}),\n",
       " Document(page_content=\"Test Your Knowledge: Answers\\n1. The output here \\nis '1 2 5' , because 1 and 2 are passed to a and b by position, and\\nc is omitted in the call and defaults to 5.\\n2. The output this time is '1 2 3': 1 is passed to a by position, and b and c are passed\\n2 and 3 by name (the left-to-right order doesn’t matter when keyword arguments\\nare used like this).\\n3. This code prints '1 (2, 3)', because 1 is passed to a and the *pargs collects the\\nremaining positional arguments into a new tuple object. We can step through the\\nextra positional arguments tuple with any iteration tool (e.g., for arg in\\npargs: ...).\\n4. This time the code prints '1, {'c': 3, 'b': 2}', because 1 is passed to a by name\\nand the **kargs collects the remaining keyword arguments into a dictionary. We\\ncould step through the extra keyword arguments dictionary by key with any iter-\\nation tool (e.g., for key in kargs: ...).\\n5. The output here is '1 5 6 4': 1 matches a by position, 5 and 6 match b and c by\\n*name positionals ( 6 overrides c’s default), and d defaults to 4 because it was not\\npassed a value.\\n6. Functions can send back results with return statements, by changing passed-in\\nmutable arguments, and by setting global variables. Globals are generally frowned\\nupon (except for very special cases, like multithreaded programs) because they can\\nmake code more difficult to understand and use. return statements are usually\\nbest, but changing mutables is fine, if expected. Functions may also communicate\\nwith system devices such as files and sockets, but these are beyond our scope here.\\n462 | Chapter 18: \\u2002Arguments\", metadata={'source': 'python.pdf', 'page': 512}),\n",
       " Document(page_content='CHAPTER 19\\nAdvanced Function Topics\\nThis chapter introduces a collection of more advanced function-related topics: recur-\\nsive functions, function \\nattributes and annotations, the lambda expression, and func-\\ntional programming tools such as map and filter. These are all somewhat advanced\\ntools that, depending on your job description, you may not encounter on a regular\\nbasis. Because of their roles in some domains, though, a basic understanding can be\\nuseful; lambdas, for instance, are regular customers in GUIs.\\nPart of the art of using functions lies in the interfaces between them, so we will also\\nexplore some general function design principles here. The next chapter continues this\\nadvanced theme with an exploration of generator functions and expressions and a re-\\nvival of list comprehensions in the context of the functional tools we will study here.\\nFunction Design Concepts\\nNow that we’ve had a chance to study function basics in Python, let’s begin this chapter\\nwith a few words of context. When you start using functions in earnest, you’re faced\\nwith choices about how to glue components together—for instance, how to decompose\\na task into purposeful functions (known as cohesion), how your functions should com-\\nmunicate (called coupling), and so on. You also need to take into account concepts such\\nas the size of your functions, because they directly impact code usability. Some of this\\nfalls into the category of structured analysis and design, but it applies to Python code\\nas to any other.\\nWe introduced some ideas related to function and module coupling in the Chap-\\nter 17  when studying scopes, but here is a review of a few general guidelines for function\\nbeginners:\\n•Coupling: use arguments for inputs and  return for outputs . Generally, you\\nshould strive to make a function independent of things outside of it. Arguments\\nand return statements are often the best ways to isolate external dependencies to\\na small number of well-known places in your code.\\n463', metadata={'source': 'python.pdf', 'page': 513}),\n",
       " Document(page_content=\"•Coupling: use global variables only when truly necessary . Global variables\\n(i.e., names in the enclosing module) are usually a poor way for functions to com-\\nmunicate. They can create dependencies and timing issues that make programs\\ndifficult to debug and change.\\n•Coupling: don’t change mutable arguments unless the caller expects it .\\nFunctions can change parts of passed-in mutable objects, but (as with global\\nvariables) this creates lots of coupling between the caller and callee, which can\\nmake a function too specific and brittle.\\n•Cohesion: each function should have a single, unified purpose . When de-\\nsigned well, each of your functions should do one thing—something you can sum-\\nmarize in a simple declarative sentence. If that sentence is very broad (e.g., “this\\nfunction implements my whole program”), or contains lots of conjunctions (e.g.,\\n“this function gives employee raises and submits a pizza order”), you might want\\nto think about splitting it into separate and simpler functions. Otherwise, there is\\nno way to reuse the code behind the steps mixed together in the function.\\n•Size: each function should be relatively small . This naturally follows from the\\npreceding goal, but if your functions start spanning multiple pages on your display,\\nit’s probably time to split them. Especially given that Python code is so concise to\\nbegin with, a long or deeply nested function is often a symptom of design problems.\\nKeep it simple, and keep it short.\\n•Coupling: avoid changing variables in another module file directly . We in-\\ntroduced this concept in Chapter 17, and we’ll revisit it in the next part of the book\\nwhen we focus on modules. For reference, though, remember that changing vari-\\nables across file boundaries sets up a coupling between modules similar to how\\nglobal variables couple functions—the modules become difficult to understand\\nand reuse. Use accessor functions whenever possible, instead of direct assignment\\nstatements.\\nFigure 19-1  summarizes the ways functions can talk to the outside world; inputs may\\ncome from items on the left side, and results may be sent out in any of the forms on the\\nright. Good function designers prefer to use only arguments for inputs and return\\nstatements for outputs, whenever possible.\\nOf course, there are plenty of exceptions to the preceding design rules, including some\\nrelated to Python’s OOP support. As you’ll see in Part VI, Python classes depend on\\nchanging a passed-in mutable object—class functions set attributes of an automatically\\npassed-in argument called self to change per-object state information (e.g.,\\nself.name='bob'). Moreover, if classes are not used, global variables are often the most\\nstraightforward way for functions in modules to retain state between calls. Side effects\\nare dangerous only if they’re unexpected.\\nIn general though, you should strive to minimize external dependencies in functions\\nand other program components. The more self-contained a function is, the easier it will\\nbe to understand, reuse, and modify.\\n464 | Chapter 19: \\u2002Advanced Function Topics\", metadata={'source': 'python.pdf', 'page': 514}),\n",
       " Document(page_content='Recursive Functions\\nWhile discussing scope \\nrules near the start of Chapter 17 , we briefly noted that Python\\nsupports recursive functions —functions that call themselves either directly or indirectly\\nin order to loop. Recursion is a somewhat advanced topic, and it’s relatively rare to see\\nin Python. Still, it’s a useful technique to know about, as it allows programs to traverse\\nstructures that have arbitrary and unpredictable shapes. Recursion is even an alternative\\nfor simple loops and iterations, though not necessarily the simplest or most efficient\\none.\\nSummation with Recursion\\nLet’s look at some examples. To sum a list (or other sequence) of numbers, we can\\neither use the built-in sum function or write a more custom version of our own. Here’s\\nwhat a custom summing function might look like when coded with recursion:\\n>>> def mysum(L):\\n...     if not L:\\n...         return 0\\n...     else:\\n...         return L[0] + mysum(L[1:])           # Call myself\\n>>> mysum([1, 2, 3, 4, 5])\\n15\\nAt each level, this function calls itself recursively to compute the sum of the rest of the\\nlist, which is later added to the item at the front. The recursive loop ends and zero is\\nreturned when the list becomes empty. When using recursion like this, each open level\\nFigure 19-1. Function execution environment. Functions may obtain input and produce output in a\\nvariety of ways, \\nthough functions are usually easier to understand and maintain if you use arguments\\nfor input and return statements and anticipated mutable argument changes for output. In Python 3,\\noutputs may also take the form of declared nonlocal names that exist in an enclosing function scope.\\nRecursive Functions | 465', metadata={'source': 'python.pdf', 'page': 515}),\n",
       " Document(page_content=\"of call to the function has its own copy of the function’s local scope on the runtime call\\nstack—here, that means L is different in each level.\\nIf this is \\ndifficult to understand (and it often is for new programmers), try adding a\\nprint of L to the function and run it again, to trace the current list at each call level:\\n>>> def mysum(L):\\n...     print(L)                                 # Trace recursive levels\\n...     if not L:                                # L shorter at each level\\n...         return 0\\n...     else:\\n...         return L[0] + mysum(L[1:])\\n...\\n>>> mysum([1, 2, 3, 4, 5])\\n[1, 2, 3, 4, 5]\\n[2, 3, 4, 5]\\n[3, 4, 5]\\n[4, 5]\\n[5]\\n[]\\n15\\nAs you can see, the list to be summed grows smaller at each recursive level, until it\\nbecomes empty—the termination of the recursive loop. The sum is computed as the\\nrecursive calls unwind.\\nCoding Alternatives\\nInterestingly, we can also use Python’s if/else ternary expression (described in Chap-\\nter 12) to save some code real-estate here. We can also generalize for any summable\\ntype (which is easier if we assume at least one item in the input, as we did in Chap-\\nter 18 ’s minimum value example) and use Python 3.0’s extended sequence assignment\\nto make the first/rest unpacking simpler (as covered in Chapter 11):\\ndef mysum(L):\\n    return 0 if not L else L[0] + mysum(L[1:])           # Use ternary expression\\ndef mysum(L):\\n    return L[0] if len(L) == 1 else L[0] + mysum(L[1:])  # Any type, assume one\\ndef mysum(L):\\n    first, *rest = L\\n    return first if not rest else first + mysum(rest)    # Use 3.0 ext seq assign\\nThe latter two of these fail for empty lists but allow for sequences of any object type\\nthat supports +, not just numbers:\\n>>> mysum([1])                              # mysum([]) fails in last 2\\n1\\n>>> mysum([1, 2, 3, 4, 5])\\n15\\n>>> mysum(('s', 'p', 'a', 'm'))             # But various types now work\\n'spam'\\n466 | Chapter 19: \\u2002Advanced Function Topics\", metadata={'source': 'python.pdf', 'page': 516}),\n",
       " Document(page_content=\">>> mysum(['spam', 'ham', 'eggs'])\\n'spamhameggs'\\nIf you study \\nthese three variants, you’ll find that the latter two also work on a single\\nstring argument (e.g., mysum ('spam')) , because strings are sequences of one-character\\nstrings; the third variant works on arbitary iterables, including open input files, but the\\nothers do not because they index; and the function header def mysum(first, * rest) ,\\nalthough similar to the third variant, wouldn’t work at all, because it expects individual\\narguments, not a single iterable.\\nKeep in mind that recursion can be direct, as in the examples so far, or indirect, as in\\nthe following (a function that calls another function, which calls back to its caller). The\\nnet effect is the same, though there are two function calls at each level instead of one:\\n>>> def mysum(L):\\n...     if not L: return 0\\n...     return nonempty(L)                  # Call a function that calls me\\n...\\n>>> def nonempty(L):\\n...     return L[0] + mysum(L[1:])          # Indirectly recursive\\n...\\n>>> mysum([1.1, 2.2, 3.3, 4.4])\\n11.0\\nLoop Statements Versus Recursion\\nThough recursion works for summing in the prior sections’ examples, it’s probably\\noverkill in this context. In fact, recursion is not used nearly as often in Python as in\\nmore esoteric languages like Prolog or Lisp, because Python emphasizes simpler pro-\\ncedural statements like loops, which are usually more natural. The while, for example,\\noften makes things a bit more concrete, and it doesn’t require that a function be defined\\nto allow recursive calls:\\n>>> L = [1, 2, 3, 4, 5]\\n>>> sum = 0\\n>>> while L:\\n...     sum += L[0]\\n...     L = L[1:]\\n...\\n>>> sum\\n15\\nBetter yet, for loops iterate for us automatically, making recursion largely extraneous\\nin most cases (and, in all likelihood, less efficient in terms of memory space and exe-\\ncution time):\\n>>> L = [1, 2, 3, 4, 5]\\n>>> sum = 0\\n>>> for x in L: sum += x\\n...\\n>>> sum\\n15\\nRecursive Functions | 467\", metadata={'source': 'python.pdf', 'page': 517}),\n",
       " Document(page_content='With looping statements, we don’t require a fresh copy of a local scope on the call stack\\nfor each iteration, \\nand we avoid the speed costs associated with function calls in general.\\n(Stay tuned for Chapter 20 ’s timer case study for ways to compare the execution times\\nof alternatives like these.)\\nHandling Arbitrary Structures\\nOn the other hand, recursion (or equivalent explicit stack-based algorithms, which\\nwe’ll finesse here) can be required to traverse arbitrarily shaped structures. As a simple\\nexample of recursion’s role in this context, consider the task of computing the sum of\\nall the numbers in a nested sublists structure like this:\\n[1, [2, [3, 4], 5], 6, [7, 8]]                   # Arbitrarily nested sublists\\nSimple looping statements won’t work here because this not a linear iteration. Nested\\nlooping statements do not suffice either, because the sublists may be nested to arbitrary\\ndepth and in an arbitrary shape. Instead, the following code accommodates such gen-\\neral nesting by using recursion to visit sublists along the way:\\ndef sumtree(L):\\n    tot = 0\\n    for x in L:                                  # For each item at this level\\n        if not isinstance(x, list):\\n            tot += x                             # Add numbers directly\\n        else:\\n            tot += sumtree(x)                    # Recur for sublists\\n    return tot\\nL = [1, [2, [3, 4], 5], 6, [7, 8]]               # Arbitrary nesting\\nprint(sumtree(L))                                # Prints 36\\n# Pathological cases\\nprint(sumtree([1, [2, [3, [4, [5]]]]]))          # Prints 15 (right-heavy)\\nprint(sumtree([[[[[1], 2], 3], 4], 5]))          # Prints 15 (left-heavy)\\nTrace through the test cases at the bottom of this script to see how recursion traverses\\ntheir nested lists. Although this example is artificial, it is representative of a larger class\\nof programs; inheritance trees and module import chains, for example, can exhibit\\nsimilarly general structures. In fact, we will use recursion again in such roles in more\\nrealistic examples later in this book:\\n• In Chapter 24’s reloadall.py, to traverse import chains\\n• In Chapter 28’s classtree.py, to traverse class inheritance trees\\n• In Chapter 30’s lister.py, to traverse class inheritance trees again\\n468 | Chapter 19: \\u2002Advanced Function Topics', metadata={'source': 'python.pdf', 'page': 518}),\n",
       " Document(page_content=\"Although you should generally prefer looping statements to recursion for linear itera-\\ntions on the \\ngrounds of simplicity and efficiency, we’ll find that recursion is essential\\nin scenarios like those in these later examples.\\nMoreover, you sometimes need to be aware of the potential of unintended recursion in\\nyour programs. As you’ll also see later in the book, some operator overloading methods\\nin classes such as __setattr__ and __getattribute__ have the potential to recursively\\nloop if used incorrectly. Recursion is a powerful tool, but it tends to be best when\\nexpected!\\nFunction Objects: Attributes and Annotations\\nPython functions are more flexible than you might think. As we’ve seen in this part of\\nthe book, functions in Python are much more than code-generation specifications for\\na compiler—Python functions are full-blown objects, stored in pieces of memory all\\ntheir own. As such, they can be freely passed around a program and called indirectly.\\nThey also support operations that have little to do with calls at all—attribute storage\\nand annotation.\\nIndirect Function Calls\\nBecause Python functions are objects, you can write programs that process them ge-\\nnerically. Function objects may be assigned to other names, passed to other functions,\\nembedded in data structures, returned from one function to another, and more, as if\\nthey were simple numbers or strings. Function objects also happen to support a special\\noperation: they can be called by listing arguments in parentheses after a function ex-\\npression. Still, functions belong to the same general category as other objects.\\nWe’ve seen some of these generic use cases for functions in earlier examples, but a quick\\nreview helps to underscore the object model. For example, there’s really nothing special\\nabout the name used in a def statement: it’s just a variable assigned in the current scope,\\nas if it had appeared on the left of an = sign. After a def runs, the function name is simply\\na reference to an object—you can reassign that object to other names freely and call it\\nthrough any reference:\\n>>> def echo(message):                   # Name echo assigned to function object\\n...     print(message)\\n...\\n>>> echo('Direct call')                  # Call object through original name\\nDirect call\\n>>> x = echo                             # Now x references the function too\\n>>> x('Indirect call!')                  # Call object through name by adding ()\\nIndirect call!\\nFunction Objects: Attributes and Annotations | 469\", metadata={'source': 'python.pdf', 'page': 519}),\n",
       " Document(page_content=\"Because arguments are passed by assigning objects, it’s just as easy to pass functions to\\nother \\nfunctions as arguments. The callee may then call the passed-in function just by\\nadding arguments in parentheses:\\n>>> def indirect(func, arg):\\n...     func(arg)                        # Call the passed-in object by adding ()\\n...\\n>>> indirect(echo, 'Argument call!')     # Pass the function to another function\\nArgument call!\\nYou can even stuff function objects into data structures, as though they were integers\\nor strings. The following, for example, embeds the function twice in a list of tuples, as\\na sort of actions table. Because Python compound types like these can contain any sort\\nof object, there’s no special case here, either:\\n>>> schedule = [ (echo, 'Spam!'), (echo, 'Ham!') ]\\n>>> for (func, arg) in schedule:\\n...     func(arg)                        # Call functions embedded in containers\\n...\\nSpam!\\nHam!\\nThis code simply steps through the schedule list, calling the echo function with one\\nargument each time through (notice the tuple-unpacking assignment in the for loop\\nheader, introduced in Chapter 13). As we saw in Chapter 17’s examples, functions can\\nalso be created and returned for use elsewhere:\\n>>> def make(label):                     # Make a function but don't call it\\n...     def echo(message):\\n...         print(label + ':' + message)\\n...     return echo\\n...\\n>>> F = make('Spam')                     # Label in enclosing scope is retained\\n>>> F('Ham!')                            # Call the function that make returned\\nSpam:Ham!\\n>>> F('Eggs!')\\nSpam:Eggs!\\nPython’s universal object model and lack of type declarations make for an incredibly\\nflexible programming language.\\nFunction Introspection\\nBecause they are objects, we can also process functions with normal object tools. In\\nfact, functions are more flexible than you might expect. For instance, once we make a\\nfunction, we can call it as usual:\\n>>> def func(a):\\n...     b = 'spam'\\n...     return b * a\\n...\\n>>> func(8)\\n'spamspamspamspamspamspamspamspam'\\n470 | Chapter 19: \\u2002Advanced Function Topics\", metadata={'source': 'python.pdf', 'page': 520}),\n",
       " Document(page_content='But the call expression is just one operation defined to work on function objects. We\\ncan also inspect \\ntheir attributes generically (the following is run in Python 3.0, but 2.6\\nresults are similar):\\n>>> func.__name__\\n\\'func\\'\\n>>> dir(func)\\n[\\'__annotations__\\', \\'__call__\\', \\'__class__\\', \\'__closure__\\', \\'__code__\\',\\n...more omitted...\\n\\'__repr__\\', \\'__setattr__\\', \\'__sizeof__\\', \\'__str__\\', \\'__subclasshook__\\']\\nIntrospection tools allow us to explore implementation details too—functions have\\nattached code objects , for example, which provide details on aspects such as the func-\\ntions’ local variables and arguments:\\n>>> func.__code__\\n<code object func at 0x0257C9B0, file \"<stdin>\", line 1>\\n>>> dir(func.__code__)\\n[\\'__class__\\', \\'__delattr__\\', \\'__doc__\\', \\'__eq__\\', \\'__format__\\', \\'__ge__\\',\\n...more omitted...\\n\\'co_argcount\\', \\'co_cellvars\\', \\'co_code\\', \\'co_consts\\', \\'co_filename\\',\\n\\'co_firstlineno\\', \\'co_flags\\', \\'co_freevars\\', \\'co_kwonlyargcount\\', \\'co_lnotab\\',\\n\\'co_name\\', \\'co_names\\', \\'co_nlocals\\', \\'co_stacksize\\', \\'co_varnames\\']\\n>>> func.__code__.co_varnames\\n(\\'a\\', \\'b\\')\\n>>> func.__code__.co_argcount\\n1\\nTool writers can make use of such information to manage functions (in fact, we will\\ntoo in Chapter 38, to implement validation of function arguments in decorators).\\nFunction Attributes\\nFunction objects are not limited to the system-defined attributes listed in the prior\\nsection, though. As we learned in Chapter 17 , it’s possible to attach arbitrary user-\\ndefined attributes to them as well:\\n>>> func\\n<function func at 0x0257C738>\\n>>> func.count = 0\\n>>> func.count += 1\\n>>> func.count\\n1\\n>>> func.handles = \\'Button-Press\\'\\n>>> func.handles\\n\\'Button-Press\\'\\n>>> dir(func)\\n[\\'__annotations__\\', \\'__call__\\', \\'__class__\\', \\'__closure__\\', \\'__code__\\',\\n...more omitted...\\n__str__\\', \\'__subclasshook__\\', \\'count\\', \\'handles\\']\\nFunction Objects: Attributes and Annotations | 471', metadata={'source': 'python.pdf', 'page': 521}),\n",
       " Document(page_content=\"As we saw in that chapter, such attributes can be used to attach state information  to\\nfunction \\nobjects directly, instead of using other techniques such as globals, nonlocals,\\nand classes. Unlike nonlocals, such attributes are accessible anywhere the function itself\\nis. In a sense, this is also a way to emulate “static locals” in other languages—variables\\nwhose names are local to a function, but whose values are retained after a function\\nexits. Attributes are related to objects instead of scopes, but the net effect is similar.\\nFunction Annotations in 3.0\\nIn Python 3.0 (but not 2.6), it’s also possible to attach annotation information—\\narbitrary user-defined data about a function’s arguments and result—to a function\\nobject. Python provides special syntax for specifying annotations, but it doesn’t do\\nanything with them itself; annotations are completely optional, and when present are\\nsimply attached to the function object’s __annotations__ attribute for use by other\\ntools.\\nWe met Python 3.0’s keyword-only arguments in the prior chapter; annotations gen-\\neralize function header syntax further. Consider the following nonannotated function,\\nwhich is coded with three arguments and returns a result:\\n>>> def func(a, b, c):\\n...     return a + b + c\\n...\\n>>> func(1, 2, 3)\\n6\\nSyntactically, function annotations are coded in def header lines, as arbitrary expres-\\nsions associated with arguments and return values. For arguments, they appear after a\\ncolon immediately following the argument’s name; for return values, they are written\\nafter a -> following the arguments list. This code, for example, annotates all three of\\nthe prior function’s arguments, as well as its return value:\\n>>> def func(a: 'spam', b: (1, 10), c: float) -> int:\\n...     return a + b + c\\n...\\n>>> func(1, 2, 3)\\n6\\nCalls to an annotated function work as usual, but when annotations are present Python\\ncollects them in a dictionary and attaches it to the function object itself. Argument\\nnames become keys, the return value annotation is stored under key “return” if coded,\\nand the values of annotation keys are assigned to the results of the annotation\\nexpressions:\\n>>> func.__annotations__\\n{'a': 'spam', 'c': <class 'float'>, 'b': (1, 10), 'return': <class 'int'>}\\nBecause they are just Python objects attached to a Python object, annotations are\\nstraightforward to process. The following annotates just two of three arguments and\\nsteps through the attached annotations generically:\\n472 | Chapter 19: \\u2002Advanced Function Topics\", metadata={'source': 'python.pdf', 'page': 522}),\n",
       " Document(page_content=\">>> def func(a: 'spam', b, c: 99):\\n...     return a + b + c\\n...\\n>>> func(1, 2, 3)\\n6\\n>>> func.__annotations__\\n{'a': 'spam', 'c': 99}\\n>>> for arg in func.__annotations__:\\n...    print(arg, '=>', func.__annotations__[arg])\\n...\\na => spam\\nc => 99\\nThere are two \\nfine points to note here. First, you can still use defaults for arguments if\\nyou code annotations—the annotation (and its : character) appear before the default\\n(and its = character). In the following, for example, a: 'spam' = 4 means that argument\\na defaults to 4 and is annotated with the string 'spam':\\n>>> def func(a: 'spam' = 4, b: (1, 10) = 5, c: float = 6) -> int:\\n...     return a + b + c\\n...\\n>>> func(1, 2, 3)\\n6\\n>>> func()                       # 4 + 5 + 6   (all defaults)\\n15\\n>>> func(1, c=10)                # 1 + 5 + 10  (keywords work normally)\\n16\\n>>> func.__annotations__\\n{'a': 'spam', 'c': <class 'float'>, 'b': (1, 10), 'return': <class 'int'>}\\nSecond, note that the blank spaces  in the prior example are all optional—you can use\\nspaces between components in function headers or not, but omitting them might de-\\ngrade your code’s readability to some observers:\\n>>> def func(a:'spam'=4, b:(1,10)=5, c:float=6)->int:\\n...     return a + b + c\\n...\\n>>> func(1, 2)                   # 1 + 2 + 6\\n9\\n>>> func.__annotations__\\n{'a': 'spam', 'c': <class 'float'>, 'b': (1, 10), 'return': <class 'int'>}\\nAnnotations are a new feature in 3.0, and some of their potential uses remain to be\\nuncovered. It’s easy to imagine annotations being used to specify constraints for argu-\\nment types or values, though, and larger APIs might use this feature as a way to register\\nfunction interface information. In fact, we’ll see a potential application in Chap-\\nter 38, where we’ll look at annotations as an alternative to function decorator argu-\\nments (a more general concept in which information is coded outside the function\\nheader and so is not limited to a single role). Like Python itself, annotation is a tool\\nwhose roles are shaped by your imagination.\\nFunction Objects: Attributes and Annotations | 473\", metadata={'source': 'python.pdf', 'page': 523}),\n",
       " Document(page_content='Finally, note that annotations work only in def statements, not lambda  expressions,\\nbecause lambda’s syntax already limits the utility of the functions it defines. Coinci-\\ndentally, this brings us to our next topic.\\nAnonymous Functions: lambda\\nBesides the def statement, Python also provides an expression form that generates\\nfunction objects. Because of its similarity to a tool in the Lisp language, it’s called\\nlambda.* Like def, this expression creates a function to be called later, but it returns the\\nfunction instead of assigning it to a name. This is why lambdas are sometimes known\\nas anonymous (i.e., unnamed) functions. In practice, they are often used as a way to\\ninline a function definition, or to defer execution of a piece of code.\\nlambda Basics\\nThe lambda’s general form is the keyword lambda, followed by one or more arguments\\n(exactly like the arguments list you enclose in parentheses in a def header), followed\\nby an expression after a colon:\\nlambda argument1, argument2,... argumentN :expression using arguments\\nFunction objects returned by running lambda expressions work exactly the same as\\nthose created and assigned by defs, but there are a few differences that make lambdas\\nuseful in specialized roles:\\n•lambda is an expression, not a statement. Because of this, a lambda can appear in\\nplaces a def is not allowed by Python’s syntax—inside a list literal or a function\\ncall’s arguments, for example. As an expression, lambda returns a value (a new\\nfunction) that can optionally be assigned a name. In contrast, the def statement\\nalways assigns the new function to the name in the header, instead of returning it\\nas a result.\\n•lambda’s body is a single expression, not a block of statements . The lambda’s\\nbody is similar to what you’d put in a def body’s return statement; you simply type\\nthe result as a naked expression, instead of explicitly returning it. Because it is\\nlimited to an expression, a lambda is less general than a def—you can only squeeze\\nso much logic into a lambda body without using statements such as if. This is by\\ndesign, to limit program nesting: lambda is designed for coding simple functions,\\nand def handles larger tasks.\\n* The lambda tends to intimidate people more than it should. This reaction seems to stem from the name\\n“lambda” itself—a name that comes from the Lisp language, which got it from lambda calculus, which is a\\nform of symbolic logic. In Python, though, it’s really just a keyword that introduces the expression\\nsyntactically. Obscure mathematical heritage aside, lambda is simpler to use than you may think.\\n474 | Chapter 19: \\u2002Advanced Function Topics', metadata={'source': 'python.pdf', 'page': 524}),\n",
       " Document(page_content='Apart from those distinctions, defs and lambdas do the same sort of work. For instance,\\nwe’ve seen how to make a function with a def statement:\\n>>> def func(x, y, z): return x + y + z\\n...\\n>>> func(2, 3, 4)\\n9\\nBut you can achieve the same effect with a lambda expression by explicitly assigning its\\nresult to a name through which you can later call the function:\\n>>> f = lambda x, y, z: x + y + z\\n>>> f(2, 3, 4)\\n9\\nHere, f is assigned the function object the lambda expression creates; this is how def\\nworks, too, but its assignment is automatic.\\nDefaults work on lambda arguments, just like in a def:\\n>>> x = (lambda a=\"fee\", b=\"fie\", c=\"foe\": a + b + c)\\n>>> x(\"wee\")\\n\\'weefiefoe\\'\\nThe code in a lambda body also follows the same scope lookup rules as code inside a\\ndef. lambda expressions introduce a local scope much like a nested def, which auto-\\nmatically sees names in enclosing functions, the module, and the built-in scope (via the\\nLEGB rule):\\n>>> def knights():\\n...     title = \\'Sir\\'\\n...     action = (lambda x: title + \\' \\' + x)        # Title in enclosing def\\n...     return action                               # Return a function\\n...\\n>>> act = knights()\\n>>> act(\\'robin\\')\\n\\'Sir robin\\'\\nIn this example, prior to Release 2.2, the value for the name title would typically have\\nbeen passed in as a default argument value instead; flip back to the scopes coverage in\\nChapter 17 if you’ve forgotten why.\\nWhy Use lambda?\\nGenerally speaking, lambdas come in handy as a sort of function shorthand that allows\\nyou to embed a function’s definition within the code that uses it. They are entirely\\noptional (you can always use defs instead), but they tend to be simpler coding con-\\nstructs in scenarios where you just need to embed small bits of executable code.\\nFor instance, we’ll see later that callback handlers are frequently coded as inline\\nlambda expressions embedded directly in a registration call’s arguments list, instead of\\nbeing defined with a def elsewhere in a file and referenced by name (see the sidebar\\n“Why You Will Care: Callbacks” on page 479 for an example).\\nAnonymous Functions: lambda | 475', metadata={'source': 'python.pdf', 'page': 525}),\n",
       " Document(page_content=\"lambdas are also commonly used to code jump tables , which are lists or dictionaries of\\nactions to be performed on demand. For example:\\nL = [lambda x: x ** 2,               # Inline function definition\\n     lambda x: x ** 3,\\n     lambda x: x ** 4]               \\n# A list of 3 callable functions\\nfor f in L:\\n    print(f(2))                      # Prints 4, 8, 16\\nprint(L[0](3))                       # Prints 9\\nThe lambda expression is most useful as a shorthand for def, when you need to stuff\\nsmall pieces of executable code into places where statements are illegal syntactically.\\nThis code snippet, for example, builds up a list of three functions by embedding\\nlambda expressions inside a list literal; a def won’t work inside a list literal like this\\nbecause it is a statement, not an expression. The equivalent def coding would require\\ntemporary function names and function definitions outside the context of intended use:\\ndef f1(x): return x ** 2\\ndef f2(x): return x ** 3             # Define named functions\\ndef f3(x): return x ** 4\\nL = [f1, f2, f3]                     # Reference by name\\nfor f in L:\\n    print(f(2))                      # Prints 4, 8, 16\\nprint(L[0](3))                       # Prints 9\\nIn fact, you can do the same sort of thing with dictionaries and other data structures\\nin Python to build up more general sorts of action tables. Here’s another example to\\nillustrate, at the interactive prompt:\\n>>> key = 'got'\\n>>> {'already': (lambda: 2 + 2),\\n...  'got':     (lambda: 2 * 4),\\n...  'one':     (lambda: 2 ** 6)}[key]()\\n8\\nHere, when Python makes the temporary dictionary, each of the nested lambdas gen-\\nerates and leaves behind a function to be called later. Indexing by key fetches one of\\nthose functions, and parentheses force the fetched function to be called. When coded\\nthis way, a dictionary becomes a more general multiway branching tool than what I\\ncould show you in Chapter 12’s coverage of if statements.\\nTo make this work without lambda, you’d need to instead code three def statements\\nsomewhere else in your file, outside the dictionary in which the functions are to be\\nused, and reference the functions by name:\\n>>> def f1(): return 2 + 2\\n...\\n>>> def f2(): return 2 * 4\\n...\\n476 | Chapter 19: \\u2002Advanced Function Topics\", metadata={'source': 'python.pdf', 'page': 526}),\n",
       " Document(page_content=\">>> def f3(): return 2 ** 6\\n...\\n>>> key = 'one'\\n>>> {'already': f1, 'got': f2, 'one': f3}[key]()\\n64\\nThis works, too, but your defs may be \\narbitrarily far away in your file, even if they are\\njust little bits of code. The code proximity  that lambdas provide is especially useful for\\nfunctions that will only be used in a single context—if the three functions here are not\\nuseful anywhere else, it makes sense to embed their definitions within the dictionary\\nas lambdas. Moreover, the def form requires you to make up names for these little\\nfunctions that may clash with other names in this file (perhaps unlikely, but always\\npossible).\\nlambdas also come in handy in function-call argument lists as a way to inline temporary\\nfunction definitions not used anywhere else in your program; we’ll see some examples\\nof such other uses later in this chapter, when we study map.\\nHow (Not) to Obfuscate Your Python Code\\nThe fact that the body of a lambda has to be a single expression (not a series of state-\\nments) would seem to place severe limits on how much logic you can pack into a\\nlambda. If you know what you’re doing, though, you can code most statements in Py-\\nthon as expression-based equivalents.\\nFor example, if you want to print from the body of a lambda function, simply say\\nsys.stdout.write(str(x)+'\\\\n'), instead of print(x) (recall from Chapter 11  that this\\nis what print really does). Similarly, to nest logic in a lambda, you can use the if/else\\nternary expression introduced in Chapter 12, or the equivalent but trickier and/or com-\\nbination also described there. As you learned earlier, the following statement:\\nif a:\\n    b\\nelse:\\n    c\\ncan be emulated by either of these roughly equivalent expressions:\\nb if a else c\\n((a and b) or c)\\nBecause expressions like these can be placed inside a lambda, they may be used to im-\\nplement selection logic within a lambda function:\\n>>> lower = (lambda x, y: x if x < y else y)\\n>>> lower('bb', 'aa')\\n'aa'\\n>>> lower('aa', 'bb')\\n'aa'\\nAnonymous Functions: lambda | 477\", metadata={'source': 'python.pdf', 'page': 527}),\n",
       " Document(page_content=\"Furthermore, if you need to perform loops within a lambda, you can also embed things\\nlike map calls and list comprehension expressions (tools we met in earlier chapters and\\nwill revisit in this and the next chapter):\\n>>> import sys\\n>>> showall = lambda x: list(map(sys.stdout.write, x))        # Use list in 3.0\\n>>> t = showall(['spam\\\\n', 'toast\\\\n', 'eggs\\\\n'])\\nspam\\ntoast\\neggs\\n>>> showall = lambda x: [sys.stdout.write(line) for line in x]\\n>>> t = showall(('bright\\\\n', 'side\\\\n', 'of\\\\n', 'life\\\\n'))\\nbright\\nside\\nof\\nlife\\nNow that I’ve shown you these tricks, I am required by law to ask you to please only\\nuse them as a last resort. Without due care, they can lead to unreadable (a.k.a. obfus-\\ncated) Python code. In general, simple is better than complex, explicit is better than\\nimplicit, and full statements are better than arcane expressions. That’s why lambda is\\nlimited to expressions. If you have larger logic to code, use def; lambda is for small pieces\\nof inline code. On the other hand, you may find these techniques useful in moderation.\\nNested lambdas and Scopes\\nlambdas are the main beneficiaries of nested function scope lookup (the E in the LEGB\\nscope rule we studied in Chapter 17 ). In the following, for example, the lambda appears\\ninside a def—the typical case—and so can access the value that the name x had in the\\nenclosing function’s scope at the time that the enclosing function was called:\\n>>> def action(x):\\n...     return (lambda y: x + y)         # Make and return function, remember x\\n...\\n>>> act = action(99)\\n>>> act\\n<function <lambda> at 0x00A16A88>\\n>>> act(2)                               # Call what action returned\\n101\\nWhat wasn’t illustrated in the prior discussion of nested function scopes is that a\\nlambda also has access to the names in any enclosing lambda. This case is somewhat\\nobscure, but imagine if we recoded the prior def with a lambda:\\n>>> action = (lambda x: (lambda y: x + y))\\n>>> act = action(99)\\n>>> act(3)\\n102\\n478 | Chapter 19: \\u2002Advanced Function Topics\", metadata={'source': 'python.pdf', 'page': 528}),\n",
       " Document(page_content='>>> ((lambda x: (lambda y: x + y))(99))(4)\\n103\\nHere, the nested lambda\\n structure makes a function that makes a function when called.\\nIn both cases, the nested lambda’s code has access to the variable x in the enclosing\\nlambda. This works, but it’s fairly convoluted code; in the interest of readability, nested\\nlambdas are generally best avoided.\\nWhy You Will Care: Callbacks\\nAnother very common \\napplication of lambda is to define inline callback functions for\\nPython’s tkinter GUI API (this module is named Tkinter in Python 2.6). For example,\\nthe following creates a button that prints a message on the console when pressed, as-\\nsuming tkinter is available on your computer (it is by default on Windows and other\\nOSs):\\nimport sys\\nfrom tkinter import Button, mainloop     # Tkinter in 2.6\\nx = Button(\\n        text =\\'Press me\\',\\n        command=(lambda:sys.stdout.write(\\'Spam\\\\n\\')))\\nx.pack()\\nmainloop()\\nHere, the callback handler is registered by passing a function generated with a lambda\\nto the command keyword argument. The advantage of lambda over def here is that the\\ncode that handles a button press is right here, embedded in the button-creation call.\\nIn effect, the lambda defers execution of the handler until the event occurs: the write\\ncall happens on button presses, not when the button is created.\\nBecause the nested function scope rules apply to lambdas as well, they are also easier to\\nuse as callback handlers, as of Python 2.2—they automatically see names in the func-\\ntions in which they are coded and no longer require passed-in defaults in most cases.\\nThis is especially handy for accessing the special self instance argument that is a local\\nvariable in enclosing class method functions (more on classes in Part VI):\\nclass MyGui:\\n    def makewidgets(self):\\n        Button(command=(lambda: self.onPress(\"spam\")))\\n    def onPress(self, message):\\n        ...use message...\\nIn prior releases, even self had to be passed in to a lambda with defaults.\\nMapping Functions over Sequences: map\\nOne of the more \\ncommon things programs do with lists and other sequences is apply\\nan operation to each item and collect the results. For instance, updating all the counters\\nin a list can be done easily with a for loop:\\nMapping Functions over Sequences: map | 479', metadata={'source': 'python.pdf', 'page': 529}),\n",
       " Document(page_content='>>> counters = [1, 2, 3, 4]\\n>>>\\n>>> updated = []\\n>>> for x in counters:\\n...     updated.append(x + 10)                 # Add 10 to each item\\n...\\n>>> updated\\n[11, 12, 13, 14]\\nBut because this \\nis such a common operation, Python actually provides a built-in that\\ndoes most of the work for you. The map function applies a passed-in function to each\\nitem in an iterable object and returns a list containing all the function call results. For\\nexample:\\n>>> def inc(x): return x + 10                  # Function to be run\\n...\\n>>> list(map(inc, counters))                   # Collect results\\n[11, 12, 13, 14]\\nWe met map briefly in Chapters 13 and 14, as a way to apply a built-in function to items\\nin an iterable. Here, we make better use of it by passing in a user-defined function to\\nbe applied to each item in the list— map calls inc on each list item and collects all the\\nreturn values into a new list. Remember that map is an iterable in Python 3.0, so a\\nlist call is used to force it to produce all its results for display here; this isn’t necessary\\nin 2.6.\\nBecause map expects a function to be passed in, it also happens to be one of the places\\nwhere lambda commonly appears:\\n>>> list(map((lambda x: x + 3), counters))     # Function expression\\n[4, 5, 6, 7]\\nHere, the function adds 3 to each item in the counters list; as this little function isn’t\\nneeded elsewhere, it was written inline as a lambda. Because such uses of map are equiv-\\nalent to for loops, with a little extra code you can always code a general mapping utility\\nyourself:\\n>>> def mymap(func, seq):\\n...     res = []\\n...     for x in seq: res.append(func(x))\\n...     return res\\nAssuming the function inc is still as it was when it was shown previously, we can map\\nit across a sequence with the built-in or our equivalent:\\n>>> list(map(inc, [1, 2, 3]))             # Built-in is an iterator\\n[11, 12, 13]\\n>>> mymap(inc, [1, 2, 3])                 # Ours builds a list (see generators)\\n[11, 12, 13]\\nHowever, as map is a built-in, it’s always available, always works the same way, and has\\nsome performance benefits (as we’ll prove in the next chapter, it’s usually faster than\\na manually coded for loop). Moreover, map can be used in more advanced ways than\\n480 | Chapter 19: \\u2002Advanced Function Topics', metadata={'source': 'python.pdf', 'page': 530}),\n",
       " Document(page_content='shown here. For instance, given multiple sequence arguments, it sends items taken from\\nsequences in parallel as distinct arguments to the function:\\n>>> pow(3, 4)                             # 3**4\\n81\\n>>> list(map(pow, [1, 2, 3], [2, 3, 4]))  # 1**2, 2**3, 3**4\\n[1, 8, 81]\\nWith multiple sequences, map\\n expects an N-argument function for N sequences. Here,\\nthe pow function takes two arguments on each call—one from each sequence passed to\\nmap. It’s not much extra work to simulate this multiple-sequence generality in code,\\ntoo, but we’ll postpone doing so until later in the next chapter, after we’ve met some\\nadditional iteration tools.\\nThe map call is similar to the list comprehension expressions we studied in Chap-\\nter 14 and will meet again in the next chapter, but map applies a function call to each\\nitem instead of an arbitrary expression. Because of this limitation, it is a somewhat less\\ngeneral tool. However, in some cases map may be faster to run than a list comprehension\\n(e.g., when mapping a built-in function), and it may also require less coding.\\nFunctional Programming Tools: filter and reduce\\nThe map function is the simplest representative of a class of Python built-ins used for\\nfunctional programming —tools that apply functions to sequences and other iterables.\\nIts relatives filter out items based on a test function ( filter) and apply functions to\\npairs of items and running results ( reduce). Because they return iterables, range and\\nfilter both require list calls to display all their results in 3.0. For example, the fol-\\nlowing filter call picks out items in a sequence that are greater than zero:\\n>>> list(range(−5, 5))                                   # An iterator in 3.0\\n[−5, −4, −3, −2, −1, 0, 1, 2, 3, 4]\\n>>> list(filter((lambda x: x > 0), range(−5, 5)))        # An iterator in 3.0\\n[1, 2, 3, 4]\\nItems in the sequence or iterable for which the function returns a true result are added\\nto the result list. Like map, this function is roughly equivalent to a for loop, but it is\\nbuilt-in and fast:\\n>>> res = []\\n>>> for x in range(−5, 5):\\n...     if x > 0:\\n...         res.append(x)\\n...\\n>>> res\\n[1, 2, 3, 4]\\nreduce, which is a simple built-in function in 2.6 but lives in the functools module in\\n3.0, is more complex. It accepts an iterator to process, but it’s not an iterator itself—it\\nFunctional Programming Tools: filter and reduce | 481', metadata={'source': 'python.pdf', 'page': 531}),\n",
       " Document(page_content='returns a single result. Here are two reduce calls that compute the sum and product of\\nthe items in a list:\\n>>> from functools import reduce      # Import in 3.0, not in 2.6\\n>>> reduce((lambda x, y: x + y), [1, 2, 3, 4])\\n10\\n>>> reduce((lambda x, y: x * y), [1, 2, 3, 4])\\n24\\nAt each step, reduce passes the current sum or product, along with the next item from\\nthe list, to the passed-in lambda function. By default, the first item in the sequence\\ninitializes the starting value. To illustrate, here’s the for loop equivalent to the first of\\nthese calls, with the addition hardcoded inside the loop:\\n>>> L = [1,2,3,4]\\n>>> res = L[0]\\n>>> for x in L[1:]:\\n...     res = res + x\\n...\\n>>> res\\n10\\nCoding your own version of reduce is actually fairly straightforward. The following\\nfunction emulates most of the built-in’s behavior and helps demystify its operation in\\ngeneral:\\n>>> def myreduce(function, sequence):\\n...     tally = sequence[0]\\n...     for next in sequence[1:]:\\n...         tally = function(tally, next)\\n...     return tally\\n...\\n>>> myreduce((lambda x, y: x + y), [1, 2, 3, 4, 5])\\n15\\n>>> myreduce((lambda x, y: x * y), [1, 2, 3, 4, 5])\\n120\\nThe built-in reduce also allows an optional third argument placed before the items in\\nthe sequence to serve as a default result when the sequence is empty, but we’ll leave\\nthis extension as a suggested exercise.\\nIf this coding technique has sparked your interest, you might also be interested in the\\nstandard library operator module, which provides functions that correspond to built-\\nin expressions and so comes in handy for some uses of functional tools (see Python’s\\nlibrary manual for more details on this module):\\n>>> import operator, functools\\n>>> functools.reduce(operator.add, [2, 4, 6])        # Function-based +\\n12\\n>>> functools.reduce((lambda x, y: x + y), [2, 4, 6])\\n12\\n482 | Chapter 19: \\u2002Advanced Function Topics', metadata={'source': 'python.pdf', 'page': 532}),\n",
       " Document(page_content='Together with map, filter and reduce support powerful functional programming tech-\\nniques. Some observers might also extend the functional programming toolset in Py-\\nthon to include lambda, discussed earlier, as well as list comprehensions—a topic we\\nwill return to in the next chapter.\\nChapter Summary\\nThis chapter took us on a tour of advanced function-related concepts: recursive func-\\ntions; function annotations; lambda expression functions; functional tools such as map,\\nfilter, and reduce; and general function design ideas. The next chapter continues the\\nadvanced topics motif with a look at generators and a reprisal of iterators and list com-\\nprehensions—tools that are just as related to functional programming as to looping\\nstatements. Before you move on, though, make sure you’ve mastered the concepts\\ncovered here by working through this chapter’s quiz.\\nTest Your Knowledge: Quiz\\n1. How are lambda\\n expressions and def statements related?\\n2. What’s the point of using lamba?\\n3. Compare and contrast map, filter, and reduce.\\n4. What are function annotations, and how are they used?\\n5. What are recursive functions, and how are they used?\\n6. What are some general design guidelines for coding functions?\\nTest Your Knowledge: Answers\\n1. Both lambda and def create function objects to be called later. Because lambda is an\\nexpression, though, it returns a function object instead of assigning it to a name,\\nand it can be used to nest a function definition in places where a def will not work\\nsyntactically. A lambda only allows for a single implicit return value expression,\\nthough; because it does not support a block of statements, it is not ideal for larger\\nfunctions.\\n2.lambdas allow us to “inline” small units of executable code, defer its execution, and\\nprovide it with state in the form of default arguments and enclosing scope variables.\\nUsing a lambda is never required; you can always code a def instead and reference\\nthe function by name. lambdas come in handy, though, to embed small pieces of\\ndeferred code that are unlikely to be used elsewhere in a program. They commonly\\nappear in callback-based program such as GUIs, and they have a natural affinity\\nwith function tools like map and filter that expect a processing function.\\nTest Your Knowledge: Answers | 483', metadata={'source': 'python.pdf', 'page': 533}),\n",
       " Document(page_content='3. These three built-in functions all apply another function to items in a sequence\\n(iterable) object \\nand collect results. map passes each item to the function and collects\\nall results, filter collects items for which the function returns a True value, and\\nreduce computes a single value by applying the function to an accumulator and\\nsuccessive items. Unlike the other two, reduce is available in the functools module\\nin 3.0, not the built-in scope.\\n4. Function annotations, available in 3.0 and later, are syntactic embellishments of a\\nfunction’s arguments and result, which are collected into a dictionary assigned to\\nthe function’s __annotations__ attribute. Python places no semantic meaning on\\nthese annotations, but simply packages them for potential use by other tools.\\n5. Recursive functions call themselves either directly or indirectly in order to loop.\\nThey may be used to traverse arbitrarily shaped structures, but they can also be\\nused for iteration in general (though the latter role is often more simply and effi-\\nciently coded with looping statements).\\n6. Functions should generally be small, as self-contained as possible, have a single\\nunified purpose, and communicate with other components through input argu-\\nments and return values. They may use mutable arguments to communicate results\\ntoo if changes are expected, and some types of programs imply other communi-\\ncation mechanisms.\\n484 | Chapter 19: \\u2002Advanced Function Topics', metadata={'source': 'python.pdf', 'page': 534}),\n",
       " Document(page_content='CHAPTER 20\\nIterations and Comprehensions, Part 2\\nThis chapter continues the advanced function topics theme, with a reprisal of the com-\\nprehension and iteration \\nconcepts introduced in Chapter 14 . Because list comprehen-\\nsions are as much related to the prior chapter’s functional tools (e.g., map and filter)\\nas they are to for loops, we’ll revisit them in this context here. We’ll also take a second\\nlook at iterators in order to study generator functions and their generator expression\\nrelatives—user-defined ways to produce results on demand.\\nIteration in Python also encompasses user-defined classes, but we’ll defer that final part\\nof this story until Part VI , when we study operator overloading. As this is the last pass\\nwe’ll make over built-in iteration tools, though, we will summarize the various tools\\nwe’ve met thus far, and time the relative performance of some of them. Finally, because\\nthis is the last chapter in the part of the book, we’ll close with the usual sets of “gotchas”\\nand exercises to help you start coding the ideas you’ve read about.\\nList Comprehensions Revisited: Functional Tools\\nIn the prior chapter, we studied functional programming tools like map and filter,\\nwhich map operations over sequences and collect results. Because this is such a com-\\nmon task in Python coding, Python eventually sprouted a new expression—the list\\ncomprehension—that is even more flexible than the tools we just studied. In short, list\\ncomprehensions apply an arbitrary expression to items in an iterable, rather than ap-\\nplying a function. As such, they can be more general tools.\\nWe met list comprehensions in Chapter 14, in conjunction with looping statements.\\nBecause they’re also related to functional programming tools like the map and filter\\ncalls, though, we’ll resurrect the topic here for one last look. Technically, this feature\\nis not tied to functions—as we’ll see, list comprehensions can be a more general tool\\nthan map and filter—but it is sometimes best understood by analogy to function-based\\nalternatives.\\n485', metadata={'source': 'python.pdf', 'page': 535}),\n",
       " Document(page_content=\"List Comprehensions Versus map\\nLet’s work through \\nan example that demonstrates the basics. As we saw in Chap-\\nter 7, Python’s built-in ord function returns the ASCII integer code of a single character\\n(the chr built-in is the converse—it returns the character for an ASCII integer code):\\n>>> ord('s')\\n115\\nNow, suppose we wish to collect the ASCII codes of all characters in an entire string.\\nPerhaps the most straightforward approach is to use a simple for loop and append the\\nresults to a list:\\n>>> res = []\\n>>> for x in 'spam':\\n...     res.append(ord(x))\\n...\\n>>> res\\n[115, 112, 97, 109]\\nNow that we know about map, though, we can achieve similar results with a single\\nfunction call without having to manage list construction in the code:\\n>>> res = list(map(ord, 'spam'))          # Apply function to sequence\\n>>> res\\n[115, 112, 97, 109]\\nHowever, we can get the same results from a list comprehension expression—while\\nmap maps a function over a sequence, list comprehensions map an expression over a\\nsequence:\\n>>> res = [ord(x) for x in 'spam']        # Apply expression to sequence\\n>>> res\\n[115, 112, 97, 109]\\nList comprehensions collect the results of applying an arbitrary expression to a se-\\nquence of values and return them in a new list. Syntactically, list comprehensions are\\nenclosed in square brackets (to remind you that they construct lists). In their simple\\nform, within the brackets you code an expression that names a variable followed by\\nwhat looks like a for loop header that names the same variable. Python then collects\\nthe expression’s results for each iteration of the implied loop.\\nThe effect of the preceding example is similar to that of the manual for loop and the\\nmap call. List comprehensions become more convenient, though, when we wish to apply\\nan arbitrary expression to a sequence:\\n>>> [x ** 2 for x in range(10)]\\n[0, 1, 4, 9, 16, 25, 36, 49, 64, 81]\\nHere, we’ve collected the squares of the numbers 0 through 9 (we’re just letting the\\ninteractive prompt print the resulting list; assign it to a variable if you need to retain\\nit). To do similar work with a map call, we would probably need to invent a little function\\nto implement the square operation. Because we won’t need this function elsewhere,\\n486 | Chapter 20: \\u2002Iterations and Comprehensions, Part 2\", metadata={'source': 'python.pdf', 'page': 536}),\n",
       " Document(page_content='we’d typically (but not necessarily) code it inline, with a lambda, instead of using a\\ndef statement elsewhere:\\n>>> list(map((lambda x: x ** 2), range(10)))\\n[0, 1, 4, 9, 16, 25, 36, 49, 64, 81]\\nThis does the same job, and it’s only a few keystrokes longer than the equivalent list\\ncomprehension. It’s also only marginally more complex (at least, once you understand\\nthe lambda). For more advanced kinds of expressions, though, list comprehensions will\\noften require considerably less typing. The next section shows why.\\nAdding Tests and Nested Loops: filter\\nList comprehensions are even more general than shown so far. For instance, as we\\nlearned in Chapter 14 , you can code an if clause after the for to add selection logic.\\nList comprehensions with if clauses can be thought of as analogous to the filter built-\\nin discussed in the prior chapter—they skip sequence items for which the if clause is\\nnot true.\\nTo demonstrate, here are both schemes picking up even numbers from 0 to 4; like the\\nmap list comprehension alternative of the prior section, the filter version here must\\ninvent a little lambda function for the test expression. For comparison, the equivalent\\nfor loop is shown here as well:\\n>>> [x for x in range(5) if x % 2 == 0]\\n[0, 2, 4]\\n>>> list(filter((lambda x: x % 2 == 0), range(5)))\\n[0, 2, 4]\\n>>> res = []\\n>>> for x in range(5):\\n...     if x % 2 == 0:\\n...         res.append(x)\\n...\\n>>> res\\n[0, 2, 4]\\nAll of these use the modulus (remainder of division) operator, %, to detect even numbers:\\nif there is no remainder after dividing a number by 2, it must be even. The filter call\\nhere is not much longer than the list comprehension either. However, we can combine\\nan if clause and an arbitrary expression in our list comprehension, to give it the effect\\nof a filter and a map, in a single expression:\\n>>> [x ** 2 for x in range(10) if x % 2 == 0]\\n[0, 4, 16, 36, 64]\\nThis time, we collect the squares of the even numbers from 0 through 9: the for loop\\nskips numbers for which the attached if clause on the right is false, and the expression\\non the left computes the squares. The equivalent map call would require a lot more work\\nList Comprehensions Revisited: Functional Tools | 487', metadata={'source': 'python.pdf', 'page': 537}),\n",
       " Document(page_content=\"on our part—we would have to combine filter selections with map iteration, making\\nfor a noticeably more complex expression:\\n>>> list( map((lambda x: x**2), filter((lambda x: x % 2 == 0), range(10))) )\\n[0, 4, 16, 36, 64]\\nIn fact, list \\ncomprehensions are more general still. You can code any number of nested\\nfor loops in a list comprehension, and each may have an optional associated if test.\\nThe general structure of list comprehensions looks like this:\\n[ expression for target1 in iterable1 [if condition1]\\n             for target2 in iterable2 [if condition2] ...\\n             for targetN in iterableN [if conditionN] ]\\nWhen for clauses are nested within a list comprehension, they work like equivalent\\nnested for loop statements. For example, the following:\\n>>> res = [x + y for x in [0, 1, 2] for y in [100, 200, 300]]\\n>>> res\\n[100, 200, 300, 101, 201, 301, 102, 202, 302]\\nhas the same effect as this substantially more verbose equivalent:\\n>>> res = []\\n>>> for x in [0, 1, 2]:\\n...     for y in [100, 200, 300]:\\n...         res.append(x + y)\\n...\\n>>> res\\n[100, 200, 300, 101, 201, 301, 102, 202, 302]\\nAlthough list comprehensions construct lists, remember that they can iterate over any\\nsequence or other iterable type. Here’s a similar bit of code that traverses strings instead\\nof lists of numbers, and so collects concatenation results:\\n>>> [x + y for x in 'spam' for y in 'SPAM']\\n['sS', 'sP', 'sA', 'sM', 'pS', 'pP', 'pA', 'pM',\\n'aS', 'aP', 'aA', 'aM', 'mS', 'mP', 'mA', 'mM']\\nFinally, here is a much more complex list comprehension that illustrates the effect of\\nattached if selections on nested for clauses:\\n>>> [(x, y) for x in range(5) if x % 2 == 0 for y in range(5) if y % 2 == 1]\\n[(0, 1), (0, 3), (2, 1), (2, 3), (4, 1), (4, 3)]\\nThis expression permutes even numbers from 0 through 4 with odd numbers from 0\\nthrough 4. The if clauses filter out items in each sequence iteration. Here is the equiv-\\nalent statement-based code:\\n>>> res = []\\n>>> for x in range(5):\\n...     if x % 2 == 0:\\n...         for y in range(5):\\n...             if y % 2 == 1:\\n...                 res.append((x, y))\\n...\\n488 | Chapter 20: \\u2002Iterations and Comprehensions, Part 2\", metadata={'source': 'python.pdf', 'page': 538}),\n",
       " Document(page_content='>>> res\\n[(0, 1), (0, 3), (2, 1), (2, 3), (4, 1), (4, 3)]\\nRecall that if \\nyou’re confused about what a complex list comprehension does, you can\\nalways nest the list comprehension’s for and if clauses inside each other (indenting\\nsuccessively further to the right) to derive the equivalent statements. The result is lon-\\nger, but perhaps clearer.\\nThe map and filter equivalent would be wildly complex and deeply nested, so I won’t\\neven try showing it here. I’ll leave its coding as an exercise for Zen masters, ex-Lisp\\nprogrammers, and the criminally insane....\\nList Comprehensions and Matrixes\\nNot all list comprehensions are so artificial, of course. Let’s look at one more applica-\\ntion to stretch a few synapses. One basic way to code matrixes (a.k.a. multidimensional\\narrays) in Python is with nested list structures. The following, for example, defines two\\n3 × 3 matrixes as lists of nested lists:\\n>>> M = [[1, 2, 3],\\n...      [4, 5, 6],\\n...      [7, 8, 9]]\\n>>> N = [[2, 2, 2],\\n...      [3, 3, 3],\\n...      [4, 4, 4]]\\nGiven this structure, we can always index rows, and columns within rows, using normal\\nindex operations:\\n>>> M[1]\\n[4, 5, 6]\\n>>> M[1][2]\\n6\\nList comprehensions are powerful tools for processing such structures, though, because\\nthey automatically scan rows and columns for us. For instance, although this structure\\nstores the matrix by rows, to collect the second column we can simply iterate across\\nthe rows and pull out the desired column, or iterate through positions in the rows and\\nindex as we go:\\n>>> [row[1] for row in M]\\n[2, 5, 8]\\n>>> [M[row][1] for row in (0, 1, 2)]\\n[2, 5, 8]\\nGiven positions, we can also easily perform tasks such as pulling out a diagonal. The\\nfollowing expression uses range to generate the list of offsets and then indexes with the\\nrow and column the same, picking out M[0][0], then M[1][1], and so on (we assume\\nthe matrix has the same number of rows and columns):\\nList Comprehensions Revisited: Functional Tools | 489', metadata={'source': 'python.pdf', 'page': 539}),\n",
       " Document(page_content='>>> [M[i][i] for i in range(len(M))]\\n[1, 5, 9]\\nFinally, with a \\nbit of creativity, we can also use list comprehensions to combine multiple\\nmatrixes. The following first builds a flat list that contains the result of multiplying the\\nmatrixes pairwise, and then builds a nested list structure having the same values by\\nnesting list comprehensions:\\n>>> [M[row][col] * N[row][col] for row in range(3) for col in range(3)]\\n[2, 4, 6, 12, 15, 18, 28, 32, 36]\\n>>> [[M[row][col] * N[row][col] for col in range(3)] for row in range(3)]\\n[[2, 4, 6], [12, 15, 18], [28, 32, 36]]\\nThis last expression works because the row iteration is an outer loop: for each row, it\\nruns the nested column iteration to build up one row of the result matrix. It’s equivalent\\nto this statement-based code:\\n>>> res = []\\n>>> for row in range(3):\\n...     tmp = []\\n...     for col in range(3):\\n...         tmp.append(M[row][col] * N[row][col])\\n...     res.append(tmp)\\n...\\n>>> res\\n[[2, 4, 6], [12, 15, 18], [28, 32, 36]]\\nCompared to these statements, the list comprehension version requires only one line\\nof code, will probably run substantially faster for large matrixes, and just might make\\nyour head explode! Which brings us to the next section.\\nComprehending List Comprehensions\\nWith such generality, list comprehensions can quickly become, well, incomprehensi-\\nble, especially when nested. Consequently, my advice is typically to use simple for\\nloops when getting started with Python, and map or comprehensions in isolated cases\\nwhere they are easy to apply. The “keep it simple” rule applies here, as always: code\\nconciseness is a much less important goal than code readability.\\nHowever, in this case, there is currently a substantial performance advantage to\\nthe extra complexity: based on tests run under Python today, map calls are roughly twice\\nas fast as equivalent for loops, and list comprehensions are usually slightly faster than\\nmap calls.* This speed difference is generally due to the fact that map and list\\n* These performance generalizations can depend on call patterns, as well as changes and optimizations in\\nPython itself. \\nRecent Python releases have sped up the simple for loop statement, for example. Usually,\\nthough, list comprehensions are still substantially faster than for loops and even faster than map (though\\nmap can still win for built-in functions). To time these alternatives yourself, see the standard library’s time\\nmodule’s time.clock and time.time calls, the newer timeit module added in Release 2.4, or this chapter’s\\nupcoming section “Timing Iteration Alternatives” on page 509.\\n490 | Chapter 20: \\u2002Iterations and Comprehensions, Part 2', metadata={'source': 'python.pdf', 'page': 540}),\n",
       " Document(page_content=\"comprehensions run at C language speed inside the interpreter, which is much faster\\nthan stepping through Python for loop code within the PVM.\\nBecause for loops make logic more explicit, I recommend them in general on the\\ngrounds of simplicity. However, map and list comprehensions are worth knowing and\\nusing for simpler kinds of iterations, and if your application’s speed is an important\\nconsideration. In addition, because map and list comprehensions are both expressions,\\nthey can show up syntactically in places that for loop statements cannot, such as in the\\nbodies of lambda functions, within list and dictionary literals, and more. Still, you should\\ntry to keep your map calls and list comprehensions simple; for more complex tasks, use\\nfull statements instead.\\nWhy You Will Care: List Comprehensions and map\\nHere’s a more \\nrealistic example of list comprehensions and map in action (we solved\\nthis problem with list comprehensions in Chapter 14, but we’ll revive it here to add\\nmap-based alternatives). Recall that the file readlines method returns lines with \\\\n end-\\nof-line characters at the ends:\\n>>> open('myfile').readlines()\\n['aaa\\\\n', 'bbb\\\\n', 'ccc\\\\n']\\nIf you don’t want the end-of-line characters, you can slice them off all the lines in a\\nsingle step with a list comprehension or a map call (map results are iterables in Python\\n3.0, so we must run them through list to see all their results at once):\\n>>> [line.rstrip() for line in open('myfile').readlines()]\\n['aaa', 'bbb', 'ccc']\\n>>> [line.rstrip() for line in open('myfile')]\\n['aaa', 'bbb', 'ccc']\\n>>> list(map((lambda line: line.rstrip()), open('myfile')))\\n['aaa', 'bbb', 'ccc']\\nThe last two of these make use of file iterators  (which essentially means that you don’t\\nneed a method call to grab all the lines in iteration contexts such as these). The map call\\nis slightly longer than the list comprehension, but neither has to manage result list\\nconstruction explicitly.\\nA list comprehension can also be used as a sort of column projection operation. Py-\\nthon’s standard SQL database API returns query results as a list of tuples much like the\\nfollowing—the list is the table, tuples are rows, and items in tuples are column values:\\nlistoftuple = [('bob', 35, 'mgr'), ('mel', 40, 'dev')]\\nA for loop could pick up all the values from a selected column manually, but map and\\nlist comprehensions can do it in a single step, and faster:\\n>>> [age for (name, age, job) in listoftuple]\\n[35, 40]\\n>>> list(map((lambda row: row[1]), listoftuple))\\n[35, 40]\\nList Comprehensions Revisited: Functional Tools | 491\", metadata={'source': 'python.pdf', 'page': 541}),\n",
       " Document(page_content='The first of these makes use of tuple assignment  to unpack row tuples in the list, and\\nthe second uses indexing. In Python 2.6 (but not in 3.0—see the note on 2.6 argument\\nunpacking in Chapter 18), map can use tuple unpacking on its argument, too:\\n# 2.6 only\\n>>> list(map((lambda (name, age, job): age), listoftuple))\\n[35, 40]\\nSee other books and resources for more on Python’s database API.\\nBeside the distinction between running functions versus expressions, the biggest dif-\\nference between map and list comprehensions in Python 3.0 is that map is an iterator,\\ngenerating results on demand; to achieve the same memory economy, list comprehen-\\nsions must be coded as generator expressions (one of the topics of this chapter).\\nIterators Revisited: Generators\\nPython today supports procrastination \\nmuch more than it did in the past—it provides\\ntools that produce results only when needed, instead of all at once. In particular, two\\nlanguage constructs delay result creation whenever possible:\\n•Generator functions  are coded as normal def statements but use yield statements\\nto return results one at a time, suspending and resuming their state between each.\\n•Generator expressions are similar to the list comprehensions of the prior section,\\nbut they return an object that produces results on demand instead of building a\\nresult list.\\nBecause neither constructs a result list all at once, they save memory space and allow\\ncomputation time to be split across result requests. As we’ll see, both of these ultimately\\nperform their delayed-results magic by implementing the iteration protocol  we studied\\nin Chapter 14.\\nGenerator Functions: yield Versus return\\nIn this part of the book, we’ve learned about coding normal functions that receive input\\nparameters and send back a single result immediately. It is also possible, however, to\\nwrite functions that may send back a value and later be resumed, picking up where they\\nleft off. Such functions are known as generator functions  because they generate a se-\\nquence of values over time.\\nGenerator functions are like normal functions in most respects, and in fact are coded\\nwith normal def statements. However, when created, they are automatically made to\\nimplement the iteration protocol so that they can appear in iteration contexts. We\\nstudied iterators in Chapter 14 ; here, we’ll revisit them to see how they relate to\\ngenerators.\\n492 | Chapter 20: \\u2002Iterations and Comprehensions, Part 2', metadata={'source': 'python.pdf', 'page': 542}),\n",
       " Document(page_content='State suspension\\nUnlike normal functions \\nthat return a value and exit, generator functions automatically\\nsuspend and resume their execution and state around the point of value generation.\\nBecause of that, they are often a useful alternative to both computing an entire series\\nof values up front and manually saving and restoring state in classes. Because the state\\nthat generator functions retain when they are suspended includes their entire local\\nscope, their local variables retain information and make it available when the functions\\nare resumed.\\nThe chief code difference between generator and normal functions is that a generator\\nyields a value, rather than returning one—the yield statement suspends the function\\nand sends a value back to the caller, but retains enough state to enable the function to\\nresume from where it left off. When resumed, the function continues execution im-\\nmediately after the last yield run. From the function’s perspective, this allows its code\\nto produce a series of values over time, rather than computing them all at once and\\nsending them back in something like a list.\\nIteration protocol integration\\nTo truly understand generator functions, you need to know that they are closely bound\\nup with the notion of the iteration protocol in Python. As we’ve seen, iterable objects\\ndefine a __next__ method, which either returns the next item in the iteration, or raises\\nthe special StopIteration exception to end the iteration. An object’s iterator is fetched\\nwith the iter built-in function.\\nPython for loops, and all other iteration contexts, use this iteration protocol to step\\nthrough a sequence or value generator, if the protocol is supported; if not, iteration\\nfalls back on repeatedly indexing sequences instead.\\nTo support this protocol, functions containing a yield statement are compiled specially\\nas generators. When called, they return a generator object that supports the iteration\\ninterface with an automatically created method named __next__ to resume execution.\\nGenerator functions may also have a return statement that, along with falling off the\\nend of the def block, simply terminates the generation of values—technically, by raising\\na StopIteration exception after any normal function exit actions. From the caller’s\\nperspective, the generator’s __next__ method resumes the function and runs until either\\nthe next yield result is returned or a StopIteration is raised.\\nThe net effect is that generator functions, coded as def statements containing yield\\nstatements, are automatically made to support the iteration protocol and thus may be\\nused in any iteration context to produce results over time and on demand.\\nIterators Revisited: Generators | 493', metadata={'source': 'python.pdf', 'page': 543}),\n",
       " Document(page_content=\"As noted in Chapter 14, in Python 2.6 and earlier, iterable objects define\\na method named next instead of __next__. This includes the generator\\nobjects we are using here. In 3.0 this method is renamed to __next__.\\nThe next built-in function is provided as a convenience and portability\\ntool: next(I) is the same as I.__next__() in 3.0 and I.next() in 2.6.\\nPrior to 2.6, programs simply call I.next() instead to iterate manually.\\nGenerator functions in action\\nTo illustrate generator basics, let’s turn to some code. The following code defines a\\ngenerator function that can be used to generate the squares of a series of numbers over\\ntime:\\n>>> def gensquares(N):\\n...     for i in range(N):\\n...         yield i ** 2        # Resume here later\\n...\\nThis function yields a value, and so returns to its caller, each time through the loop;\\nwhen it is resumed, its prior state is restored and control picks up again immediately\\nafter the yield statement. For example, when it’s used in the body of a for loop, control\\nreturns to the function after its yield statement each time through the loop:\\n>>> for i in gensquares(5):     # Resume the function\\n...     print(i, end=' : ')     # Print last yielded value\\n...\\n0 : 1 : 4 : 9 : 16 :\\n>>>\\nTo end the generation of values, functions either use a return statement with no value\\nor simply allow control to fall off the end of the function body.\\nIf you want to see what is going on inside the for, call the generator function directly:\\n>>> x = gensquares(4)\\n>>> x\\n<generator object at 0x0086C378>\\nYou get back a generator object that supports the iteration protocol we met in Chap-\\nter 14 —the generator object has a __next__ method that starts the function, or resumes\\nit from where it last yielded a value, and raises a StopIteration exception when the end\\nof the series of values is reached. For convenience, the next(X) built-in calls an object’s\\nX.__next__() method for us:\\n>>> next(x)                     # Same as x.__next__() in 3.0\\n0\\n>>> next(x)                     # Use x.next() or next() in 2.6\\n1\\n>>> next(x)\\n4\\n>>> next(x)\\n9\\n>>> next(x)\\n494 | Chapter 20: \\u2002Iterations and Comprehensions, Part 2\", metadata={'source': 'python.pdf', 'page': 544}),\n",
       " Document(page_content=\"Traceback (most recent call last):\\n...more text omitted...\\nStopIteration\\nAs we learned \\nin Chapter 14 , for loops (and other iteration contexts) work with gen-\\nerators in the same way—by calling the __next__ method repeatedly, until an exception\\nis caught. If the object to be iterated over does not support this protocol, for loops\\ninstead use the indexing protocol to iterate.\\nNote that in this example, we could also simply build the list of yielded values all at\\nonce:\\n>>> def buildsquares(n):\\n...     res = []\\n...     for i in range(n): res.append(i ** 2)\\n...     return res\\n...\\n>>> for x in buildsquares(5): print(x, end=' : ')\\n...\\n0 : 1 : 4 : 9 : 16 :\\nFor that matter, we could use any of the for loop, map, or list comprehension techniques:\\n>>> for x in [n ** 2 for n in range(5)]:\\n...     print(x, end=' : ')\\n...\\n0 : 1 : 4 : 9 : 16 :\\n>>> for x in map((lambda n: n ** 2), range(5)):\\n...     print(x, end=' : ')\\n...\\n0 : 1 : 4 : 9 : 16 :\\nHowever, generators can be better in terms of both memory use and performance. They\\nallow functions to avoid doing all the work up front, which is especially useful when\\nthe result lists are large or when it takes a lot of computation to produce each value.\\nGenerators distribute the time required to produce the series of values among loop\\niterations.\\nMoreover, for more advanced uses, generators can provide a simpler alternative to\\nmanually saving the state between iterations in class objects—with generators,\\nvariables accessible in the function’s scopes are saved and restored automatically.†\\nWe’ll discuss class-based iterators in more detail in Part VI.\\n† Interestingly, generator functions are also something of a “poor man’s” multithreading device—they\\ninterleave a function’s work with that of its caller, by dividing its operation into steps run between yields.\\nGenerators are not threads, though: the program is explicitly directed to and from the function within a single\\nthread of control. In one sense, threading is more general (producers can run truly independently and post\\nresults to a queue), but generators may be simpler to code. See the second footnote in Chapter 17  for a brief\\nintroduction to Python multithreading tools. Note that because control is routed explicitly at yield and\\nnext calls, generators are also not backtracking, but are more strongly related to coroutines—formal concepts\\nthat are both beyond this chapter’s scope.\\nIterators Revisited: Generators | 495\", metadata={'source': 'python.pdf', 'page': 545}),\n",
       " Document(page_content='Extended generator function protocol: send versus next\\nIn Python 2.5, a send method was added to the generator function protocol. The send\\nmethod advances \\nto the next item in the series of results, just like __next__, but also\\nprovides a way for the caller to communicate with the generator, to affect its operation.\\nTechnically, yield is now an expression form that returns the item passed to send, not\\na statement (though it can be called either way—as yield X, or A = (yield X)). The\\nexpression must be enclosed in parentheses unless it’s the only item on the right side\\nof the assignment statement. For example, X = yield Y is OK, as is X = (yield Y) + 42.\\nWhen this extra protocol is used, values are sent into a generator G by calling\\nG.send(value). The generator’s code is then resumed, and the yield expression in the\\ngenerator returns the value passed to send. If the regular G.__next__() method (or its\\nnext(G) equivalent) is called to advance, the yield simply returns None. For example:\\n>>> def gen():\\n...    for i in range(10):\\n...        X = yield i\\n...        print(X)\\n...\\n>>> G = gen()\\n>>> next(G)              # Must call next() first, to start generator\\n0\\n>>> G.send(77)           # Advance, and send value to yield expression\\n77\\n1\\n>>> G.send(88)\\n88\\n2\\n>>> next(G)              # next() and X.__next__() send None\\nNone\\n3\\nThe send method can be used, for example, to code a generator that its caller can ter-\\nminate by sending a termination code, or redirect by passing a new position. In addi-\\ntion, generators in 2.5 also support a throw(type) method to raise an exception inside\\nthe generator at the latest yield, and a close method that raises a special Generator\\nExit exception inside the generator to terminate the iteration. These are advanced fea-\\ntures that we won’t delve into in more detail here; see reference texts and Python’s\\nstandard manuals for more information.\\nNote that while Python 3.0 provides a next(X) convenience built-in that calls the\\nX.__next__() method of an object, other generator methods, like send, must be called\\nas methods of generator objects directly (e.g., G.send(X)). This makes sense if you re-\\nalize that these extra methods are implemented on built-in generator objects only,\\nwhereas the __next__ method applies to all iterable objects (both built-in types and\\nuser-defined classes).\\n496 | Chapter 20: \\u2002Iterations and Comprehensions, Part 2', metadata={'source': 'python.pdf', 'page': 546}),\n",
       " Document(page_content=\"Generator Expressions: Iterators Meet Comprehensions\\nIn all recent \\nversions of Python, the notions of iterators and list comprehensions are\\ncombined in a new feature of the language, generator expressions . Syntactically, gen-\\nerator expressions are just like normal list comprehensions, but they are enclosed in \\nparentheses instead of square brackets:\\n>>> [x ** 2 for x in range(4)]          # List comprehension: build a list\\n[0, 1, 4, 9]\\n>>> (x ** 2 for x in range(4))          # Generator expression: make an iterable\\n<generator object at 0x011DC648>\\nIn fact, at least on a function basis, coding a list comprehension is essentially the same\\nas wrapping a generator expression in a list built-in call to force it to produce all its\\nresults in a list at once:\\n>>> list(x ** 2 for x in range(4))      # List comprehension equivalence\\n[0, 1, 4, 9]\\nOperationally, however, generator expressions are very different—instead of building\\nthe result list in memory, they return a generator object, which in turn supports the\\niteration protocol to yield one piece of the result list at a time in any iteration context:\\n>>> G = (x ** 2 for x in range(4))\\n>>> next(G)\\n0\\n>>> next(G)\\n1\\n>>> next(G)\\n4\\n>>> next(G)\\n9\\n>>> next(G)\\nTraceback (most recent call last):\\n...more text omitted...\\nStopIteration\\nWe don’t typically see the next iterator machinery under the hood of a generator ex-\\npression like this because for loops trigger it for us automatically:\\n>>> for num in (x ** 2 for x in range(4)):\\n...     print('%s, %s' % (num, num / 2.0))\\n...\\n0, 0.0\\n1, 0.5\\n4, 2.0\\n9, 4.5\\nAs we’ve already learned, every iteration context does this, including the sum, map, and\\nsorted built-in functions; list comprehensions; and other iteration contexts we learned\\nabout in Chapter 14, such as the any, all, and list built-in functions.\\nIterators Revisited: Generators | 497\", metadata={'source': 'python.pdf', 'page': 547}),\n",
       " Document(page_content=\"Notice that the parentheses are not required around a generator expression if they are\\nthe sole item \\nenclosed in other parentheses, like those of a function call. Extra paren-\\ntheses are required, however, in the second call to sorted:\\n>>> sum(x ** 2 for x in range(4))\\n14\\n>>> sorted(x ** 2 for x in range(4))\\n[0, 1, 4, 9]\\n>>> sorted((x ** 2 for x in range(4)), reverse=True)\\n[9, 4, 1, 0]\\n>>> import math\\n>>> list( map(math.sqrt, (x ** 2 for x in range(4))) )\\n[0.0, 1.0, 2.0, 3.0]\\nGenerator expressions are primarily a memory-space optimization—they do not re-\\nquire the entire result list to be constructed all at once, as the square-bracketed list\\ncomprehension does. They may also run slightly slower in practice, so they are probably\\nbest used only for very large result sets. A more authoritative statement about per-\\nformance, though, will have to await the timing script we’ll code later in this chapter.\\nGenerator Functions Versus Generator Expressions\\nInterestingly, the same iteration can often be coded with either a generator function or\\na generator expression. The following generator expression , for example, repeats each\\ncharacter in a string four times:\\n>>> G = (c * 4 for c in 'SPAM')           # Generator expression\\n>>> list(G)                               # Force generator to produce all results\\n['SSSS', 'PPPP', 'AAAA', 'MMMM']\\nThe equivalent generator function  requires slightly more code, but as a multistatement\\nfunction it will be able to code more logic and use more state information if needed:\\n>>> def timesfour(S):                     # Generator function\\n...     for c in S:\\n...         yield c * 4\\n...\\n>>> G = timesfour('spam')\\n>>> list(G)                               # Iterate automatically\\n['ssss', 'pppp', 'aaaa', 'mmmm']\\nBoth expressions and functions support both automatic and manual iteration—the\\nprior list call iterates automatically, and the following iterate manually:\\n>>> G = (c * 4 for c in 'SPAM')\\n>>> I = iter(G)                           # Iterate manually\\n>>> next(I)\\n'SSSS'\\n>>> next(I)\\n'PPPP'\\n498 | Chapter 20: \\u2002Iterations and Comprehensions, Part 2\", metadata={'source': 'python.pdf', 'page': 548}),\n",
       " Document(page_content=\">>> G = timesfour('spam')\\n>>> I = iter(G)\\n>>> next(I)\\n'ssss'\\n>>> next(I)\\n'pppp'\\nNotice that we \\nmake new generators here to iterate again—as explained in the next\\nsection, generators are one-shot iterators.\\nGenerators Are Single-Iterator Objects\\nBoth generator functions and generator expressions are their own iterators and thus\\nsupport just one active iteration —unlike some built-in types, you can’t have multiple\\niterators of either positioned at different locations in the set of results. For example,\\nusing the prior section’s generator expression, a generator’s iterator is the generator\\nitself (in fact, calling iter on a generator is a no-op):\\n>>> G = (c * 4 for c in 'SPAM')\\n>>> iter(G) is G                          # My iterator is myself: G has __next__\\nTrue\\nIf you iterate over the results stream manually with multiple iterators, they will all point\\nto the same position:\\n>>> G = (c * 4 for c in 'SPAM')           # Make a new generator\\n>>> I1 = iter(G)                          # Iterate manually\\n>>> next(I1)\\n'SSSS'\\n>>> next(I1)\\n'PPPP'\\n>>> I2 = iter(G)                          # Second iterator at same position!\\n>>> next(I2)\\n'AAAA'\\nMoreover, once any iteration runs to completion, all are exhausted—we have to make\\na new generator to start again:\\n>>> list(I1)                              # Collect the rest of I1's items\\n['MMMM']\\n>>> next(I2)                              # Other iterators exhausted too\\nStopIteration\\n>>> I3 = iter(G)                          # Ditto for new iterators\\n>>> next(I3)\\nStopIteration\\n>>> I3 = iter(c * 4 for c in 'SPAM')      # New generator to start over\\n>>> next(I3)\\n'SSSS'\\nIterators Revisited: Generators | 499\", metadata={'source': 'python.pdf', 'page': 549}),\n",
       " Document(page_content=\"The same holds true for generator functions—the following def statement-based equiv-\\nalent supports just one active iterator and is exhausted after one pass:\\n>>> \\ndef timesfour(S):\\n...     for c in S:\\n...         yield c * 4\\n...\\n>>> G = timesfour('spam')                 # Generator functions work the same way\\n>>> iter(G) is G\\nTrue\\n>>> I1, I2 = iter(G), iter(G)\\n>>> next(I1)\\n'ssss'\\n>>> next(I1)\\n'pppp'\\n>>> next(I2)                              # I2 at same position as I1\\n'aaaa'\\nThis is different from the behavior of some built-in types, which support multiple iter-\\nators and passes and reflect their in-place changes in active iterators:\\n>>> L = [1, 2, 3, 4]\\n>>> I1, I2 = iter(L), iter(L)\\n>>> next(I1)\\n1\\n>>> next(I1)\\n2\\n>>> next(I2)                              # Lists support multiple iterators\\n1\\n>>> del L[2:]                             # Changes reflected in iterators\\n>>> next(I1)\\nStopIteration\\nWhen we begin coding class-based iterators in Part VI , we’ll see that it’s up to us to\\ndecide how any iterations we wish to support for our objects, if any.\\nEmulating zip and map with Iteration Tools\\nTo demonstrate the power of iteration tools in action, let’s turn to some more advanced\\nuse case examples. Once you know about list comprehensions, generators, and other\\niteration tools, it turns out that emulating many of Python’s functional built-ins is both\\nstraightforward and instructive.\\nFor example, we’ve already seen how the built-in zip and map functions combine itera-\\nbles and project functions across them, respectively. With multiple sequence argu-\\nments, map projects the function across items taken from each sequence in much the\\nsame way that zip pairs them up:\\n>>> S1 = 'abc'\\n>>> S2 = 'xyz123'\\n>>> list(zip(S1, S2))                     # zip pairs items from iterables\\n[('a', 'x'), ('b', 'y'), ('c', 'z')]\\n500 | Chapter 20: \\u2002Iterations and Comprehensions, Part 2\", metadata={'source': 'python.pdf', 'page': 550}),\n",
       " Document(page_content='# zip pairs items, truncates at shortest\\n>>> list(zip([−2, −1, 0, 1, 2]))               # Single sequence: 1-ary tuples\\n[(−2,), (−1,), (0,), (1,), (2,)]\\n>>> list(zip([1, 2, 3], [2, 3, 4, 5]))         # N sequences: N-ary tuples\\n[(1, 2), (2, 3), (3, 4)]\\n# map passes paired itenms to a function, truncates\\n>>> list(map(abs, [−2, −1, 0, 1, 2]))          # Single sequence: 1-ary function\\n[2, 1, 0, 1, 2]\\n>>> list(map(pow, [1, 2, 3], [2, 3, 4, 5]))    # N sequences: N-ary function\\n[1, 8, 81]\\nThough they’re being \\nused for different purposes, if you study these examples long\\nenough, you might notice a relationship between zip results and mapped function\\narguments that our next example can exploit.\\nCoding your own map(func, ...)\\nAlthough the map and zip built-ins are fast and convenient, it’s always possible to em-\\nulate them in code of our own. In the preceding chapter, for example, we saw a function\\nthat emulated the map built-in for a single sequence argument. It doesn’t take much\\nmore work to allow for multiple sequences, as the built-in does:\\n# map(func, seqs...) workalike with zip\\ndef mymap(func, *seqs):\\n    res = []\\n    for args in zip(*seqs):\\n        res.append(func(*args))\\n    return res\\nprint(mymap(abs, [−2, −1, 0, 1, 2]))\\nprint(mymap(pow, [1, 2, 3], [2, 3, 4, 5]))\\nThis version relies heavily upon the special *args argument-passing syntax—it collects\\nmultiple sequence (really, iterable) arguments, unpacks them as zip arguments to com-\\nbine, and then unpacks the paired zip results as arguments to the passed-in function.\\nThat is, we’re using the fact that the zipping is essentially a nested operation in mapping.\\nThe test code at the bottom applies this to both one and two sequences to produce this\\noutput (the same we would get with the built-in map):\\n[2, 1, 0, 1, 2]\\n[1, 8, 81]\\nReally, though, the prior version exhibits the classic list comprehension pattern , building\\na list of operation results within a for loop. We can code our map more concisely as\\nan equivalent one-line list comprehension:\\nIterators Revisited: Generators | 501', metadata={'source': 'python.pdf', 'page': 551}),\n",
       " Document(page_content=\"# Using a list comprehension\\ndef mymap(func, *seqs):\\n    return [func(*args) for args in zip(*seqs)]\\nprint(mymap(abs, [−2, −1, 0, 1, 2]))\\nprint(mymap(pow, [1, 2, 3], [2, 3, 4, 5]))\\nWhen this is \\nrun the result is the same as before, but the code is more concise and might\\nrun faster (more on performance in the section “Timing Iteration Alterna-\\ntives” on page 509). Both of the preceding mymap versions build result lists all at once,\\nthough, and this can waste memory for larger lists. Now that we know about generator\\nfunctions and expressions , it’s simple to recode both these alternatives to produce results\\non demand instead:\\n# Using generators: yield and (...)\\ndef mymap(func, *seqs):\\n    res = []\\n    for args in zip(*seqs):\\n        yield func(*args)\\ndef mymap(func, *seqs):\\n    return (func(*args) for args in zip(*seqs))\\nThese versions produce the same results but return generators designed to support the\\niteration protocol—the first yields one result at a time, and the second returns a gen-\\nerator expression’s result to do the same. They produce the same results if we wrap\\nthem in list calls to force them to produce their values all at once:\\nprint(list(mymap(abs, [−2, −1, 0, 1, 2])))\\nprint(list(mymap(pow, [1, 2, 3], [2, 3, 4, 5])))\\nNo work is really done here until the list calls force the generators to run, by activating\\nthe iteration protocol. The generators returned by these functions themselves, as well\\nas that returned by the Python 3.0 flavor of the zip built-in they use, produce results\\nonly on demand.\\nCoding your own zip(...) and map(None, ...)\\nOf course, much of the magic in the examples shown so far lies in their use of the zip\\nbuilt-in to pair arguments from multiple sequences. You’ll also note that our map\\nworkalikes are really emulating the behavior of the Python 3.0 map—they truncate at\\nthe length of the shortest sequence, and they do not support the notion of padding\\nresults when lengths differ, as map does in Python 2.X with a None argument:\\nC:\\\\misc> c:\\\\python26\\\\python\\n>>> map(None, [1, 2, 3], [2, 3, 4, 5])\\n[(1, 2), (2, 3), (3, 4), (None, 5)]\\n>>> map(None, 'abc', 'xyz123')\\n[('a', 'x'), ('b', 'y'), ('c', 'z'), (None, '1'), (None, '2'), (None, '3')]\\n502 | Chapter 20: \\u2002Iterations and Comprehensions, Part 2\", metadata={'source': 'python.pdf', 'page': 552}),\n",
       " Document(page_content=\"Using iteration tools, we can code workalikes that emulate both truncating zip and\\n2.6’s padding map\\n—these turn out to be nearly the same in code:\\n# zip(seqs...) and 2.6 map(None, seqs...) workalikes\\ndef myzip(*seqs):\\n    seqs = [list(S) for S in seqs]\\n    res  = []\\n    while all(seqs):\\n        res.append(tuple(S.pop(0) for S in seqs))\\n    return res\\ndef mymapPad(*seqs, pad=None):\\n    seqs = [list(S) for S in seqs]\\n    res  = []\\n    while any(seqs):\\n        res.append(tuple((S.pop(0) if S else pad) for S in seqs))\\n    return res\\nS1, S2 = 'abc', 'xyz123'\\nprint(myzip(S1, S2))\\nprint(mymapPad(S1, S2))\\nprint(mymapPad(S1, S2, pad=99))\\nBoth of the functions coded here work on any type of iterable object, because they run\\ntheir arguments through the list built-in to force result generation (e.g., files would\\nwork as arguments, in addition to sequences like strings). Notice the use of the all and\\nany built-ins here—these return True if all and any items in an iterable are True (or\\nequivalently, nonempty), respectively. These built-ins are used to stop looping when\\nany or all of the listified arguments become empty after deletions.\\nAlso note the use of the Python 3.0 keyword-only argument, pad; unlike the 2.6 map,\\nour version will allow any pad object to be specified (if you’re using 2.6, use a\\n**kargs form to support this option instead; see Chapter 18 for details). When these\\nfunctions are run, the following results are printed—a zip, and two padding maps:\\n[('a', 'x'), ('b', 'y'), ('c', 'z')]\\n[('a', 'x'), ('b', 'y'), ('c', 'z'), (None, '1'), (None, '2'), (None, '3')]\\n[('a', 'x'), ('b', 'y'), ('c', 'z'), (99, '1'), (99, '2'), (99, '3')]\\nThese functions aren’t amenable to list comprehension translation because their loops\\nare too specific. As before, though, while our zip and map workalikes currently build\\nand return result lists, it’s just as easy to turn them into generators with yield so that\\nthey each return one piece of their result set at a time. The results are the same as before,\\nbut we need to use list again to force the generators to yield their values for display:\\n# Using generators: yield\\ndef myzip(*seqs):\\n    seqs = [list(S) for S in seqs]\\n    while all(seqs):\\n        yield tuple(S.pop(0) for S in seqs)\\nIterators Revisited: Generators | 503\", metadata={'source': 'python.pdf', 'page': 553}),\n",
       " Document(page_content=\"def mymapPad(*seqs, pad=None):\\n    seqs = [list(S) for S in seqs]\\n    while any(seqs):\\n        yield tuple((S.pop(0) if S else pad) for S in seqs)\\nS1, S2 = 'abc', 'xyz123'\\nprint(list(myzip(S1, S2)))\\nprint(list(mymapPad(S1, S2)))\\nprint(list(mymapPad(S1, S2, pad=99)))\\nFinally, here’s an \\nalternative implementation of our zip and map emulators—rather than\\ndeleting arguments from lists with the pop method, the following versions do their job\\nby calculating the minimum and maximum argument lengths. Armed with these\\nlengths, it’s easy to code nested list comprehensions to step through argument index\\nranges:\\n# Alternate implementation with lengths\\ndef myzip(*seqs):\\n    minlen = min(len(S) for S in seqs)\\n    return [tuple(S[i] for S in seqs) for i in range(minlen)]\\ndef mymapPad(*seqs, pad=None):\\n    maxlen = max(len(S) for S in seqs)\\n    index  = range(maxlen)\\n    return [tuple((S[i] if len(S) > i else pad) for S in seqs) for i in index]\\nS1, S2 = 'abc', 'xyz123'\\nprint(myzip(S1, S2))\\nprint(mymapPad(S1, S2))\\nprint(mymapPad(S1, S2, pad=99))\\nBecause these use len and indexing, they assume that arguments are sequences or sim-\\nilar, not arbitrary iterables. The outer comprehensions here step through argument\\nindex ranges, and the inner comprehensions (passed to tuple) step through the passed-\\nin sequences to pull out arguments in parallel. When they’re run, the results are as\\nbefore.\\nMost strikingly, generators and iterators seem to run rampant in this example. The\\narguments passed to min and max are generator expressions, which run to completion\\nbefore the nested comprehensions begin iterating. Moreover, the nested list compre-\\nhensions employ two levels of delayed evaluation—the Python 3.0 range built-in is an\\niterable, as is the generator expression argument to tuple.\\nIn fact, no results are produced here until the square brackets of the list comprehensions\\nrequest values to place in the result list—they force the comprehensions and generators\\nto run. To turn these functions themselves into generators instead of list builders, use\\nparentheses instead of square brackets again. Here’s the case for our zip:\\n# Using generators: (...)\\ndef myzip(*seqs):\\n    minlen = min(len(S) for S in seqs)\\n504 | Chapter 20: \\u2002Iterations and Comprehensions, Part 2\", metadata={'source': 'python.pdf', 'page': 554}),\n",
       " Document(page_content=\"    return (tuple(S[i] for S in seqs) for i in range(minlen))\\nprint(list(myzip(S1, S2)))\\nIn this case, \\nit takes a list call to activate the generators and iterators to produce their\\nresults. Experiment with these on your own for more details. Developing further coding\\nalternatives is left as a suggested exercise (see also the sidebar “Why You Will Care:\\nOne-Shot Iterations” for investigation of one such option).\\nWhy You Will Care: One-Shot Iterations\\nIn Chapter 14, \\nwe saw how some built-ins (like map) support only a single traversal and\\nare empty after it occurs, and I promised to show you an example of how that can\\nbecome subtle but important in practice. Now that we’ve studied a few more iteration\\ntopics, I can make good on this promise. Consider the following clever alternative cod-\\ning for this chapter’s zip emulation examples, adapted from one in Python’s manuals:\\ndef myzip(*args):\\n    iters = map(iter, args)\\n    while iters:\\n        res = [next(i) for i in iters]\\n        yield tuple(res)\\nBecause this code uses iter and next, it works on any type of iterable. Note that there\\nis no reason to catch the StopIteration raised by the next(it) inside the comprehension\\nhere when any one of the arguments’ iterators is exhausted—allowing it to pass ends\\nthis generator function and has the same effect that a return statement would. The\\nwhile iters:  suffices to loop if at least one argument is passed, and avoids an infinite\\nloop otherwise (the list comprehension would always return an empty list).\\nThis code works fine in Python 2.6 as is:\\n>>> list(myzip('abc', 'lmnop'))\\n[('a', 'l'), ('b', 'm'), ('c', 'n')]\\nBut it falls into an infinite loop and fails in Python 3.0, because the 3.0 map returns a\\none-shot iterable object instead of a list as in 2.6. In 3.0, as soon as we’ve run the list\\ncomprehension inside the loop once, iters will be empty (and res will be []) forever.\\nTo make this work in 3.0, we need to use the list built-in function to create an object\\nthat can support multiple iterations:\\ndef myzip(*args):\\n    iters = list(map(iter, args))\\n    ...rest as is...\\nRun this on your own to trace its operation. The lesson here: wrapping map calls in\\nlist calls in 3.0 is not just for display!\\nIterators Revisited: Generators | 505\", metadata={'source': 'python.pdf', 'page': 555}),\n",
       " Document(page_content=\"Value Generation in Built-in Types and Classes\\nFinally, although we’ve \\nfocused on coding value generators ourselves in this section,\\ndon’t forget that many built-in types behave in similar ways—as we saw in Chap-\\nter 14, for example, dictionaries have iterators that produce keys on each iteration:\\n>>> D = {'a':1, 'b':2, 'c':3}\\n>>> x = iter(D)\\n>>> next(x)\\n'a'\\n>>> next(x)\\n'c'\\nLike the values produced by handcoded generators, dictionary keys may be iterated\\nover both manually and with automatic iteration tools including for loops, map calls,\\nlist comprehensions, and the many other contexts we met in Chapter 14:\\n>>> for key in D:\\n...     print(key, D[key])\\n...\\na 1\\nc 3\\nb 2\\nAs we’ve also seen, for file iterators, Python simply loads lines from the file on demand:\\n>>> for line in open('temp.txt'):\\n...     print(line, end='')\\n...\\nTis but\\na flesh wound.\\nWhile built-in type iterators are bound to a specific type of value generation, the concept\\nis similar to generators we code with expressions and functions. Iteration contexts like\\nfor loops accept any iterable, whether user-defined or built-in.\\nAlthough beyond the scope of this chapter, it is also possible to implement arbitrary\\nuser-defined generator objects with classes that conform to the iteration protocol. Such\\nclasses define a special __iter__ method run by the iter built-in function that returns\\nan object having a __next__ method run by the next built-in function (a __getitem__\\nindexing method is also available as a fallback option for iteration).\\nThe instance objects created from such a class are considered iterable and may be used\\nin for loops and all other iteration contexts. With classes, though, we have access to\\nricher logic and data structuring options than other generator constructs can offer.\\nThe iterator story won’t really be complete until we’ve seen how it maps to classes, too.\\nFor now, we’ll have to settle for postponing its conclusion until we study class-based\\niterators in Chapter 29.\\n506 | Chapter 20: \\u2002Iterations and Comprehensions, Part 2\", metadata={'source': 'python.pdf', 'page': 556}),\n",
       " Document(page_content='3.0 Comprehension Syntax Summary\\nWe’ve been focusing on \\nlist comprehensions and generators in this chapter, but keep\\nin mind that there are two other comprehension expression forms: set and dictionary\\ncomprehensions are also available as of Python 3.0. We met these briefly in Chapters\\n5 and 8, but with our new knowledge of comprehensions and generators, you should \\nnow be able to grasp these 3.0 extensions in full:\\n• For sets, the new literal form {1, 3, 2} is equivalent to set([1, 3, 2]), and the\\nnew set comprehension syntax {f(x) for x in S if P(x)} is like the generator\\nexpression set(f(x) for x in S if P(x)), where f(x) is an arbitrary expression.\\n• For dictionaries, the new dictionary comprehension syntax {key: val for (key,\\nval) in zip(keys, vals)} works like the form dict(zip(keys, vals)), and {x:\\nf(x) for x in items} is like the generator expression dict((x, f(x)) for x in\\nitems).\\nHere’s a summary of all the comprehension alternatives in 3.0. The last two are new\\nand are not available in 2.6:\\n>>> [x * x for x in range(10)]            # List comprehension: builds list\\n[0, 1, 4, 9, 16, 25, 36, 49, 64, 81]      # like list(generator expr)\\n>>> (x * x for x in range(10))            # Generator expression: produces items\\n<generator object at 0x009E7328>          # Parens are often optional\\n>>> {x * x for x in range(10)}            # Set comprehension, new in 3.0\\n{0, 1, 4, 81, 64, 9, 16, 49, 25, 36}      # {x, y} is a set in 3.0 too\\n>>> {x: x * x for x in range(10)}         # Dictionary comprehension, new in 3.0\\n{0: 0, 1: 1, 2: 4, 3: 9, 4: 16, 5: 25, 6: 36, 7: 49, 8: 64, 9: 81}\\nComprehending Set and Dictionary Comprehensions\\nIn a sense, set and dictionary comprehensions are just syntactic sugar for passing gen-\\nerator expressions to the type names. Because both accept any iterable, a generator\\nworks well here:\\n>>> {x * x for x in range(10)}                # Comprehension\\n{0, 1, 4, 81, 64, 9, 16, 49, 25, 36}\\n>>> set(x * x for x in range(10))             # Generator and type name\\n{0, 1, 4, 81, 64, 9, 16, 49, 25, 36}\\n>>> {x: x * x for x in range(10)}\\n{0: 0, 1: 1, 2: 4, 3: 9, 4: 16, 5: 25, 6: 36, 7: 49, 8: 64, 9: 81}\\n>>> dict((x, x * x) for x in range(10))\\n{0: 0, 1: 1, 2: 4, 3: 9, 4: 16, 5: 25, 6: 36, 7: 49, 8: 64, 9: 81}\\nAs for list comprehensions, though, we can always build the result objects with manual\\ncode, too. Here are statement-based equivalents of the last two comprehensions:\\n3.0 Comprehension Syntax Summary | 507', metadata={'source': 'python.pdf', 'page': 557}),\n",
       " Document(page_content=\">>> res = set()\\n>>> for x in range(10):                        # Set comprehension equivalent\\n...     res.add(x * x)\\n...\\n>>> res\\n{0, 1, 4, 81, 64, 9, 16, 49, 25, 36}\\n>>> res = {}\\n>>> for x in range(10):                        # Dict comprehension equivalent\\n...     res[x] = x * x\\n...\\n>>> res\\n{0: 0, 1: 1, 2: 4, 3: 9, 4: 16, 5: 25, 6: 36, 7: 49, 8: 64, 9: 81}\\nNotice that although \\nboth forms accept iterators, they have no notion of generating\\nresults on demand—both forms build objects all at once. If you mean to produce keys\\nand values upon request, a generator expression is more appropriate:\\n>>> G = ((x, x * x) for x in range(10))\\n>>> next(G)\\n(0, 0)\\n>>> next(G)\\n(1, 1)\\nExtended Comprehension Syntax for Sets and Dictionaries\\nLike list comprehensions and generator expressions, both set and dictionary compre-\\nhensions support nested associated if clauses to filter items out of the result—the\\nfollowing collect squares of even items (i.e., items having no remainder for division by\\n2) in a range:\\n>>> [x * x for x in range(10) if x % 2 == 0]           # Lists are ordered\\n[0, 4, 16, 36, 64]\\n>>> {x * x for x in range(10) if x % 2 == 0}           # But sets are not\\n{0, 16, 4, 64, 36}\\n>>> {x: x * x for x in range(10) if x % 2 == 0}        # Neither are dict keys\\n{0: 0, 8: 64, 2: 4, 4: 16, 6: 36}\\nNested for loops work as well, though the unordered and no-duplicates nature of both\\ntypes of objects can make the results a bit less straightforward to decipher:\\n>>> [x + y for x in [1, 2, 3] for y in [4, 5, 6]]      # Lists keep duplicates\\n[5, 6, 7, 6, 7, 8, 7, 8, 9]\\n>>> {x + y for x in [1, 2, 3] for y in [4, 5, 6]}      # But sets do not\\n{8, 9, 5, 6, 7}\\n>>> {x: y for x in [1, 2, 3] for y in [4, 5, 6]}       # Neither do dict keys\\n{1: 6, 2: 6, 3: 6}\\nLike list comprehensions, the set and dictionary varieties can also iterate over any type\\nof iterator—lists, strings, files, ranges, and anything else that supports the iteration\\nprotocol:\\n>>> {x + y for x in 'ab' for y in 'cd'}\\n{'bd', 'ac', 'ad', 'bc'}\\n508 | Chapter 20: \\u2002Iterations and Comprehensions, Part 2\", metadata={'source': 'python.pdf', 'page': 558}),\n",
       " Document(page_content=\">>> {x + y: (ord(x), ord(y)) for x in 'ab' for y in 'cd'}\\n{'bd': (98, 100), 'ac': (97, 99), 'ad': (97, 100), 'bc': (98, 99)}\\n>>> {k * 2 for k in ['spam', 'ham', 'sausage'] if k[0] == 's'}\\n{'sausagesausage', 'spamspam'}\\n>>> {k.upper(): k * 2 for k in ['spam', 'ham', 'sausage'] if k[0] == 's'}\\n{'SAUSAGE': 'sausagesausage', 'SPAM': 'spamspam'}\\nFor more details, \\nexperiment with these tools on your own. They may or may not have\\na performance advantage over the generator or for loop alternatives, but we would\\nhave to time their performance explicitly to be sure—which seems a natural segue to\\nthe next section.\\nTiming Iteration Alternatives\\nWe’ve met quite a few iteration alternatives in this book. To summarize, let’s work\\nthrough a larger case study that pulls together some of the things we’ve learned about\\niteration and functions.\\nI’ve mentioned a few times that list comprehensions have a speed performance ad-\\nvantage over for loop statements, and that map performance can be better or worse\\ndepending on call patterns. The generator expressions of the prior sections tend to be\\nslightly slower than list comprehensions, though they minimize memory space\\nrequirements.\\nAll that’s true today, but relative performance can vary over time because Python’s\\ninternals are constantly being changed and optimized. If you want to verify their per-\\nformance for yourself, you need to time these alternatives on your own computer and\\nyour own version of Python.\\nTiming Module\\nLuckily, Python makes it easy to time code. To see how the iteration options stack up,\\nlet’s start with a simple but general timer utility function coded in a module file, so it\\ncan be used in a variety of programs:\\n# File mytimer.py\\nimport time\\nreps = 1000\\nrepslist = range(reps)\\ndef timer(func, *pargs, **kargs):\\n    start = time.clock()\\n    for i in repslist:\\n        ret = func(*pargs, **kargs)\\n    elapsed = time.clock() - start\\n    return (elapsed, ret)\\nTiming Iteration Alternatives | 509\", metadata={'source': 'python.pdf', 'page': 559}),\n",
       " Document(page_content='Operationally, this module times calls to any function with any positional and keyword\\narguments by fetching \\nthe start time, calling the function a fixed number of times, and\\nsubtracting the start time from the stop time. Points to notice:\\n• Python’s time module gives access to the current time, with precision that varies\\nper platform. On Windows, this call is claimed to give microsecond granularity\\nand so is very accurate.\\n• The range call is hoisted out of the timing loop, so its construction cost is not\\ncharged to the timed function in Python 2.6. In 3.0 range is an iterator, so this step\\nisn’t required (but doesn’t hurt).\\n• The reps count is a global that importers can change if needed: mytimer.reps = N .\\nWhen complete, the total elapsed time for all calls is returned in a tuple, along with the\\ntimed function’s final return value so callers can verify its operation.\\nFrom a larger perspective, because this function is coded in a module file, it becomes\\na generally useful tool anywhere we wish to import it. You’ll learn more about modules\\nand imports in the next part of this book, but you’ve already seen enough of the basics\\nto make sense of this code—simply import the module and call the function to use this\\nfile’s timer (and see Chapter 3 ’s coverage of module attributes if you need a refresher).\\nTiming Script\\nNow, to time iteration tool speed, run the following script—it uses the timer module\\nwe just wrote to time the relative speeds of the various list construction techniques\\nwe’ve studied:\\n# File timeseqs.py\\nimport sys, mytimer                              # Import timer function\\nreps = 10000\\nrepslist = range(reps)                           # Hoist range out in 2.6\\ndef forLoop():\\n    res = []\\n    for x in repslist:\\n        res.append(abs(x))\\n    return res\\ndef listComp():\\n    return [abs(x) for x in repslist]\\ndef mapCall():\\n    return list(map(abs, repslist))              # Use list in 3.0 only\\ndef genExpr():\\n    return list(abs(x) for x in repslist)        # list forces results\\ndef genFunc():\\n    def gen():\\n510 | Chapter 20: \\u2002Iterations and Comprehensions, Part 2', metadata={'source': 'python.pdf', 'page': 560}),\n",
       " Document(page_content=\"        for x in repslist:\\n            yield abs(x)\\n    return list(gen())\\nprint(sys.version)\\nfor test in (forLoop, listComp, mapCall, genExpr, genFunc):\\n    elapsed, result = mytimer.timer(test)\\n    print ('-' * 33)\\n    print ('%-9s: %.5f => [%s...%s]' %\\n           (test.__name__, elapsed, result[0], result[-1]))\\nThis script tests \\nfive alternative ways to build lists of results and, as shown, executes\\non the order of 10 million steps for each—that is, each of the five tests builds a list of\\n10,000 items 1,000 times.\\nNotice how we have to run the generator expression and function results through the\\nbuilt-in list call to force them to yield all of their values; if we did not, we would just\\nproduce generators that never do any real work. In Python 3.0 (only) we must do\\nthe same for the map result, since it is now an iterable object as well. Also notice how\\nthe code at the bottom steps through a tuple of four function objects and prints the\\n__name__ of each: as we’ve seen, this is a built-in attribute that gives a function’s name.\\nTiming Results\\nWhen the script of the prior section is run under Python 3.0, I get the following results\\non my Windows Vista laptop— map is slightly faster than list comprehensions, both are\\nsubstantially quicker than for loops, and generator expressions and functions place in\\nthe middle:\\nC:\\\\misc> c:\\\\python30\\\\python timeseqs.py\\n3.0.1 (r301:69561, Feb 13 2009, 20:04:18) [MSC v.1500 32 bit (Intel)]\\n---------------------------------\\nforLoop  : 2.64441 => [0...9999]\\n---------------------------------\\nlistComp : 1.60110 => [0...9999]\\n---------------------------------\\nmapCall  : 1.41977 => [0...9999]\\n---------------------------------\\ngenExpr  : 2.21758 => [0...9999]\\n---------------------------------\\ngenFunc  : 2.18696 => [0...9999]\\nIf you study this code and its output long enough, you’ll notice that generator expres-\\nsions run slower than list comprehensions. Although wrapping a generator expression\\nin a list call makes it functionally equivalent to a square-bracketed list comprehension,\\nthe internal implementations of the two expressions appear to differ (though we’re also\\neffectively timing the list call for the generator test):\\nreturn [abs(x) for x in range(size)]         # 1.6 seconds\\nreturn list(abs(x) for x in range(size))     # 2.2 seconds: differs internally\\nTiming Iteration Alternatives | 511\", metadata={'source': 'python.pdf', 'page': 561}),\n",
       " Document(page_content='Interestingly, when I ran this on Windows XP with Python 2.5 for the prior edition of\\nthis book, the \\nresults were relatively similar—list comprehensions were nearly twice as\\nfast as equivalent for loop statements, and map was slightly quicker than list compre-\\nhensions when mapping a built-in function such as abs (absolute value). I didn’t test\\ngenerator functions then, and the output format wasn’t quite as grandiose:\\n2.5 (r25:51908, Sep 19 2006, 09:52:17) [MSC v.1310 32 bit (Intel)]\\nforStatement         => 6.10899996758\\nlistComprehension    => 3.51499986649\\nmapFunction          => 2.73399996758\\ngeneratorExpression  => 4.11600017548\\nThe fact that the actual 2.5 test times listed here are over two times as slow as the output\\nI showed earlier is likely due to my using a quicker laptop for the more recent test, not\\ndue to improvements in Python 3.0. In fact, all the 2.6 results for this script are slightly\\nquicker than 3.0 on this same machine if the list call is removed from the map test to\\navoid creating the results list twice (try this on your own to verify).\\nWatch what happens, though, if we change this script to perform a real operation on\\neach iteration, such as addition, instead of calling a trivial built-in function like abs (the\\nomitted parts of the following are the same as before):\\n# File timeseqs.py\\n...\\n...\\ndef forLoop():\\n    res = []\\n    for x in repslist:\\n        res.append(x + 10)\\n    return res\\ndef listComp():\\n    return [x + 10 for x in repslist]\\ndef mapCall():\\n    return list(map((lambda x: x + 10), repslist))          # list in 3.0 only\\ndef genExpr():\\n    return list(x + 10 for x in repslist)                   # list in 2.6 + 3.0\\ndef genFunc():\\n    def gen():\\n        for x in repslist:\\n            yield x + 10\\n    return list(gen())\\n...\\n...\\nNow the need to call a user-defined function for the map call makes it slower than the\\nfor loop statements, despite the fact that the looping statements version is larger in\\nterms of code. On Python 3.0:\\nC:\\\\misc> c:\\\\python30\\\\python timeseqs.py\\n3.0.1 (r301:69561, Feb 13 2009, 20:04:18) [MSC v.1500 32 bit (Intel)]\\n512 | Chapter 20: \\u2002Iterations and Comprehensions, Part 2', metadata={'source': 'python.pdf', 'page': 562}),\n",
       " Document(page_content='---------------------------------\\nforLoop  : 2.60754 => [10...10009]\\n---------------------------------\\nlistComp : 1.57585 => [10...10009]\\n---------------------------------\\nmapCall  : 3.10276 => [10...10009]\\n---------------------------------\\ngenExpr  : 1.96482 => [10...10009]\\n---------------------------------\\ngenFunc  : 1.95340 => [10...10009]\\nThe Python 2.5 \\nresults on a slower machine were again relatively similar in the prior\\nedition, but twice as slow due to test machine differences:\\n2.5 (r25:51908, Sep 19 2006, 09:52:17) [MSC v.1310 32 bit (Intel)]\\nforStatement         => 5.25699996948\\nlistComprehension    => 2.68400001526\\nmapFunction          => 5.96900010109\\ngeneratorExpression  => 3.37400007248\\nBecause the interpreter optimizes so much internally, performance analysis of Python\\ncode like this is a very tricky affair. It’s virtually impossible to guess which method will\\nperform the best—the best you can do is time your own code, on your computer, with\\nyour version of Python. In this case, all we should say for certain is that on this Python,\\nusing a user-defined function in map calls can slow performance by at least a factor of\\n2, and that list comprehensions run quickest for this test.\\nAs I’ve mentioned before, however, performance should not be your primary concern\\nwhen writing Python code—the first thing you should do to optimize Python code is\\nto not optimize Python code! Write for readability and simplicity  first, then optimize\\nlater, if and only if needed. It could very well be that any of the five alternatives is quick\\nenough for the data sets your program needs to process; if so, program clarity should\\nbe the chief goal.\\nTiming Module Alternatives\\nThe timing module of the prior section works, but it’s a bit primitive on multiple fronts:\\n• It always uses the time.clock call to time code. While that option is best on Win-\\ndows, the time.time call may provide better resolution on some Unix platforms.\\n• Adjusting the number of repetitions requires changing module-level globals—a\\nless than ideal arrangement if the timer function is being used and shared by mul-\\ntiple importers.\\n• As is, the timer works by running the test function a large number of times. To\\naccount for random system load fluctuations, it might be better to select the best\\ntime among all the tests, instead of the total time.\\nThe following alternative implements a more sophisticated timer module that addresses\\nall three points by selecting a timer call based on platform, allowing the repeat count\\nTiming Iteration Alternatives | 513', metadata={'source': 'python.pdf', 'page': 563}),\n",
       " Document(page_content='to be passed in as a keyword argument named _reps, and providing a best-of-N alter-\\nnative timing function:\\n# File mytimer.py (2.6 and 3.0)\\n\"\"\"\\ntimer(spam, 1, 2, a=3, b=4, _reps=1000) calls and times spam(1, 2, a=3)\\n_reps times, and returns total time for all runs, with final result;\\nbest(spam, 1, 2, a=3, b=4, _reps=50) runs best-of-N timer to filter out\\nany system load variation, and returns best time among _reps tests\\n\"\"\"\\nimport time, sys\\nif sys.platform[:3] == \\'win\\':\\n    timefunc = time.clock               # Use time.clock on Windows\\nelse:\\n    timefunc = time.time                # Better resolution on some Unix platforms\\ndef trace(*args): pass                  # Or: print args\\ndef timer(func, *pargs, **kargs):\\n    _reps = kargs.pop(\\'_reps\\', 1000)    # Passed-in or default reps\\n    trace(func, pargs, kargs, _reps)\\n    repslist = range(_reps)             # Hoist range out for 2.6 lists\\n    start = timefunc()\\n    for i in repslist:\\n        ret = func(*pargs, **kargs)\\n    elapsed = timefunc() - start\\n    return (elapsed, ret)\\ndef best(func, *pargs, **kargs):\\n    _reps = kargs.pop(\\'_reps\\', 50)\\n    best = 2 ** 32\\n    for i in range(_reps):\\n        (time, ret) = timer(func, *pargs, _reps=1, **kargs)\\n        if time < best: best = time\\n    return (best, ret)\\nThis module’s docstring \\nat the top of the file describes its intended usage. It uses dic-\\ntionary pop operations to remove the _reps argument from arguments intended for the\\ntest function and provide it with a default, and it traces arguments during development\\nif you change its trace function to print. To test with this new timer module on either\\nPython 3.0 or 2.6, change the timing script as follows (the omitted code in the test\\nfunctions of this version use the x + 1 operation for each test, as coded in the prior\\nsection):\\n# File timeseqs.py\\nimport sys, mytimer\\nreps = 10000\\nrepslist = range(reps)\\ndef forLoop(): ...\\n514 | Chapter 20: \\u2002Iterations and Comprehensions, Part 2', metadata={'source': 'python.pdf', 'page': 564}),\n",
       " Document(page_content=\"def listComp(): ...\\ndef mapCall(): ...\\ndef genExpr(): ...\\ndef genFunc(): ...\\nprint(sys.version)\\nfor tester in (mytimer.timer, mytimer.best):\\n    print('<%s>' % tester.__name__)\\n    for test in (forLoop, listComp, mapCall, genExpr, genFunc):\\n        elapsed, result = tester(test)\\n        print ('-' * 35)\\n        print ('%-9s: %.5f => [%s...%s]' %\\n               (test.__name__, elapsed, result[0], result[-1]))\\nWhen run under \\nPython 3.0, the timing results are essentially the same as before, and\\nrelatively the same for both to the total-of-N and best-of-N timing techniques—running\\ntests many times seems to do as good a job filtering out system load fluctuations as\\ntaking the best case, but the best-of-N scheme may be better when testing a long-\\nrunning function. The results on my machine are as follows:\\nC:\\\\misc> c:\\\\python30\\\\python timeseqs.py\\n3.0.1 (r301:69561, Feb 13 2009, 20:04:18) [MSC v.1500 32 bit (Intel)]\\n<timer>\\n-----------------------------------\\nforLoop  : 2.35371 => [10...10009]\\n-----------------------------------\\nlistComp : 1.29640 => [10...10009]\\n-----------------------------------\\nmapCall  : 3.16556 => [10...10009]\\n-----------------------------------\\ngenExpr  : 1.97440 => [10...10009]\\n-----------------------------------\\ngenFunc  : 1.95072 => [10...10009]\\n<best>\\n-----------------------------------\\nforLoop  : 0.00193 => [10...10009]\\n-----------------------------------\\nlistComp : 0.00124 => [10...10009]\\n-----------------------------------\\nmapCall  : 0.00268 => [10...10009]\\n-----------------------------------\\ngenExpr  : 0.00164 => [10...10009]\\n-----------------------------------\\ngenFunc  : 0.00165 => [10...10009]\\nThe times reported by the best-of-N timer here are small, of course, but they might\\nbecome significant if your program iterates many times over large data sets. At least in\\nterms of relative performance, list comprehensions appear best in most cases; map is\\nonly slightly better when built-ins are applied.\\nTiming Iteration Alternatives | 515\", metadata={'source': 'python.pdf', 'page': 565}),\n",
       " Document(page_content='Using keyword-only arguments in 3.0\\nWe can also \\nmake use of Python 3.0 keyword-only arguments  here to simplify the timer\\nmodule’s code. As we learned in Chapter 19 , keyword-only arguments are ideal for\\nconfiguration options such as our functions’ _reps argument. They must be coded after\\na * and before a ** in the function header, and in a function call they must be passed\\nby keyword and appear before the ** if used. Here’s a keyword-only-based alternative\\nto the prior module. Though simpler, it compiles and runs under Python 3.X only, not\\n2.6:\\n# File mytimer.py (3.X only)\\n\"\"\"\\nUse 3.0 keyword-only default arguments, instead of ** and dict pops.\\nNo need to hoist range() out of test in 3.0: a generator, not a list\\n\"\"\"\\nimport time, sys\\ntrace = lambda *args: None  # or print\\ntimefunc = time.clock if sys.platform == \\'win32\\' else time.time\\ndef timer(func, *pargs, _reps=1000, **kargs):\\n    trace(func, pargs, kargs, _reps)\\n    start = timefunc()\\n    for i in range(_reps):\\n        ret = func(*pargs, **kargs)\\n    elapsed = timefunc() - start\\n    return (elapsed, ret)\\ndef best(func, *pargs, _reps=50, **kargs):\\n    best = 2 ** 32\\n    for i in range(_reps):\\n        (time, ret) = timer(func, *pargs, _reps=1, **kargs)\\n        if time < best: best = time\\n    return (best, ret)\\nThis version is used the same way as and produces results identical to the prior version,\\nnot counting negligible test time differences from run to run:\\nC:\\\\misc> c:\\\\python30\\\\python timeseqs.py\\n...same results as before...\\nIn fact, for variety we can also test this version of the module from the interactive\\nprompt, completely independent of the sequence timer script—it’s a general-purpose\\ntool:\\nC:\\\\misc> c:\\\\python30\\\\python\\n>>> from mytimer import timer, best\\n>>>\\n>>> def power(X, Y): return X ** Y            # Test function\\n...\\n>>> timer(power, 2, 32)                       # Total time, last result\\n(0.002625403507987747, 4294967296)\\n>>> timer(power, 2, 32, _reps=1000000)        # Override defult reps\\n516 | Chapter 20: \\u2002Iterations and Comprehensions, Part 2', metadata={'source': 'python.pdf', 'page': 566}),\n",
       " Document(page_content='(1.1822605247314932, 4294967296)\\n>>> timer(power, 2, 100000)[0]                # 2 ** 100,000 tot time @1,000 reps\\n2.2496919999608878\\n>>> best(power, 2, 32)                        # Best time, last result\\n(5.58730229727189e-06, 4294967296)\\n>>> best(power, 2, 100000)[0]                 # 2 ** 100,000 best time\\n0.0019937589833460834\\n>>> best(power, 2, 100000, _reps=500)[0]      # Override default reps\\n0.0019845399345541637\\nFor trivial functions \\nlike the one tested in this interactive session, the costs of the timer’s\\ncode are probably as significant as those of the timed function, so you should not take\\ntimer results too absolutely (we are timing more than just X ** Y here). The timer’s\\nresults can help you judge relative speeds of coding alternatives, though, and may be\\nmore meaningful for longer-running operations like the following—calculating 2 to the\\npower one million takes an order of magnitude (power of 10) longer than the preceding\\n2**100,000:\\n>>> timer(power, 2, 1000000, _reps=1)[0]      # 2 ** 1,000,000: total time\\n0.088112804839710179\\n>>> timer(power, 2, 1000000, _reps=10)[0]\\n0.40922470593329763\\n>>> best(power, 2, 1000000, _reps=1)[0]       # 2 ** 1,000,000: best time\\n0.086550036387279761\\n>>> best(power, 2, 1000000, _reps=10)[0]      # 10 is sometimes as good as 50\\n0.029616752967200455\\n>>> best(power, 2, 1000000, _reps=50)[0]      # Best resolution\\n0.029486918030102061\\nAgain, although the times measured here are small, the differences can be significant\\nin programs that compute powers often.\\nSee Chapter 19 for more on keyword-only arguments in 3.0; they can simplify code for\\nconfigurable tools like this one but are not backward compatible with 2.X Pythons. If\\nyou want to compare 2.X and 3.X speed, for example, or support programmers using\\neither Python line, the prior version is likely a better choice. If you’re using Python 2.6,\\nthe above session runs the same with the prior version of the timer module.\\nOther Suggestions\\nFor more insight, try modifying the repetition counts used by these modules, or explore\\nthe alternative timeit module in Python’s standard library, which automates timing of\\ncode, supports command-line usage modes, and finesses some platform-specific issues.\\nPython’s manuals document its use.\\nYou might also want to look at the profile standard library module for a complete\\nsource code profiler tool—we’ll learn more about it in Chapter 35  in the context of\\ndevelopment tools for large projects. In general, you should profile code to isolate bot-\\ntlenecks before recoding and timing alternatives as we’ve done here.\\nTiming Iteration Alternatives | 517', metadata={'source': 'python.pdf', 'page': 567}),\n",
       " Document(page_content=\"It might be useful as well to experiment with using the new str.format method in\\nPython 2.6 and 3.0 instead of the %\\n formatting expression (which could potentially be\\ndeprecated in the future!), by changing the timing script’s formatted print lines as\\nfollows:\\nprint('<%s>' % tester.__name__)            # From expression\\n    print('<{0}>'.format(tester.__name__))     # To method call\\n        print ('%-9s: %.5f => [%s...%s]' %\\n               (test.__name__, elapsed, result[0], result[-1]))\\n        print('{0:<9}: {1:.5f} => [{2}...{3}]'.format(\\n                test.__name__, elapsed, result[0], result[-1]))\\nYou can judge the difference between these techniques yourself.\\nIf you feel ambitious, you might also try modifying or emulating the timing script to\\nmeasure the speed of the 3.0 set and dictionary comprehensions  illustrated in this chap-\\nter, and their for loop equivalents. Since using them is much less common in Python\\nprograms than building lists of results, we’ll leave this task in the suggested exercise\\ncolumn (and please, no wagering...).\\nFinally, keep the timing module we wrote here filed away for future reference—we’ll\\nrepurpose it to measure performance of alternative numeric square root operations in\\nan exercise at the end of this chapter. If you’re interested in pursuing this topic further,\\nwe’ll also experiment with techniques for timing dictionary comprehensions versus\\nfor loops interactively.\\nFunction Gotchas\\nNow that we’ve reached the end of the function story, let’s review some common pit-\\nfalls. Functions have some jagged edges that you might not expect. They’re all obscure,\\nand a few have started to fall away from the language completely in recent releases, but\\nmost have been known to trip up new users.\\nLocal Names Are Detected Statically\\nAs you know, Python classifies names assigned in a function as locals by default; they\\nlive in the function’s scope and exist only while the function is running. What you may\\nnot realize is that Python detects locals statically, when it compiles the def’s code, rather\\nthan by noticing assignments as they happen at runtime. This leads to one of the most\\ncommon oddities posted on the Python newsgroup by beginners.\\nNormally, a name that isn’t assigned in a function is looked up in the enclosing module:\\n518 | Chapter 20: \\u2002Iterations and Comprehensions, Part 2\", metadata={'source': 'python.pdf', 'page': 568}),\n",
       " Document(page_content='>>> X = 99\\n>>> def selector():       # X used but not assigned\\n...     print(X)          # X found in global scope\\n...\\n>>> selector()\\n99\\nHere, the X in the function resolves to the X in the module. But watch what happens if\\nyou add an assignment to X after the reference:\\n>>> def selector():\\n...     print(X)          # Does not yet exist!\\n...     X = 88            # X classified as a local name (everywhere)\\n...                       # Can also happen for \"import X\", \"def X\"...\\n>>> selector()\\n...error text omitted...\\nUnboundLocalError: local variable \\'X\\' referenced before assignment\\nYou get the \\nname usage error shown here, but the reason is subtle. Python reads and\\ncompiles this code when it’s typed interactively or imported from a module. While\\ncompiling, Python sees the assignment to X and decides that X will be a local name\\neverywhere in the function. But when the function is actually run, because the assign-\\nment hasn’t yet happened when the print executes, Python says you’re using an un-\\ndefined name. According to its name rules, it should say this; the local X is used before\\nbeing assigned. In fact, any assignment in a function body makes a name local. Imports,\\n=, nested defs, nested classes, and so on are all susceptible to this behavior.\\nThe problem occurs because assigned names are treated as locals everywhere in a func-\\ntion, not just after the statements where they are assigned. Really, the previous example\\nis ambiguous at best: was the intention to print the global X and then create a local X,\\nor is this a genuine programming error? Because Python treats X as a local everywhere,\\nit is viewed as an error; if you really mean to print the global X, you need to declare it\\nin a global statement:\\n>>> def selector():\\n...     global X                # Force X to be global (everywhere)\\n...     print(X)\\n...     X = 88\\n...\\n>>> selector()\\n99\\nRemember, though, that this means the assignment also changes the global X, not a\\nlocal X. Within a function, you can’t use both local and global versions of the same\\nsimple name. If you really meant to print the global and then set a local of the same\\nname, you’d need to import the enclosing module and use module attribute notation\\nto get to the global version:\\n>>> X = 99\\n>>> def selector():\\n...     import __main__         # Import enclosing module\\n...     print(__main__.X)       # Qualify to get to global version of name\\n...     X = 88                  # Unqualified X classified as local\\nFunction Gotchas | 519', metadata={'source': 'python.pdf', 'page': 569}),\n",
       " Document(page_content='...     print(X)                # Prints local version of name\\n...\\n>>> selector()\\n99\\n88\\nQualification (the .X \\npart) fetches a value from a namespace object. The interactive\\nnamespace is a module called __main__, so __main__.X reaches the global version of X.\\nIf that isn’t clear, check out Chapter 17.\\nIn recent versions Python has improved on this story somewhat by issuing for this case\\nthe more specific “unbound local” error message shown in the example listing (it used\\nto simply raise a generic name error); this gotcha is still present in general, though.\\nDefaults and Mutable Objects\\nDefault argument values are evaluated and saved when a def statement is run, not when\\nthe resulting function is called. Internally, Python saves one object per default argument\\nattached to the function itself.\\nThat’s usually what you want—because defaults are evaluated at def time, it lets you\\nsave values from the enclosing scope, if needed. But because a default retains an object\\nbetween calls, you have to be careful about changing mutable defaults. For instance,\\nthe following function uses an empty list as a default value, and then changes it in-place\\neach time the function is called:\\n>>> def saver(x=[]):               # Saves away a list object\\n...     x.append(1)                # Changes same object each time!\\n...     print(x)\\n...\\n>>> saver([2])                     # Default not used\\n[2, 1]\\n>>> saver()                        # Default used\\n[1]\\n>>> saver()                        # Grows on each call!\\n[1, 1]\\n>>> saver()\\n[1, 1, 1]\\nSome see this behavior as a feature—because mutable default arguments retain their\\nstate between function calls, they can serve some of the same roles as static local func-\\ntion variables in the C language. In a sense, they work sort of like global variables, but\\ntheir names are local to the functions and so will not clash with names elsewhere in a\\nprogram.\\nTo most observers, though, this seems like a gotcha, especially the first time they run\\ninto it. There are better ways to retain state between calls in Python (e.g., using classes,\\nwhich will be discussed in Part VI).\\nMoreover, mutable defaults are tricky to remember (and to understand at all). They\\ndepend upon the timing of default object construction. In the prior example, there is\\n520 | Chapter 20: \\u2002Iterations and Comprehensions, Part 2', metadata={'source': 'python.pdf', 'page': 570}),\n",
       " Document(page_content=\"just one list object for the default value—the one created when the def is executed. You\\ndon’t get a new list every time the function is called, so the list grows with each new\\nappend; it is not reset to empty on each call.\\nIf that’s not the behavior you want, simply make a copy of the default at the start of\\nthe function body, or move the default value expression into the function body. As long\\nas the value resides in code that’s actually executed each time the function runs, you’ll\\nget a new object each time through:\\n>>> def saver(x=None):\\n...     if x is None:             # No argument passed?\\n...         x = []                # Run code to make a new list\\n...     x.append(1)               # Changes new list object\\n...     print(x)\\n...\\n>>> saver([2])\\n[2, 1]\\n>>> saver()                       # Doesn't grow here\\n[1]\\n>>> saver()\\n[1]\\nBy the way, the if statement in this example could almost be replaced by the assignment\\nx = x or [], which takes advantage of the fact that Python’s or returns one of its\\noperand objects: if no argument was passed, x would default to None, so the or would\\nreturn the new empty list on the right.\\nHowever, this isn’t exactly the same. If an empty list were passed in, the or expression\\nwould cause the function to extend and return a newly created list, rather than ex-\\ntending and returning the passed-in list like the if version. (The expression becomes\\n[] or [], which evaluates to the new empty list on the right; see the section “Truth\\nTests” on page 320 if you don’t recall why). Real program requirements may call for\\neither behavior.\\nToday, another way to achieve the effect of mutable defaults in a possibly less confusing\\nway is to use the function attributes we discussed in Chapter 19:\\n>>> def saver():\\n...     saver.x.append(1)\\n...     print(saver.x)\\n...\\n>>> saver.x = []\\n>>> saver()\\n[1]\\n>>> saver()\\n[1, 1]\\n>>> saver()\\n[1, 1, 1]\\nThe function name is global to the function itself, but it need not be declared because\\nit isn’t changed directly within the function. This isn’t used in exactly the same way,\\nFunction Gotchas | 521\", metadata={'source': 'python.pdf', 'page': 571}),\n",
       " Document(page_content='but when coded like this, the attachment of an object to the function is much more\\nexplicit (and arguably less magical).\\nFunctions Without returns\\nIn Python functions, return\\n (and yield) statements are optional. When a function\\ndoesn’t return a value explicitly, the function exits when control falls off the end of the\\nfunction body. Technically, all functions return a value; if you don’t provide a return\\nstatement, your function returns the None object automatically:\\n>>> def proc(x):\\n...     print(x)                 # No return is a None return\\n...\\n>>> x = proc(\\'testing 123...\\')\\ntesting 123...\\n>>> print(x)\\nNone\\nFunctions such as this without a return are Python’s equivalent of what are called\\n“procedures” in some languages. They’re usually invoked as statements, and the None\\nresults are ignored, as they do their business without computing a useful result.\\nThis is worth knowing, because Python won’t tell you if you try to use the result of a\\nfunction that doesn’t return one. For instance, assigning the result of a list append\\nmethod won’t raise an error, but you’ll get back None, not the modified list:\\n>>> list = [1, 2, 3]\\n>>> list = list.append(4)        # append is a \"procedure\"\\n>>> print(list)                  # append changes list in-place\\nNone\\nAs mentioned in “Common Coding Gotchas” on page 387 in Chapter 15 , such func-\\ntions do their business as a side effect and are usually designed to be run as statements,\\nnot expressions.\\nEnclosing Scope Loop Variables\\nWe described this gotcha in Chapter 17 ’s discussion of enclosing function scopes, but\\nas a reminder, be careful about relying on enclosing function scope lookup for variables\\nthat are changed by enclosing loops—all such references will remember the value of\\nthe last loop iteration. Use defaults to save loop variable values instead (see Chap-\\nter 17 for more details on this topic).\\nChapter Summary\\nThis chapter wrapped up our coverage of built-in comprehension and iteration tools.\\nIt explored list comprehensions in the context of functional tools and presented gen-\\nerator functions and expressions as additional iteration protocol tools. As a finale, we\\n522 | Chapter 20: \\u2002Iterations and Comprehensions, Part 2', metadata={'source': 'python.pdf', 'page': 572}),\n",
       " Document(page_content='also measured the performance of iteration alternatives, and we closed with a review\\nof common function-related mistakes to help you avoid pitfalls.\\nThis concludes the \\nfunctions part of this book. In the next part, we will study modules—\\nthe topmost organizational structure in Python, and the structure in which our func-\\ntions always live. After that, we will explore classes, tools that are largely packages of\\nfunctions with special first arguments. As we’ll see, user-defined classes can implement\\nobjects that tap into the iteration protocol, just like the generators and iterables we met\\nhere. Everything we have learned in this part of the book will apply when functions\\npop up later in the context of class methods.\\nBefore moving on to modules, though, be sure to work through this chapter’s quiz and\\nthe exercises for this part of the book, to practice what we’ve learned about functions\\nhere.\\nTest Your Knowledge: Quiz\\n1. What is the \\ndifference between enclosing a list comprehension in square brackets\\nand parentheses?\\n2. How are generators and iterators related?\\n3. How can you tell if a function is a generator function?\\n4. What does a yield statement do?\\n5. How are map calls and list comprehensions related? Compare and contrast the two.\\nTest Your Knowledge: Answers\\n1. List comprehensions in square brackets produce the result list all at once in mem-\\nory. When they are enclosed in parentheses instead, they are actually generator\\nexpressions—they have a similar meaning but do not produce the result list all at\\nonce. Instead, generator expressions return a generator object, which yields one\\nitem in the result at a time when used in an iteration context.\\n2. Generators are objects that support the iteration protocol—they have a __next__\\nmethod that repeatedly advances to the next item in a series of results and raises\\nan exception at the end of the series. In Python, we can code generator functions\\nwith def, generator expressions with parenthesized list comprehensions, and gen-\\nerator objects with classes that define a special method named __iter__ (discussed\\nlater in the book).\\n3. A generator function has a yield statement somewhere in its code. Generator\\nfunctions are otherwise identical to normal functions syntactically, but they are\\ncompiled specially by Python so as to return an iterable object when called.\\nTest Your Knowledge: Answers | 523', metadata={'source': 'python.pdf', 'page': 573}),\n",
       " Document(page_content='4. When present, this statement makes Python compile the function specially as a\\ngenerator; when \\ncalled, the function returns a generator object that supports the\\niteration protocol. When the yield statement is run, it sends a result back to the\\ncaller and suspends the function’s state; the function can then be resumed after the\\nlast yield statement, in response to a next built-in or __next__ method call issued\\nby the caller. Generator functions may also have a return statement, which termi-\\nnates the generator.\\n5. The map call is similar to a list comprehension—both build a new list by collecting\\nthe results of applying an operation to each item in a sequence or other iterable,\\none item at a time. The main difference is that map applies a function call to each\\nitem, and list comprehensions apply arbitrary expressions. Because of this, list\\ncomprehensions are more general; they can apply a function call expression like\\nmap, but map requires a function to apply other kinds of expressions. List compre-\\nhensions also support extended syntax such as nested for loops and if clauses that\\nsubsume the filter built-in.\\nTest Your Knowledge: Part IV Exercises\\nIn these exercises, you’re going to start coding more sophisticated programs. Be sure\\nto check the solutions in “Part IV, Functions” on page 1111 in Appendix B , and be\\nsure to start writing your code in module files. You won’t want to retype these exercises\\nfrom scratch if you make a mistake.\\n1.The basics . At the Python interactive prompt, write a function that prints its single\\nargument to the screen and call it interactively, passing a variety of object types:\\nstring, integer, list, dictionary. Then, try calling it without passing any argument.\\nWhat happens? What happens when you pass two arguments?\\n2.Arguments. Write a function called adder in a Python module file. The function\\nshould accept two arguments and return the sum (or concatenation) of the two.\\nThen, add code at the bottom of the file to call the adder function with a variety of\\nobject types (two strings, two lists, two floating points), and run this file as a script\\nfrom the system command line. Do you have to print the call statement results to\\nsee results on your screen?\\n3.varargs. Generalize the adder function you wrote in the last exercise to compute\\nthe sum of an arbitrary number of arguments, and change the calls to pass more\\nor fewer than two arguments. What type is the return value sum? (Hints: a slice\\nsuch as S[:0] returns an empty sequence of the same type as S, and the type built-\\nin function can test types; but see the manually coded min examples in Chap-\\nter 18  for a simpler approach.) What happens if you pass in arguments of different\\ntypes? What about passing in dictionaries?\\n524 | Chapter 20: \\u2002Iterations and Comprehensions, Part 2', metadata={'source': 'python.pdf', 'page': 574}),\n",
       " Document(page_content='4.Keywords. Change the adder  function from exercise 2 to accept and sum/concat-\\nenate three arguments: def adder(good, bad, ugly) . Now, provide default values\\nfor each argument, and experiment with calling the function interactively. Try\\npassing one, two, three, and four arguments. Then, try passing keyword argu-\\nments. Does the call adder(ugly=1, good=2) work? Why? Finally, generalize the\\nnew adder to accept and sum/concatenate an arbitrary number of keyword argu-\\nments. This is similar to what you did in exercise 3, but you’ll need to iterate over\\na dictionary, not a tuple. (Hint: the dict.keys method returns a list you can step\\nthrough with a for or while, but be sure to wrap it in a list call to index it in 3.0!)\\n5. Write a function called copyDict(dict) that copies its dictionary argument. It\\nshould return a new dictionary containing all the items in its argument. Use the\\ndictionary keys method to iterate (or, in Python 2.2, step over a dictionary’s keys\\nwithout calling keys). Copying sequences is easy ( X[:] makes a top-level copy);\\ndoes this work for dictionaries, too?\\n6. Write a function called addDict(dict1, dict2) that computes the union of two\\ndictionaries. It should return a new dictionary containing all the items in both its\\narguments (which are assumed to be dictionaries). If the same key appears in both\\narguments, feel free to pick a value from either. Test your function by writing it in\\na file and running the file as a script. What happens if you pass lists instead of\\ndictionaries? How could you generalize your function to handle this case, too?\\n(Hint: see the type built-in function used earlier.) Does the order of the arguments\\npassed in matter?\\n7.More argument-matching examples. First, define the following six functions (either\\ninteractively or in a module file that can be imported):\\ndef f1(a, b): print(a, b)            # Normal args\\ndef f2(a, *b): print(a, b)           # Positional varargs\\ndef f3(a, **b): print(a, b)          # Keyword varargs\\ndef f4(a, *b, **c): print(a, b, c)   # Mixed modes\\ndef f5(a, b=2, c=3): print(a, b, c)  # Defaults\\ndef f6(a, b=2, *c): print(a, b, c)   # Defaults and positional varargs\\nNow, test the following calls interactively, and try to explain each result; in some\\ncases, you’ll probably need to fall back on the matching algorithm shown in Chap-\\nter 18. Do you think mixing matching modes is a good idea in general? Can you\\nthink of cases where it would be useful?\\n>>> f1(1, 2)\\n>>> f1(b=2, a=1)\\n>>> f2(1, 2, 3)\\n>>> f3(1, x=2, y=3)\\n>>> f4(1, 2, 3, x=2, y=3)\\nTest Your Knowledge: Part IV Exercises | 525', metadata={'source': 'python.pdf', 'page': 575}),\n",
       " Document(page_content=\">>> f5(1)\\n>>> f5(1, 4)\\n>>> f6(1)\\n>>> f6(1, 3, 4)\\n8.Primes revisited . Recall \\nthe following code snippet from Chapter 13 , which sim-\\nplistically determines whether a positive integer is prime:\\nx = y // 2                           # For some y > 1\\nwhile x > 1:\\n    if y % x == 0:                   # Remainder\\n      print(y, 'has factor', x)\\n      break                         # Skip else\\n    x -= 1\\nelse:                               # Normal exit\\n    print(y, 'is prime')\\nPackage this code as a reusable function in a module file ( y should be a passed-in\\nargument), and add some calls to the function at the bottom of your file. While\\nyou’re at it, experiment with replacing the first line’s // operator with / to see how\\ntrue division changes the / operator in Python 3.0 and breaks this code (refer back\\nto Chapter 5 if you need a refresher). What can you do about negatives, and the\\nvalues 0 and 1? How about speeding this up? Your outputs should look something\\nlike this:\\n13 is prime\\n13.0 is prime\\n15 has factor 5\\n15.0 has factor 5.0\\n9.List comprehensions . Write code to build a new list containing the square roots of\\nall the numbers in this list: [2, 4, 9, 16, 25]. Code this as a for loop first, then\\nas a map call, and finally as a list comprehension. Use the sqrt function in the built-\\nin math module to do the calculation (i.e., import math and say math.sqrt(x)). Of\\nthe three, which approach do you like best?\\n10.Timing tools. In Chapter 5, we saw three ways to compute square roots:\\nmath.sqrt(X), X ** .5, and pow(X, .5). If your programs run a lot these, their\\nrelative performance might become important. To see which is quickest, repurpose\\nthe timerseqs.py script we wrote in this chapter to time each of these three tools.\\nUse the mytimer.py timer module with the best function (you can use either the\\n3.0-ony keyword-only variant, or the 2.6/3.0 version). You might also want to\\nrepackage the testing code in this script for better reusability—by passing a test\\nfunctions tuple to a general tester function, for example (for this exercise a\\ncopy-and-modify approach is fine). Which of the three square root tools seems to\\nrun fastest on your machine and Python in general? Finally, how might you go\\nabout interactively timing the speed of dictionary comprehensions versus for\\nloops?\\n526 | Chapter 20: \\u2002Iterations and Comprehensions, Part 2\", metadata={'source': 'python.pdf', 'page': 576}),\n",
       " Document(page_content='PART V\\nModules', metadata={'source': 'python.pdf', 'page': 577}),\n",
       " Document(page_content='', metadata={'source': 'python.pdf', 'page': 578}),\n",
       " Document(page_content='CHAPTER 21\\nModules: The Big Picture\\nThis chapter begins our in-depth look at the Python module, the highest-level program\\norganization unit, which packages program code and data for reuse. In concrete terms,\\nmodules usually correspond to Python program files (or extensions coded in external\\nlanguages such as C, Java, or C#). Each file is a module, and modules import other\\nmodules to use the names they define. Modules are processed with two statements and\\none important function:\\nimport\\nLets a client (importer) fetch a module as a whole\\nfrom\\nAllows clients to fetch particular names from a module\\nimp.reload\\nProvides a way to reload a module’s code without stopping Python\\nChapter 3 introduced module fundamentals, and we’ve been using them ever since.\\nThis part of the book begins by expanding on core module concepts, then moves on\\nto explore more advanced module usage. This first chapter offers a general look at the\\nrole of modules in overall program structure. In the following chapters, we’ll dig into\\nthe coding details behind the theory.\\nAlong the way, we’ll flesh out module details omitted so far: you’ll learn about reloads,\\nthe __name__ and __all__ attributes, package imports, relative import syntax, and so\\non. Because modules and classes are really just glorified namespaces, we’ll formalize\\nnamespace concepts here as well.\\nWhy Use Modules?\\nIn short, modules provide an easy way to organize components into a system by serving\\nas self-contained packages of variables known as namespaces. All the names defined at\\nthe top level of a module file become attributes of the imported module object. As we\\nsaw in the last part of this book, imports give access to names in a module’s global\\n529', metadata={'source': 'python.pdf', 'page': 579}),\n",
       " Document(page_content='scope. That is, the module file’s global scope morphs into the module object’s attribute\\nnamespace when it \\nis imported. Ultimately, Python’s modules allow us to link indi-\\nvidual files into a larger program system.\\nMore specifically, from an abstract perspective, modules have at least three roles:\\nCode reuse\\nAs discussed in Chapter 3 , modules let you save code in files permanently. Unlike\\ncode you type at the Python interactive prompt, which goes away when you exit\\nPython, code in module files is persistent—it can be reloaded and rerun as many\\ntimes as needed. More to the point, modules are a place to define names, known\\nas attributes, which may be referenced by multiple external clients.\\nSystem namespace partitioning\\nModules are also the highest-level program organization unit in Python. Funda-\\nmentally, they are just packages of names. Modules seal up names into\\nself-contained packages, which helps avoid name clashes—you can never see a\\nname in another file, unless you explicitly import that file. In fact, everything “lives”\\nin a module—code you execute and objects you create are always implicitly en-\\nclosed in modules. Because of that, modules are natural tools for grouping system\\ncomponents.\\nImplementing shared services or data\\nFrom an operational perspective, modules also come in handy for implementing\\ncomponents that are shared across a system and hence require only a single copy.\\nFor instance, if you need to provide a global object that’s used by more than one\\nfunction or file, you can code it in a module that can then be imported by many\\nclients.\\nFor you to truly understand the role of modules in a Python system, though, we need\\nto digress for a moment and explore the general structure of a Python program.\\nPython Program Architecture\\nSo far in this book, I’ve sugarcoated some of the complexity in my descriptions of\\nPython programs. In practice, programs usually involve more than just one file; for all\\nbut the simplest scripts, your programs will take the form of multifile systems. And\\neven if you can get by with coding a single file yourself, you will almost certainly wind\\nup using external files that someone else has already written.\\nThis section introduces the general architecture of Python programs—the way you\\ndivide a program into a collection of source files (a.k.a. modules) and link the parts\\ninto a whole. Along the way, we’ll also explore the central concepts of Python modules,\\nimports, and object attributes.\\n530 | Chapter 21: \\u2002Modules: The Big Picture', metadata={'source': 'python.pdf', 'page': 580}),\n",
       " Document(page_content='How to Structure a Program\\nGenerally, a Python \\nprogram consists of multiple text files containing Python state-\\nments. The program is structured as one main, top-level file, along with zero or more\\nsupplemental files known as modules in Python.\\nIn Python, the top-level (a.k.a. script) file contains the main flow of control of your\\nprogram—this is the file you run to launch your application. The module files are\\nlibraries of tools used to collect components used by the top-level file (and possibly\\nelsewhere). Top-level files use tools defined in module files, and modules use tools\\ndefined in other modules.\\nModule files generally don’t do anything when run directly; rather, they define tools\\nintended for use in other files. In Python, a file imports a module to gain access to the\\ntools it defines, which are known as its attributes (i.e., variable names attached to ob-\\njects such as functions). Ultimately, we import modules and access their attributes to\\nuse their tools.\\nImports and Attributes\\nLet’s make this a bit more concrete. Figure 21-1  sketches the structure of a Python\\nprogram composed of three files: a.py, b.py, and c.py. The file a.py is chosen to be the\\ntop-level file; it will be a simple text file of statements, which is executed from top to\\nbottom when launched. The files b.py and c.py are modules; they are simple text files\\nof statements as well, but they are not usually launched directly. Instead, as explained\\npreviously, modules are normally imported by other files that wish to use the tools they\\ndefine.\\nFigure 21-1. Program architecture in Python. A program is a system of modules. It has one top-level\\nscript file (launched \\nto run the program), and multiple module files (imported libraries of tools). Scripts\\nand modules are both text files containing Python statements, though the statements in modules\\nusually just create objects to be used later. Python’s standard library provides a collection of precoded\\nmodules.\\nPython Program Architecture | 531', metadata={'source': 'python.pdf', 'page': 581}),\n",
       " Document(page_content=\"For instance, suppose the file b.py in Figure 21-1  defines a function called spam, for\\nexternal use. As we learned when studying functions in Part IV, b.py will contain a\\nPython def statement to generate the function, which can later be run by passing zero\\nor more values in parentheses after the function’s name:\\ndef spam(text):\\n    print(text, 'spam')\\nNow, suppose a.py wants to use spam. To this end, it might contain Python statements\\nsuch as the following:\\nimport b\\nb.spam('gumby')\\nThe first of these, a Python import statement, gives the file a.py access to everything\\ndefined by top-level code in the file b.py. It roughly means “load the file b.py (unless\\nit’s already loaded), and give me access to all its attributes through the name b.”\\nimport (and, as you’ll see later, from) statements execute and load other files at runtime.\\nIn Python, cross-file module linking is not resolved until such import statements are\\nexecuted at runtime; their net effect is to assign module names—simple variables—to\\nloaded module objects. In fact, the module name used in an import statement serves\\ntwo purposes: it identifies the external file to be loaded, but it also becomes a variable\\nassigned to the loaded module. Objects defined by a module are also created at runtime,\\nas the import is executing: import literally runs statements in the target file one at a time\\nto create its contents.\\nThe second of the statements in a.py calls the function spam defined in the module b,\\nusing object attribute notation. The code b.spam means “fetch the value of the name\\nspam that lives within the object b.” This happens to be a callable function in our ex-\\nample, so we pass a string in parentheses ( 'gumby'). If you actually type these files, save\\nthem, and run a.py, the words “gumby spam” will be printed.\\nYou’ll see the object.attribute notation used throughout Python scripts—most ob-\\njects have useful attributes that are fetched with the “.” operator. Some are callable\\nthings like functions, and others are simple data values that give object properties (e.g.,\\na person’s name).\\nThe notion of importing is also completely general throughout Python. Any file can\\nimport tools from any other file. For instance, the file a.py may import b.py to call its\\nfunction, but b.py might also import c.py to leverage different tools defined there. Im-\\nport chains can go as deep as you like: in this example, the module a can import b,\\nwhich can import c, which can import b again, and so on.\\nBesides serving as the highest organizational structure, modules (and module packages,\\ndescribed in Chapter 23 ) are also the highest level of code reuse  in Python. Coding\\ncomponents in module files makes them useful in your original program, and in any\\nother programs you may write. For instance, if after coding the program in Fig-\\nure 21-1  we discover that the function b.spam is a general-purpose tool, we can reuse\\n532 | Chapter 21: \\u2002Modules: The Big Picture\", metadata={'source': 'python.pdf', 'page': 582}),\n",
       " Document(page_content='it in a completely different program; all we have to do is import the file b.py again from\\nthe other program’s files.\\nStandard Library Modules\\nNotice \\nthe rightmost portion of Figure 21-1 . Some of the modules that your programs\\nwill import are provided by Python itself and are not files you will code.\\nPython automatically comes with a large collection of utility modules known as the \\nstandard library. This collection, roughly 200 modules large at last count, contains\\nplatform-independent support for common programming tasks: operating system in-\\nterfaces, object persistence, text pattern matching, network and Internet scripting, GUI\\nconstruction, and much more. None of these tools are part of the Python language\\nitself, but you can use them by importing the appropriate modules on any standard\\nPython installation. Because they are standard library modules, you can also be rea-\\nsonably sure that they will be available and will work portably on most platforms on\\nwhich you will run Python.\\nYou will see a few of the standard library modules in action in this book’s examples,\\nbut for a complete look you should browse the standard Python library reference man-\\nual, available either with your Python installation (via IDLE or the Python Start button\\nmenu on Windows) or online at http://www.python.org.\\nBecause there are so many modules, this is really the only way to get a feel for what\\ntools are available. You can also find tutorials on Python library tools in commercial\\nbooks that cover application-level programming, such as O’Reilly’s Programming Py\\nthon, but the manuals are free, viewable in any web browser (they ship in HTML for-\\nmat), and updated each time Python is rereleased.\\nHow Imports Work\\nThe prior section talked about importing modules without really explaining what hap-\\npens when you do so. Because imports are at the heart of program structure in Python,\\nthis section goes into more detail on the import operation to make this process less\\nabstract.\\nSome C programmers like to compare the Python module import operation to a C\\n#include, but they really shouldn’t—in Python, imports are not just textual insertions\\nof one file into another. They are really runtime operations that perform three distinct\\nsteps the first time a program imports a given file:\\n1.Find the module’s file.\\n2.Compile it to byte code (if needed).\\n3.Run the module’s code to build the objects it defines.\\nHow Imports Work | 533', metadata={'source': 'python.pdf', 'page': 583}),\n",
       " Document(page_content='To better understand module imports, we’ll explore these steps in turn. Bear in mind\\nthat all three \\nof these steps are carried out only the first time  a module is imported\\nduring a program’s execution; later imports of the same module bypass all of these\\nsteps and simply fetch the already loaded module object in memory. Technically, Py-\\nthon does this by storing loaded modules in a table named sys.modules and checking\\nthere at the start of an import operation. If the module is not present, a three-step\\nprocess begins.\\n1. Find It\\nFirst, Python must locate the module file referenced by an import statement. Notice\\nthat the import statement in the prior section’s example names the file without a .py\\nsuffix and without its directory path: it just says import b, instead of something like\\nimport c:\\\\dir1\\\\b.py . In fact, you can only list a simple name; path and suffix details\\nare omitted on purpose and Python uses a standard module search path to locate the\\nmodule file corresponding to an import statement.* Because this is the main part of the\\nimport operation that programmers must know about, we’ll return to this topic in a\\nmoment.\\n2. Compile It (Maybe)\\nAfter finding a source code file that matches an import statement by traversing the\\nmodule search path, Python next compiles it to byte code, if necessary. (We discussed\\nbyte code in Chapter 2.)\\nPython checks the file timestamps and, if the byte code file is older than the source file\\n(i.e., if you’ve changed the source), automatically regenerates the byte code when the\\nprogram is run. If, on the other hand, it finds a .pyc byte code file that is not older than\\nthe corresponding .py source file, it skips the source-to–byte code compile step. In\\naddition, if Python finds only a byte code file on the search path and no source, it simply\\nloads the byte code directly (this means you can ship a program as just byte code files\\nand avoid sending source). In other words, the compile step is bypassed if possible to\\nspeed program startup.\\nNotice that compilation happens when a file is being imported. Because of this, you\\nwill not usually see a .pyc byte code file for the top-level file of your program, unless it\\nis also imported elsewhere—only imported files leave behind .pyc files on your\\n* It’s actually syntactically illegal to include path and suffix details in a standard import. Package imports , which\\nwe’ll discuss in Chapter 23 , allow import statements to include part of the directory path leading to a file as\\na set of period-separated names; however, package imports still rely on the normal module search path to\\nlocate the leftmost directory in a package path (i.e., they are relative to a directory in the search path). They\\nalso cannot make use of any platform-specific directory syntax in the import statements; such syntax only\\nworks on the search path. Also, note that module file search path issues are not as relevant when you run\\nfrozen executables (discussed in Chapter 2); they typically embed byte code in the binary image.\\n534 | Chapter 21: \\u2002Modules: The Big Picture', metadata={'source': 'python.pdf', 'page': 584}),\n",
       " Document(page_content='machine. The byte code of top-level files is used internally and discarded; byte code of\\nimported files is saved in files to speed future imports.\\nTop-level files \\nare often designed to be executed directly and not imported at all. Later,\\nwe’ll see that it is possible to design a file that serves both as the top-level code of a\\nprogram and as a module of tools to be imported. Such a file may be both executed\\nand imported, and thus does generate a .pyc. To learn how this works, watch for the\\ndiscussion of the special __name__ attribute and __main__ in Chapter 24.\\n3. Run It\\nThe final step of an import operation executes the byte code of the module. All state-\\nments in the file are executed in turn, from top to bottom, and any assignments made\\nto names during this step generate attributes of the resulting module object. This exe-\\ncution step therefore generates all the tools that the module’s code defines. For instance,\\ndef statements in a file are run at import time to create functions and assign attributes\\nwithin the module to those functions. The functions can then be called later in the\\nprogram by the file’s importers.\\nBecause this last import step actually runs the file’s code, if any top-level code in a\\nmodule file does real work, you’ll see its results at import time. For example, top-level\\nprint statements in a module show output when the file is imported. Function def\\nstatements simply define objects for later use.\\nAs you can see, import operations involve quite a bit of work—they search for files,\\npossibly run a compiler, and run Python code. Because of this, any given module is\\nimported only once per process by default. Future imports skip all three import steps\\nand reuse the already loaded module in memory. If you need to import a file again after\\nit has already been loaded (for example, to support end-user customization), you have\\nto force the issue with an imp.reload call—a tool we’ll meet in the next chapter.†\\nThe Module Search Path\\nAs mentioned earlier, the part of the import procedure that is most important to pro-\\ngrammers is usually the first—locating the file to be imported (the “find it” part). Be-\\ncause you may need to tell Python where to look to find files to import, you need to\\nknow how to tap into its search path in order to extend it.\\n† As described earlier, Python keeps already imported modules in the built-in sys.modules dictionary so it can\\nkeep track of what’s been loaded. In fact, if you want to see which modules are loaded, you can import sys\\nand print list(sys.modules.keys()). More on other uses for this internal table in Chapter 24.\\nThe Module Search Path | 535', metadata={'source': 'python.pdf', 'page': 585}),\n",
       " Document(page_content='In many cases, you can rely on the automatic nature of the module import search path\\nand won’t need \\nto configure this path at all. If you want to be able to import files across\\ndirectory boundaries, though, you will need to know how the search path works in\\norder to customize it. Roughly, Python’s module search path is composed of the\\nconcatenation of these major components, some of which are preset for you and some\\nof which you can tailor to tell Python where to look:\\n1. The home directory of the program\\n2.PYTHONPATH directories (if set)\\n3. Standard library directories\\n4. The contents of any .pth files (if present)\\nUltimately, the concatenation of these four components becomes sys.path, a list of\\ndirectory name strings that I’ll expand upon later in this section. The first and third\\nelements of the search path are defined automatically. Because Python searches the\\nconcatenation of these components from first to last, though, the second and fourth\\nelements can be used to extend the path to include your own source code directories.\\nHere is how Python uses each of these path components:\\nHome directory\\nPython first looks for the imported file in the home directory. The meaning of this\\nentry depends on how you are running the code. When you’re running a program,\\nthis entry is the directory containing your program’s top-level script file. When\\nyou’re working interactively, this entry is the directory in which you are working\\n(i.e., the current working directory).\\nBecause this directory is always searched first, if a program is located entirely in a\\nsingle directory, all of its imports will work automatically with no path configura-\\ntion required. On the other hand, because this directory is searched first, its files\\nwill also override modules of the same name in directories elsewhere on the path;\\nbe careful not to accidentally hide library modules this way if you need them in\\nyour program.\\nPYTHONPATH directories\\nNext, Python searches all directories listed in your PYTHONPATH environment\\nvariable setting, from left to right (assuming you have set this at all). In brief,\\nPYTHONPATH is simply set to a list of user-defined and platform-specific names of\\ndirectories that contain Python code files. You can add all the directories from\\nwhich you wish to be able to import, and Python will extend the module search\\npath to include all the directories your PYTHONPATH lists.\\nBecause Python searches the home directory first, this setting is only important\\nwhen importing files across directory boundaries—that is, if you need to import a\\nfile that is stored in a different directory from the file that imports it. You’ll probably\\nwant to set your PYTHONPATH variable once you start writing substantial programs,\\nbut when you’re first starting out, as long as you save all your module files in the\\n536 | Chapter 21: \\u2002Modules: The Big Picture', metadata={'source': 'python.pdf', 'page': 586}),\n",
       " Document(page_content='directory in which you’re working (i.e., the home directory, described earlier) your\\nimports will work without you needing to worry about this setting at all.\\nStandard library directories\\nNext, Python automatically \\nsearches the directories where the standard library\\nmodules are installed on your machine. Because these are always searched, they\\nnormally do not need to be added to your PYTHONPATH or included in path files\\n(discussed next).\\n.pth path file directories\\nFinally, a lesser-used feature of Python allows users to add directories to the module\\nsearch path by simply listing them, one per line, in a text file whose name ends\\nwith a .pth suffix (for “path”). These path configuration files are a somewhat ad-\\nvanced installation-related feature; we won’t them cover fully here, but they pro-\\nvide an alternative to PYTHONPATH settings.\\nIn short, text files of directory names dropped in an appropriate directory can serve\\nroughly the same role as the PYTHONPATH environment variable setting. For instance,\\nif you’re running Windows and Python 3.0, a file named myconfig.pth may be\\nplaced at the top level of the Python install directory ( C:\\\\Python30) or in the site-\\npackages subdirectory of the standard library there ( C:\\\\Python30\\\\Lib\\\\site-\\npackages) to extend the module search path. On Unix-like systems, this file might\\nbe located in usr/local/lib/python3.0/site-packages or /usr/local/lib/site-python\\ninstead.\\nWhen present, Python will add the directories listed on each line of the file, from\\nfirst to last, near the end of the module search path list. In fact, Python will collect\\nthe directory names in all the path files it finds and will filter out any duplicates\\nand nonexistent directories. Because they are files rather than shell settings, path\\nfiles can apply to all users of an installation, instead of just one user or shell. More-\\nover, for some users text files may be simpler to code than environment settings.\\nThis feature is more sophisticated than I’ve described here. For more details consult\\nthe Python library manual, and especially its documentation for the standard li-\\nbrary module site—this module allows the locations of Python libraries and path\\nfiles to be configured, and its documentation describes the expected locations of\\npath files in general. I recommend that beginners use PYTHONPATH or perhaps a sin-\\ngle .pth file, and then only if you must import across directories. Path files are used\\nmore often by third-party libraries, which commonly install a path file in Python’s\\nsite-packages directory so that user settings are not required (Python’s distutils\\ninstall system, described in an upcoming sidebar, automates many install steps).\\nConfiguring the Search Path\\nThe net effect of all of this is that both the PYTHONPATH and path file components of the\\nsearch path allow you to tailor the places where imports look for files. The way you set\\nenvironment variables and where you store path files varies per platform. For instance,\\nThe Module Search Path | 537', metadata={'source': 'python.pdf', 'page': 587}),\n",
       " Document(page_content='on Windows, you might use your Control Panel’s System icon to set PYTHONPATH to a\\nlist of directories separated by semicolons, like this:\\nc:\\\\pycode\\\\utilities;d:\\\\pycode\\\\package1\\nOr you might instead create a text file called C:\\\\Python30\\\\pydirs.pth\\n, which looks like\\nthis:\\nc:\\\\pycode\\\\utilities\\nd:\\\\pycode\\\\package1\\nThese settings are analogous on other platforms, but the details can vary too widely for\\nus to cover in this chapter. See Appendix A for pointers on extending your module\\nsearch path with PYTHONPATH or .pth files on various platforms.\\nSearch Path Variations\\nThis description of the module search path is accurate, but generic; the exact config-\\nuration of the search path is prone to changing across platforms and Python releases.\\nDepending on your platform, additional directories may automatically be added to the\\nmodule search path as well.\\nFor instance, Python may add an entry for the current working directory—the directory\\nfrom which you launched your program—in the search path after the PYTHONPATH di-\\nrectories, and before the standard library entries. When you’re launching from a com-\\nmand line, the current working directory may not be the same as the home directory\\nof your top-level file (i.e., the directory where your program file resides). Because the\\ncurrent working directory can vary each time your program runs, you normally\\nshouldn’t depend on its value for import purposes. See Chapter 3  for more on launching\\nprograms from command lines.‡\\nTo see how your Python configures the module search path on your platform, you can\\nalways inspect sys.path—the topic of the next section.\\nThe sys.path List\\nIf you want to see how the module search path is truly configured on your machine,\\nyou can always inspect the path as Python knows it by printing the built-in sys.path\\nlist (that is, the path attribute of the standard library module sys). This list of directory\\nname strings is the actual search path within Python; on imports, Python searches each\\ndirectory in this list from left to right.\\n‡ See also Chapter 23 ’s discussion of the new relative import syntax in Python 3.0; this modifies the search\\npath for from statements in files inside packages when “.” characters are used (e.g., from . import string).\\nBy default, a package’s own directory is not automatically searched by imports in Python 3.0, unless relative\\nimports are used by files in the package itself.\\n538 | Chapter 21: \\u2002Modules: The Big Picture', metadata={'source': 'python.pdf', 'page': 588}),\n",
       " Document(page_content=\"Really, sys.path is the module search path. Python configures it at program startup,\\nautomatically merging the home directory of the top-level file (or an empty string to\\ndesignate the current working directory), any PYTHONPATH directories, the contents of\\nany .pth file paths you’ve created, and the standard library directories. The result is a\\nlist of directory name strings that Python searches on each import of a new file.\\nPython exposes this list for two good reasons. First, it provides a way to verify the search\\npath settings you’ve made—if you don’t see your settings somewhere in this list, you\\nneed to recheck your work. For example, here is what my module search path looks\\nlike on Windows under Python 3.0, with my PYTHONPATH set to C:\\\\users and a\\nC:\\\\Python30\\\\mypath.py path file that lists C:\\\\users\\\\mark. The empty string at the front\\nmeans current directory and my two settings are merged in (the rest are standard library\\ndirectories and files):\\n>>> import sys\\n>>> sys.path\\n['', 'C:\\\\\\\\users', 'C:\\\\\\\\Windows\\\\\\\\system32\\\\\\\\python30.zip', 'c:\\\\\\\\Python30\\\\\\\\DLLs',\\n'c:\\\\\\\\Python30\\\\\\\\lib', 'c:\\\\\\\\Python30\\\\\\\\lib\\\\\\\\plat-win', 'c:\\\\\\\\Python30',\\n'C:\\\\\\\\Users\\\\\\\\Mark', 'c:\\\\\\\\Python30\\\\\\\\lib\\\\\\\\site-packages']\\nSecond, if you know what you’re doing, this list provides a way for scripts to tailor their\\nsearch paths manually. As you’ll see later in this part of the book, by modifying the\\nsys.path list, you can modify the search path for all future imports. Such changes only\\nlast for the duration of the script, however; PYTHONPATH and .pth files offer more per-\\nmanent ways to modify the path.§\\nModule File Selection\\nKeep in mind that filename suffixes (e.g., .py) are intentionally omitted from import\\nstatements. Python chooses the first file it can find on the search path that matches the\\nimported name. For example, an import statement of the form import b might load:\\n• A source code file named b.py\\n• A byte code file named b.pyc\\n• A directory named b, for package imports (described in Chapter 23)\\n• A compiled extension module, usually coded in C or C++ and dynamically linked\\nwhen imported (e.g., b.so on Linux, or b.dll or b.pyd on Cygwin and Windows)\\n• A compiled built-in module coded in C and statically linked into Python\\n• A ZIP file component that is automatically extracted when imported\\n• An in-memory image, for frozen executables\\n§ Some programs really need to change sys.path, though. Scripts that run on web servers, for example, often\\nrun as the user “nobody” to limit machine access. Because such scripts cannot usually depend on “nobody”\\nto have set PYTHONPATH in any particular way, they often set sys.path manually to include required source\\ndirectories, prior to running any import statements. A sys.path.append(dirname) will often suffice.\\nThe Module Search Path | 539\", metadata={'source': 'python.pdf', 'page': 589}),\n",
       " Document(page_content='• A Java class, in the Jython version of Python\\n• A .NET component, in the IronPython version of Python\\nC extensions, \\nJython, and package imports all extend imports beyond simple files. To\\nimporters, though, differences in the loaded file type are completely transparent, both\\nwhen importing and when fetching module attributes. Saying import b  gets whatever\\nmodule b is, according to your module search path, and b.attr fetches an item in the\\nmodule, be it a Python variable or a linked-in C function. Some standard modules we\\nwill use in this book are actually coded in C, not Python; because of this transparency,\\ntheir clients don’t have to care.\\nIf you have both a b.py and a b.so in different directories, Python will always load the\\none found in the first (leftmost) directory of your module search path during the left-\\nto-right search of sys.path. But what happens if it finds both a b.py and a b.so in the\\nsame directory? In this case, Python follows a standard picking order, though this order\\nis not guaranteed to stay the same over time. In general, you should not depend on\\nwhich type of file Python will choose within a given directory—make your module\\nnames distinct, or configure your module search path to make your module selection\\npreferences more obvious.\\nAdvanced Module Selection Concepts\\nNormally, imports work as described in this section—they find and load files on your\\nmachine. However, it is possible to redefine much of what an import operation does\\nin Python, using what are known as import hooks . These hooks can be used to make\\nimports do various useful things, such as loading files from archives, performing de-\\ncryption, and so on.\\nIn fact, Python itself makes use of these hooks to enable files to be directly imported\\nfrom ZIP archives: archived files are automatically extracted at import time when\\na .zip file is selected from the module import search path. One of the standard library\\ndirectories in the earlier sys.path display, for example, is a .zip file today. For more\\ndetails, see the Python standard library manual’s description of the built-in\\n__import__ function, the customizable tool that import statements actually run.\\nPython also supports the notion of .pyo optimized byte code files, created and run with\\nthe -O Python command-line flag; because these run only slightly faster than nor-\\nmal .pyc files (typically 5 percent faster), however, they are infrequently used. The Psyco\\nsystem (see Chapter 2) provides more substantial speedups.\\nThird-Party Software: distutils\\nThis chapter’s description \\nof module search path settings is targeted mainly at user-\\ndefined source code that you write on your own. Third-party extensions for Python\\ntypically use the distutils tools in the standard library to automatically install them-\\nselves, so no path configuration is required to use their code.\\n540 | Chapter 21: \\u2002Modules: The Big Picture', metadata={'source': 'python.pdf', 'page': 590}),\n",
       " Document(page_content='Systems that use distutils generally come with a setup.py script, which is run to install\\nthem; this script imports and uses distutils modules to place such systems in a direc-\\ntory that is automatically part of the module search path (usually in the Lib\\\\site-\\npackages subdirectory of the Python install tree, wherever that resides on the target\\nmachine).\\nFor more details on distributing and installing with distutils, see the Python standard\\nmanual set; its use is beyond the scope of this book (for instance, it also provides ways\\nto automatically compile C-coded extensions on the target machine). Also check out\\nthe emerging third-party open source eggs system, which adds dependency checking\\nfor installed Python software.\\nChapter Summary\\nIn this chapter, \\nwe covered the basics of modules, attributes, and imports and explored\\nthe operation of import statements. We learned that imports find the designated file on\\nthe module search path, compile it to byte code, and execute all of its statements to\\ngenerate its contents. We also learned how to configure the search path to be able to\\nimport from directories other than the home directory and the standard library direc-\\ntories, primarily with PYTHONPATH settings.\\nAs this chapter demonstrated, the import operation and modules are at the heart of\\nprogram architecture in Python. Larger programs are divided into multiple files, which\\nare linked together at runtime by imports. Imports in turn use the module search path\\nto locate files, and modules define attributes for external use.\\nOf course, the whole point of imports and modules is to provide a structure to your\\nprogram, which divides its logic into self-contained software components. Code in one\\nmodule is isolated from code in another; in fact, no file can ever see the names defined\\nin another, unless explicit import statements are run. Because of this, modules minimize\\nname collisions between different parts of your program.\\nYou’ll see what this all means in terms of actual statements and code in the next chapter.\\nBefore we move on, though, let’s run through the chapter quiz.\\nTest Your Knowledge: Quiz\\n1. How does a module source code file become a module object?\\n2.Why might you have to set your \\nPYTHONPATH environment variable?\\n3. Name the four major components of the module import search path.\\n4. Name four file types that Python might load in response to an import operation.\\n5. What is a namespace, and what does a module’s namespace contain?\\nTest Your Knowledge: Quiz | 541', metadata={'source': 'python.pdf', 'page': 591}),\n",
       " Document(page_content='Test Your Knowledge: Answers\\n1. A module’s source \\ncode file automatically becomes a module object when that\\nmodule is imported. Technically, the module’s source code is run during the\\nimport, one statement at a time, and all the names assigned in the process become\\nattributes of the module object.\\n2. You only need to set PYTHONPATH to import from directories other than the one in\\nwhich you are working (i.e., the current directory when working interactively, or\\nthe directory containing your top-level file).\\n3. The four major components of the module import search path are the top-level\\nscript’s home directory (the directory containing it), all directories listed in the\\nPYTHONPATH environment variable, the standard library directories, and all directo-\\nries listed in .pth path files located in standard places. Of these, programmers can\\ncustomize PYTHONPATH and .pth files.\\n4. Python might load a source code ( .py) file, a byte code ( .pyc) file, a C extension\\nmodule (e.g., a .so file on Linux or a .dll or .pyd file on Windows), or a directory\\nof the same name for package imports. Imports may also load more exotic things\\nsuch as ZIP file components, Java classes under the Jython version of Python, .NET\\ncomponents under IronPython, and statically linked C extensions that have no files\\npresent at all. With import hooks, imports can load anything.\\n5. A namespace is a self-contained package of variables, which are known as the\\nattributes of the namespace object. A module’s namespace contains all the names\\nassigned by code at the top level of the module file (i.e., not nested in def or\\nclass statements). Technically, a module’s global scope morphs into the module\\nobject’s attributes namespace. A module’s namespace may also be altered by as-\\nsignments from other files that import it, though this is frowned upon (see Chap-\\nter 17 for more on this issue).\\n542 | Chapter 21: \\u2002Modules: The Big Picture', metadata={'source': 'python.pdf', 'page': 592}),\n",
       " Document(page_content='CHAPTER 22\\nModule Coding Basics\\nNow that we’ve looked at the larger ideas behind modules, let’s turn to a simple ex-\\nample of modules \\nin action. Python modules are easy to create; they’re just files of\\nPython program code created with a text editor. You don’t need to write special syntax\\nto tell Python you’re making a module; almost any text file will do. Because Python\\nhandles all the details of finding and loading modules, modules are also easy to use;\\nclients simply import a module, or specific names a module defines, and use the objects\\nthey reference.\\nModule Creation\\nTo define a module, simply use your text editor to type some Python code into a text\\nfile, and save it with a “.py” extension; any such file is automatically considered a\\nPython module. All the names assigned at the top level of the module become its\\nattributes (names associated with the module object) and are exported for clients to use.\\nFor instance, if you type the following def into a file called module1.py and import it,\\nyou create a module object with one attribute—the name printer, which happens to\\nbe a reference to a function object:\\ndef printer(x):                   # Module attribute\\n    print(x)\\nBefore we go on, I should say a few more words about module filenames. You can call\\nmodules just about anything you like, but module filenames should end in a .py suffix\\nif you plan to import them. The .py is technically optional for top-level files that will\\nbe run but not imported, but adding it in all cases makes your files’ types more obvious\\nand allows you to import any of your files in the future.\\nBecause module names become variable names inside a Python program (without\\nthe .py), they should also follow the normal variable name rules outlined in Chap-\\nter 11 . For instance, you can create a module file named if.py, but you cannot import\\nit because if is a reserved word—when you try to run import if, you’ll get a syntax\\nerror. In fact, both the names of module files and the names of directories used in\\n543', metadata={'source': 'python.pdf', 'page': 593}),\n",
       " Document(page_content=\"package imports (discussed in the next chapter) must conform to the rules for variable\\nnames presented in Chapter \\n11; they may, for instance, contain only letters, digits, and\\nunderscores. Package directories also cannot contain platform-specific syntax such as\\nspaces in their names.\\nWhen a module is imported, Python maps the internal module name to an external\\nfilename by adding a directory path from the module search path to the front, and\\na .py or other extension at the end. For instance, a module named M ultimately maps\\nto some external file <directory>\\\\M.<extension> that contains the module’s code.\\nAs mentioned in the preceding chapter, it is also possible to create a Python module by\\nwriting code in an external language such as C or C++ (or Java, in the Jython imple-\\nmentation of the language). Such modules are called extension modules , and they are\\ngenerally used to wrap up external libraries for use in Python scripts. When imported\\nby Python code, extension modules look and feel the same as modules coded as Python\\nsource code files—they are accessed with import statements, and they provide functions\\nand objects as module attributes. Extension modules are beyond the scope of this book;\\nsee Python’s standard manuals or advanced texts such as Programming Python for more\\ndetails.\\nModule Usage\\nClients can use the simple module file we just wrote by running an import or from\\nstatement. Both statements find, compile, and run a module file’s code, if it hasn’t yet\\nbeen loaded. The chief difference is that import fetches the module as a whole, so you\\nmust qualify to fetch its names; in contrast, from fetches (or copies) specific names out\\nof the module.\\nLet’s see what this means in terms of code. All of the following examples wind up calling\\nthe printer function defined in the prior section’s module1.py module file, but in dif-\\nferent ways.\\nThe import Statement\\nIn the first example, the name module1 serves two different purposes—it identifies an\\nexternal file to be loaded, and it becomes a variable in the script, which references the\\nmodule object after the file is loaded:\\n>>> import module1                         # Get module as a whole\\n>>> module1.printer('Hello world!')        # Qualify to get names\\nHello world!\\nBecause import gives a name that refers to the whole module object, we must go through\\nthe module name to fetch its attributes (e.g., module1.printer).\\n544 | Chapter 22: \\u2002Module Coding Basics\", metadata={'source': 'python.pdf', 'page': 594}),\n",
       " Document(page_content=\"The from Statement\\nBy contrast, because from\\n also copies names from one file over to another scope, it\\nallows us to use the copied names directly in the script without going through the\\nmodule (e.g., printer):\\n>>> from module1 import printer            # Copy out one variable\\n>>> printer('Hello world!')                # No need to qualify name\\nHello world!\\nThis has the same effect as the prior example, but because the imported name is copied\\ninto the scope where the from statement appears, using that name in the script requires\\nless typing: we can use it directly instead of naming the enclosing module.\\nAs you’ll see in more detail later, the from statement is really just a minor extension to\\nthe import statement—it imports the module file as usual, but adds an extra step that\\ncopies one or more names out of the file.\\nThe from * Statement\\nFinally, the next example uses a special form of from: when we use a *, we get copies\\nof all the names assigned at the top level of the referenced module. Here again, we can\\nthen use the copied name printer in our script without going through the module name:\\n>>> from module1 import *                   # Copy out all variables\\n>>> printer('Hello world!')\\nHello world!\\nTechnically, both import and from statements invoke the same import operation; the\\nfrom *  form simply adds an extra step that copies all the names in the module into the\\nimporting scope. It essentially collapses one module’s namespace into another; again,\\nthe net effect is less typing for us.\\nAnd that’s it—modules really are simple to use. To give you a better understanding of\\nwhat really happens when you define and use modules, though, let’s move on to look\\nat some of their properties in more detail.\\nIn Python 3.0, the from ...* statement form described here can be used\\nonly at the top level of a module file, not within a function. Python 2.6\\nallows it to be used within a function, but issues a warning. It’s ex-\\ntremely rare to see this statement used inside a function in practice;\\nwhen present, it makes it impossible for Python to detect variables stat-\\nically, before the function runs.\\nModule Usage | 545\", metadata={'source': 'python.pdf', 'page': 595}),\n",
       " Document(page_content=\"Imports Happen Only Once\\nOne of the \\nmost common questions people seem to ask when they start using modules\\nis, “Why won’t my imports keep working?” They often report that the first import\\nworks fine, but later imports during an interactive session (or program run) seem to\\nhave no effect. In fact, they’re not supposed to. This section explains why.\\nModules are loaded and run on the first import or from, and only the first. This is on\\npurpose—because importing is an expensive operation, by default Python does it just\\nonce per file, per process. Later import operations simply fetch the already loaded\\nmodule object.\\nAs one consequence, because top-level code in a module file is usually executed only\\nonce, you can use it to initialize variables. Consider the file simple.py, for example:\\nprint('hello')\\nspam = 1                   # Initialize variable\\nIn this example, the print and = statements run the first time the module is imported,\\nand the variable spam is initialized at import time:\\n% python\\n>>> import simple          # First import: loads and runs file's code\\nhello\\n>>> simple.spam            # Assignment makes an attribute\\n1\\nSecond and later imports don’t rerun the module’s code; they just fetch the already\\ncreated module object from Python’s internal modules table. Thus, the variable spam\\nis not reinitialized:\\n>>> simple.spam = 2        # Change attribute in module\\n>>> import simple          # Just fetches already loaded module\\n>>> simple.spam            # Code wasn't rerun: attribute unchanged\\n2\\nOf course, sometimes you really want a module’s code to be rerun on a subsequent\\nimport. We’ll see how to do this with Python’s reload function later in this chapter.\\nimport and from Are Assignments\\nJust like def, import and from are executable statements, not compile-time declarations.\\nThey may be nested in if tests, appear in function defs, and so on, and they are not\\nresolved or run until Python reaches them while executing your program. In other\\nwords, imported modules and names are not available until their associated import or\\nfrom statements run. Also, like def, import and from are implicit assignments:\\n•import assigns an entire module object to a single name.\\n•from assigns one or more names to objects of the same names in another module.\\n546 | Chapter 22: \\u2002Module Coding Basics\", metadata={'source': 'python.pdf', 'page': 596}),\n",
       " Document(page_content=\"All the things we’ve already discussed about assignment apply to module access, too.\\nFor instance, names \\ncopied with a from become references to shared objects; as with\\nfunction arguments, reassigning a fetched name has no effect on the module from which\\nit was copied, but changing a fetched mutable object  can change it in the module from\\nwhich it was imported. To illustrate, consider the following file, small.py:\\nx = 1\\ny = [1, 2]\\n% python\\n>>> from small import x, y         # Copy two names out\\n>>> x = 42                         # Changes local x only\\n>>> y[0] = 42                      # Changes shared mutable in-place\\nHere, x is not a shared mutable object, but y is. The name y in the importer and the\\nimportee reference the same list object, so changing it from one place changes it in the\\nother:\\n>>> import small                   # Get module name (from doesn't)\\n>>> small.x                        # Small's x is not my x\\n1\\n>>> small.y                        # But we share a changed mutable\\n[42, 2]\\nFor a graphical picture of what from assignments do with references, flip back to Fig-\\nure 18-1  (function argument passing), and mentally replace “caller” and “function”\\nwith “imported” and “importer.” The effect is the same, except that here we’re dealing\\nwith names in modules, not functions. Assignment works the same everywhere in\\nPython.\\nCross-File Name Changes\\nRecall from the preceding example that the assignment to x in the interactive session\\nchanged the name x in that scope only, not the x in the file—there is no link from a\\nname copied with from back to the file it came from. To really change a global name in\\nanother file, you must use import:\\n% python\\n>>> from small import x, y         # Copy two names out\\n>>> x = 42                         # Changes my x only\\n>>> import small                   # Get module name\\n>>> small.x = 42                   # Changes x in other module\\nThis phenomenon was introduced in Chapter 17 . Because changing variables in other\\nmodules like this is a common source of confusion (and often a bad design choice),\\nwe’ll revisit this technique again later in this part of the book. Note that the change to\\ny[0] in the prior session is different; it changes an object, not a name.\\nModule Usage | 547\", metadata={'source': 'python.pdf', 'page': 597}),\n",
       " Document(page_content='import and from Equivalence\\nNotice in the \\nprior example that we have to execute an import statement after the\\nfrom to access the small module name at all. from only copies names from one module\\nto another; it does not assign the module name itself. At least conceptually, a from\\nstatement like this one:\\nfrom module import name1, name2     # Copy these two names out (only)\\nis equivalent to this statement sequence:\\nimport module                       # Fetch the module object\\nname1 = module.name1                # Copy names out by assignment\\nname2 = module.name2\\ndel module                          # Get rid of the module name\\nLike all assignments, the from statement creates new variables in the importer, which\\ninitially refer to objects of the same names in the imported file. Only the names are\\ncopied out, though, not the module itself. When we use the from *  form of this state-\\nment (from module import * ), the equivalence is the same, but all the top-level names\\nin the module are copied over to the importing scope this way.\\nNotice that the first step of the from runs a normal import operation. Because of this,\\nthe from always imports the entire module into memory if it has not yet been imported,\\nregardless of how many names it copies out of the file. There is no way to load just part\\nof a module file (e.g., just one function), but because modules are byte code in Python\\ninstead of machine code, the performance implications are generally negligible.\\nPotential Pitfalls of the from Statement\\nBecause the from statement makes the location of a variable more implicit and obscure\\n(name is less meaningful to the reader than module.name), some Python users recommend\\nusing import instead of from most of the time. I’m not sure this advice is warranted,\\nthough; from is commonly and widely used, without too many dire consequences. In\\npractice, in realistic programs, it’s often convenient not to have to type a module’s name\\nevery time you wish to use one of its tools. This is especially true for large modules that\\nprovide many attributes—the standard library’s tkinter GUI module, for example.\\nIt is true that the from statement has the potential to corrupt namespaces, at least in\\nprinciple—if you use it to import variables that happen to have the same names as\\nexisting variables in your scope, your variables will be silently overwritten. This prob-\\nlem doesn’t occur with the simple import statement because you must always go\\nthrough a module’s name to get to its contents ( module.attr will not clash with a\\nvariable named attr in your scope). As long as you understand and expect that this can\\nhappen when using from, though, this isn’t a major concern in practice, especially if\\nyou list the imported names explicitly (e.g., from module import x, y, z).\\nOn the other hand, the from statement has more serious issues when used in conjunc-\\ntion with the reload call, as imported names might reference prior versions of objects.\\n548 | Chapter 22: \\u2002Module Coding Basics', metadata={'source': 'python.pdf', 'page': 598}),\n",
       " Document(page_content='Moreover, the from module import * form really can corrupt namespaces and make\\nnames difficult to understand, especially when applied to more than one file—in this\\ncase, there is no way to tell which module a name came from, short of searching the\\nexternal source files. In effect, the from *  form collapses one namespace into another,\\nand so defeats the namespace partitioning feature of modules. We will explore these\\nissues in more detail in the section “Module Gotchas” on page 599 at the end of this\\npart of the book (see Chapter 24).\\nProbably the best real-world advice here is to generally prefer import to from for simple\\nmodules, to explicitly list the variables you want in most from statements, and to limit\\nthe from * form to just one import per file. That way, any undefined names can be\\nassumed to live in the module referenced with the from * . Some care is required when\\nusing the from statement, but armed with a little knowledge, most programmers find\\nit to be a convenient way to access modules.\\nWhen import is required\\nThe only time you really must use import instead of from is when you must use the same\\nname defined in two different modules. For example, if two files define the same name\\ndifferently:\\n# M.py\\ndef func():\\n    ...do something...\\n# N.py\\ndef func():\\n    ...do something else...\\nand you must use both versions of the name in your program, the from statement will\\nfail—you can only have one assignment to the name in your scope:\\n# O.py\\nfrom M import func\\nfrom N import func        # This overwites the one we got from M\\nfunc()                    # Calls N.func only\\nAn import will work here, though, because including the name of the enclosing module\\nmakes the two names unique:\\n# O.py\\nimport M, N               # Get the whole modules, not their names\\nM.func()                  # We can call both names now\\nN.func()                  # The module names make them unique\\nThis case is unusual enough that you’re unlikely to encounter it very often in practice.\\nIf you do, though, import allows you to avoid the name collision.\\nModule Usage | 549', metadata={'source': 'python.pdf', 'page': 599}),\n",
       " Document(page_content='Module Namespaces\\nModules are probably \\nbest understood as simply packages of names—i.e., places to\\ndefine names you want to make visible to the rest of a system. Technically, modules\\nusually correspond to files, and Python creates a module object to contain all the names\\nassigned in a module file. But in simple terms, modules are just namespaces (places\\nwhere names are created), and the names that live in a module are called its attrib-\\nutes. We’ll explore how all this works in this section.\\nFiles Generate Namespaces\\nSo, how do files morph into namespaces? The short story is that every name that is\\nassigned a value at the top level of a module file (i.e., not nested in a function or class\\nbody) becomes an attribute of that module.\\nFor instance, given an assignment statement such as X = 1  at the top level of a module\\nfile M.py, the name X becomes an attribute of M, which we can refer to from outside the\\nmodule as M.X. The name X also becomes a global variable to other code inside M.py,\\nbut we need to explain the notion of module loading and scopes a bit more formally\\nto understand why:\\n•Module statements run on the first import . The first time a module is imported\\nanywhere in a system, Python creates an empty module object and executes the\\nstatements in the module file one after another, from the top of the file to the\\nbottom.\\n•Top-level assignments create module attributes . During an import, statements\\nat the top level of the file not nested in a def or class that assign names (e.g., =,\\ndef) create attributes of the module object; assigned names are stored in the mod-\\nule’s namespace.\\n•Module namespaces can be accessed via the attribute __dict__ or dir(M).\\nModule namespaces created by imports are dictionaries; they may be accessed\\nthrough the built-in __dict__ attribute associated with module objects and may be\\ninspected with the dir function. The dir function is roughly equivalent to the sorted\\nkeys list of an object’s __dict__ attribute, but it includes inherited names for classes,\\nmay not be complete, and is prone to changing from release to release.\\n•Modules are a single scope (local is global) . As we saw in Chapter 17 , names\\nat the top level of a module follow the same reference/assignment rules as names\\nin a function, but the local and global scopes are the same (more formally, they\\nfollow the LEGB scope rule we met in Chapter 17 , but without the L and E lookup\\nlayers). But, in modules, the module scope becomes an attribute dictionary of a\\nmodule object after the module has been loaded. Unlike with functions (where the\\nlocal namespace exists only while the function runs), a module file’s scope becomes\\na module object’s attribute namespace and lives on after the import.\\n550 | Chapter 22: \\u2002Module Coding Basics', metadata={'source': 'python.pdf', 'page': 600}),\n",
       " Document(page_content=\"Here’s a demonstration of these ideas. Suppose we create the following module file in\\na text editor and call it module2.py:\\nprint('starting to load...')\\nimport sys\\nname = 42\\ndef func(): pass\\nclass klass: pass\\nprint('done loading.')\\nThe first time \\nthis module is imported (or run as a program), Python executes its state-\\nments from top to bottom. Some statements create names in the module’s namespace\\nas a side effect, but others do actual work while the import is going on. For instance,\\nthe two print statements in this file execute at import time:\\n>>> import module2\\nstarting to load...\\ndone loading.\\nOnce the module is loaded, its scope becomes an attribute namespace in the module\\nobject we get back from import. We can then access attributes in this namespace by\\nqualifying them with the name of the enclosing module:\\n>>> module2.sys\\n<module 'sys' (built-in)>\\n>>> module2.name\\n42\\n>>> module2.func\\n<function func at 0x026D3BB8>\\n>>> module2.klass\\n<class 'module2.klass'>\\nHere, sys, name, func, and klass were all assigned while the module’s statements were\\nbeing run, so they are attributes after the import. We’ll talk about classes in Part VI,\\nbut notice the sys attribute—import statements really assign module objects to names,\\nand any type of assignment to a name at the top level of a file generates a module\\nattribute.\\nInternally, module namespaces are stored as dictionary objects. These are just normal\\ndictionary objects with the usual methods. We can access a module’s namespace dic-\\ntionary through the module’s __dict__ attribute (remember to wrap this in a list call\\nin Python 3.0—it’s a view object):\\n>>> list(module2.__dict__.keys())\\n['name', '__builtins__', '__file__', '__package__', 'sys', 'klass', 'func',\\n'__name__', '__doc__']\\nModule Namespaces | 551\", metadata={'source': 'python.pdf', 'page': 601}),\n",
       " Document(page_content='The names we assigned in the module file become dictionary keys internally, so most\\nof the names \\nhere reflect top-level assignments in our file. However, Python also adds\\nsome names in the module’s namespace for us; for instance, __file__ gives the name\\nof the file the module was loaded from, and __name__ gives its name as known to im-\\nporters (without the .py extension and directory path).\\nAttribute Name Qualification\\nNow that you’re becoming more familiar with modules, we should look at the notion\\nof name qualification (fetching attributes) in more depth. In Python, you can access the\\nattributes of any object that has attributes using the qualification syntax\\nobject.attribute.\\nQualification is really an expression that returns the value assigned to an attribute name\\nassociated with an object. For example, the expression module2.sys in the previous\\nexample fetches the value assigned to sys in module2. Similarly, if we have a built-in list\\nobject L, L.append returns the append method object associated with that list.\\nSo, what does attribute qualification do to the scope rules we studied in Chapter 17 ?\\nNothing, really: it’s an independent concept. When you use qualification to access\\nnames, you give Python an explicit object from which to fetch the specified names. The\\nLEGB rule applies only to bare, unqualified names. Here are the rules:\\nSimple variables\\nX means search for the name X in the current scopes (following the LEGB rule).\\nQualification\\nX.Y means find X in the current scopes, then search for the attribute Y in the object\\nX (not in scopes).\\nQualification paths\\nX.Y.Z means look up the name Y in the object X, then look up Z in the object X.Y.\\nGenerality\\nQualification works on all objects with attributes: modules, classes, C extension\\ntypes, etc.\\nIn Part VI , we’ll see that qualification means a bit more for classes (it’s also the place\\nwhere something called inheritance happens), but in general, the rules outlined here\\napply to all names in Python.\\nImports Versus Scopes\\nAs we’ve learned, it is never possible to access names defined in another module file\\nwithout first importing that file. That is, you never automatically get to see names in\\nanother file, regardless of the structure of imports or function calls in your program. A\\nvariable’s meaning is always determined by the locations of assignments in your source\\ncode, and attributes are always requested of an object explicitly.\\n552 | Chapter 22: \\u2002Module Coding Basics', metadata={'source': 'python.pdf', 'page': 602}),\n",
       " Document(page_content=\"For example, consider the following two simple modules. The first, moda.py, defines\\na variable X \\nglobal to code in its file only, along with a function that changes the global\\nX in this file:\\nX = 88                        # My X: global to this file only\\ndef f():\\n    global X                  # Change this file's X\\n    X = 99                    # Cannot see names in other modules\\nThe second module, modb.py, defines its own global variable X and imports and calls\\nthe function in the first module:\\nX = 11                        # My X: global to this file only\\nimport moda                   # Gain access to names in moda\\nmoda.f()                      # Sets moda.X, not this file's X\\nprint(X, moda.X)\\nWhen run, moda.f changes the X in moda, not the X in modb. The global scope for\\nmoda.f is always the file enclosing it, regardless of which module it is ultimately called\\nfrom:\\n% python modb.py\\n11 99\\nIn other words, import operations never give upward visibility to code in imported\\nfiles—an imported file cannot see names in the importing file. More formally:\\n• Functions can never see names in other functions, unless they are physically\\nenclosing.\\n• Module code can never see names in other modules, unless they are explicitly\\nimported.\\nSuch behavior is part of the lexical scoping  notion—in Python, the scopes surrounding\\na piece of code are completely determined by the code’s physical position in your file.\\nScopes are never influenced by function calls or module imports.*\\nNamespace Nesting\\nIn some sense, although imports do not nest namespaces upward, they do nest down-\\nward. Using attribute qualification paths, it’s possible to descend into arbitrarily nested\\nmodules and access their attributes. For example, consider the next three files.\\nmod3.py defines a single global name and attribute by assignment:\\nX = 3\\nmod2.py in turn defines its own X, then imports mod3 and uses qualification to access\\nthe imported module’s attribute:\\n* Some languages act differently and provide for dynamic scoping , where scopes really may depend on runtime\\ncalls. This tends to make code trickier, though, because the meaning of a variable can differ over time.\\nModule Namespaces | 553\", metadata={'source': 'python.pdf', 'page': 603}),\n",
       " Document(page_content=\"X = 2\\nimport mod3\\nprint(X, end=' ')             # My global X\\nprint(mod3.X)                 # mod3's X\\nmod1.py also defines \\nits own X, then imports mod2, and fetches attributes in both the\\nfirst and second files:\\nX = 1\\nimport mod2\\nprint(X, end=' ')             # My global X\\nprint(mod2.X, end=' ')        # mod2's X\\nprint(mod2.mod3.X)            # Nested mod3's X\\nReally, when mod1 imports mod2 here, it sets up a two-level namespace nesting. By using\\nthe path of names mod2.mod3.X, it can descend into mod3, which is nested in the imported\\nmod2. The net effect is that mod1 can see the Xs in all three files, and hence has access to\\nall three global scopes:\\n% python mod1.py\\n2 3\\n1 2 3\\nThe reverse, however, is not true: mod3 cannot see names in mod2, and mod2 cannot see\\nnames in mod1. This example may be easier to grasp if you don’t think in terms of\\nnamespaces and scopes, but instead focus on the objects involved. Within mod1, mod2\\nis just a name that refers to an object with attributes, some of which may refer to other\\nobjects with attributes ( import is an assignment). For paths like mod2.mod3.X, Python\\nsimply evaluates from left to right, fetching attributes from objects along the way.\\nNote that mod1 can say import mod2, and then mod2.mod3.X, but it cannot say import\\nmod2.mod3—this syntax invokes something called package (directory) imports,\\ndescribed in the next chapter. Package imports also create module namespace nesting,\\nbut their import statements are taken to reflect directory trees, not simple import chains.\\nReloading Modules\\nAs we’ve seen, a module’s code is run only once per process by default. To force a\\nmodule’s code to be reloaded and rerun, you need to ask Python to do so explicitly by\\ncalling the reload built-in function. In this section, we’ll explore how to use reloads to\\nmake your systems more dynamic. In a nutshell:\\n• Imports (via both import and from statements) load and run a module’s code only\\nthe first time the module is imported in a process.\\n• Later imports use the already loaded module object without reloading or rerunning\\nthe file’s code.\\n554 | Chapter 22: \\u2002Module Coding Basics\", metadata={'source': 'python.pdf', 'page': 604}),\n",
       " Document(page_content='• The reload function forces an already loaded module’s code to be reloaded and\\nrerun. Assignments in the file’s new code change the existing module object\\nin-place.\\nWhy all the fuss about reloading modules? The reload function allows parts of a pro-\\ngram to be changed without stopping the whole program. With reload, therefore, the\\neffects of changes in components can be observed immediately. Reloading doesn’t help\\nin every situation, but where it does, it makes for a much shorter development cycle.\\nFor instance, imagine a database program that must connect to a server on startup;\\nbecause program changes or customizations can be tested immediately after reloads,\\nyou need to connect only once while debugging. Long-running servers can update\\nthemselves this way, too.\\nBecause Python is interpreted (more or less), it already gets rid of the compile/link steps\\nyou need to go through to get a C program to run: modules are loaded dynamically\\nwhen imported by a running program. Reloading offers a further performance ad-\\nvantage by allowing you to also change parts of running programs without stopping.\\nNote that reload currently only works on modules written in Python; compiled exten-\\nsion modules coded in a language such as C can be dynamically loaded at runtime, too,\\nbut they can’t be reloaded.\\nVersion skew note : In Python 2.6, reload is available as a built-in func-\\ntion. In Python 3.0, it has been moved to the imp standard library\\nmodule—it’s known as imp.reload in 3.0. This simply means that an\\nextra import or from statement is required to load this tool (in 3.0 only).\\nReaders using 2.6 can ignore these imports in this book’s examples, or\\nuse them anyhow—2.6 also has a reload in its imp module to ease mi-\\ngration to 3.0. Reloading works the same regardless of its packaging.\\nreload Basics\\nUnlike import and from:\\n•reload is a function in Python, not a statement.\\n•reload is passed an existing module object, not a name.\\n•reload lives in a module in Python 3.0 and must be imported itself.\\nBecause reload expects an object, a module must have been previously imported suc-\\ncessfully before you can reload it (if the import was unsuccessful, due to a syntax or\\nother error, you may need to repeat it before you can reload the module). Furthermore,\\nthe syntax of import statements and reload calls differs: reloads require parentheses,\\nbut imports do not. Reloading looks like this:\\nimport module                     # Initial import\\n...use module.attributes...\\n...                               # Now, go change the module file\\n...\\nReloading Modules | 555', metadata={'source': 'python.pdf', 'page': 605}),\n",
       " Document(page_content='from imp import reload            # Get reload itself (in 3.0)\\nreload(module)                    # Get updated exports\\n...use module.attributes...\\nThe typical usage \\npattern is that you import a module, then change its source code in\\na text editor, and then reload it. When you call reload, Python rereads the module file’s\\nsource code and reruns its top-level statements. Perhaps the most important thing to\\nknow about reload is that it changes a module object in-place; it does not delete and\\nre-create the module object. Because of that, every reference to a module object any-\\nwhere in your program is automatically affected by a reload. Here are the details:\\n•reload runs a module file’s new code in the module’s current namespace .\\nRerunning a module file’s code overwrites its existing namespace, rather than de-\\nleting and re-creating it.\\n•Top-level assignments in the file replace names with new values . For instance,\\nrerunning a def statement replaces the prior version of the function in the module’s\\nnamespace by reassigning the function name.\\n•Reloads impact all clients that use  import to fetch modules . Because clients\\nthat use import qualify to fetch attributes, they’ll find new values in the module\\nobject after a reload.\\n•Reloads impact future  from clients only. Clients that used from to fetch attributes\\nin the past won’t be affected by a reload; they’ll still have references to the old\\nobjects fetched before the reload.\\nreload Example\\nTo demonstrate, here’s a more concrete example of reload in action. In the following,\\nwe’ll change and reload a module file without stopping the interactive Python session.\\nReloads are used in many other scenarios, too (see the sidebar “Why You Will Care:\\nModule Reloads” on page 557), but we’ll keep things simple for illustration here.\\nFirst, in the text editor of your choice, write a module file named changer.py with the\\nfollowing contents:\\nmessage = \"First version\"\\ndef printer():\\n    print(message)\\nThis module creates and exports two names—one bound to a string, and another to a\\nfunction. Now, start the Python interpreter, import the module, and call the function\\nit exports. The function will print the value of the global message variable:\\n% python\\n>>> import changer\\n>>> changer.printer()\\nFirst version\\n556 | Chapter 22: \\u2002Module Coding Basics', metadata={'source': 'python.pdf', 'page': 606}),\n",
       " Document(page_content='Keeping the interpreter active, now edit the module file in another window:\\n...modify changer.py without stopping Python...\\n% vi changer.py\\nChange the global message variable, as well as the printer function body:\\nmessage = \"After editing\"\\ndef printer():\\n    print(\\'reloaded:\\', message)\\nThen, return to \\nthe Python window and reload the module to fetch the new code. Notice\\nin the following interaction that importing the module again has no effect; we get the\\noriginal message, even though the file’s been changed. We have to call reload in order\\nto get the new version:\\n...back to the Python interpreter/program...\\n>>> import changer\\n>>> changer.printer()                 # No effect: uses loaded module\\nFirst version\\n>>> from imp import reload\\n>>> reload(changer)                   # Forces new code to load/run\\n<module \\'changer\\' from \\'changer.py\\'>\\n>>> changer.printer()                 # Runs the new version now\\nreloaded: After editing\\nNotice that reload actually returns the module object for us—its result is usually ig-\\nnored, but because expression results are printed at the interactive prompt, Python\\nshows a default <module \\'name\\'...> representation.\\nWhy You Will Care: Module Reloads\\nBesides allowing you \\nto reload (and hence rerun) modules at the interactive prompt,\\nmodule reloads are also useful in larger systems, especially when the cost of restarting\\nthe entire application is prohibitive. For instance, systems that must connect to servers\\nover a network on startup are prime candidates for dynamic reloads.\\nThey’re also useful in GUI work (a widget’s callback action can be changed while the\\nGUI remains active), and when Python is used as an embedded language in a C or\\nC++ program (the enclosing program can request a reload of the Python code it runs,\\nwithout having to stop). See Programming Python  for more on reloading GUI callbacks\\nand embedded Python code.\\nMore generally, reloads allow programs to provide highly dynamic interfaces. For in-\\nstance, Python is often used as a customization language for larger systems—users can\\ncustomize products by coding bits of Python code onsite, without having to recompile\\nthe entire product (or even having its source code at all). In such worlds, the Python\\ncode already adds a dynamic flavor by itself.\\nReloading Modules | 557', metadata={'source': 'python.pdf', 'page': 607}),\n",
       " Document(page_content='To be even more dynamic, though, such systems can automatically reload the Python\\ncustomization code periodically \\nat runtime. That way, users’ changes are picked up\\nwhile the system is running; there is no need to stop and restart each time the Python\\ncode is modified. Not all systems require such a dynamic approach, but for those that\\ndo, module reloads provide an easy-to-use dynamic customization tool.\\nChapter Summary\\nThis chapter delved \\ninto the basics of module coding tools—the import and from state-\\nments, and the reload call. We learned how the from statement simply adds an extra\\nstep that copies names out of a file after it has been imported, and how reload forces\\na file to be imported again without stopping and restarting Python. We also surveyed\\nnamespace concepts, saw what happens when imports are nested, explored the way\\nfiles become module namespaces, and learned about some potential pitfalls of the\\nfrom statement.\\nAlthough we’ve already seen enough to handle module files in our programs, the next\\nchapter extends our coverage of the import model by presenting package imports—a\\nway for our import statements to specify part of the directory path leading to the desired\\nmodule. As we’ll see, package imports give us a hierarchy that is useful in larger systems\\nand allow us to break conflicts between same-named modules. Before we move on,\\nthough, here’s a quick quiz on the concepts presented here.\\nTest Your Knowledge: Quiz\\n1. How do you make a module?\\n2. How is the \\nfrom statement related to the import statement?\\n3. How is the reload function related to imports?\\n4. When must you use import instead of from?\\n5. Name three potential pitfalls of the from statement.\\n6. What...is the airspeed velocity of an unladen swallow?\\nTest Your Knowledge: Answers\\n1. To create a module, you just write a text file containing Python statements; every\\nsource code file is automatically a module, and there is no syntax for declaring one.\\nImport operations load module files into module objects in memory. You can also\\nmake a module by writing code in an external language like C or Java, but such\\nextension modules are beyond the scope of this book.\\n558 | Chapter 22: \\u2002Module Coding Basics', metadata={'source': 'python.pdf', 'page': 608}),\n",
       " Document(page_content='2. The from statement imports an entire module, like the import statement, but as an\\nextra step it also copies one or more variables from the imported module into the\\nscope where the from appears. This enables you to use the imported names directly\\n(name) instead of having to go through the module (module.name).\\n3. By default, a module is imported only once per process. The reload function forces\\na module to be imported again. It is mostly used to pick up new versions of a\\nmodule’s source code during development, and in dynamic customization\\nscenarios.\\n4. You must use import instead of from only when you need to access the same name\\nin two different modules; because you’ll have to specify the names of the enclosing\\nmodules, the two names will be unique.\\n5. The from statement can obscure the meaning of a variable (which module it is\\ndefined in), can have problems with the reload call (names may reference prior\\nversions of objects), and can corrupt namespaces (it might silently overwrite names\\nyou are using in your scope). The from * form is worse in most regards—it can\\nseriously corrupt namespaces and obscure the meaning of variables, so it is prob-\\nably best used sparingly.\\n6. What do you mean? An African or European swallow?\\nTest Your Knowledge: Answers | 559', metadata={'source': 'python.pdf', 'page': 609}),\n",
       " Document(page_content='', metadata={'source': 'python.pdf', 'page': 610}),\n",
       " Document(page_content='CHAPTER 23\\nModule Packages\\nSo far, when we’ve imported modules, we’ve been loading files. This represents typical\\nmodule usage, and \\nit’s probably the technique you’ll use for most imports you’ll code\\nearly on in your Python career. However, the module import story is a bit richer than\\nI have thus far implied.\\nIn addition to a module name, an import can name a directory path. A directory of\\nPython code is said to be a package, so such imports are known as package imports . In\\neffect, a package import turns a directory on your computer into another Python name-\\nspace, with attributes corresponding to the subdirectories and module files that the\\ndirectory contains.\\nThis is a somewhat advanced feature, but the hierarchy it provides turns out to be handy\\nfor organizing the files in a large system and tends to simplify module search path\\nsettings. As we’ll see, package imports are also sometimes required to resolve import\\nambiguities when multiple program files of the same name are installed on a single\\nmachine.\\nBecause it is relevant to code in packages only, we’ll also introduce Python’s recent\\nrelative imports  model and syntax here. As we’ll see, this model modifies search paths\\nand extends the from statement for imports within packages.\\nPackage Import Basics\\nSo, how do package imports work? In the place where you have been naming a simple\\nfile in your import statements, you can instead list a path of names separated by periods:\\nimport dir1.dir2.mod\\nThe same goes for from statements:\\nfrom dir1.dir2.mod import x\\n561', metadata={'source': 'python.pdf', 'page': 611}),\n",
       " Document(page_content='The “dotted” path in these statements is assumed to correspond to a path through the\\ndirectory hierarchy on your machine, leading to the file mod.py (or similar; the exten-\\nsion may vary). That is, the preceding statements indicate that on your machine there\\nis a directory dir1, which has a subdirectory dir2, which contains a module file\\nmod.py (or similar).\\nFurthermore, these imports imply that dir1 resides within some container directory\\ndir0, which is a component of the Python module search path. In other words, the two\\nimport statements imply a directory structure that looks something like this (shown\\nwith DOS backslash separators):\\ndir0\\\\dir1\\\\dir2\\\\mod.py               # Or mod.pyc, mod.so, etc.\\nThe container directory dir0 needs to be added to your module search path (unless it’s\\nthe home directory of the top-level file), exactly as if dir1 were a simple module file.\\nMore generally, the leftmost component in a package import path is still relative to a\\ndirectory included in the sys.path module search path list we met in Chapter 21. From\\nthere down, though, the import statements in your script give the directory paths lead-\\ning to the modules explicitly.\\nPackages and Search Path Settings\\nIf you use this feature, keep in mind that the directory paths in your import statements\\ncan only be variables separated by periods. You cannot use any platform-specific path\\nsyntax in your import statements, such as C:\\\\dir1, My Documents.dir2 or ../dir1—these\\ndo not work syntactically. Instead, use platform-specific syntax in your module search\\npath settings to name the container directories.\\nFor instance, in the prior example, dir0—the directory name you add to your module\\nsearch path—can be an arbitrarily long and platform-specific directory path leading up\\nto dir1. Instead of using an invalid statement like this:\\nimport C:\\\\mycode\\\\dir1\\\\dir2\\\\mod      # Error: illegal syntax\\nadd C:\\\\mycode to your PYTHONPATH variable or a .pth file (assuming it is not the program’s\\nhome directory, in which case this step is not necessary), and say this in your script:\\nimport dir1.dir2.mod\\nIn effect, entries on the module search path provide platform-specific directory path\\nprefixes, which lead to the leftmost names in import statements. import statements\\nprovide directory path tails in a platform-neutral fashion.*\\n* The dot path syntax was chosen partly for platform neutrality, but also because paths in import statements\\nbecome \\nreal nested object paths. This syntax also means that you get odd error messages if you forget to omit\\nthe .py in your import statements. For example, import mod.py  is assumed to be a directory path import—it\\nloads mod.py, then tries to load a mod\\\\py.py, and ultimately issues a potentially confusing “No module named\\npy” error message.\\n562 | Chapter 23: \\u2002Module Packages', metadata={'source': 'python.pdf', 'page': 612}),\n",
       " Document(page_content='Package __init__.py Files\\nIf you choose \\nto use package imports, there is one more constraint you must follow:\\neach directory named within the path of a package import statement must contain a\\nfile named __init__.py, or your package imports will fail. That is, in the example we’ve\\nbeen using, both dir1 and dir2 must contain a file called __init__.py; the container\\ndirectory dir0 does not require such a file because it’s not listed in the import statement\\nitself. More formally, for a directory structure such as this:\\ndir0\\\\dir1\\\\dir2\\\\mod.py\\nand an import statement of the form:\\nimport dir1.dir2.mod\\nthe following rules apply:\\n•dir1 and dir2 both must contain an __init__.py file.\\n•dir0, the container, does not require an __init__.py file; this file will simply be\\nignored if present.\\n•dir0, not dir0\\\\dir1, must be listed on the module search path (i.e., it must be the\\nhome directory, or be listed in your PYTHONPATH, etc.).\\nThe net effect is that this example’s directory structure should be as follows, with in-\\ndentation designating directory nesting:\\ndir0\\\\                               # Container on module search path\\n    dir1\\\\\\n        __init__.py\\n        dir2\\\\\\n            __init__.py\\n            mod.py\\nThe __init__.py files can contain Python code, just like normal module files. They are\\npartly present as a declaration to Python, however, and can be completely empty. As\\ndeclarations, these files serve to prevent directories with common names from unin-\\ntentionally hiding true modules that appear later on the module search path. Without\\nthis safeguard, Python might pick a directory that has nothing to do with your code,\\njust because it appears in an earlier directory on the search path.\\nMore generally, the __init__.py file serves as a hook for package-initialization-time ac-\\ntions, generates a module namespace for a directory, and implements the behavior of\\nfrom * (i.e., from .. import *) statements when used with directory imports:\\nPackage initialization\\nThe first time Python imports through a directory, it automatically runs all the code\\nin the directory’s __init__.py file. Because of that, these files are a natural place to\\nput code to initialize the state required by files in a package. For instance, a package\\nmight use its initialization file to create required data files, open connections to\\nPackage Import Basics | 563', metadata={'source': 'python.pdf', 'page': 613}),\n",
       " Document(page_content=\"databases, and so on. Typically, __init__.py files are not meant to be useful if exe-\\ncuted directly; they are run automatically when a package is first accessed.\\nModule namespace initialization\\nIn the package import model, the directory paths in your script become real nested\\nobject paths after an import. For instance, in the preceding example, after the im-\\nport the expression dir1.dir2 works and returns a module object whose namespace\\ncontains all the names assigned by dir2’s __init__.py file. Such files provide a\\nnamespace for module objects created for directories, which have no real associ-\\nated module files.\\nfrom * statement behavior\\nAs an advanced feature, you can use __all__ lists in __init__.py files to define what\\nis exported when a directory is imported with the from * statement form. In an\\n__init__.py file, the __all__ list is taken to be the list of submodule names that\\nshould be imported when from * is used on the package (directory) name. If\\n__all__ is not set, the from *  statement does not automatically load submodules\\nnested in the directory; instead, it loads just names defined by assignments in the\\ndirectory’s __init__.py file, including any submodules explicitly imported by code\\nin this file. For instance, the statement from submodule import X in a directory’s\\n__init__.py makes the name X available in that directory’s namespace. (We’ll see\\nadditional roles for __all__ in Chapter 24.)\\nYou can also simply leave these files empty, if their roles are beyond your needs (and\\nfrankly, they are often empty in practice). They must exist, though, for your directory\\nimports to work at all.\\nDon’t confuse package __init__.py files with the class __init__ con-\\nstructor methods we’ll meet in the next part of the book. The former\\nare files of code run when imports first step through a package directory,\\nwhile the latter are called when an instance is created. Both have ini-\\ntialization roles, but they are otherwise very different.\\nPackage Import Example\\nLet’s actually code the example we’ve been talking about to show how initialization\\nfiles and paths come into play. The following three files are coded in a directory dir1\\nand its subdirectory dir2—comments give the path names of these files:\\n# dir1\\\\__init__.py\\nprint('dir1 init')\\nx = 1\\n# dir1\\\\dir2\\\\__init__.py\\nprint('dir2 init')\\ny = 2\\n564 | Chapter 23: \\u2002Module Packages\", metadata={'source': 'python.pdf', 'page': 614}),\n",
       " Document(page_content=\"# dir1\\\\dir2\\\\mod.py\\nprint('in mod.py')\\nz = 3\\nHere, dir1 will be \\neither a subdirectory of the one we’re working in (i.e., the home\\ndirectory), or a subdirectory of a directory that is listed on the module search path\\n(technically, on sys.path). Either way, dir1’s container does not need an __init__.py file.\\nimport statements run each directory’s initialization file the first time that directory is\\ntraversed, as Python descends the path; print statements are included here to trace\\ntheir execution. As with module files, an already imported directory may be passed to\\nreload to force reexecution of that single item. As shown here, reload accepts a dotted\\npathname to reload nested directories and files:\\n% python\\n>>> import dir1.dir2.mod      # First imports run init files\\ndir1 init\\ndir2 init\\nin mod.py\\n>>>\\n>>> import dir1.dir2.mod      # Later imports do not\\n>>>\\n>>> from imp import reload    # Needed in 3.0\\n>>> reload(dir1)\\ndir1 init\\n<module 'dir1' from 'dir1\\\\__init__.pyc'>\\n>>>\\n>>> reload(dir1.dir2)\\ndir2 init\\n<module 'dir1.dir2' from 'dir1\\\\dir2\\\\__init__.pyc'>\\nOnce imported, the path in your import statement becomes a nested object path  in your\\nscript. Here, mod is an object nested in the object dir2, which in turn is nested in the\\nobject dir1:\\n>>> dir1\\n<module 'dir1' from 'dir1\\\\__init__.pyc'>\\n>>> dir1.dir2\\n<module 'dir1.dir2' from 'dir1\\\\dir2\\\\__init__.pyc'>\\n>>> dir1.dir2.mod\\n<module 'dir1.dir2.mod' from 'dir1\\\\dir2\\\\mod.pyc'>\\nIn fact, each directory name in the path becomes a variable assigned to a module object\\nwhose namespace is initialized by all the assignments in that directory’s __init__.py\\nfile. dir1.x refers to the variable x assigned in dir1\\\\__init__.py, much as mod.z refers to\\nthe variable z assigned in mod.py:\\n>>> dir1.x\\n1\\n>>> dir1.dir2.y\\n2\\n>>> dir1.dir2.mod.z\\n3\\nPackage Import Example | 565\", metadata={'source': 'python.pdf', 'page': 615}),\n",
       " Document(page_content=\"from Versus import with Packages\\nimport statements can \\nbe somewhat inconvenient to use with packages, because you\\nmay have to retype the paths frequently in your program. In the prior section’s example,\\nfor instance, you must retype and rerun the full path from dir1 each time you want to\\nreach z. If you try to access dir2 or mod directly, you’ll get an error:\\n>>> dir2.mod\\nNameError: name 'dir2' is not defined\\n>>> mod.z\\nNameError: name 'mod' is not defined\\nIt’s often more convenient, therefore, to use the from statement with packages to avoid\\nretyping the paths at each access. Perhaps more importantly, if you ever restructure\\nyour directory tree, the from statement requires just one path update in your code,\\nwhereas imports may require many. The import as extension, discussed formally in the\\nnext chapter, can also help here by providing a shorter synonym for the full path:\\n% python\\n>>> from dir1.dir2 import mod      # Code path here only\\ndir1 init\\ndir2 init\\nin mod.py\\n>>> mod.z                          # Don't repeat path\\n3\\n>>> from dir1.dir2.mod import z\\n>>> z\\n3\\n>>> import dir1.dir2.mod as mod    # Use shorter name (see Chapter 24)\\n>>> mod.z\\n3\\nWhy Use Package Imports?\\nIf you’re new to Python, make sure that you’ve mastered simple modules before step-\\nping up to packages, as they are a somewhat advanced feature. They do serve useful\\nroles, though, especially in larger programs: they make imports more informative, serve\\nas an organizational tool, simplify your module search path, and can resolve\\nambiguities.\\nFirst of all, because package imports give some directory information in program files,\\nthey both make it easier to locate your files and serve as an organizational tool. Without\\npackage paths, you must often resort to consulting the module search path to find files.\\nMoreover, if you organize your files into subdirectories for functional areas, package\\nimports make it more obvious what role a module plays, and so make your code more\\nreadable. For example, a normal import of a file in a directory somewhere on the module\\nsearch path, like this:\\nimport utilities\\n566 | Chapter 23: \\u2002Module Packages\", metadata={'source': 'python.pdf', 'page': 616}),\n",
       " Document(page_content='offers much less information than an import that includes the path:\\nimport database.client.utilities\\nPackage imports can \\nalso greatly simplify your PYTHONPATH and .pth file search path\\nsettings. In fact, if you use explicit package imports for all your cross-directory imports,\\nand you make those package imports relative to a common root directory where all\\nyour Python code is stored, you really only need a single entry on your search path: the\\ncommon root. Finally, package imports serve to resolve ambiguities by making explicit\\nexactly which files you want to import. The next section explores this role in more\\ndetail.\\nA Tale of Three Systems\\nThe only time package imports are actually required is to resolve ambiguities that may\\narise when multiple programs with same-named files are installed on a single machine.\\nThis is something of an install issue, but it can also become a concern in general practice.\\nLet’s turn to a hypothetical scenario to illustrate.\\nSuppose that a programmer develops a Python program that contains a file called\\nutilities.py for common utility code and a top-level file named main.py that users launch\\nto start the program. All over this program, its files say import utilities  to load and\\nuse the common code. When the program is shipped, it arrives as a single .tar or .zip\\nfile containing all the program’s files, and when it is installed, it unpacks all its files into\\na single directory named system1 on the target machine:\\nsystem1\\\\\\n    utilities.py        # Common utility functions, classes\\n    main.py             # Launch this to start the program\\n    other.py            # Import utilities to load my tools\\nNow, suppose that a second programmer develops a different program with files also\\ncalled utilities.py and main.py, and again uses import utilities throughout the pro-\\ngram to load the common code file. When this second system is fetched and installed\\non the same computer as the first system, its files will unpack into a new directory called\\nsystem2 somewhere on the receiving machine (ensuring that they do not overwrite\\nsame-named files from the first system):\\nsystem2\\\\\\n    utilities.py        # Common utilities\\n    main.py             # Launch this to run\\n    other.py            # Imports utilities\\nSo far, there’s no problem: both systems can coexist and run on the same machine. In\\nfact, you won’t even need to configure the module search path to use these programs\\non your computer—because Python always searches the home directory first (that is,\\nthe directory containing the top-level file), imports in either system’s files will auto-\\nmatically see all the files in that system’s directory. For instance, if you click on\\nsystem1\\\\main.py, all imports will search system1 first. Similarly, if you launch\\nWhy Use Package Imports? | 567', metadata={'source': 'python.pdf', 'page': 617}),\n",
       " Document(page_content=\"system2\\\\main.py, system2 will be searched first instead. Remember, module search path\\nsettings are only needed to import across directory boundaries.\\nHowever, suppose that after you’ve installed these two programs on your machine, you\\ndecide that you’d like to use some of the code in each of the utilities.py files in a system\\nof your own. It’s common utility code, after all, and Python code by nature wants to\\nbe reused. In this case, you want to be able to say the following from code that you’re\\nwriting in a third directory to load one of the two files:\\nimport utilities\\nutilities.func('spam')\\nNow the problem starts to materialize. To make this work at all, you’ll have to set the\\nmodule search path to include the directories containing the utilities.py files. But which\\ndirectory do you put first in the path—system1 or system2?\\nThe problem is the linear nature of the search path. It is always scanned from left to\\nright, so no matter how long you ponder this dilemma, you will always get utilities.py\\nfrom the directory listed first (leftmost) on the search path. As is, you’ll never be able\\nto import it from the other directory at all. You could try changing sys.path within\\nyour script before each import operation, but that’s both extra work and highly error\\nprone. By default, you’re stuck.\\nThis is the issue that packages actually fix. Rather than installing programs as flat lists\\nof files in standalone directories, you can package and install them as subdirectories\\nunder a common root. For instance, you might organize all the code in this example as\\nan install hierarchy that looks like this:\\nroot\\\\\\n    system1\\\\\\n        __init__.py\\n        utilities.py\\n        main.py\\n        other.py\\n    system2\\\\\\n        __init__.py\\n        utilities.py\\n        main.py\\n        other.py\\n    system3\\\\                    # Here or elsewhere\\n        __init__.py             # Your new code here\\n        myfile.py\\nNow, add just the common root directory to your search path. If your code’s imports\\nare all relative to this common root, you can import either system’s utility file with a\\npackage import—the enclosing directory name makes the path (and hence, the module\\nreference) unique. In fact, you can import both utility files in the same module, as long\\nas you use an import statement and repeat the full path each time you reference the\\nutility modules:\\n568 | Chapter 23: \\u2002Module Packages\", metadata={'source': 'python.pdf', 'page': 618}),\n",
       " Document(page_content=\"import system1.utilities\\nimport system2.utilities\\nsystem1.utilities.function('spam')\\nsystem2.utilities.function('eggs')\\nThe names of the enclosing directories here make the module references unique.\\nNote that you \\nhave to use import instead of from with packages only if you need to\\naccess the same attribute in two or more paths. If the name of the called function here\\nwas different in each path, from statements could be used to avoid repeating the full\\npackage path whenever you call one of the functions, as described earlier.\\nAlso, notice in the install hierarchy shown earlier that __init__.py files were added to\\nthe system1 and system2 directories to make this work, but not to the root directory.\\nOnly directories listed within import statements in your code require these files; as you’ll\\nrecall, they are run automatically the first time the Python process imports through a\\npackage directory.\\nTechnically, in this case the system3 directory doesn’t have to be under root—just the\\npackages of code from which you will import. However, because you never know when\\nyour own modules might be useful in other programs, you might as well place them\\nunder the common root directory as well to avoid similar name-collision problems in\\nthe future.\\nFinally, notice that both of the two original systems’ imports will keep working un-\\nchanged. Because their home directories are searched first, the addition of the common\\nroot on the search path is irrelevant to code in system1 and system2; they can keep\\nsaying just import utilities and expect to find their own files. Moreover, if you’re\\ncareful to unpack all your Python systems under a common root like this, path con-\\nfiguration becomes simple: you’ll only need to add the common root directory, once.\\nPackage Relative Imports\\nThe coverage of package imports so far has focused mostly on importing package files\\nfrom outside the package. Within the package itself, imports of package files can use\\nthe same path syntax as outside imports, but they can also make use of special intra-\\npackage search rules to simplify import statements. That is, rather than listing package\\nimport paths, imports within the package can be relative to the package.\\nThe way this works is version-dependent today: Python 2.6 implicitly searches package\\ndirectories first on imports, while 3.0 requires explicit relative import syntax. This 3.0\\nchange can enhance code readability, by making same-package imports more obvious.\\nIf you’re starting out in Python with version 3.0, your focus in this section will likely\\nbe on its new import syntax. If you’ve used other Python packages in the past, though,\\nyou’ll probably also be interested in how the 3.0 model differs.\\nPackage Relative Imports | 569\", metadata={'source': 'python.pdf', 'page': 619}),\n",
       " Document(page_content='Changes in Python 3.0\\nThe way import operations in \\npackages work has changed slightly in Python 3.0. This\\nchange applies only to imports within files located in the package directories we’ve\\nbeen studying in this chapter; imports in other files work as before. For imports in\\npackages, though, Python 3.0 introduces two changes:\\n• It modifies the module import search path semantics to skip the package’s own\\ndirectory by default. Imports check only other components of the search path.\\nThese are known as “absolute” imports.\\n• It extends the syntax of from statements to allow them to explicitly request that\\nimports search the package’s directory only. This is known as “relative” import\\nsyntax.\\nThese changes are fully present in Python 3.0. The new from statement relative syntax\\nis also available in Python 2.6, but the default search path change must be enabled as\\nan option. It’s currently scheduled to be added in the 2.7 release†—this change is being\\nphased in this way because the search path portion is not backward compatible with\\nearlier Pythons.\\nThe impact of this change is that in 3.0 (and optionally in 2.6), you must generally use\\nspecial from syntax to import modules located in the same package as the importer,\\nunless you spell out a complete path from a package root. Without this syntax, your\\npackage is not automatically searched.\\nRelative Import Basics\\nIn Python 3.0 and 2.6, from statements can now use leading dots (“.”) to specify that\\nthey require modules located within the same package (known as package relative im-\\nports), instead of modules located elsewhere on the module import search path (called \\nabsolute imports). That is:\\n• In both Python 3.0 and 2.6, you can use leading dots in from statements to indicate\\nthat imports should be relative to the containing package—such imports will\\nsearch for modules inside the package only and will not look for same-named\\nmodules located elsewhere on the import search path ( sys.path). The net effect is\\nthat package modules override outside modules.\\n• In Python 2.6, normal imports in a package’s code (without leading dots) currently\\ndefault to a relative-then-absolute search path order—that is, they search the pack-\\nage’s own directory first. However, in Python 3.0, imports within a package are\\nabsolute by default—in the absence of any special dot syntax, imports skip the\\ncontaining package itself and look elsewhere on the sys.path search path.\\n† Yes, there will be a 2.7 release, and possibly 2.8 and later releases, in parallel with new releases in the 3.X\\nline. As \\ndescribed in the Preface, both the Python 2 and Python 3 lines are expected to be fully supported for\\nyears to come, to accommodate the large existing Python 2 user and code bases.\\n570 | Chapter 23: \\u2002Module Packages', metadata={'source': 'python.pdf', 'page': 620}),\n",
       " Document(page_content=\"For example, in both Python 3.0 and 2.6, a statement of the form:\\nfrom . import spam                        # Relative to this package\\ninstructs Python to \\nimport a module named spam located in the same package directory\\nas the file in which this statement appears. Similarly, this statement:\\nfrom .spam import name\\nmeans “from a module named spam located in the same package as the file that contains\\nthis statement, import the variable name.”\\nThe behavior of a statement without the leading dot depends on which version of\\nPython you use. In 2.6, such an import will still default to the current\\nrelative-then-absolute search path order (i.e., searching the package’s directory first),\\nunless a statement of the following form is included in the importing file:\\nfrom __future__ import  absolute_import   # Required until 2.7?\\nIf present, this statement enables the Python 3.0 absolute-by-default default search path\\nchange, described in the next paragraph.\\nIn 3.0, an import without a leading dot always causes Python to skip the relative com-\\nponents of the module import search path and look instead in the absolute directories\\nthat sys.path contains. For instance, in 3.0’s model, a statement of the following form\\nwill always find a string module somewhere on sys.path, instead of a module of the\\nsame name in the package:\\nimport string                             # Skip this package's version\\nWithout the from __future__ statement in 2.6, if there’s a string module in the package,\\nit will be imported instead. To get the same behavior in 3.0 and in 2.6 when the absolute\\nimport change is enabled, run a statement of the following form to force a relative\\nimport:\\nfrom . import string                      # Searches this package only\\nThis works in both Python 2.6 and 3.0 today. The only difference in the 3.0 model is\\nthat it is required in order to load a module that is located in the same package directory\\nas the file in which this appears, when the module is given with a simple name.\\nNote that leading dots can be used to force relative imports only with the from state-\\nment, not with the import statement. In Python 3.0, the import modname statement is\\nalways absolute, skipping the containing package’s directory. In 2.6, this statement\\nform still performs relative imports today (i.e., the package’s directory is searched first),\\nbut these will become absolute in Python 2.7, too. from statements without leading dots\\nbehave the same as import statements—absolute in 3.0 (skipping the package direc-\\ntory), and relative-then-absolute in 2.6 (searching the package directory first).\\nOther dot-based relative reference patterns are possible, too. Within a module file lo-\\ncated in a package directory named mypkg, the following alternative import forms work\\nas described:\\nPackage Relative Imports | 571\", metadata={'source': 'python.pdf', 'page': 621}),\n",
       " Document(page_content='from .string import name1, name2            # Imports names from mypkg.string\\nfrom . import string                        # Imports mypkg.string\\nfrom .. import string                       # Imports string sibling of mypkg\\nTo understand these \\nlatter forms better, we need to understand the rationale behind\\nthis change.\\nWhy Relative Imports?\\nThis feature is designed to allow scripts to resolve ambiguities that can arise when a\\nsame-named file appears in multiple places on the module search path. Consider the\\nfollowing package directory:\\nmypkg\\\\\\n    __init__.py\\n    main.py\\n    string.py\\nThis defines a package named mypkg containing modules named mypkg.main and\\nmypkg.string. Now, suppose that the main module tries to import a module named\\nstring. In Python 2.6 and earlier, Python will first look in the mypkg directory to per-\\nform a relative import. It will find and import the string.py file located there, assigning\\nit to the name string in the mypkg.main module’s namespace.\\nIt could be, though, that the intent of this import was to load the Python standard\\nlibrary’s string module instead. Unfortunately, in these versions of Python, there’s no\\nstraightforward way to ignore mypkg.string and look for the standard library’s string\\nmodule located on the module search path. Moreover, we cannot resolve this with\\npackage import paths, because we cannot depend on any extra package directory\\nstructure above the standard library being present on every machine.\\nIn other words, imports in packages can be ambiguous—within a package, it’s not clear\\nwhether an import spam statement refers to a module within or outside the package.\\nMore accurately, a local module or package can hide another hanging directly off of\\nsys.path, whether intentionally or not.\\nIn practice, Python users can avoid reusing the names of standard library modules they\\nneed for modules of their own (if you need the standard string, don’t name a new\\nmodule string!). But this doesn’t help if a package accidentally hides a standard mod-\\nule; moreover, Python might add a new standard library module in the future that has\\nthe same name as a module of your own. Code that relies on relative imports is also\\nless easy to understand, because the reader may be confused about which module is\\nintended to be used. It’s better if the resolution can be made explicit in code.\\nThe relative imports solution in 3.0\\nTo address this dilemma, imports run within packages have changed in Python 3.0\\n(and as an option in 2.6) to be absolute. Under this model, an import statement of the\\n572 | Chapter 23: \\u2002Module Packages', metadata={'source': 'python.pdf', 'page': 622}),\n",
       " Document(page_content='following form in our example file mypkg/main.py will always find a string outside the\\npackage, via an absolute import search of sys.path:\\nimport string                          # Imports string outside package\\nA from import without leading-dot syntax is considered absolute as well:\\nfrom string import name                # Imports name from string outside package\\nIf you really want to import a module from your package without giving its full path\\nfrom the package root, though, relative imports are still possible by using the dot syntax\\nin the from statement:\\nfrom . import string                   # Imports mypkg.string (relative)\\nThis form imports the string module relative to the current package only and is the\\nrelative equivalent to the prior import example’s absolute form; when this special rel-\\native syntax is used, the package’s directory is the only directory searched.\\nWe can also copy specific names from a module with relative syntax:\\nfrom .string import name1, name2       # Imports names from mypkg.string\\nThis statement again refers to the string module relative to the current package. If this\\ncode appears in our mypkg.main module, for example, it will import name1 and name2\\nfrom mypkg.string.\\nIn effect, the “.” in a relative import is taken to stand for the package directory con-\\ntaining the file in which the import appears. An additional leading dot performs the\\nrelative import starting from the parent of the current package. For example, this\\nstatement:\\nfrom .. import spam                    # Imports a sibling of mypkg\\nwill load a sibling of mypkg—i.e., the spam module located in the package’s own con-\\ntainer directory, next to mypkg. More generally, code located in some module A.B.C can\\ndo any of these:\\nfrom . import D                        # Imports A.B.D     (. means A.B)\\nfrom .. import E                       # Imports A.E       (.. means A)\\nfrom .D import X                       # Imports A.B.D.X   (. means A.B)\\nfrom ..E import X                      # Imports A.E.X     (.. means A)\\nRelative imports versus absolute package paths\\nAlternatively, a file can sometimes name its own package explicitly in an absolute im-\\nport statement. For example, in the following, mypkg will be found in an absolute di-\\nrectory on sys.path:\\nfrom mypkg import string                    # Imports mypkg.string (absolute)\\nHowever, this relies on both the configuration and the order of the module search path\\nsettings, while relative import dot syntax does not. In fact, this form requires that the\\ndirectory immediately containing mypkg be included in the module search path. In\\nPackage Relative Imports | 573', metadata={'source': 'python.pdf', 'page': 623}),\n",
       " Document(page_content='general, absolute import statements must list all the directories below the package’s\\nroot entry in sys.path\\n when naming packages explicitly like this:\\nfrom system.section.mypkg import string     # system container on sys.path only\\nIn large or deep packages, that could be much more work than a dot:\\nfrom . import string                        # Relative import syntax\\nWith this latter form, the containing package is searched automatically, regardless of\\nthe search path settings.\\nThe Scope of Relative Imports\\nRelative imports can seem a bit perplexing on first encounter, but it helps if you re-\\nmember a few key points about them:\\n•Relative imports apply to imports within packages only. Keep in mind that\\nthis feature’s module search path change applies only to import statements within\\nmodule files located in a package. Normal imports coded outside package files still\\nwork exactly as described earlier, automatically searching the directory containing\\nthe top-level script first.\\n•Relative imports apply to the from statement only . Also remember that this\\nfeature’s new syntax applies only to from statements, not import statements. It’s\\ndetected by the fact that the module name in a from begins with one or more dots\\n(periods). Module names that contain dots but don’t have a leading dot are package\\nimports, not relative imports.\\n•The terminology is ambiguous. Frankly, the terminology used to describe this\\nfeature is probably more confusing than it needs to be. Really, all imports are rel-\\native to something. Outside a package, imports are still relative to directories listed\\non the sys.path module search path. As we learned in Chapter 21, this path in-\\ncludes the program’s container directory, PYTHONPATH settings, path file settings,\\nand standard libraries. When working interactively, the program container direc-\\ntory is simply the current working directory.\\nFor imports made inside packages, 2.6 augments this behavior by searching the\\npackage itself first. In the 3.0 model, all that really changes is that normal “abso-\\nlute” import syntax skips the package directory, but special “relative” import syn-\\ntax causes it to be searched first and only. When we talk about 3.0 imports as being\\n“absolute,” what we really mean is that they are relative to the directories on\\nsys.path, but not the package itself. Conversely, when we speak of “relative” im-\\nports, we mean they are relative to the package directory only. Some sys.path\\nentries could, of course, be absolute or relative paths too. (And I could probably\\nmake up something more confusing, but it would be a stretch!)\\n574 | Chapter 23: \\u2002Module Packages', metadata={'source': 'python.pdf', 'page': 624}),\n",
       " Document(page_content=\"In other words, “package relative imports” in 3.0 really just boil down to a removal of\\n2.6’s special search \\npath behavior for packages, along with the addition of special\\nfrom syntax to explicitly request relative behavior. If you wrote your package imports\\nin the past to not depend on 2.6’s special implicit relative lookup (e.g., by always spell-\\ning out full paths from a package root), this change is largely a moot point. If you didn’t,\\nyou’ll need to update your package files to use the new from syntax for local package\\nfiles.\\nModule Lookup Rules Summary\\nWith packages and relative imports, the module search story in Python 3.0 in its entirety\\ncan be summarized as follows:\\n• Simple module names (e.g., A) are looked up by searching each directory on the\\nsys.path list, from left to right. This list is constructed from both system defaults\\nand user-configurable settings.\\n• Packages are simply directories of Python modules with a special __init__.py file,\\nwhich enables A.B.C directory path syntax in imports. In an import of A.B.C, for\\nexample, the directory named A is located relative to the normal module import\\nsearch of sys.path, B is another package subdirectory within A, and C is a module\\nor other importable item within B.\\n• Within a package’s files, normal import statements use the same sys.path search\\nrule as imports elsewhere. Imports in packages using from statements and leading\\ndots, however, are relative to the package; that is, only the package directory is\\nchecked, and the normal sys.path lookup is not used. In from . import A, for\\nexample, the module search is restricted to the directory containing the file in which\\nthis statement appears.\\nRelative Imports in Action\\nBut enough theory: let’s run some quick tests to demonstrate the concepts behind\\nrelative imports.\\nImports outside packages\\nFirst of all, as mentioned previously, this feature does not impact imports outside a\\npackage. Thus, the following finds the standard library string module as expected:\\nC:\\\\test> c:\\\\Python30\\\\python\\n>>> import string\\n>>> string\\n<module 'string' from 'c:\\\\Python30\\\\lib\\\\string.py'>\\nPackage Relative Imports | 575\", metadata={'source': 'python.pdf', 'page': 625}),\n",
       " Document(page_content='But if we add a module of the same name in the directory we’re working in, it is selected\\ninstead, because the \\nfirst entry on the module search path is the current working\\ndirectory (CWD):\\n# test\\\\string.py\\nprint(\\'string\\' * 8)\\nC:\\\\test> c:\\\\Python30\\\\python\\n>>> import string\\nstringstringstringstringstringstringstringstring\\n>>> string\\n<module \\'string\\' from \\'string.py\\'>\\nIn other words, normal imports are still relative to the “home” directory (the top-level\\nscript’s container, or the directory you’re working in). In fact, relative import syntax is\\nnot even allowed in code that is not in a file being used as part of a package:\\n>>> from . import string\\nTraceback (most recent call last):\\n  File \"<stdin>\", line 1, in <module>\\nValueError: Attempted relative import in non-package\\nIn this and all examples in this section, code entered at the interactive prompt behaves\\nthe same as it would if run in a top-level script, because the first entry on sys.path is\\neither the interactive working directory or the directory containing the top-level file.\\nThe only difference is that the start of sys.path is an absolute directory, not an empty\\nstring:\\n# test\\\\main.py\\nimport string\\nprint(string)\\nC:\\\\test> C:\\\\python30\\\\python main.py                   # Same results in 2.6\\nstringstringstringstringstringstringstringstring\\n<module \\'string\\' from \\'C:\\\\test\\\\string.py\\'>\\nImports within packages\\nNow, let’s get rid of the local string module we coded in the CWD and build a package\\ndirectory there with two modules, including the required but empty test\\\\pkg\\n\\\\__init__.py file (which I’ll omit here):\\nC:\\\\test> del string*\\nC:\\\\test> mkdir pkg\\n# test\\\\pkg\\\\spam.py\\nimport eggs                    # <== Works in 2.6 but not 3.0!\\nprint(eggs.X)\\n# test\\\\pkg\\\\eggs.py\\nX = 99999\\nimport string\\nprint(string)\\n576 | Chapter 23: \\u2002Module Packages', metadata={'source': 'python.pdf', 'page': 626}),\n",
       " Document(page_content='The first file in this package tries to import the second with a normal import statement.\\nBecause this \\nis taken to be relative in 2.6 but absolute in 3.0, it fails in the latter. That\\nis, 2.6 searches the containing package first, but 3.0 does not. This is the noncompatible\\nbehavior you have to be aware of in 3.0:\\nC:\\\\test> c:\\\\Python26\\\\python\\n>>> import pkg.spam\\n<module \\'string\\' from \\'c:\\\\Python26\\\\lib\\\\string.pyc\\'>\\n99999\\nC:\\\\test> c:\\\\Python30\\\\python\\n>>> import pkg.spam\\nTraceback (most recent call last):\\n  File \"<stdin>\", line 1, in <module>\\n  File \"pkg\\\\spam.py\", line 1, in <module>\\n    import eggs\\nImportError: No module named eggs\\nTo make this work in both 2.6 and 3.0, change the first file to use the special relative\\nimport syntax, so that its import searches the package directory in 3.0, too:\\n# test\\\\pkg\\\\spam.py\\nfrom . import eggs             # <== Use package relative import in 2.6 or 3.0\\nprint(eggs.X)\\n# test\\\\pkg\\\\eggs.py\\nX = 99999\\nimport string\\nprint(string)\\nC:\\\\test> c:\\\\Python26\\\\python\\n>>> import pkg.spam\\n<module \\'string\\' from \\'c:\\\\Python26\\\\lib\\\\string.pyc\\'>\\n99999\\nC:\\\\test> c:\\\\Python30\\\\python\\n>>> import pkg.spam\\n<module \\'string\\' from \\'c:\\\\Python30\\\\lib\\\\string.py\\'>\\n99999\\nImports are still relative to the CWD\\nNotice in the preceding example that the package modules still have access to standard\\nlibrary modules like string. Really, their imports are still relative to the entries on the\\nmodule search path, even if those entries are relative themselves. If you add a string\\nmodule to the CWD again, imports in a package will find it there instead of in the\\nstandard library. Although you can skip the package directory with an absolute import\\nin 3.0, you still can’t skip the home directory of the program that imports the package:\\n# test\\\\string.py\\nprint(\\'string\\' * 8)\\n# test\\\\pkg\\\\spam.py\\nfrom . import eggs\\nPackage Relative Imports | 577', metadata={'source': 'python.pdf', 'page': 627}),\n",
       " Document(page_content=\"print(eggs.X)\\n# test\\\\pkg\\\\eggs.py\\nX = 99999\\nimport string                  # <== Gets string in CWD, not Python lib!\\nprint(string)\\nC:\\\\test> c:\\\\Python30\\\\python    # Same result in 2.6\\n>>> import pkg.spam\\nstringstringstringstringstringstringstringstring\\n<module 'string' from 'string.py'>\\n99999\\nSelecting modules with relative and absolute imports\\nTo show how \\nthis applies to imports of standard library modules, reset the package\\none more time. Get rid of the local string module, and define a new one inside the\\npackage itself:\\nC:\\\\test> del string*\\n# test\\\\pkg\\\\spam.py\\nimport string                  # <== Relative in 2.6, absolute in 3.0\\nprint(string)\\n# test\\\\pkg\\\\string.py\\nprint('Ni' * 8)\\nNow, which version of the string module you get depends on which Python you use.\\nAs before, 3.0 interprets the import in the first file as absolute and skips the package,\\nbut 2.6 does not:\\nC:\\\\test> c:\\\\Python30\\\\python\\n>>> import pkg.spam\\n<module 'string' from 'c:\\\\Python30\\\\lib\\\\string.py'>\\nC:\\\\test> c:\\\\Python26\\\\python\\n>>> import pkg.spam\\nNiNiNiNiNiNiNiNi\\n<module 'pkg.string' from 'pkg\\\\string.py'>\\nUsing relative import syntax in 3.0 forces the package to be searched again, as it is in\\n2.6—by using absolute or relative import syntax in 3.0, you can either skip or select\\nthe package directory explicitly. In fact, this is the use case that the 3.0 model addresses:\\n# test\\\\pkg\\\\spam.py\\nfrom . import string           # <== Relative in both 2.6 and 3.0\\nprint(string)\\n# test\\\\pkg\\\\string.py\\nprint('Ni' * 8)\\nC:\\\\test> c:\\\\Python30\\\\python\\n>>> import pkg.spam\\nNiNiNiNiNiNiNiNi\\n578 | Chapter 23: \\u2002Module Packages\", metadata={'source': 'python.pdf', 'page': 628}),\n",
       " Document(page_content=\"<module 'pkg.string' from 'pkg\\\\string.py'>\\nC:\\\\test> c:\\\\Python26\\\\python\\n>>> import pkg.spam\\nNiNiNiNiNiNiNiNi\\n<module 'pkg.string' from 'pkg\\\\string.py'>\\nIt’s important to \\nnote that relative import syntax is really a binding declaration, not\\njust a preference. If we delete the string.py file in this example, the relative import in\\nspam.py fails in both 3.0 and 2.6, instead of falling back on the standard library’s version\\nof this module (or any other):\\n# test\\\\pkg\\\\spam.py\\nfrom . import string           # <== Fails if no string.py here!\\nC:\\\\test> C:\\\\python30\\\\python\\n>>> import pkg.spam\\n...text omitted...\\nImportError: cannot import name string\\nModules referenced by relative imports must exist in the package directory.\\nImports are still relative to the CWD (again)\\nAlthough absolute imports let you skip package modules, they still rely on other com-\\nponents of sys.path. For one last test, let’s define two string modules of our own. In\\nthe following, there is one module by that name in the CWD, one in the package, and\\nanother in the standard library:\\n# test\\\\string.py\\nprint('string' * 8)\\n# test\\\\pkg\\\\spam.py\\nfrom . import string           # <== Relative in both 2.6 and 3.0\\nprint(string)\\n# test\\\\pkg\\\\string.py\\nprint('Ni' * 8)\\nWhen we import the string module with relative import syntax, we get the version in\\nthe package, as desired:\\nC:\\\\test> c:\\\\Python30\\\\python    # Same result in 2.6\\n>>> import pkg.spam\\nNiNiNiNiNiNiNiNi\\n<module 'pkg.string' from 'pkg\\\\string.py'>\\nWhen absolute syntax is used, though, the module we get varies per version again. 2.6\\ninterprets this as relative to the package, but 3.0 makes it “absolute,” which in this case\\nreally just means it skips the package and loads the version relative to the CWD ( not\\nthe version the standard library):\\n# test\\\\string.py\\nprint('string' * 8)\\nPackage Relative Imports | 579\", metadata={'source': 'python.pdf', 'page': 629}),\n",
       " Document(page_content='# test\\\\pkg\\\\spam.py\\nimport string                  # <== Relative in 2.6, \"absolute\" in 3.0: CWD!\\nprint(string)\\n# test\\\\pkg\\\\string.py\\nprint(\\'Ni\\' * 8)\\nC:\\\\test> c:\\\\Python30\\\\python\\n>>> import pkg.spam\\nstringstringstringstringstringstringstringstring\\n<module \\'string\\' from \\'string.py\\'>\\nC:\\\\test> c:\\\\Python26\\\\python\\n>>> import pkg.spam\\nNiNiNiNiNiNiNiNi\\n<module \\'pkg.string\\' from \\'pkg\\\\string.pyc\\'>\\nAs you can \\nsee, although packages can explicitly request modules within their own\\ndirectories, their imports are otherwise still relative to the rest of the normal module\\nsearch path. In this case, a file in the program using the package hides the standard\\nlibrary module the package may want. All that the change in 3.0 really accomplishes is\\nallowing package code to select files either inside or outside the package (i.e., relatively\\nor absolutely). Because import resolution can depend on an enclosing context that may\\nnot be foreseen, absolute imports in 3.0 are not a guarantee of finding a module in the\\nstandard library.\\nExperiment with these examples on your own for more insight. In practice, this is not\\nusually as ad-hoc as it might seem: you can generally structure your imports, search\\npaths, and module names to work the way you wish during development. You should\\nkeep in mind, though, that imports in larger systems may depend upon context of use,\\nand the module import protocol is part of a successful library’s design.\\nNow that you’ve learned about package-relative imports, also keep in\\nmind that they \\nmay not always be your best option. Absolute package\\nimports, relative to a directory on sys.path, are still sometimes preferred\\nover both implicit package-relative imports in Python 2, and explicit\\npackage-relative import syntax in both Python 2 and 3.\\nPackage-relative import syntax and Python 3.0’s new absolute import\\nsearch rules at least require relative imports from a package to be made\\nexplicit, and thus easier to understand and maintain. Files that use im-\\nports with dots, though, are implicitly bound to a package directory and\\ncannot be used elsewhere without code changes.\\nNaturally, the extent to which this may impact your modules can vary\\nper package; absolute imports may also require changes when directo-\\nries are reorganized.\\n580 | Chapter 23: \\u2002Module Packages', metadata={'source': 'python.pdf', 'page': 630}),\n",
       " Document(page_content='Why You Will Care: Module Packages\\nNow that packages \\nare a standard part of Python, it’s common to see larger third-party\\nextensions shipped as sets of package directories, rather than flat lists of modules. The\\nwin32all Windows extensions package for Python, for instance, was one of the first to\\njump on the package bandwagon. Many of its utility modules reside in packages im-\\nported with paths. For instance, to load client-side COM tools, you use a statement\\nlike this:\\nfrom win32com.client import constants, Dispatch\\nThis line fetches names from the client module of the win32com package (an install\\nsubdirectory).\\nPackage imports are also pervasive in code run under the Jython Java-based imple-\\nmentation of Python, because Java libraries are organized into hierarchies as well. In\\nrecent Python releases, the email and XML tools are likewise organized into package\\nsubdirectories in the standard library, and Python 3.0 groups even more related mod-\\nules into packages (including tkinter GUI tools, HTTP networking tools, and more).\\nThe following imports access various standard library tools in 3.0:\\nfrom email.message import Message\\nfrom tkinter.filedialog import askopenfilename\\nfrom http.server import CGIHTTPRequestHandler\\nWhether you create package directories or not, you will probably import from them \\neventually.\\nChapter Summary\\nThis chapter introduced \\nPython’s package import model—an optional but useful way\\nto explicitly list part of the directory path leading up to your modules. Package imports\\nare still relative to a directory on your module import search path, but rather than\\nrelying on Python to traverse the search path manually, your script gives the rest of the\\npath to the module explicitly.\\nAs we’ve seen, packages not only make imports more meaningful in larger systems, but\\nalso simplify import search path settings (if all cross-directory imports are relative to a\\ncommon root directory) and resolve ambiguities when there is more than one module\\nof the same name (including the name of the enclosing directory in a package import\\nhelps distinguish between them).\\nBecause it’s relevant only to code in packages, we also explored the newer relative\\nimport model here—a way for imports in package files to select modules in the same\\npackage using leading dots in a from, instead of relying on an older implicit package\\nsearch rule.\\nChapter Summary | 581', metadata={'source': 'python.pdf', 'page': 631}),\n",
       " Document(page_content='In the next chapter, we will survey a handful of more advanced module-related topics,\\nsuch as relative \\nimport syntax and the __name__ usage mode variable. As usual, though,\\nwe’ll close out this chapter with a short quiz to test what you’ve learned here.\\nTest Your Knowledge: Quiz\\n1. What is the purpose of an __init__.py\\n file in a module package directory?\\n2. How can you avoid repeating the full package path every time you reference a\\npackage’s content?\\n3. Which directories require __init__.py files?\\n4. When must you use import instead of from with packages?\\n5. What is the difference between from mypkg import spam and from . import spam?\\nTest Your Knowledge: Answers\\n1. The __init__.py file serves to declare and initialize a module package; Python au-\\ntomatically runs its code the first time you import through a directory in a process.\\nIts assigned variables become the attributes of the module object created in memory\\nto correspond to that directory. It is also not optional—you can’t import through\\na directory with package syntax unless it contains this file.\\n2. Use the from statement with a package to copy names out of the package directly,\\nor use the as extension with the import statement to rename the path to a shorter\\nsynonym. In both cases, the path is listed in only one place, in the from or import\\nstatement.\\n3. Each directory listed in an import or from statement must contain an __init__.py\\nfile. Other directories, including the directory containing the leftmost component\\nof a package path, do not need to include this file.\\n4. You must use import instead of from with packages only if you need to access the\\nsame name defined in more than one path. With import, the path makes the ref-\\nerences unique, but from allows only one version of any given name.\\n5.from mypkg import spam is an absolute import—the search for mypkg skips the\\npackage directory and the module is located in an absolute directory in sys.path.\\nA statement from . import spam, on the other hand, is a relative import— spam is\\nlooked up relative to the package in which this statement is contained before\\nsys.path is searched.\\n582 | Chapter 23: \\u2002Module Packages', metadata={'source': 'python.pdf', 'page': 632}),\n",
       " Document(page_content='CHAPTER 24\\nAdvanced Module Topics\\nThis chapter concludes this part of the book with a collection of more advanced\\nmodule-related topics—data hiding, \\nthe __future__ module, the __name__ variable,\\nsys.path changes, listing tools, running modules by name string, transitive reloads, and\\nso on—along with the standard set of gotchas and exercises related to what we’ve\\ncovered in this part of the book.\\nAlong the way, we’ll build some larger and more useful tools than we have so far, that\\ncombine functions and modules. Like functions, modules are more effective when their\\ninterfaces are well defined, so this chapter also briefly reviews module design concepts,\\nsome of which we have explored in prior chapters.\\nDespite the word “advanced” in this chapter’s title, this is also something of a grab bag\\nof additional module topics. Because some of the topics discussed here are widely used\\n(especially the __name__ trick), be sure to take a look before moving on to classes in the\\nnext part of the book.\\nData Hiding in Modules\\nAs we’ve seen, a Python module exports all the names assigned at the top level of its\\nfile. There is no notion of declaring which names should and shouldn’t be visible out-\\nside the module. In fact, there’s no way to prevent a client from changing names inside\\na module if it wants to.\\nIn Python, data hiding in modules is a convention, not a syntactical constraint. If you\\nwant to break a module by trashing its names, you can, but fortunately, I’ve yet to meet\\na programmer who would. Some purists object to this liberal attitude toward data\\nhiding, claiming that it means Python can’t implement encapsulation. However, en-\\ncapsulation in Python is more about packaging than about restricting.\\n583', metadata={'source': 'python.pdf', 'page': 633}),\n",
       " Document(page_content='Minimizing from * Damage: _X and __all__\\nAs a special \\ncase, you can prefix names with a single underscore (e.g., _X) to prevent\\nthem from being copied out when a client imports a module’s names with a from *\\nstatement. This really is intended only to minimize namespace pollution; because from\\n* copies out all names, the importer may get more than it’s bargained for (including\\nnames that overwrite names in the importer). Underscores aren’t “private” declara-\\ntions: you can still see and change such names with other import forms, such as the\\nimport statement.\\nAlternatively, you can achieve a hiding effect similar to the _X naming convention by\\nassigning a list of variable name strings to the variable __all__ at the top level of the\\nmodule. For example:\\n__all__ = [\"Error\", \"encode\", \"decode\"]     # Export these only\\nWhen this feature is used, the from *  statement will copy out only those names listed\\nin the __all__ list. In effect, this is the converse of the _X convention: __all__ identifies\\nnames to be copied, while _X identifies names not to be copied. Python looks for an\\n__all__ list in the module first; if one is not defined, from *  copies all names without\\na single leading underscore.\\nLike the _X convention, the __all__ list has meaning only to the from *  statement form\\nand does not amount to a privacy declaration. Module writers can use either trick to\\nimplement modules that are well behaved when used with from *. (See also the dis-\\ncussion of __all__ lists in package __init__.py files in Chapter 23; there, these lists\\ndeclare submodules to be loaded for a from *.)\\nEnabling Future Language Features\\nChanges to the language that may potentially break existing code are introduced grad-\\nually. Initially, they appear as optional extensions, which are disabled by default. To\\nturn on such extensions, use a special import statement of this form:\\nfrom __future__ import featurename\\nThis statement should generally appear at the top of a module file (possibly after a\\ndocstring), because it enables special compilation of code on a per-module basis. It’s\\nalso possible to submit this statement at the interactive prompt to experiment with\\nupcoming language changes; the feature will then be available for the rest of the inter-\\nactive session.\\nFor example, in prior editions of this book, we had to use this statement form to dem-\\nonstrate generator functions, which required a keyword that was not yet enabled by\\ndefault (they use a featurename of generators). We also used this statement to activate\\n3.0 true division in Chapter 5 , 3.0 print calls in Chapter 11 , and 3.0 absolute imports\\nfor packages in Chapter 23.\\n584 | Chapter 24: \\u2002Advanced Module Topics', metadata={'source': 'python.pdf', 'page': 634}),\n",
       " Document(page_content='All of these changes have the potential to break existing code in Python 2.6, so they are\\nbeing phased in gradually as optional features enabled with this special import.\\nMixed Usage Modes: __name__ and __main__\\nHere’s another module-related \\ntrick that lets you both import a file as a module and\\nrun it as a standalone program. Each module has a built-in attribute called __name__,\\nwhich Python sets automatically as follows:\\n• If the file is being run as a top-level program file, __name__ is set to the string\\n\"__main__\" when it starts.\\n• If the file is being imported instead, __name__ is set to the module’s name as known\\nby its clients.\\nThe upshot is that a module can test its own __name__ to determine whether it’s being\\nrun or imported. For example, suppose we create the following module file, named\\nrunme.py, to export a single function called tester:\\ndef tester():\\n    print(\"It\\'s Christmas in Heaven...\")\\nif __name__ == \\'__main__\\':           # Only when run\\n    tester()                         # Not when imported\\nThis module defines a function for clients to import and use as usual:\\n% python\\n>>> import runme\\n>>> runme.tester()\\nIt\\'s Christmas in Heaven...\\nBut, the module also includes code at the bottom that is set up to call the function when\\nthis file is run as a program:\\n% python runme.py\\nIt\\'s Christmas in Heaven...\\nIn effect, a module’s __name__ variable serves as a usage mode flag , allowing its code to\\nbe leveraged as both an importable library and a top-level script. Though simple, you’ll\\nsee this hook used in nearly every realistic Python program file you are likely to\\nencounter.\\nPerhaps the most common way you’ll see the __name__ test applied is for self-test code.\\nIn short, you can package code that tests a module’s exports in the module itself by\\nwrapping it in a __name__ test at the bottom of the file. This way, you can use the file\\nin clients by importing it, but also test its logic by running it from the system shell or\\nvia another launching scheme. In practice, self-test code at the bottom of a file under\\nthe __name__ test is probably the most common and simplest unit-testing protocol in\\nPython. ( Chapter 35  will discuss other commonly used options for testing Python\\nMixed Usage Modes: __name__ and __main__ | 585', metadata={'source': 'python.pdf', 'page': 635}),\n",
       " Document(page_content=\"code—as you’ll see, the unittest and doctest standard library modules provide more\\nadvanced testing tools.)\\nThe __name__ trick is \\nalso commonly used when writing files that can be used both as\\ncommand-line utilities and as tool libraries. For instance, suppose you write a file-finder\\nscript in Python. You can get more mileage out of your code if you package it in func-\\ntions and add a __name__ test in the file to automatically call those functions when the\\nfile is run standalone. That way, the script’s code becomes reusable in other programs.\\nUnit Tests with __name__\\nIn fact, we’ve already seen a prime example in this book of an instance where the\\n__name__ check could be useful. In the section on arguments in Chapter 18 , we coded\\na script that computed the minimum value from the set of arguments sent in:\\ndef minmax(test, *args):\\n    res = args[0]\\n    for arg in args[1:]:\\n        if test(arg, res):\\n            res = arg\\n    return res\\ndef lessthan(x, y): return x < y\\ndef grtrthan(x, y): return x > y\\nprint(minmax(lessthan, 4, 2, 1, 5, 6, 3))        # Self-test code\\nprint(minmax(grtrthan, 4, 2, 1, 5, 6, 3))\\nThis script includes self-test code at the bottom, so we can test it without having to\\nretype everything at the interactive command line each time we run it. The problem\\nwith the way it is currently coded, however, is that the output of the self-test call will\\nappear every time this file is imported from another file to be used as a tool—not exactly\\na user-friendly feature! To improve it, we can wrap up the self-test call in a __name__\\ncheck, so that it will be launched only when the file is run as a top-level script, not when\\nit is imported:\\nprint('I am:', __name__)\\ndef minmax(test, *args):\\n    res = args[0]\\n    for arg in args[1:]:\\n        if test(arg, res):\\n            res = arg\\n    return res\\ndef lessthan(x, y): return x < y\\ndef grtrthan(x, y): return x > y\\nif __name__ == '__main__':\\n    print(minmax(lessthan, 4, 2, 1, 5, 6, 3))    # Self-test code\\n    print(minmax(grtrthan, 4, 2, 1, 5, 6, 3))\\n586 | Chapter 24: \\u2002Advanced Module Topics\", metadata={'source': 'python.pdf', 'page': 636}),\n",
       " Document(page_content='We’re also printing the value of __name__ at the top here to trace its value. Python creates\\nand assigns this usage-mode variable as soon as it starts loading a file. When we run\\nthis file as a top-level script, its name is set to __main__, so its self-test code kicks in\\nautomatically:\\n% python min.py\\nI am: __main__\\n1\\n6\\nBut, if we import the file, its name is not __main__, so we must explicitly call the function\\nto make it run:\\n>>> import min\\nI am: min\\n>>> min.minmax(min.lessthan, \\'s\\', \\'p\\', \\'a\\', \\'m\\')\\n\\'a\\'\\nAgain, regardless of whether this is used for testing, the net effect is that we get to use\\nour code in two different roles—as a library module of tools, or as an executable\\nprogram.\\nUsing Command-Line Arguments with __name__\\nHere’s a more substantial module example that demonstrates another way that the\\n__name__ trick is commonly employed. The following module, formats.py, defines string\\nformatting utilities for importers, but also checks its name to see if it is being run as a\\ntop-level script; if so, it tests and uses arguments listed on the system command line to\\nrun a canned or passed-in test. In Python, the sys.argv list contains command-line\\narguments—it is a list of strings reflecting words typed on the command line, where\\nthe first item is always the name of the script being run:\\n\"\"\"\\nVarious specialized string display formatting utilities.\\nTest me with canned self-test or command-line arguments.\\n\"\"\"\\ndef commas(N):\\n    \"\"\"\\n    format positive integer-like N for display with\\n    commas between digit groupings: xxx,yyy,zzz\\n    \"\"\"\\n    digits = str(N)\\n    assert(digits.isdigit())\\n    result = \\'\\'\\n    while digits:\\n        digits, last3 = digits[:-3], digits[-3:]\\n        result = (last3 + \\',\\' + result) if result else last3\\n    return result\\ndef money(N, width=0):\\n    \"\"\"\\nMixed Usage Modes: __name__ and __main__ | 587', metadata={'source': 'python.pdf', 'page': 637}),\n",
       " Document(page_content='    format number N for display with commas, 2 decimal digits,\\n    leading $ and sign, and optional padding: $  -xxx,yyy.zz\\n    \"\"\"\\n    sign   = \\'-\\' if N < 0 else \\'\\'\\n    N      = abs(N)\\n    whole  = commas(int(N))\\n    fract  = (\\'%.2f\\' % N)[-2:]\\n    format = \\'%s%s.%s\\' % (sign, whole, fract)\\n    return \\'$%*s\\' % (width, format)\\nif __name__ == \\'__main__\\':\\n    def selftest():\\n        tests  = 0, 1        # fails: −1, 1.23\\n        tests += 12, 123, 1234, 12345, 123456, 1234567\\n        tests += 2 ** 32, 2 ** 100\\n        for test in tests:\\n            print(commas(test))\\n        print(\\'\\')\\n        tests  = 0, 1, −1, 1.23, 1., 1.2, 3.14159\\n        tests += 12.34, 12.344, 12.345, 12.346\\n        tests += 2 ** 32, (2 ** 32 + .2345)\\n        tests += 1.2345, 1.2, 0.2345\\n        tests += −1.2345, −1.2, −0.2345\\n        tests += −(2 ** 32), −(2**32 + .2345)\\n        tests += (2 ** 100), −(2 ** 100)\\n        for test in tests:\\n            print(\\'%s [%s]\\' % (money(test, 17), test))\\n    import sys\\n    if len(sys.argv) == 1:\\n        selftest()\\n    else:\\n        print(money(float(sys.argv[1]), int(sys.argv[2])))\\nThis file works \\nthe same in Python 2.6 and 3.0. When run directly, it tests itself as\\nbefore, but it uses options on the command line to control the test behavior. Run this\\nfile directly with no command-line arguments on your own to see what its self-test code\\nprints. To test specific strings, pass them in on the command line along with a minimum\\nfield width:\\nC:\\\\misc> python formats.py 999999999 0\\n$999,999,999.00\\nC:\\\\misc> python formats.py −999999999 0\\n$-999,999,999.00\\nC:\\\\misc> python formats.py 123456789012345 0\\n$123,456,789,012,345.00\\nC:\\\\misc> python formats.py −123456789012345 25\\n$  −123,456,789,012,345.00\\nC:\\\\misc> python formats.py 123.456 0\\n$123.46\\n588 | Chapter 24: \\u2002Advanced Module Topics', metadata={'source': 'python.pdf', 'page': 638}),\n",
       " Document(page_content=\"C:\\\\misc> python formats.py −123.454 0\\n$-123.45\\nC:\\\\misc> python formats.py\\n...canned tests: try this yourself...\\nAs before, because \\nthis code is instrumented for dual-mode usage, we can also import\\nits tools normally in other contexts as library components:\\n>>> from formats import money, commas\\n>>> money(123.456)\\n'$123.46'\\n>>> money(-9999999.99, 15)\\n'$  −9,999,999.99'\\n>>> X = 99999999999999999999\\n>>> '%s (%s)' % (commas(X), X)\\n'99,999,999,999,999,999,999 (99999999999999999999)'\\nBecause this file uses the docstring feature introduced in Chapter 15, we can use the\\nhelp function to explore its tools as well—it serves as a general-purpose tool:\\n>>> import formats\\n>>> help(formats)\\nHelp on module formats:\\nNAME\\n    formats\\nFILE\\n    c:\\\\misc\\\\formats.py\\nDESCRIPTION\\n    Various specialized string display formatting utilities.\\n    Test me with canned self-test or command-line arguments.\\nFUNCTIONS\\n    commas(N)\\n        format positive integer-like N for display with\\n        commas between digit groupings: xxx,yyy,zzz\\n    money(N, width=0)\\n        format number N for display with commas, 2 decimal digits,\\n        leading $ and sign, and optional padding: $  -xxx,yyy.zz\\nYou can use command-line arguments in similar ways to provide general inputs to\\nscripts that may also package their code as functions and classes for reuse by importers.\\nFor more advanced command-line processing, be sure to see the getopt and optparse\\nmodules in Python’s standard library and manuals. In some scenarios, you might also\\nuse the built-in input function introduced in Chapter 3 and used in Chapter 10 to\\nprompt the shell user for test inputs instead of pulling them from the command line.\\nMixed Usage Modes: __name__ and __main__ | 589\", metadata={'source': 'python.pdf', 'page': 639}),\n",
       " Document(page_content='Also see Chapter 7’s discussion of the new {,d} string format method\\nsyntax that will be available in Python 3.1 and later; this formatting\\nextension separates thousands groups with commas much like the code\\nhere. The module listed here, though, adds money formatting and serves\\nas a manual alternative for comma insertion for Python versions before\\n3.1.\\nChanging the Module Search Path\\nIn Chapter 21 , we learned that the module search path is a list of directories that can\\nbe customized via the environment variable PYTHONPATH, and possibly via .pth files. What\\nI haven’t shown you until now is how a Python program itself can actually change the\\nsearch path by changing a built-in list called sys.path (the path attribute in the built-\\nin sys module). sys.path is initialized on startup, but thereafter you can delete, append,\\nand reset its components however you like:\\n>>> import sys\\n>>> sys.path\\n[\\'\\', \\'C:\\\\\\\\users\\', \\'C:\\\\\\\\Windows\\\\\\\\system32\\\\\\\\python30.zip\\', ...more deleted...]\\n>>> sys.path.append(\\'C:\\\\\\\\sourcedir\\')         # Extend module search path\\n>>> import string                            # All imports search the new dir last\\nOnce you’ve made such a change, it will impact future imports anywhere in the Python\\nprogram, as all imports and all files share the single sys.path list. In fact, this list may\\nbe changed arbitrarily:\\n>>> sys.path = [r\\'d:\\\\temp\\']                  # Change module search path\\n>>> sys.path.append(\\'c:\\\\\\\\lp4e\\\\\\\\examples\\')    # For this process only\\n>>> sys.path\\n[\\'d:\\\\\\\\temp\\', \\'c:\\\\\\\\lp4e\\\\\\\\examples\\']\\n>>> import string\\nTraceback (most recent call last):\\n  File \"<stdin>\", line 1, in <module>\\nImportError: No module named string\\nThus, you can use this technique to dynamically configure a search path inside a Python\\nprogram. Be careful, though: if you delete a critical directory from the path, you may\\nlose access to critical utilities. In the prior example, for instance, we no longer have\\naccess to the string module because we deleted the Python source library’s directory\\nfrom the path.\\nAlso, remember that such sys.path settings endure for only as long as the Python ses-\\nsion or program (technically, process) that made them runs; they are not retained after\\nPython exits. PYTHONPATH and .pth file path configurations live in the operating system\\ninstead of a running Python program, and so are more global: they are picked up by\\nevery program on your machine and live on after a program completes.\\n590 | Chapter 24: \\u2002Advanced Module Topics', metadata={'source': 'python.pdf', 'page': 640}),\n",
       " Document(page_content='The as Extension for import and from\\nBoth the import \\nand from statements have been extended to allow an imported name\\nto be given a different name in your script. The following import statement:\\nimport modulename as name\\nis equivalent to:\\nimport modulename\\nname = modulename\\ndel modulename                                # Don\\'t keep original name\\nAfter such an import, you can (and in fact must) use the name listed after the as to refer\\nto the module. This works in a from statement, too, to assign a name imported from a\\nfile to a different name in your script:\\nfrom modulename import attrname as name\\nThis extension is commonly used to provide short synonyms for longer names, and to\\navoid name clashes when you are already using a name in your script that would oth-\\nerwise be overwritten by a normal import statement:\\nimport reallylongmodulename as name           # Use shorter nickname\\nname.func()\\nfrom module1 import utility as util1          # Can have only 1 \"utility\"\\nfrom module2 import utility as util2\\nutil1(); util2()\\nIt also comes in handy for providing a short, simple name for an entire directory path\\nwhen using the package import feature described in Chapter 23:\\nimport dir1.dir2.mod as mod                   # Only list full path once\\nmod.func()\\nModules Are Objects: Metaprograms\\nBecause modules expose most of their interesting properties as built-in attributes, it’s\\neasy to write programs that manage other programs. We usually call such manager\\nprograms metaprograms because they work on top of other systems. This is also referred\\nto as introspection, because programs can see and process object internals. Introspec-\\ntion is an advanced feature, but it can be useful for building programming tools.\\nFor instance, to get to an attribute called name in a module called M, we can use quali-\\nfication or index the module’s attribute dictionary, exposed in the built-in __dict__\\nattribute we met briefly in Chapter 22. Python also exports the list of all loaded modules\\nas the sys.modules dictionary (that is, the modules attribute of the sys module) and\\nprovides a built-in called getattr that lets us fetch attributes from their string names\\n(it’s like saying object.attr, but attr is an expression that yields a string at runtime).\\nBecause of that, all the following expressions reach the same attribute and object:\\nModules Are Objects: Metaprograms | 591', metadata={'source': 'python.pdf', 'page': 641}),\n",
       " Document(page_content='M.name                                        # Qualify object\\nM.__dict__[\\'name\\']                            # Index namespace dictionary manually\\nsys.modules[\\'M\\'].name                         # Index loaded-modules table manually\\ngetattr(M, \\'name\\')                            # Call built-in fetch function\\nBy exposing module \\ninternals like this, Python helps you build programs about pro-\\ngrams.* For example, here is a module named mydir.py that puts these ideas to work\\nto implement a customized version of the built-in dir function. It defines and exports\\na function called listing, which takes a module object as an argument and prints a\\nformatted listing of the module’s namespace:\\n\"\"\"\\nmydir.py: a module that lists the namespaces of other modules\\n\"\"\"\\nseplen = 60\\nsepchr = \\'-\\'\\ndef listing(module, verbose=True):\\n    sepline = sepchr * seplen\\n    if verbose:\\n        print(sepline)\\n        print(\\'name:\\', module.__name__, \\'file:\\', module.__file__)\\n        print(sepline)\\n    count = 0\\n    for attr in module.__dict__:              # Scan namespace keys\\n        print(\\'%02d) %s\\' % (count, attr), end = \\' \\')\\n        if attr.startswith(\\'__\\'):\\n            print(\\'<built-in name>\\')          # Skip __file__, etc.\\n        else:\\n            print(getattr(module, attr))      # Same as .__dict__[attr]\\n        count += 1\\n    if verbose:\\n        print(sepline)\\n        print(module.__name__, \\'has %d names\\' % count)\\n        print(sepline)\\nif __name__ == \\'__main__\\':\\n    import mydir\\n    listing(mydir)                            # Self-test code: list myself\\nNotice the docstring at the top; as in the prior formats.py example, because we may\\nwant to use this as a general tool, a docstring is coded to provide functional information\\naccessible via __doc__ attributes or the help function (see Chapter 15 for details):\\n* As we saw in Chapter 17, because a function can access its enclosing module by going through the\\nsys.modules table like this, it’s possible to emulate the effect of the global statement. For instance, the effect\\nof global X; X=0 can be simulated (albeit with much more typing!) by saying this inside a function:\\nimport sys; glob=sys.modules[__name__]; glob.X=0. Remember, each module gets a __name__ attribute for\\nfree; it’s visible as a global name inside the functions within the module. This trick provides another way to\\nchange both local and global variables of the same name inside a function.\\n592 | Chapter 24: \\u2002Advanced Module Topics', metadata={'source': 'python.pdf', 'page': 642}),\n",
       " Document(page_content=\">>> import mydir\\n>>> help(mydir)\\nHelp on module mydir:\\nNAME\\n    mydir - mydir.py: a module that lists the namespaces of other modules\\nFILE\\n    c:\\\\users\\\\veramark\\\\mark\\\\mydir.py\\nFUNCTIONS\\n    listing(module, verbose=True)\\nDATA\\n    sepchr = '-'\\n    seplen = 60\\nI’ve also provided self-test\\n logic at the bottom of this module, which narcissistically\\nimports and lists itself. Here’s the sort of output produced in Python 3.0 (to use this in\\n2.6, enable 3.0 print calls with the __future__ import described in Chapter 11 —the\\nend keyword is 3.0-only):\\nC:\\\\Users\\\\veramark\\\\Mark> c:\\\\Python30\\\\python mydir.py\\n------------------------------------------------------------\\nname: mydir file: C:\\\\Users\\\\veramark\\\\Mark\\\\mydir.py\\n------------------------------------------------------------\\n00) seplen 60\\n01) __builtins__ <built-in name>\\n02) __file__ <built-in name>\\n03) __package__ <built-in name>\\n04) listing <function listing at 0x026D3B70>\\n05) __name__ <built-in name>\\n06) sepchr -\\n07) __doc__ <built-in name>\\n------------------------------------------------------------\\nmydir has 8 names\\n------------------------------------------------------------\\nTo use this as a tool for listing other modules, simply pass the modules in as objects to\\nthis file’s function. Here it is listing attributes in the tkinter GUI module in the standard\\nlibrary (a.k.a. Tkinter in Python 2.6):\\n>>> import mydir\\n>>> import tkinter\\n>>> mydir.listing(tkinter)\\n------------------------------------------------------------\\nname: tkinter file: c:\\\\PYTHON30\\\\lib\\\\tkinter\\\\__init__.py\\n------------------------------------------------------------\\n00) getdouble <class 'float'>\\n01) MULTIPLE multiple\\n02) mainloop <function mainloop at 0x02913B70>\\n03) Canvas <class 'tkinter.Canvas'>\\n04) AtSelLast <function AtSelLast at 0x028FA7C8>\\n...many more name omitted...\\n151) StringVar <class 'tkinter.StringVar'>\\nModules Are Objects: Metaprograms | 593\", metadata={'source': 'python.pdf', 'page': 643}),\n",
       " Document(page_content='152) ARC arc\\n153) At <function At at 0x028FA738>\\n154) NSEW nsew\\n155) SCROLL scroll\\n------------------------------------------------------------\\ntkinter has 156 names\\n------------------------------------------------------------\\nWe’ll meet getattr  \\nand its relatives again later. The point to notice here is that mydir\\nis a program that lets you browse other programs. Because Python exposes its internals,\\nyou can process objects generically.†\\nImporting Modules by Name String\\nThe module name in an import or from statement is a hardcoded variable name. Some-\\ntimes, though, your program will get the name of a module to be imported as a string\\nat runtime (e.g., if a user selects a module name from within a GUI). Unfortunately,\\nyou can’t use import statements directly to load a module given its name as a string—\\nPython expects a variable name, not a string. For instance:\\n>>> import \"string\"\\n  File \"<stdin>\", line 1\\n    import \"string\"\\n                  ^\\nSyntaxError: invalid syntax\\nIt also won’t work to simply assign the string to a variable name:\\nx = \"string\"\\nimport x\\nHere, Python will try to import a file x.py, not the string module—the name in an\\nimport statement both becomes a variable assigned to the loaded module and identifies\\nthe external file literally.\\nTo get around this, you need to use special tools to load a module dynamically from a\\nstring that is generated at runtime. The most general approach is to construct an\\nimport statement as a string of Python code and pass it to the exec built-in function to\\nrun (exec is a statement in Python 2.6, but it can be used exactly as shown here—the\\nparentheses are simply ignored):\\n>>> modname = \"string\"\\n>>> exec(\"import \" + modname)      # Run a string of code\\n>>> string                         # Imported in this namespace\\n<module \\'string\\' from \\'c:\\\\Python30\\\\lib\\\\string.py\\'>\\n† Tools such as mydir.listing  can be preloaded into the interactive namespace by importing them in the file\\nreferenced by the PYTHONSTARTUP environment variable. Because code in the startup file runs in the interactive\\nnamespace (module __main__), importing common tools in the startup file can save you some typing. See\\nAppendix A for more details.\\n594 | Chapter 24: \\u2002Advanced Module Topics', metadata={'source': 'python.pdf', 'page': 644}),\n",
       " Document(page_content='The exec function (and its cousin for expressions, eval) compiles a string of code and\\npasses it to the Python interpreter to be executed. In Python, the byte code compiler is\\navailable at runtime, so you can write programs that construct and run other programs\\nlike this. By default, exec runs the code in the current scope, but you can get more\\nspecific by passing in optional namespace dictionaries.\\nThe only real drawback to exec is that it must compile the import statement each time\\nit runs; if it runs many times, your code may run quicker if it uses the built-in\\n__import__ function to load from a name string instead. The effect is similar, but\\n__import__ returns the module object, so assign it to a name here to keep it:\\n>>> modname = \"string\"\\n>>> string = __import__(modname)\\n>>> string\\n<module \\'string\\' from \\'c:\\\\Python30\\\\lib\\\\string.py\\'>\\nTransitive Module Reloads\\nWe studied module reloads in Chapter 22, as a way to pick up changes in code without\\nstopping and restarting a program. When you reload a module, though, Python only\\nreloads that particular module’s file; it doesn’t automatically reload modules that the\\nfile being reloaded happens to import.\\nFor example, if you reload some module A, and A imports modules B and C, the reload\\napplies only to A, not to B and C. The statements inside A that import B and C are rerun\\nduring the reload, but they just fetch the already loaded B and C module objects (as-\\nsuming they’ve been imported before). In actual code, here’s the file A.py:\\nimport B                   # Not reloaded when A is\\nimport C                   # Just an import of an already loaded module\\n% python\\n>>> . . .\\n>>> from imp import reload\\n>>> reload(A)\\nBy default, this means that you cannot depend on reloads picking up changes in all the\\nmodules in your program transitively—instead, you must use multiple reload calls to\\nupdate the subcomponents independently. This can require substantial work for large\\nsystems you’re testing interactively. You can design your systems to reload their sub-\\ncomponents automatically by adding reload calls in parent modules like A, but this\\ncomplicates the modules’ code.\\nA better approach is to write a general tool to do transitive reloads automatically by\\nscanning modules’ __dict__ attributes and checking each item’s type to find nested\\nmodules to reload. Such a utility function could call itself recursively to navigate arbi-\\ntrarily shaped import dependency chains. Module __dict__ attributes were introduced\\nearlier in, the section “Modules Are Objects: Metaprograms” on page 591, and the\\ntype call was presented in Chapter 9; we just need to combine the two tools.\\nTransitive Module Reloads | 595', metadata={'source': 'python.pdf', 'page': 645}),\n",
       " Document(page_content='For example, the module reloadall.py listed next has a reload_all function that auto-\\nmatically reloads a module, every module that the module imports, and so on, all the\\nway to the bottom of each import chain. It uses a dictionary to keep track of already\\nreloaded modules, recursion to walk the import chains, and the standard library’s\\ntypes module, which simply predefines type results for built-in types. The visited\\ndictionary technique works to avoid cycles here when imports are recursive or redun-\\ndant, because module objects can be dictionary keys (as we learned in Chapter 5 , a set\\nwould offer similar functionality if we use visited.add(module) to insert):\\n\"\"\"\\nreloadall.py: transitively reload nested modules\\n\"\"\"\\nimport types\\nfrom imp import reload                               # from required in 3.0\\ndef status(module):\\n    print(\\'reloading \\' + module.__name__)\\ndef transitive_reload(module, visited):\\n    if not module in visited:                        # Trap cycles, duplicates\\n        status(module)                               # Reload this module\\n        reload(module)                               # And visit children\\n        visited[module] = None\\n        for attrobj in module.__dict__.values():     # For all attrs\\n            if type(attrobj) == types.ModuleType:    # Recur if module\\n                transitive_reload(attrobj, visited)\\ndef reload_all(*args):\\n    visited = {}\\n    for arg in args:\\n        if type(arg) == types.ModuleType:\\n            transitive_reload(arg, visited)\\nif __name__ == \\'__main__\\':\\n    import reloadall                                 # Test code: reload myself\\n    reload_all(reloadall)                            # Should reload this, types\\nTo use this utility, import its reload_all function and pass it the name of an already\\nloaded module (like you would the built-in reload function). When the file runs stand-\\nalone, its self-test code will test itself—it has to import itself because its own name is\\nnot defined in the file without an import (this code works in both 3.0 and 2.6 and prints\\nidentical output, because we’ve used + instead of a comma in the print):\\nC:\\\\misc> c:\\\\Python30\\\\python reloadall.py\\nreloading reloadall\\nreloading types\\nHere is this module at work in 3.0 on some standard library modules. Notice how os\\nis imported by tkinter, but tkinter reaches sys before os can (if you want to test this\\non Python 2.6, substitute Tkinter for tkinter):\\n596 | Chapter 24: \\u2002Advanced Module Topics', metadata={'source': 'python.pdf', 'page': 646}),\n",
       " Document(page_content=\">>> from reloadall import reload_all\\n>>> import os, tkinter\\n>>> reload_all(os)\\nreloading os\\nreloading copyreg\\nreloading ntpath\\nreloading genericpath\\nreloading stat\\nreloading sys\\nreloading errno\\n>>> reload_all(tkinter)\\nreloading tkinter\\nreloading _tkinter\\nreloading tkinter._fix\\nreloading sys\\nreloading ctypes\\nreloading os\\nreloading copyreg\\nreloading ntpath\\nreloading genericpath\\nreloading stat\\nreloading errno\\nreloading ctypes._endian\\nreloading tkinter.constants\\nAnd here is \\na session that shows the effect of normal versus transitive reloads—changes\\nmade to the two nested files are not picked up by reloads, unless the transitive utility\\nis used:\\nimport b                          # a.py\\nX = 1\\nimport c                          # b.py\\nY = 2\\nZ = 3                             # c.py\\nC:\\\\misc> C:\\\\Python30\\\\python\\n>>> import a\\n>>> a.X, a.b.Y, a.b.c.Z\\n(1, 2, 3)\\n# Change all three files' assignment values and save\\n>>> from imp import reload\\n>>> reload(a)                     # Normal reload is top level only\\n<module 'a' from 'a.py'>\\n>>> a.X, a.b.Y, a.b.c.Z\\n(111, 2, 3)\\n>>> from reloadall import reload_all\\n>>> reload_all(a)\\nreloading a\\nTransitive Module Reloads | 597\", metadata={'source': 'python.pdf', 'page': 647}),\n",
       " Document(page_content='reloading b\\nreloading c\\n>>> a.X, a.b.Y, a.b.c.Z           # Reloads all nested modules too\\n(111, 222, 333)\\nFor more insight, \\nstudy and experiment with this example on your own; it’s another\\nimportable tool you might want to add to your own source code library.\\nModule Design Concepts\\nLike functions, modules present design tradeoffs: you have to think about which func-\\ntions go in which modules, module communication mechanisms, and so on. All of this\\nwill become clearer when you start writing bigger Python systems, but here are a few\\ngeneral ideas to keep in mind:\\n•You’re always in a module in Python. There’s no way to write code that doesn’t\\nlive in some module. In fact, code typed at the interactive prompt really goes in a\\nbuilt-in module called __main__; the only unique things about the interactive\\nprompt are that code runs and is discarded immediately, and expression results\\nare printed automatically.\\n•Minimize module coupling: global variables . Like functions, modules work\\nbest if they’re written to be closed boxes. As a rule of thumb, they should be as\\nindependent of global variables used within other modules as possible, except for\\nfunctions and classes imported from them.\\n•Maximize module cohesion: unified purpose . You can minimize a module’s\\ncouplings by maximizing its cohesion; if all the components of a module share a\\ngeneral purpose, you’re less likely to depend on external names.\\n•Modules should rarely change other modules’ variables . We illustrated this\\nwith code in Chapter 17, but it’s worth repeating here: it’s perfectly OK to use\\nglobals defined in another module (that’s how clients import services, after all),\\nbut changing globals in another module is often a symptom of a design problem.\\nThere are exceptions, of course, but you should try to communicate results through\\ndevices such as function arguments and return values, not cross-module changes.\\nOtherwise, your globals’ values become dependent on the order of arbitrarily re-\\nmote assignments in other files, and your modules become harder to understand\\nand reuse.\\nAs a summary, Figure 24-1  sketches the environment in which modules operate. Mod-\\nules contain variables, functions, classes, and other modules (if imported). Functions\\nhave local variables of their own, as do classes—i.e., objects that live within modules,\\nwhich we’ll meet next in Chapter 25.\\n598 | Chapter 24: \\u2002Advanced Module Topics', metadata={'source': 'python.pdf', 'page': 648}),\n",
       " Document(page_content='Module Gotchas\\nIn this section, \\nwe’ll take a look at the usual collection of boundary cases that make life\\ninteresting for Python beginners. Some are so obscure that it was hard to come up with\\nexamples, but most illustrate something important about the language.\\nStatement Order Matters in Top-Level Code\\nWhen a module is first imported (or reloaded), Python executes its statements one by\\none, from the top of the file to the bottom. This has a few subtle implications regarding\\nforward references that are worth underscoring here:\\n• Code at the top level of a module file (not nested in a function) runs as soon as\\nPython reaches it during an import; because of that, it can’t reference names as-\\nsigned lower in the file.\\n• Code inside a function body doesn’t run until the function is called; because names\\nin a function aren’t resolved until the function actually runs, they can usually ref-\\nerence names anywhere in the file.\\nGenerally, forward references are only a concern in top-level module code that executes\\nimmediately; functions can reference names arbitrarily. Here’s an example that illus-\\ntrates forward reference:\\nFigure 24-1. Module execution environment. Modules are imported, but modules also import and use\\nother modules, which \\nmay be coded in Python or another language such as C. Modules in turn contain\\nvariables, functions, and classes to do their work, and their functions and classes may contain variables\\nand other items of their own. At the top, though, programs are just sets of modules.\\nModule Gotchas | 599', metadata={'source': 'python.pdf', 'page': 649}),\n",
       " Document(page_content='func1()                           # Error: \"func1\" not yet assigned\\ndef func1():\\n    print(func2())                # Okay: \"func2\" looked up later\\nfunc1()                           # Error: \"func2\" not yet assigned\\ndef func2():\\n    return \"Hello\"\\nfunc1()                           # Okay: \"func1\" and \"func2\" assigned\\nWhen this file \\nis imported (or run as a standalone program), Python executes its state-\\nments from top to bottom. The first call to func1 fails because the func1 def hasn’t run\\nyet. The call to func2 inside func1 works as long as func2’s def has been reached by the\\ntime func1 is called (it hasn’t when the second top-level func1 call is run). The last call\\nto func1 at the bottom of the file works because func1 and func2 have both been\\nassigned.\\nMixing defs with top-level code is not only hard to read, it’s dependent on statement\\nordering. As a rule of thumb, if you need to mix immediate code with defs, put your\\ndefs at the top of the file and your top-level code at the bottom. That way, your functions\\nare guaranteed to be defined and assigned by the time code that uses them runs.\\nfrom Copies Names but Doesn’t Link\\nAlthough it’s commonly used, the from statement is the source of a variety of potential\\ngotchas in Python. The from statement is really an assignment to names in the importer’s\\nscope—a name-copy operation, not a name aliasing. The implications of this are the\\nsame as for all assignments in Python, but they’re subtle, especially given that the code\\nthat shares the objects lives in different files. For instance, suppose we define the fol-\\nlowing module, nested1.py:\\n# nested1.py\\nX = 99\\ndef printer(): print(X)\\nIf we import its two names using from in another module, nested2.py, we get copies of\\nthose names, not links to them. Changing a name in the importer resets only the binding\\nof the local version of that name, not the name in nested1.py:\\n# nested2.py\\nfrom nested1 import X, printer    # Copy names out\\nX = 88                            # Changes my \"X\" only!\\nprinter()                         # nested1\\'s X is still 99\\n% python nested2.py\\n99\\n600 | Chapter 24: \\u2002Advanced Module Topics', metadata={'source': 'python.pdf', 'page': 650}),\n",
       " Document(page_content=\"If we use import to get the whole module and then assign to a qualified name, however,\\nwe change the name in nested1.py. Qualification directs Python to a name in the module\\nobject, rather than a name in the importer, nested3.py:\\n# nested3.py\\nimport nested1                    # Get module as a whole\\nnested1.X = 88                    # OK: change nested1's X\\nnested1.printer()\\n% python nested3.py\\n88\\nfrom * Can Obscure the Meaning of Variables\\nI mentioned this earlier but saved the details for here. Because you don’t list the vari-\\nables you want when using the from module import * statement form, it can accidentally\\noverwrite names you’re already using in your scope. Worse, it can make it difficult to\\ndetermine where a variable comes from. This is especially true if the from * form is used\\non more than one imported file.\\nFor example, if you use from *  on three modules, you’ll have no way of knowing what\\na raw function call really means, short of searching all three external module files (all\\nof which may be in other directories):\\n>>> from module1 import *          # Bad: may overwrite my names silently\\n>>> from module2 import *          # Worse: no way to tell what we get!\\n>>> from module3 import *\\n>>> . . .\\n>>> func()                         # Huh???\\nThe solution again is not to do this: try to explicitly list the attributes you want in your\\nfrom statements, and restrict the from *  form to at most one imported module per file.\\nThat way, any undefined names must by deduction be in the module named in the\\nsingle from *. You can avoid the issue altogether if you always use import instead of\\nfrom, but that advice is too harsh; like much else in programming, from is a convenient\\ntool if used wisely. Even this example isn’t an absolute evil—it’s OK for a program to\\nuse this technique to collect names in a single space for convenience, as long as it’s well\\nknown.\\nreload May Not Impact from Imports\\nHere’s another from-related gotcha: as discussed previously, because from copies (as-\\nsigns) names when run, there’s no link back to the modules where the names came\\nfrom. Names imported with from simply become references to objects, which happen\\nto have been referenced by the same names in the importee when the from ran.\\nModule Gotchas | 601\", metadata={'source': 'python.pdf', 'page': 651}),\n",
       " Document(page_content='Because of this behavior, reloading the importee has no effect on clients that import its\\nnames using from. \\nThat is, the client’s names will still reference the original objects\\nfetched with from, even if the names in the original module are later reset:\\nfrom module import X          # X may not reflect any module reloads!\\n . . .\\nfrom imp import reload\\nreload(module)                # Changes module, but not my names\\nX                             # Still references old object\\nTo make reloads more effective, use import and name qualification instead of from.\\nBecause qualifications always go back to the module, they will find the new bindings\\nof module names after reloading:\\nimport module                 # Get module, not names\\n . . .\\nfrom imp import reload\\nreload(module)                # Changes module in-place\\nmodule.X                      # Get current X: reflects module reloads\\nreload, from, and Interactive Testing\\nIn fact, the prior gotcha is even more subtle than it appears. Chapter 3  warned that it’s\\nusually better not to launch programs with imports and reloads because of the com-\\nplexities involved. Things get even worse when from is brought into the mix. Python\\nbeginners often stumble onto its issues in scenarios like the one outlined next. Say that\\nafter opening a module file in a text edit window, you launch an interactive session to\\nload and test your module with from:\\nfrom module import function\\nfunction(1, 2, 3)\\nFinding a bug, you jump back to the edit window, make a change, and try to reload\\nthe module this way:\\nfrom imp import reload\\nreload(module)\\nThis doesn’t work, because the from statement assigned the name function, not\\nmodule. To refer to the module in a reload, you have to first load it with an import\\nstatement at least once:\\nfrom imp import reload\\nimport module\\nreload(module)\\nfunction(1, 2, 3)\\nHowever, this doesn’t quite work either— reload updates the module object, but as\\ndiscussed in the preceding section, names like function that were copied out of the\\nmodule in the past still refer to the old objects  (in this instance, the original version of\\nthe function). To really get the new function, you must refer to it as module.function\\nafter the reload, or rerun the from:\\n602 | Chapter 24: \\u2002Advanced Module Topics', metadata={'source': 'python.pdf', 'page': 652}),\n",
       " Document(page_content='from imp import reload\\nimport module\\nreload(module)\\nfrom module import function        # Or give up and use module.function()\\nfunction(1, 2, 3)\\nNow, the new version of the function will finally run.\\nAs you can \\nsee, there are problems inherent in using reload with from: not only do you\\nhave to remember to reload after imports, but you also have to remember to rerun your\\nfrom statements after reloads. This is complex enough to trip up even an expert once\\nin a while. (In fact, the situation has gotten even worse in Python 3.0, because you must\\nalso remember to import reload itself!)\\nThe short story is that you should not expect reload and from to play together nicely.\\nThe best policy is not to combine them at all—use reload with import, or launch your\\nprograms other ways, as suggested in Chapter 3 : using the Run →Run Module menu\\noption in IDLE, file icon clicks, system command lines, or the exec built-in function.\\nRecursive from Imports May Not Work\\nI saved the most bizarre (and, thankfully, obscure) gotcha for last. Because imports\\nexecute a file’s statements from top to bottom, you need to be careful when using\\nmodules that import each other (known as recursive imports ). Because the statements\\nin a module may not all have been run when it imports another module, some of its\\nnames may not yet exist.\\nIf you use import to fetch the module as a whole, this may or may not matter; the\\nmodule’s names won’t be accessed until you later use qualification to fetch their values.\\nBut if you use from to fetch specific names, you must bear in mind that you will only\\nhave access to names in that module that have already been assigned.\\nFor instance, take the following modules, recur1 and recur2. recur1 assigns a name X,\\nand then imports recur2 before assigning the name Y. At this point, recur2 can fetch\\nrecur1 as a whole with an import (it already exists in Python’s internal modules table),\\nbut if it uses from, it will be able to see only the name X; the name Y, which is assigned\\nbelow the import in recur1, doesn’t yet exist, so you get an error:\\n# recur1.py\\nX = 1\\nimport recur2                             # Run recur2 now if it doesn\\'t exist\\nY = 2\\n# recur2.py\\nfrom recur1 import X                      # OK: \"X\" already assigned\\nfrom recur1 import Y                      # Error: \"Y\" not yet assigned\\nC:\\\\misc> C:\\\\Python30\\\\python\\n>>> import recur1\\nTraceback (most recent call last):\\n  File \"<stdin>\", line 1, in <module>\\nModule Gotchas | 603', metadata={'source': 'python.pdf', 'page': 653}),\n",
       " Document(page_content='  File \"recur1.py\", line 2, in <module>\\n    import recur2\\n  File \"recur2.py\", line 2, in <module>\\n    from recur1 import Y\\nImportError: cannot import name Y\\nPython avoids rerunning recur1\\n’s statements when they are imported recursively from\\nrecur2 (otherwise the imports would send the script into an infinite loop), but\\nrecur1’s namespace is incomplete when it’s imported by recur2.\\nThe solution? Don’t use from in recursive imports (no, really!). Python won’t get stuck\\nin a cycle if you do, but your programs will once again be dependent on the order of\\nthe statements in the modules.\\nThere are two ways out of this gotcha:\\n• You can usually eliminate import cycles like this by careful design—maximizing\\ncohesion and minimizing coupling are good first steps.\\n• If you can’t break the cycles completely, postpone module name accesses by using\\nimport and qualification (instead of from), or by running your froms either inside\\nfunctions (instead of at the top level of the module), or near the bottom of your\\nfile to defer their execution.\\nChapter Summary\\nThis chapter surveyed some more advanced module-related concepts. We studied data\\nhiding techniques, enabling new language features with the __future__ module, the\\n__name__ usage mode variable, transitive reloads, importing by name strings, and more.\\nWe also explored and summarized module design issues and looked at common mis-\\ntakes related to modules to help you avoid them in your code.\\nThe next chapter begins our look at Python’s object-oriented programming tool, the\\nclass. Much of what we’ve covered in the last few chapters will apply there, too—classes\\nlive in modules and are namespaces as well, but they add an extra component to at-\\ntribute lookup called inheritance search . As this is the last chapter in this part of the\\nbook, however, before we dive into that topic, be sure to work through this part’s set\\nof lab exercises. And before that, here is this chapter’s quiz to review the topics covered \\nhere.\\nTest Your Knowledge: Quiz\\n1. What is significant \\nabout variables at the top level of a module whose names begin\\nwith a single underscore?\\n2. What does it mean when a module’s __name__ variable is the string \"__main__\"?\\n604 | Chapter 24: \\u2002Advanced Module Topics', metadata={'source': 'python.pdf', 'page': 654}),\n",
       " Document(page_content='3. If the user interactively types the name of a module to test, how can you import it?\\n4. How \\nis changing sys.path different from setting PYTHONPATH to modify the module\\nsearch path?\\n5. If the module __future__ allows us to import from the future, can we also import\\nfrom the past?\\nTest Your Knowledge: Answers\\n1. Variables at the top level of a module whose names begin with a single underscore\\nare not copied out to the importing scope when the from * statement form is used.\\nThey can still be accessed by an import or the normal from statement form, though.\\n2. If a module’s __name__ variable is the string \"__main__\", it means that the file is\\nbeing executed as a top-level script instead of being imported from another file in\\nthe program. That is, the file is being used as a program, not a library.\\n3. User input usually comes into a script as a string; to import the referenced module\\ngiven its string name, you can build and run an import statement with exec, or pass\\nthe string name in a call to the __import__ function.\\n4. Changing sys.path only affects one running program, and is temporary—the\\nchange goes away when the program ends. PYTHONPATH settings live in the operating\\nsystem—they are picked up globally by all programs on a machine, and changes\\nto these settings endure after programs exit.\\n5. No, we can’t import from the past in Python. We can install (or stubbornly use)\\nan older version of the language, but the latest Python is generally the best Python.\\nTest Your Knowledge: Part V Exercises\\nSee “Part V, Modules” on page 1119 in Appendix B for the solutions.\\n1.Import basics . Write a program that counts the lines and characters in a file (similar\\nin spirit to wc on Unix). With your text editor, code a Python module called\\nmymod.py that exports three top-level names:\\n• A countLines(name) function that reads an input file and counts the number of\\nlines in it (hint: file.readlines does most of the work for you, and len does the\\nrest).\\n• A countChars(name) function that reads an input file and counts the number of\\ncharacters in it (hint: file.read returns a single string).\\n• A test(name) function that calls both counting functions with a given input\\nfilename. Such a filename generally might be passed in, hardcoded, input with\\nthe input built-in function, or pulled from a command line via the sys.argv list\\nshown in this chapter’s formats.py example; for now, you can assume it’s a\\npassed-in function argument.\\nTest Your Knowledge: Part V Exercises | 605', metadata={'source': 'python.pdf', 'page': 655}),\n",
       " Document(page_content='All three mymod functions should expect a filename string to be passed in. If you\\ntype more than two or three lines per function, you’re working much too hard—\\nuse the hints I just gave!\\nNext, test your module interactively, using import and attribute references to fetch\\nyour exports. Does your PYTHONPATH need to include the directory where you created\\nmymod.py? Try running your module on itself: e.g., test(\"mymod.py\"). Note that\\ntest opens the file twice; if you’re feeling ambitious, you may be able to improve\\nthis by passing an open file object into the two count functions (hint:\\nfile.seek(0) is a file rewind).\\n2.from/from *. Test your mymod module from exercise 1 interactively by using from to\\nload the exports directly, first by name, then using the from * variant to fetch\\neverything.\\n3.__main__. Add a line in your mymod module that calls the test function automati-\\ncally only when the module is run as a script, not when it is imported. The line you\\nadd will probably test the value of __name__ for the string \"__main__\", as shown in\\nthis chapter. Try running your module from the system command line; then, im-\\nport the module and test its functions interactively. Does it still work in both\\nmodes?\\n4.Nested imports . Write a second module, myclient.py, that imports mymod and tests\\nits functions; then run myclient from the system command line. If myclient uses\\nfrom to fetch from mymod, will mymod’s functions be accessible from the top level of\\nmyclient? What if it imports with import instead? Try coding both variations in\\nmyclient and test interactively by importing myclient and inspecting its __dict__\\nattribute.\\n5.Package imports . Import your file from a package. Create a subdirectory called\\nmypkg nested in a directory on your module import search path, move the\\nmymod.py module file you created in exercise 1 or 3 into the new directory, and\\ntry to import it with a package import of the form import mypkg.mymod.\\nYou’ll need to add an __init__.py file in the directory your module was moved to\\nmake this go, but it should work on all major Python platforms (that’s part of the\\nreason Python uses “.” as a path separator). The package directory you create can\\nbe simply a subdirectory of the one you’re working in; if it is, it will be found via\\nthe home directory component of the search path, and you won’t have to configure\\nyour path. Add some code to your __init__.py, and see if it runs on each import.\\n6.Reloads. Experiment with module reloads: perform the tests in Chapter 22 ’s\\nchanger.py example, changing the called function’s message and/or behavior re-\\npeatedly, without stopping the Python interpreter. Depending on your system, you\\nmight be able to edit changer in another window, or suspend the Python interpreter\\nand edit in the same window (on Unix, a Ctrl-Z key combination usually suspends\\nthe current process, and an fg command later resumes it).\\n606 | Chapter 24: \\u2002Advanced Module Topics', metadata={'source': 'python.pdf', 'page': 656}),\n",
       " Document(page_content='7.Circular imports.‡ In the section on recursive import gotchas, importing recur1\\nraised an error. But if you restart Python and import recur2 interactively, the error\\ndoesn’t occur—test this and see for yourself. Why do you think it works to import\\nrecur2, but not recur1? (Hint: Python stores new modules in the built-in\\nsys.modules table—a dictionary—before running their code; later imports fetch\\nthe module from this table first, whether the module is “complete” yet or not.)\\nNow, try running recur1 as a top-level script file: python recur1.py. Do you get the\\nsame error that occurs when recur1 is imported interactively? Why? (Hint: when\\nmodules are run as programs, they aren’t imported, so this case has the same effect\\nas importing recur2 interactively; recur2 is the first module imported.) What hap-\\npens when you run recur2 as a script?\\n‡ Note that circular imports are extremely rare in practice. On the other hand, if you can understand why they\\nare a potential problem, you know a lot about Python’s import semantics.\\nTest Your Knowledge: Part V Exercises | 607', metadata={'source': 'python.pdf', 'page': 657}),\n",
       " Document(page_content='', metadata={'source': 'python.pdf', 'page': 658}),\n",
       " Document(page_content='PART VI\\nClasses and OOP', metadata={'source': 'python.pdf', 'page': 659}),\n",
       " Document(page_content='', metadata={'source': 'python.pdf', 'page': 660}),\n",
       " Document(page_content='CHAPTER 25\\nOOP: The Big Picture\\nSo far in this book, we’ve been using the term “object” generically. Really, the code\\nwritten up to \\nthis point has been object-based—we’ve passed objects around our scripts,\\nused them in expressions, called their methods, and so on. For our code to qualify as\\nbeing truly object-oriented (OO), though, our objects will generally need to also par-\\nticipate in something called an inheritance hierarchy.\\nThis chapter begins our exploration of the Python class—a device used to implement\\nnew kinds of objects in Python that support inheritance. Classes are Python’s main\\nobject-oriented programming (OOP) tool, so we’ll also look at OOP basics along the\\nway in this part of the book. OOP offers a different and often more effective way of\\nlooking at programming, in which we factor code to minimize redundancy, and write\\nnew programs by customizing existing code instead of changing it in-place.\\nIn Python, classes are created with a new statement: the class statement. As you’ll see,\\nthe objects defined with classes can look a lot like the built-in types we studied earlier\\nin the book. In fact, classes really just apply and extend the ideas we’ve already covered;\\nroughly, they are packages of functions that use and process built-in object types.\\nClasses, though, are designed to create and manage new objects, and they also support\\ninheritance—a mechanism of code customization and reuse above and beyond any-\\nthing we’ve seen so far.\\nOne note up front: in Python, OOP is entirely optional, and you don’t need to use\\nclasses just to get started. In fact, you can get plenty of work done with simpler con-\\nstructs such as functions, or even simple top-level script code. Because using classes\\nwell requires some up-front planning, they tend to be of more interest to people who\\nwork in strategic mode (doing long-term product development) than to people who\\nwork in tactical mode (where time is in very short supply).\\nStill, as you’ll see in this part of the book, classes turn out to be one of the most useful\\ntools Python provides. When used well, classes can actually cut development time\\nradically. They’re also employed in popular Python tools like the tkinter GUI API, so\\nmost Python programmers will usually find at least a working knowledge of class basics\\nhelpful.\\n611', metadata={'source': 'python.pdf', 'page': 661}),\n",
       " Document(page_content='Why Use Classes?\\nRemember when I \\ntold you that programs “do things with stuff”? In simple terms,\\nclasses are just a way to define new sorts of stuff, reflecting real objects in a program’s\\ndomain. For instance, suppose we decide to implement that hypothetical pizza-making\\nrobot we used as an example in Chapter 16 . If we implement it using classes, we can\\nmodel more of its real-world structure and relationships. Two aspects of OOP prove\\nuseful here:\\nInheritance\\nPizza-making robots are kinds of robots, so they possess the usual robot-y prop-\\nerties. In OOP terms, we say they “inherit” properties from the general category\\nof all robots. These common properties need to be implemented only once for the\\ngeneral case and can be reused by all types of robots we may build in the future.\\nComposition\\nPizza-making robots are really collections of components that work together as a\\nteam. For instance, for our robot to be successful, it might need arms to roll dough,\\nmotors to maneuver to the oven, and so on. In OOP parlance, our robot is an\\nexample of composition; it contains other objects that it activates to do its bidding.\\nEach component might be coded as a class, which defines its own behavior and\\nrelationships.\\nGeneral OOP ideas like inheritance and composition apply to any application that can\\nbe decomposed into a set of objects. For example, in typical GUI systems, interfaces\\nare written as collections of widgets—buttons, labels, and so on—which are all drawn\\nwhen their container is drawn ( composition). Moreover, we may be able to write our\\nown custom widgets—buttons with unique fonts, labels with new color schemes, and\\nthe like—which are specialized versions of more general interface devices ( inheritance).\\nFrom a more concrete programming perspective, classes are Python program units, just\\nlike functions and modules: they are another compartment for packaging logic and\\ndata. In fact, classes also define new namespaces, much like modules. But, compared\\nto other program units we’ve already seen, classes have three critical distinctions that\\nmake them more useful when it comes to building new objects:\\nMultiple instances\\nClasses are essentially factories for generating one or more objects. Every time we\\ncall a class, we generate a new object with a distinct namespace. Each object gen-\\nerated from a class has access to the class’s attributes and gets a namespace of its\\nown for data that varies per object.\\nCustomization via inheritance\\nClasses also support the OOP notion of inheritance; we can extend a class by re-\\ndefining its attributes outside the class itself. More generally, classes can build up\\nnamespace hierarchies, which define names to be used by objects created from\\nclasses in the hierarchy.\\n612 | Chapter 25: \\u2002OOP: The Big Picture', metadata={'source': 'python.pdf', 'page': 662}),\n",
       " Document(page_content='Operator overloading\\nBy providing special protocol methods, classes can define objects that respond to\\nthe sorts \\nof operations we saw at work on built-in types. For instance, objects made\\nwith classes can be sliced, concatenated, indexed, and so on. Python provides\\nhooks that classes can use to intercept and implement any built-in type operation.\\nOOP from 30,000 Feet\\nBefore we see what this all means in terms of code, I’d like to say a few words about\\nthe general ideas behind OOP. If you’ve never done anything object-oriented in your\\nlife before now, some of the terminology in this chapter may seem a bit perplexing on\\nthe first pass. Moreover, the motivation for these terms may be elusive until you’ve had\\na chance to study the ways that programmers apply them in larger systems. OOP is as\\nmuch an experience as a technology.\\nAttribute Inheritance Search\\nThe good news is that OOP is much simpler to understand and use in Python than in\\nother languages, such as C++ or Java. As a dynamically typed scripting language, Py-\\nthon removes much of the syntactic clutter and complexity that clouds OOP in other\\ntools. In fact, most of the OOP story in Python boils down to this expression:\\nobject.attribute\\nWe’ve been using this expression throughout the book to access module attributes, call\\nmethods of objects, and so on. When we say this to an object that is derived from a\\nclass statement, however, the expression kicks off a search in Python—it searches a\\ntree of linked objects, looking for the first appearance of attribute that it can find.\\nWhen classes are involved, the preceding Python expression effectively translates to\\nthe following in natural language:\\nFind the first occurrence of attribute by looking in object, then in all classes above it,\\nfrom bottom to top and left to right.\\nIn other words, attribute fetches are simply tree searches. The term inheritance is ap-\\nplied because objects lower in a tree inherit attributes attached to objects higher in that\\ntree. As the search proceeds from the bottom up, in a sense, the objects linked into a\\ntree are the union of all the attributes defined in all their tree parents, all the way up\\nthe tree.\\nIn Python, this is all very literal: we really do build up trees of linked objects with code,\\nand Python really does climb this tree at runtime searching for attributes every time we\\nuse the object.attribute expression. To make this more concrete, Figure 25-1 sketches\\nan example of one of these trees.\\nIn this figure, there is a tree of five objects labeled with variables, all of which have\\nattached attributes, ready to be searched. More specifically, this tree links together three\\nOOP from 30,000 Feet | 613', metadata={'source': 'python.pdf', 'page': 663}),\n",
       " Document(page_content='class objects (the ovals C1 , C2, and C3) and two instance objects (the rectangles I1 and\\nI2) into an inheritance search tree. Notice that in the Python object model, classes and\\nthe instances you generate from them are two distinct object types:\\nClasses\\nServe as instance factories. Their attributes provide behavior—data and\\nfunctions—that is inherited by all the instances generated from them (e.g., a func-\\ntion to compute an employee’s salary from pay and hours).\\nInstances\\nRepresent the concrete items in a program’s domain. Their attributes record data\\nthat varies per specific object (e.g., an employee’s Social Security number).\\nIn terms of search trees, an instance inherits attributes from its class, and a class inherits\\nattributes from all classes above it in the tree.\\nIn Figure 25-1, we can further categorize the ovals by their relative positions in the tree.\\nWe usually call classes higher in the tree (like C2 and C3) superclasses; classes lower in\\nthe tree (like C1) are known as subclasses.* These terms refer to relative tree positions\\nand roles. Superclasses provide behavior shared by all their subclasses, but because the\\nsearch proceeds from the bottom up, subclasses may override behavior defined in their\\nsuperclasses by redefining superclass names lower in the tree.\\nAs these last few words are really the crux of the matter of software customization in\\nOOP, let’s expand on this concept. Suppose we build up the tree in Figure 25-1 , and\\nthen say this:\\nI2.w\\nFigure 25-1. A class tree, with two instances at the bottom (I1 and I2), a class above them (C1), and\\ntwo superclasses at \\nthe top (C2 and C3). All of these objects are namespaces (packages of variables),\\nand the inheritance search is simply a search of the tree from bottom to top looking for the lowest\\noccurrence of an attribute name. Code implies the shape of such trees.\\n* In other literature, you may also occasionally see the terms base classes  and derived classes  used to describe\\nsuperclasses and subclasses, respectively.\\n614 | Chapter 25: \\u2002OOP: The Big Picture', metadata={'source': 'python.pdf', 'page': 664}),\n",
       " Document(page_content='Right away, this code invokes inheritance. Because this is an object.attribute expres-\\nsion, it triggers \\na search of the tree in Figure 25-1 —Python will search for the attribute\\nw by looking in I2 and above. Specifically, it will search the linked objects in this order:\\nI2, C1, C2, C3\\nand stop at the first attached w it finds (or raise an error if w isn’t found at all). In this\\ncase, w won’t be found until C3 is searched because it appears only in that object. In\\nother words, I2.w resolves to C3.w by virtue of the automatic search. In OOP termi-\\nnology, I2 “inherits” the attribute w from C3.\\nUltimately, the two instances inherit four attributes from their classes: w, x, y, and z.\\nOther attribute references will wind up following different paths in the tree. For\\nexample:\\n•I1.x and I2.x both find x in C1 and stop because C1 is lower than C2.\\n•I1.y and I2.y both find y in C1 because that’s the only place y appears.\\n•I1.z and I2.z both find z in C2 because C2 is further to the left than C3.\\n•I2.name finds name in I2 without climbing the tree at all.\\nTrace these searches through the tree in Figure 25-1 to get a feel for how inheritance\\nsearches work in Python.\\nThe first item in the preceding list is perhaps the most important to notice—because\\nC1 redefines the attribute x lower in the tree, it effectively replaces the version above it\\nin C2. As you’ll see in a moment, such redefinitions are at the heart of software cus-\\ntomization in OOP—by redefining and replacing the attribute, C1 effectively customizes\\nwhat it inherits from its superclasses.\\nClasses and Instances\\nAlthough they are technically two separate object types in the Python model, the classes\\nand instances we put in these trees are almost identical—each type’s main purpose is\\nto serve as another kind of namespace—a package of variables, and a place where we\\ncan attach attributes. If classes and instances therefore sound like modules, they should;\\nhowever, the objects in class trees also have automatically searched links to other\\nnamespace objects, and classes correspond to statements, not entire files.\\nThe primary difference between classes and instances is that classes are a kind of fac-\\ntory for generating instances. For example, in a realistic application, we might have an\\nEmployee class that defines what it means to be an employee; from that class, we generate\\nactual Employee instances. This is another difference between classes and modules: we\\nonly ever have one instance of a given module in memory (that’s why we have to reload\\na module to get its new code), but with classes, we can make as many instances as we\\nneed.\\nOOP from 30,000 Feet | 615', metadata={'source': 'python.pdf', 'page': 665}),\n",
       " Document(page_content='Operationally, classes will usually have functions attached to them (e.g.,\\ncomputeSalary), and the \\ninstances will have more basic data items used by the class’\\nfunctions (e.g., hoursWorked). In fact, the object-oriented model is not that different\\nfrom the classic data-processing model of programs plus records; in OOP, instances are\\nlike records with “data,” and classes are the “programs” for processing those records.\\nIn OOP, though, we also have the notion of an inheritance hierarchy, which supports\\nsoftware customization better than earlier models.\\nClass Method Calls\\nIn the prior section, we saw how the attribute reference I2.w in our example class tree\\nwas translated to C3.w by the inheritance search procedure in Python. Perhaps just as\\nimportant to understand as the inheritance of attributes, though, is what happens when\\nwe try to call methods (i.e., functions attached to classes as attributes).\\nIf this I2.w reference is a function call, what it really means is “call the C3.w function to\\nprocess I2.” That is, Python will automatically map the call I2.w() into the call\\nC3.w(I2), passing in the instance as the first argument to the inherited function.\\nIn fact, whenever we call a function attached to a class in this fashion, an instance of\\nthe class is always implied. This implied subject or context is part of the reason we refer\\nto this as an object-oriented model—there is always a subject object when an operation\\nis run. In a more realistic example, we might invoke a method called giveRaise attached\\nas an attribute to an Employee class; such a call has no meaning unless qualified with\\nthe employee to whom the raise should be given.\\nAs we’ll see later, Python passes in the implied instance to a special first argument\\nin the method, called self by convention. As we’ll also learn, methods can be\\ncalled through either an instance (e.g., bob.giveRaise()) or a class (e.g.,\\nEmployee.giveRaise(bob)), and both forms serve purposes in our scripts. To see how\\nmethods receive their subjects, though, we need to move on to some code.\\nCoding Class Trees\\nAlthough we are speaking in the abstract here, there is tangible code behind all these\\nideas. We construct trees, and their objects with class statements and class calls, which\\nwe’ll meet in more detail later. In short:\\n• Each class statement generates a new class object.\\n• Each time a class is called, it generates a new instance object.\\n• Instances are automatically linked to the classes from which they are created.\\n• Classes are linked to their superclasses by listing them in parentheses in a class\\nheader line; the left-to-right order there gives the order in the tree.\\n616 | Chapter 25: \\u2002OOP: The Big Picture', metadata={'source': 'python.pdf', 'page': 666}),\n",
       " Document(page_content=\"To build the tree in Figure 25-1 , for example, we would run Python code of this form\\n(I’ve omitted the guts of the class statements here):\\nclass C2: ...                      # Make class objects (ovals)\\nclass C3: ...\\nclass C1(C2, C3): ...              # Linked to superclasses\\nI1 = C1()                          # Make instance objects (rectangles)\\nI2 = C1()                          # Linked to their classes\\nHere, we build the three class objects by running three class statements, and make the\\ntwo instance objects by calling the class C1 twice, as though it were a function. The\\ninstances remember the class they were made from, and the class C1 remembers its listed\\nsuperclasses.\\nTechnically, this example is using something called multiple inheritance , which simply\\nmeans that a class has more than one superclass above it in the class tree. In Python, if\\nthere is more than one superclass listed in parentheses in a class statement (like C1’s\\nhere), their left-to-right order gives the order in which those superclasses will be\\nsearched for attributes.\\nBecause of the way inheritance searches proceed, the object to which you attach an\\nattribute turns out to be crucial—it determines the name’s scope. Attributes attached\\nto instances pertain only to those single instances, but attributes attached to classes are\\nshared by all their subclasses and instances. Later, we’ll study the code that hangs\\nattributes on these objects in depth. As we’ll find:\\n• Attributes are usually attached to classes by assignments made within class state-\\nments, and not nested inside function def statements.\\n• Attributes are usually attached to instances by assignments to a special argument\\npassed to functions inside classes, called self.\\nFor example, classes provide behavior for their instances with functions created by\\ncoding def statements inside class statements. Because such nested defs assign names\\nwithin the class, they wind up attaching attributes to the class object that will be in-\\nherited by all instances and subclasses:\\nclass C1(C2, C3):                # Make and link class C1\\n    def setname(self, who):      # Assign name: C1.setname\\n        self.name = who          # Self is either I1 or I2\\nI1 = C1()                        # Make two instances\\nI2 = C1()\\nI1.setname('bob')                # Sets I1.name to 'bob'\\nI2.setname('mel')                # Sets I2.name to 'mel'\\nprint(I1.name)                   # Prints 'bob'\\nOOP from 30,000 Feet | 617\", metadata={'source': 'python.pdf', 'page': 667}),\n",
       " Document(page_content=\"There’s nothing syntactically unique about def in this context. Operationally, when a\\ndef appears inside \\na class like this, it is usually known as a method, and it automatically\\nreceives a special first argument—called self by convention—that provides a handle\\nback to the instance to be processed.†\\nBecause classes are factories for multiple instances, their methods usually go through\\nthis automatically passed-in self argument whenever they need to fetch or set attributes\\nof the particular instance being processed by a method call. In the preceding code,\\nself is used to store a name in one of two instances.\\nLike simple variables, attributes of classes and instances are not declared ahead of time,\\nbut spring into existence the first time they are assigned values. When a method assigns\\nto a self attribute, it creates or changes an attribute in an instance at the bottom of the\\nclass tree (i.e., one of the rectangles) because self automatically refers to the instance\\nbeing processed.\\nIn fact, because all the objects in class trees are just namespace objects, we can fetch or\\nset any of their attributes by going through the appropriate names. Saying C1.setname\\nis as valid as saying I1.setname, as long as the names C1 and I1 are in your code’s scopes.\\nAs currently coded, our C1 class doesn’t attach a name attribute to an instance until the\\nsetname method is called. In fact, referencing I1.name before calling I1.setname would\\nproduce an undefined name error. If a class wants to guarantee that an attribute like\\nname is always set in its instances, it more typically will fill out the attribute at con-\\nstruction time, like this:\\nclass C1(C2, C3):\\n    def __init__(self, who):     # Set name when constructed\\n        self.name = who          # Self is either I1 or I2\\nI1 = C1('bob')                   # Sets I1.name to 'bob'\\nI2 = C1('mel')                   # Sets I2.name to 'mel'\\nprint(I1.name)                   # Prints 'bob'\\nIf it’s coded and inherited, Python automatically calls a method named __init__ each\\ntime an instance is generated from a class. The new instance is passed in to the self\\nargument of __init__ as usual, and any values listed in parentheses in the class call go\\nto arguments two and beyond. The effect here is to initialize instances when they are\\nmade, without requiring extra method calls.\\nThe __init__ method is known as the constructor because of when it is run. It’s the\\nmost commonly used representative of a larger class of methods called operator over-\\nloading methods , which we’ll discuss in more detail in the chapters that follow. Such\\nmethods are inherited in class trees as usual and have double underscores at the start\\nand end of their names to make them distinct. Python runs them automatically when\\ninstances that support them appear in the corresponding operations, and they are\\n† If you’ve ever used C++ or Java, you’ll recognize that Python’s self is the same as the this pointer, but\\nself is always explicit in Python to make attribute accesses more obvious.\\n618 | Chapter 25: \\u2002OOP: The Big Picture\", metadata={'source': 'python.pdf', 'page': 668}),\n",
       " Document(page_content='mostly an alternative to using simple method calls. They’re also optional: if omitted,\\nthe operations are not supported.\\nFor example, to \\nimplement set intersection, a class might either provide a method\\nnamed intersect, or overload the & expression operator to dispatch to the required\\nlogic by coding a method named __and__. Because the operator scheme makes instances\\nlook and feel more like built-in types, it allows some classes to provide a consistent and\\nnatural interface, and be compatible with code that expects a built-in type.\\nOOP Is About Code Reuse\\nAnd that, along with a few syntax details, is most of the OOP story in Python. Of course,\\nthere’s a bit more to it than just inheritance. For example, operator overloading is much\\nmore general than I’ve described so far—classes may also provide their own imple-\\nmentations of operations such as indexing, fetching attributes, printing, and more. By\\nand large, though, OOP is about looking up attributes in trees.\\nSo why would we be interested in building and searching trees of objects? Although it\\ntakes some experience to see how, when used well, classes support code reuse in ways\\nthat other Python program components cannot. With classes, we code by customizing\\nexisting software, instead of either changing existing code in-place or starting from\\nscratch for each new project.\\nAt a fundamental level, classes are really just packages of functions and other names,\\nmuch like modules. However, the automatic attribute inheritance search that we get\\nwith classes supports customization of software above and beyond what we can do\\nwith modules and functions. Moreover, classes provide a natural structure for code\\nthat localizes logic and names, and so aids in debugging.\\nFor instance, because methods are simply functions with a special first argument, we\\ncan mimic some of their behavior by manually passing objects to be processed to simple\\nfunctions. The participation of methods in class inheritance, though, allows us to nat-\\nurally customize existing software by coding subclasses with new method definitions,\\nrather than changing existing code in-place. There is really no such concept with mod-\\nules and functions.\\nAs an example, suppose you’re assigned the task of implementing an employee database\\napplication. As a Python OOP programmer, you might begin by coding a general su-\\nperclass that defines default behavior common to all the kinds of employees in your\\norganization:\\nclass Employee:                      # General superclass\\n    def computeSalary(self): ...     # Common or default behavior\\n    def giveRaise(self): ...\\n    def promote(self): ...\\n    def retire(self): ...\\nOOP from 30,000 Feet | 619', metadata={'source': 'python.pdf', 'page': 669}),\n",
       " Document(page_content=\"Once you’ve coded this general behavior, you can specialize it for each specific kind of\\nemployee to reflect how the various types differ from the norm. That is, you can code\\nsubclasses that customize \\njust the bits of behavior that differ per employee type; the\\nrest of the employee types’ behavior will be inherited from the more general class. For\\nexample, if engineers have a unique salary computation rule (i.e., not hours times rate),\\nyou can replace just that one method in a subclass:\\nclass Engineer(Employee):            # Specialized subclass\\n     def computeSalary(self): ...    # Something custom here\\nBecause the computeSalary version here appears lower in the class tree, it will replace\\n(override) the general version in Employee. You then create instances of the kinds of\\nemployee classes that the real employees belong to, to get the correct behavior:\\nbob = Employee()                     # Default behavior\\nmel = Engineer()                     # Custom salary calculator\\nNotice that you can make instances of any class in a tree, not just the ones at the\\nbottom—the class you make an instance from determines the level at which the at-\\ntribute search will begin. Ultimately, these two instance objects might wind up em-\\nbedded in a larger container object (e.g., a list, or an instance of another class) that\\nrepresents a department or company using the composition idea mentioned at the start\\nof this chapter.\\nWhen you later ask for these employees’ salaries, they will be computed according to\\nthe classes from which the objects were made, due to the principles of the inheritance\\nsearch:‡\\ncompany = [bob, mel]                   # A composite object\\nfor emp in company:\\n    print(emp.computeSalary())         # Run this object's version\\nThis is yet another instance of the idea of polymorphism introduced in Chapter 4  and\\nrevisited in Chapter 16 . Recall that polymorphism means that the meaning of an op-\\neration depends on the object being operated on. Here, the method computeSalary is\\nlocated by inheritance search in each object before it is called. In other applications,\\npolymorphism might also be used to hide (i.e., encapsulate) interface differences. For\\nexample, a program that processes data streams might be coded to expect objects with\\ninput and output methods, without caring what those methods actually do:\\ndef processor(reader, converter, writer):\\n    while 1:\\n        data = reader.read()\\n        if not data: break\\n‡ Note that the company list in this example could be stored in a file with Python object pickling, introduced in\\nChapter 9  when we met files, to yield a persistent employee database. Python also comes with a module\\nnamed shelve, which would allow you to store the pickled representation of the class instances in an access-\\nby-key filesystem; the third-party open source ZODB system does the same but has better support for\\nproduction-quality object-oriented databases.\\n620 | Chapter 25: \\u2002OOP: The Big Picture\", metadata={'source': 'python.pdf', 'page': 670}),\n",
       " Document(page_content='        data = converter(data)\\n        writer.write(data)\\nBy passing in \\ninstances of subclasses that specialize the required read and write method\\ninterfaces for various data sources, we can reuse the processor function for any data\\nsource we need to use, both now and in the future:\\nclass Reader:\\n    def read(self): ...              # Default behavior and tools\\n    def other(self): ...\\nclass FileReader(Reader):\\n    def read(self): ...              # Read from a local file\\nclass SocketReader(Reader):\\n    def read(self): ...              # Read from a network socket\\n...\\nprocessor(FileReader(...),   Converter,  FileWriter(...))\\nprocessor(SocketReader(...), Converter,  TapeWriter(...))\\nprocessor(FtpReader(...),    Converter,  XmlWriter(...))\\nMoreover, because the internal implementations of those read and write methods have\\nbeen factored into single locations, they can be changed without impacting code such\\nas this that uses them. In fact, the processor function might itself be a class to allow\\nthe conversion logic of converter to be filled in by inheritance, and to allow readers\\nand writers to be embedded by composition (we’ll see how this works later in this part\\nof the book).\\nOnce you get used to programming this way (by software customization), you’ll find\\nthat when it’s time to write a new program, much of your work may already be done—\\nyour task largely becomes one of mixing together existing superclasses that already\\nimplement the behavior required by your program. For example, someone else might\\nhave written the Employee, Reader, and Writer classes in this example for use in a com-\\npletely different program. If so, you get all of that person’s code “for free.”\\nIn fact, in many application domains, you can fetch or purchase collections of super-\\nclasses, known as frameworks, that implement common programming tasks as classes,\\nready to be mixed into your applications. These frameworks might provide database\\ninterfaces, testing protocols, GUI toolkits, and so on. With frameworks, you often\\nsimply code a subclass that fills in an expected method or two; the framework classes\\nhigher in the tree do most of the work for you. Programming in such an OOP world is\\njust a matter of combining and specializing already debugged code by writing subclasses\\nof your own.\\nOf course, it takes a while to learn how to leverage classes to achieve such OOP utopia.\\nIn practice, object-oriented work also entails substantial design work to fully realize\\nthe code reuse benefits of classes—to this end, programmers have begun cataloging\\ncommon OOP structures, known as design patterns , to help with design issues. The\\nactual code you write to do OOP in Python, though, is so simple that it will not in itself\\npose an additional obstacle to your OOP quest. To see why, you’ll have to move on to\\nChapter 26.\\nOOP from 30,000 Feet | 621', metadata={'source': 'python.pdf', 'page': 671}),\n",
       " Document(page_content='Chapter Summary\\nWe took an \\nabstract look at classes and OOP in this chapter, taking in the big picture\\nbefore we dive into syntax details. As we’ve seen, OOP is mostly about looking up\\nattributes in trees of linked objects; we call this lookup an inheritance search. Objects\\nat the bottom of the tree inherit attributes from objects higher up in the tree—a feature\\nthat enables us to program by customizing code, rather than changing it, or starting\\nfrom scratch. When used well, this model of programming can cut development time\\nradically.\\nThe next chapter will begin to fill in the coding details behind the picture painted here.\\nAs we get deeper into Python classes, though, keep in mind that the OOP model in\\nPython is very simple; as I’ve already stated, it’s really just about looking up attributes\\nin object trees. Before we move on, here’s a quick quiz to review what we’ve covered\\nhere.\\nTest Your Knowledge: Quiz\\n1. What is the main point of OOP in Python?\\n2.Where does an inheritance search look for an attribute?\\n3.\\nWhat is the difference between a class object and an instance object?\\n4. Why is the first argument in a class method function special?\\n5. What is the __init__ method used for?\\n6. How do you create a class instance?\\n7. How do you create a class?\\n8. How do you specify a class’s superclasses?\\nTest Your Knowledge: Answers\\n1. OOP is about code reuse—you factor code to minimize redundancy and program\\nby customizing what already exists instead of changing code in-place or starting\\nfrom scratch.\\n2. An inheritance search looks for an attribute first in the instance object, then in the\\nclass the instance was created from, then in all higher superclasses, progressing\\nfrom the bottom to the top of the object tree, and from left to right (by default).\\nThe search stops at the first place the attribute is found. Because the lowest version\\nof a name found along the way wins, class hierarchies naturally support customi-\\nzation by extension.\\n622 | Chapter 25: \\u2002OOP: The Big Picture', metadata={'source': 'python.pdf', 'page': 672}),\n",
       " Document(page_content='3. Both class and instance objects are namespaces (packages of variables that appear\\nas attributes). \\nThe main difference between them is that classes are a kind of factory\\nfor creating multiple instances. Classes also support operator overloading meth-\\nods, which instances inherit, and treat any functions nested within them as special\\nmethods for processing instances.\\n4. The first argument in a class method function is special because it always receives\\nthe instance object that is the implied subject of the method call. It’s usually called\\nself by convention. Because method functions always have this implied subject\\nobject context by default, we say they are “object-oriented”—i.e., designed to\\nprocess or change objects.\\n5. If the __init__ method is coded or inherited in a class, Python calls it automatically\\neach time an instance of that class is created. It’s known as the constructor method;\\nit is passed the new instance implicitly, as well as any arguments passed explicitly\\nto the class name. It’s also the most commonly used operator overloading method.\\nIf no __init__ method is present, instances simply begin life as empty namespaces.\\n6. You create a class instance by calling the class name as though it were a function;\\nany arguments passed into the class name show up as arguments two and beyond\\nin the __init__ constructor method. The new instance remembers the class it was\\ncreated from for inheritance purposes.\\n7. You create a class by running a class statement; like function definitions, these\\nstatements normally run when the enclosing module file is imported (more on this\\nin the next chapter).\\n8. You specify a class’s superclasses by listing them in parentheses in the class state-\\nment, after the new class’s name. The left-to-right order in which the classes are\\nlisted in the parentheses gives the left-to-right inheritance search order in the class\\ntree.\\nTest Your Knowledge: Answers | 623', metadata={'source': 'python.pdf', 'page': 673}),\n",
       " Document(page_content='', metadata={'source': 'python.pdf', 'page': 674}),\n",
       " Document(page_content='CHAPTER 26\\nClass Coding Basics\\nNow that we’ve talked about OOP in the abstract, it’s time to see how this translates\\nto actual code. \\nThis chapter begins to fill in the syntax details behind the class model\\nin Python.\\nIf you’ve never been exposed to OOP in the past, classes can seem somewhat compli-\\ncated if taken in a single dose. To make class coding easier to absorb, we’ll begin our\\ndetailed exploration of OOP by taking a first look at some basic classes in action in this\\nchapter. We’ll expand on the details introduced here in later chapters of this part of\\nthe book, but in their basic form, Python classes are easy to understand.\\nIn fact, classes have just three primary distinctions. At a base level, they are mostly just\\nnamespaces, much like the modules we studied in Part V . Unlike modules, though,\\nclasses also have support for generating multiple objects, for namespace inheritance,\\nand for operator overloading. Let’s begin our class statement tour by exploring each\\nof these three distinctions in turn.\\nClasses Generate Multiple Instance Objects\\nTo understand how the multiple objects idea works, you have to first understand that\\nthere are two kinds of objects in Python’s OOP model: class objects and instance ob-\\njects. Class objects provide default behavior and serve as factories for instance objects.\\nInstance objects are the real objects your programs process—each is a namespace in\\nits own right, but inherits (i.e., has automatic access to) names in the class from which\\nit was created. Class objects come from statements, and instances come from calls; each\\ntime you call a class, you get a new instance of that class.\\n625', metadata={'source': 'python.pdf', 'page': 675}),\n",
       " Document(page_content='This object-generation concept is very different from any of the other program con-\\nstructs we’ve seen \\nso far in this book. In effect, classes are essentially factories for gen-\\nerating multiple instances. By contrast, only one copy of each module is ever imported\\ninto a single program (in fact, one reason that we have to call imp.reload is to update\\nthe single module object so that changes are reflected once they’ve been made).\\nThe following is a quick summary of the bare essentials of Python OOP. As you’ll see,\\nPython classes are in some ways similar to both defs and modules, but they may be\\nquite different from what you’re used to in other languages.\\nClass Objects Provide Default Behavior\\nWhen we run a class statement, we get a class object. Here’s a rundown of the main\\nproperties of Python classes:\\n•The class statement creates a class object and assigns it a name . Just like the\\nfunction def statement, the Python class statement is an executable statement.\\nWhen reached and run, it generates a new class object and assigns it to the name\\nin the class header. Also, like defs, class statements typically run when the files\\nthey are coded in are first imported.\\n•Assignments inside  class statements make class attributes . Just like in module\\nfiles, top-level assignments within a class statement (not nested in a def) generate\\nattributes in a class object. Technically, the class statement scope morphs into the\\nattribute namespace of the class object, just like a module’s global scope. After\\nrunning a class statement, class attributes are accessed by name qualification:\\nobject.name.\\n•Class attributes provide object state and behavior . Attributes of a class object\\nrecord state information and behavior to be shared by all instances created from\\nthe class; function def statements nested inside a class generate methods, which\\nprocess instances.\\nInstance Objects Are Concrete Items\\nWhen we call a class object, we get an instance object. Here’s an overview of the key\\npoints behind class instances:\\n•Calling a class object like a function makes a new instance object . Each time\\na class is called, it creates and returns a new instance object. Instances represent\\nconcrete items in your program’s domain.\\n•Each instance object inherits class attributes and gets its own namespace .\\nInstance objects created from classes are new namespaces; they start out empty\\nbut inherit attributes that live in the class objects from which they were generated.\\n626 | Chapter 26: \\u2002Class Coding Basics', metadata={'source': 'python.pdf', 'page': 676}),\n",
       " Document(page_content='•Assignments to attributes of self in methods make per-instance attributes .\\nInside class method functions, the first argument (called self by convention) ref-\\nerences the instance object being processed; assignments to attributes of self create\\nor change data in the instance, not the class.\\nA First Example\\nLet’s turn to a real example to show how these ideas work in practice. To begin, let’s\\ndefine a class named FirstClass by running a Python class statement interactively:\\n>>> class FirstClass:               # Define a class object\\n...     def setdata(self, value):   # Define class methods\\n...         self.data = value       # self is the instance\\n...     def display(self):\\n...         print(self.data)        # self.data: per instance\\n...\\nWe’re working interactively here, but typically, such a statement would be run when\\nthe module file it is coded in is imported. Like functions created with defs, this class\\nwon’t even exist until Python reaches and runs this statement.\\nLike all compound statements, the class starts with a header line that lists the class\\nname, followed by a body of one or more nested and (usually) indented statements.\\nHere, the nested statements are defs; they define functions that implement the behavior\\nthe class means to export.\\nAs we learned in Part IV , def is really an assignment. Here, it assigns function objects\\nto the names setdata and display in the class statement’s scope, and so generates\\nattributes attached to the class: FirstClass.setdata and FirstClass.display. In fact,\\nany name assigned at the top level of the class’s nested block becomes an attribute of\\nthe class.\\nFunctions inside a class are usually called methods. They’re coded with normal defs,\\nand they support everything we’ve learned about functions already (they can have de-\\nfaults, return values, and so on). But in a method function, the first argument auto-\\nmatically receives an implied instance object when called—the subject of the call. We\\nneed to create a couple of instances to see how this works:\\n>>> x = FirstClass()                # Make two instances\\n>>> y = FirstClass()                # Each is a new namespace\\nBy calling the class this way (notice the parentheses), we generate instance objects,\\nwhich are just namespaces that have access to their classes’ attributes. Properly speak-\\ning, at this point, we have three objects: two instances and a class. Really, we have three\\nlinked namespaces, as sketched in Figure 26-1 . In OOP terms, we say that x “is a”\\nFirstClass, as is y.\\nClasses Generate Multiple Instance Objects | 627', metadata={'source': 'python.pdf', 'page': 677}),\n",
       " Document(page_content='Figure 26-1. Classes and instances are linked namespace objects in a class tree that is searched by\\ninheritance. Here, the \\n“data” attribute is found in instances, but “setdata” and “display” are in the\\nclass above them.\\nThe two instances start out empty but have links back to the class from which they\\nwere generated. If we qualify an instance with the name of an attribute that lives in the\\nclass object, Python fetches the name from the class by inheritance search (unless it\\nalso lives in the instance):\\n>>> x.setdata(\"King Arthur\")        # Call methods: self is x\\n>>> y.setdata(3.14159)              # Runs: FirstClass.setdata(y, 3.14159)\\nNeither x nor y has a setdata attribute of its own, so to find it, Python follows the link\\nfrom instance to class. And that’s about all there is to inheritance in Python: it happens\\nat attribute qualification time, and it just involves looking up names in linked objects\\n(e.g., by following the is-a links in Figure 26-1).\\nIn the setdata function inside FirstClass, the value passed in is assigned to\\nself.data. Within a method, self—the name given to the leftmost argument by con-\\nvention—automatically refers to the instance being processed ( x or y), so the assign-\\nments store values in the instances’ namespaces, not the class’s (that’s how the data\\nnames in Figure 26-1 are created).\\nBecause classes can generate multiple instances, methods must go through the self\\nargument to get to the instance to be processed. When we call the class’s display\\nmethod to print self.data, we see that it’s different in each instance; on the other hand,\\nthe name display itself is the same in x and y, as it comes (is inherited) from the class:\\n>>> x.display()                     # self.data differs in each instance\\nKing Arthur\\n>>> y.display()\\n3.14159\\nNotice that we stored different object types in the data member in each instance (a\\nstring, and a floating point). As with everything else in Python, there are no declarations\\nfor instance attributes (sometimes called members); they spring into existence the first\\ntime they are assigned values, just like simple variables. In fact, if we were to call\\ndisplay on one of our instances before calling setdata, we would trigger an undefined\\nname error—the attribute named data doesn’t even exist in memory until it is assigned\\nwithin the setdata method.\\n628 | Chapter 26: \\u2002Class Coding Basics', metadata={'source': 'python.pdf', 'page': 678}),\n",
       " Document(page_content='As another way to appreciate how dynamic this model is, consider that we can change\\ninstance attributes in \\nthe class itself, by assigning to self in methods, or outside the\\nclass, by assigning to an explicit instance object:\\n>>> x.data = \"New value\"            # Can get/set attributes\\n>>> x.display()                     # Outside the class too\\nNew value\\nAlthough less common, we could even generate a brand new attribute in the instance’s\\nnamespace by assigning to its name outside the class’s method functions:\\n>>> x.anothername = \"spam\"          # Can set new attributes here too!\\nThis would attach a new attribute called anothername, which may or may not be used\\nby any of the class’s methods, to the instance object x. Classes usually create all of the\\ninstance’s attributes by assignment to the self argument, but they don’t have to; pro-\\ngrams can fetch, change, or create attributes on any objects to which they have\\nreferences.\\nClasses Are Customized by Inheritance\\nBesides serving as factories for generating multiple instance objects, classes also allow\\nus to make changes by introducing new components (called subclasses), instead of\\nchanging existing components in-place. Instance objects generated from a class inherit\\nthe class’s attributes. Python also allows classes to inherit from other classes, opening\\nthe door to coding hierarchies of classes that specialize behavior—by redefining attrib-\\nutes in subclasses that appear lower in the hierarchy, we override the more general\\ndefinitions of those attributes higher in the tree. In effect, the further down the hierarchy\\nwe go, the more specific the software becomes. Here, too, there is no parallel with\\nmodules: their attributes live in a single, flat namespace that is not as amenable to\\ncustomization.\\nIn Python, instances inherit from classes, and classes inherit from superclasses. Here\\nare the key ideas behind the machinery of attribute inheritance:\\n•Superclasses are listed in parentheses in a  class header. To inherit attributes\\nfrom another class, just list the class in parentheses in a class statement’s header.\\nThe class that inherits is usually called a subclass, and the class that is inherited\\nfrom is its superclass.\\n•Classes inherit attributes from their superclasses . Just as instances inherit the\\nattribute names defined in their classes, classes inherit all the attribute names de-\\nfined in their superclasses; Python finds them automatically when they’re accessed,\\nif they don’t exist in the subclasses.\\n•Instances inherit attributes from all accessible classes . Each instance gets\\nnames from the class it’s generated from, as well as all of that class’s superclasses.\\nWhen looking for a name, Python checks the instance, then its class, then all\\nsuperclasses.\\nClasses Are Customized by Inheritance | 629', metadata={'source': 'python.pdf', 'page': 679}),\n",
       " Document(page_content='•Each object.attribute reference invokes a new, independent search . Python\\nperforms an independent search of the class tree for each attribute fetch expression.\\nThis includes references to instances and classes made outside class statements\\n(e.g., X.attr), as well as references to attributes of the self instance argument in\\nclass method functions. Each self.attr expression in a method invokes a new\\nsearch for attr in self and above.\\n•Logic changes are made by subclassing, not by changing superclasses . By\\nredefining superclass names in subclasses lower in the hierarchy (class tree), sub-\\nclasses replace and thus customize inherited behavior.\\nThe net effect, and the main purpose of all this searching, is that classes support fac-\\ntoring and customization of code better than any other language tool we’ve seen so far.\\nOn the one hand, they allow us to minimize code redundancy (and so reduce mainte-\\nnance costs) by factoring operations into a single, shared implementation; on the other,\\nthey allow us to program by customizing what already exists, rather than changing it\\nin-place or starting from scratch.\\nA Second Example\\nTo illustrate the role of inheritance, this next example builds on the previous one. First,\\nwe’ll define a new class, SecondClass, that inherits all of FirstClass’s names and pro-\\nvides one of its own:\\n>>> class SecondClass(FirstClass):                   # Inherits setdata\\n...     def display(self):                           # Changes display\\n...         print(\\'Current value = \"%s\"\\' % self.data)\\n...\\nSecondClass defines the display method to print with a different format. By defining\\nan attribute with the same name as an attribute in FirstClass, SecondClass effectively\\nreplaces the display attribute in its superclass.\\nRecall that inheritance searches proceed upward from instances, to subclasses, to su-\\nperclasses, stopping at the first appearance of the attribute name that it finds. In this\\ncase, since the display name in SecondClass will be found before the one in First\\nClass, we say that SecondClass overrides FirstClass’s display. Sometimes we call this\\nact of replacing attributes by redefining them lower in the tree overloading.\\nThe net effect here is that SecondClass specializes FirstClass by changing the behavior\\nof the display method. On the other hand, SecondClass (and any instances created from\\nit) still inherits the setdata method in FirstClass verbatim. Let’s make an instance to\\ndemonstrate:\\n>>> z = SecondClass()\\n>>> z.setdata(42)           # Finds setdata in FirstClass\\n>>> z.display()             # Finds overridden method in SecondClass\\nCurrent value = \"42\"\\n630 | Chapter 26: \\u2002Class Coding Basics', metadata={'source': 'python.pdf', 'page': 680}),\n",
       " Document(page_content='As before, we make a SecondClass instance object by calling it. The setdata call still\\nruns the version in FirstClass, but this time the display attribute comes from Second\\nClass and prints a custom message. Figure 26-2 sketches the namespaces involved.\\nFigure 26-2. Specialization by overriding inherited names by redefining them in extensions lower in\\nthe class tree. Here, SecondClass redefines and so customizes the “display” method for its instances.\\nNow, here’s a \\nvery important thing to notice about OOP: the specialization introduced\\nin SecondClass is completely external to FirstClass. That is, it doesn’t affect existing\\nor future FirstClass objects, like the x from the prior example:\\n>>> x.display()             # x is still a FirstClass instance (old message)\\nNew value\\nRather than changing FirstClass, we customized it. Naturally, this is an artificial ex-\\nample, but as a rule, because inheritance allows us to make changes like this in external\\ncomponents (i.e., in subclasses), classes often support extension and reuse better than\\nfunctions or modules can.\\nClasses Are Attributes in Modules\\nBefore we move on, remember that there’s nothing magic about a class name. It’s just\\na variable assigned to an object when the class statement runs, and the object can be\\nreferenced with any normal expression. For instance, if our FirstClass was coded in a\\nmodule file instead of being typed interactively, we could import it and use its name\\nnormally in a class header line:\\nfrom modulename import FirstClass           # Copy name into my scope\\nclass SecondClass(FirstClass):              # Use class name directly\\n    def display(self): ...\\nOr, equivalently:\\nimport modulename                           # Access the whole module\\nclass SecondClass(modulename.FirstClass):   # Qualify to reference\\n    def display(self): ...\\nClasses Are Customized by Inheritance | 631', metadata={'source': 'python.pdf', 'page': 681}),\n",
       " Document(page_content='Like everything else, class names always live within a module, so they must follow all\\nthe rules we \\nstudied in Part V. For example, more than one class can be coded in a\\nsingle module file—like other statements in a module, class statements are run during\\nimports to define names, and these names become distinct module attributes. More\\ngenerally, each module may arbitrarily mix any number of variables, functions, and\\nclasses, and all names in a module behave the same way. The file food.py demonstrates:\\n# food.py\\nvar = 1                                       # food.var\\ndef func():                                   # food.func\\n    ...\\nclass spam:                                   # food.spam\\n    ...\\nclass ham:                                    # food.ham\\n    ...\\nclass eggs:                                   # food.eggs\\n    ...\\nThis holds true even if the module and class happen to have the same name. For ex-\\nample, given the following file, person.py:\\nclass person:\\n   ...\\nwe need to go through the module to fetch the class as usual:\\nimport person                                 # Import module\\nx = person.person()                           # Class within module\\nAlthough this path may look redundant, it’s required: person.person refers to the\\nperson class inside the person module. Saying just person gets the module, not the class,\\nunless the from statement is used:\\nfrom person import person                     # Get class from module\\nx = person()                                  # Use class name\\nAs with any other variable, we can never see a class in a file without first importing and\\nsomehow fetching it from its enclosing file. If this seems confusing, don’t use the same\\nname for a module and a class within it. In fact, common convention in Python dictates\\nthat class names should begin with an uppercase letter, to help make them more\\ndistinct:\\nimport person                                 # Lowercase for modules\\nx = person.Person()                           # Uppercase for classes\\nAlso, keep in mind that although classes and modules are both namespaces for attach-\\ning attributes, they correspond to very different source code structures: a module re-\\nflects an entire file, but a class is a statement within a file. We’ll say more about such\\ndistinctions later in this part of the book.\\n632 | Chapter 26: \\u2002Class Coding Basics', metadata={'source': 'python.pdf', 'page': 682}),\n",
       " Document(page_content='Classes Can Intercept Python Operators\\nLet’s move on \\nto the third major difference between classes and modules: operator\\noverloading. In simple terms, operator overloading  lets objects coded with classes in-\\ntercept and respond to operations that work on built-in types: addition, slicing, print-\\ning, qualification, and so on. It’s mostly just an automatic dispatch mechanism—\\nexpressions and other built-in operations route control to implementations in classes.\\nHere, too, there is nothing similar in modules: modules can implement function calls,\\nbut not the behavior of expressions.\\nAlthough we could implement all class behavior as method functions, operator over-\\nloading lets objects be more tightly integrated with Python’s object model. Moreover,\\nbecause operator overloading makes our own objects act like built-ins, it tends to foster\\nobject interfaces that are more consistent and easier to learn, and it allows class-based\\nobjects to be processed by code written to expect a built-in type’s interface. Here is a\\nquick rundown of the main ideas behind overloading operators:\\n•Methods named with double underscores ( __X__) are special hooks . Python\\noperator overloading is implemented by providing specially named methods to\\nintercept operations. The Python language defines a fixed and unchangeable map-\\nping from each of these operations to a specially named method.\\n•Such methods are called automatically when instances appear in built-in\\noperations. For instance, if an instance object inherits an __add__ method, that\\nmethod is called whenever the object appears in a + expression. The method’s\\nreturn value becomes the result of the corresponding expression.\\n•Classes may override most built-in type operations . There are dozens of special\\noperator overloading method names for intercepting and implementing nearly ev-\\nery operation available for built-in types. This includes expressions, but also basic\\noperations like printing and object creation.\\n•There are no defaults for operator overloading methods, and none are\\nrequired. If a class does not define or inherit an operator overloading method, it\\njust means that the corresponding operation is not supported for the class’s in-\\nstances. If there is no __add__, for example, + expressions raise exceptions.\\n•Operators allow classes to integrate with Python’s object model . By over-\\nloading type operations, user-defined objects implemented with classes can act just\\nlike built-ins, and so provide consistency as well as compatibility with expected\\ninterfaces.\\nOperator overloading is an optional feature; it’s used primarily by people developing\\ntools for other Python programmers, not by application developers. And, candidly, you\\nprobably shouldn’t try to use it just because it seems “cool.” Unless a class needs to\\nmimic built-in type interfaces, it should usually stick to simpler named methods. Why\\nwould an employee database application support expressions like * and +, for example?\\nNamed methods like giveRaise and promote would usually make more sense.\\nClasses Can Intercept Python Operators | 633', metadata={'source': 'python.pdf', 'page': 683}),\n",
       " Document(page_content='Because of this, we won’t go into details on every operator overloading method available\\nin Python in \\nthis book. Still, there is one operator overloading method you are likely\\nto see in almost every realistic Python class: the __init__ method, which is known as\\nthe constructor method and is used to initialize objects’ state. You should pay special\\nattention to this method, because __init__, along with the self argument, turns out\\nto be a key requirement to understanding most OOP code in Python.\\nA Third Example\\nOn to another example. This time, we’ll define a subclass of SecondClass that imple-\\nments three specially named attributes that Python will call automatically:\\n•__init__ is run when a new instance object is created ( self is the new ThirdClass\\nobject).*\\n•__add__ is run when a ThirdClass instance appears in a + expression.\\n•__str__ is run when an object is printed (technically, when it’s converted to its\\nprint string by the str built-in function or its Python internals equivalent).\\nOur new subclass also defines a normally named method named mul, which changes\\nthe instance object in-place. Here’s the new subclass:\\n>>> class ThirdClass(SecondClass):                     # Inherit from SecondClass\\n...     def __init__(self, value):                     # On \"ThirdClass(value)\"\\n...         self.data = value\\n...     def __add__(self, other):                      # On \"self + other\"\\n...         return ThirdClass(self.data + other)\\n...     def __str__(self):                             # On \"print(self)\", \"str()\"\\n...         return \\'[ThirdClass: %s]\\' % self.data\\n...     def mul(self, other):                          # In-place change: named\\n...         self.data *= other\\n...\\n>>> a = ThirdClass(\\'abc\\')           # __init__ called\\n>>> a.display()                     # Inherited method called\\nCurrent value = \"abc\"\\n>>> print(a)                        # __str__: returns display string\\n[ThirdClass: abc]\\n>>> b = a + \\'xyz\\'                   # __add__: makes a new instance\\n>>> b.display()                     # b has all ThirdClass methods\\nCurrent value = \"abcxyz\"\\n>>> print(b)                        # __str__: returns display string\\n[ThirdClass: abcxyz]\\n>>> a.mul(3)                        # mul: changes instance in-place\\n>>> print(a)\\n[ThirdClass: abcabcabc]\\n* Not to be confused with the __init__.py files in module packages! See Chapter 23 for more details.\\n634 | Chapter 26: \\u2002Class Coding Basics', metadata={'source': 'python.pdf', 'page': 684}),\n",
       " Document(page_content='ThirdClass “is a” SecondClass, so its instances inherit the customized display method\\nfrom SecondClass. This time, \\nthough, ThirdClass creation calls pass an argument (e.g.,\\n“abc”). This argument is passed to the value argument in the __init__ constructor and\\nassigned to self.data there. The net effect is that ThirdClass arranges to set the data\\nattribute automatically at construction time, instead of requiring setdata calls after the\\nfact.\\nFurther, ThirdClass objects can now show up in + expressions and print calls. For +,\\nPython passes the instance object on the left to the self argument in __add__ and the\\nvalue on the right to other, as illustrated in Figure 26-3 ; whatever __add__ returns be-\\ncomes the result of the + expression. For print, Python passes the object being printed\\nto self in __str__; whatever string this method returns is taken to be the print string\\nfor the object. With __str__ we can use a normal print to display objects of this class,\\ninstead of calling the special display method.\\nFigure 26-3. In operator overloading, expression operators and other built-in operations performed\\non class instances \\nare mapped back to specially named methods in the class. These special methods\\nare optional and may be inherited as usual. Here, a + expression triggers the __add__ method.\\nSpecially named methods such as __init__, __add__, and __str__ are inherited by sub-\\nclasses and instances, just like any other names assigned in a class. If they’re not coded\\nin a class, Python looks for such names in all its superclasses, as usual. Operator over-\\nloading method names are also not built-in or reserved words; they are just attributes\\nthat Python looks for when objects appear in various contexts. Python usually calls\\nthem automatically, but they may occasionally be called by your code as well; the\\n__init__ method, for example, is often called manually to trigger superclass construc-\\ntors (more on this later).\\nNotice that the __add__ method makes and returns a new instance object of its class,\\nby calling ThirdClass with the result value. By contrast, mul changes the current instance\\nobject in-place, by reassigning the self attribute. We could overload the * expression\\nto do the latter, but this would be too different from the behavior of * for built-in types\\nsuch as numbers and strings, for which it always makes new objects. Common practice\\ndictates that overloaded operators should work the same way that built-in operator\\nimplementations do. Because operator overloading is really just an expression-to-\\nmethod dispatch mechanism, though, you can interpret operators any way you like in\\nyour own class objects.\\nClasses Can Intercept Python Operators | 635', metadata={'source': 'python.pdf', 'page': 685}),\n",
       " Document(page_content=\"Why Use Operator Overloading?\\nAs a class \\ndesigner, you can choose to use operator overloading or not. Your choice\\nsimply depends on how much you want your object to look and feel like built-in types.\\nAs mentioned earlier, if you omit an operator overloading method and do not inherit\\nit from a superclass, the corresponding operation will not be supported for your in-\\nstances; if it’s attempted, an exception will be thrown (or a standard default will be\\nused).\\nFrankly, many operator overloading methods tend to be used only when implementing\\nobjects that are mathematical in nature; a vector or matrix class may overload the\\naddition operator, for example, but an employee class likely would not. For simpler\\nclasses, you might not use overloading at all, and would rely instead on explicit method\\ncalls to implement your objects’ behavior.\\nOn the other hand, you might decide to use operator overloading if you need to pass\\na user-defined object to a function that was coded to expect the operators available on\\na built-in type like a list or a dictionary. Implementing the same operator set in your\\nclass will ensure that your objects support the same expected object interface and so\\nare compatible with the function. Although we won’t cover every operator overloading\\nmethod in this book, we’ll see some additional operator overloading techniques in\\naction in Chapter 29.\\nOne overloading method we will explore here is the __init__ constructor method,\\nwhich seems to show up in almost every realistic class. Because it allows classes to fill\\nout the attributes in their newly created instances immediately, the constructor is useful\\nfor almost every kind of class you might code. In fact, even though instance attributes\\nare not declared in Python, you can usually find out which attributes an instance will\\nhave by inspecting its class’s __init__ method.\\nThe World’s Simplest Python Class\\nWe’ve begun studying class statement syntax in detail in this chapter, but I’d again\\nlike to remind you that the basic inheritance model that classes produce is very simple—\\nall it really involves is searching for attributes in trees of linked objects. In fact, we can\\ncreate a class with nothing in it at all. The following statement makes a class with no\\nattributes attached (an empty namespace object):\\n>>> class rec: pass              # Empty namespace object\\nWe need the no-operation pass statement (discussed in Chapter 13 ) here because we\\ndon’t have any methods to code. After we make the class by running this statement\\ninteractively, we can start attaching attributes to the class by assigning names to it\\ncompletely outside of the original class statement:\\n>>> rec.name = 'Bob'             # Just objects with attributes\\n>>> rec.age  = 40\\n636 | Chapter 26: \\u2002Class Coding Basics\", metadata={'source': 'python.pdf', 'page': 686}),\n",
       " Document(page_content=\"And, after we’ve created these attributes by assignment, we can fetch them with the\\nusual syntax. When \\nused this way, a class is roughly similar to a “struct” in C, or a\\n“record” in Pascal. It’s basically an object with field names attached to it (we can do\\nsimilar work with dictionary keys, but it requires extra characters):\\n>>> print(rec.name)              # Like a C struct or a record\\nBob\\nNotice that this works even though there are no instances of the class yet; classes are\\nobjects in their own right, even without instances. In fact, they are just self-contained\\nnamespaces, so as long as we have a reference to a class, we can set or change its\\nattributes anytime we wish. Watch what happens when we do create two instances,\\nthough:\\n>>> x = rec()                    # Instances inherit class names\\n>>> y = rec()\\nThese instances begin their lives as completely empty namespace objects. Because they\\nremember the class from which they were made, though, they will obtain the attributes\\nwe attached to the class by inheritance:\\n>>> x.name, y.name               # name is stored on the class only\\n('Bob', 'Bob')\\nReally, these instances have no attributes of their own; they simply fetch the name at-\\ntribute from the class object where it is stored. If we do assign an attribute to an instance,\\nthough, it creates (or changes) the attribute in that object, and no other—attribute\\nreferences kick off inheritance searches, but attribute assignments affect only the ob-\\njects in which the assignments are made. Here, x gets its own name, but y still inherits\\nthe name attached to the class above it:\\n>>> x.name = 'Sue'               # But assignment changes x only\\n>>> rec.name, x.name, y.name\\n('Bob', 'Sue', 'Bob')\\nIn fact, as we’ll explore in more detail in Chapter 28, the attributes of a namespace\\nobject are usually implemented as dictionaries, and class inheritance trees are (generally\\nspeaking) just dictionaries with links to other dictionaries. If you know where to look,\\nyou can see this explicitly.\\nFor example, the __dict__ attribute is the namespace dictionary for most class-based\\nobjects (some classes may also define attributes in __slots__, an advanced and seldom-\\nused feature that we’ll study in Chapters 30 and 31). The following was run in Python\\n3.0; the order of names and set of __X__ internal names present can vary from release\\nto release, but the names we assigned are present in all:\\n>>> rec.__dict__.keys()\\n['__module__', 'name', 'age', '__dict__', '__weakref__', '__doc__']\\n>>> list(x.__dict__.keys())\\n['name']\\nThe World’s Simplest Python Class | 637\", metadata={'source': 'python.pdf', 'page': 687}),\n",
       " Document(page_content=\">>> list(y.__dict__.keys())                # list() not required in Python 2.6\\n[]\\nHere, the class’s \\nnamespace dictionary shows the name and age attributes we assigned\\nto it, x has its own name, and y is still empty. Each instance has a link to its class for\\ninheritance, though—it’s called __class__, if you want to inspect it:\\n>>> x.__class__\\n<class '__main__.rec'>\\nClasses also have a __bases__ attribute, which is a tuple of their superclasses:\\n>>> rec.__bases__                          # () empty tuple in Python 2.6\\n(<class 'object'>,)\\nThese two attributes are how class trees are literally represented in memory by Python.\\nThe main point to take away from this look under the hood is that Python’s class model\\nis extremely dynamic. Classes and instances are just namespace objects, with attributes\\ncreated on the fly by assignment. Those assignments usually happen within the class\\nstatements you code, but they can occur anywhere you have a reference to one of the\\nobjects in the tree.\\nEven methods, normally created by a def nested in a class, can be created completely\\nindependently of any class object. The following, for example, defines a simple function\\noutside of any class that takes one argument:\\n>>> def upperName(self):\\n...     return self.name.upper()    # Still needs a self\\nThere is nothing about a class here yet—it’s a simple function, and it can be called as\\nsuch at this point, provided we pass in an object with a name attribute (the name self\\ndoes not make this special in any way):\\n>>> upperName(x)                    # Call as a simple function\\n'SUE'\\nIf we assign this simple function to an attribute of our class, though, it becomes a\\nmethod, callable through any instance (as well as through the class name itself, as long\\nas we pass in an instance manually):†\\n>>> rec.method = upperName\\n>>> x.method()                              # Run  method to process x\\n'SUE'\\n>>> y.method()                              # Same, but pass y to self\\n'BOB'\\n† In fact, this is one of the reasons the self argument must always be explicit in Python methods—because\\nmethods can be created as simple functions independent of a class, they need to make the implied instance\\nargument explicit. They can be called as either functions or methods, and Python can neither guess nor\\nassume that a simple function might eventually become a class method. The main reason for the explicit\\nself argument, though, is to make the meanings of names more obvious: names not referenced through\\nself are simple variables, while names referenced through self are obviously instance attributes.\\n638 | Chapter 26: \\u2002Class Coding Basics\", metadata={'source': 'python.pdf', 'page': 688}),\n",
       " Document(page_content=\">>> rec.method(x)                           # Can call through instance or class\\n'SUE'\\nNormally, classes are \\nfilled out by class statements, and instance attributes are created\\nby assignments to self attributes in method functions. The point again, though, is that\\nthey don’t have to be; OOP in Python really is mostly about looking up attributes in\\nlinked namespace objects.\\nClasses Versus Dictionaries\\nAlthough the simple classes of the prior section are meant to illustrate class model\\nbasics, the techniques they employ can also be used for real work. For example, Chap-\\nter 8  showed how to use dictionaries to record properties of entities in our programs.\\nIt turns out that classes can serve this role, too—they package information like dic-\\ntionaries, but can also bundle processing logic in the form of methods. For reference,\\nhere is the example for dictionary-based records we used earlier in the book:\\n>>> rec = {}\\n>>> rec['name'] = 'mel'                     # Dictionary-based record\\n>>> rec['age']  = 45\\n>>> rec['job']  = 'trainer/writer'\\n>>>\\n>>> print(rec['name'])\\nmel\\nThis code emulates tools like records in other languages. As we just saw, though, there\\nare also multiple ways to do the same with classes. Perhaps the simplest is this—trading\\nkeys for attributes:\\n>>> class rec: pass\\n...\\n>>> rec.name = 'mel'                        # Class-based record\\n>>> rec.age  = 45\\n>>> rec.job  = 'trainer/writer'\\n>>>\\n>>> print(rec.age)\\n40\\nThis code has substantially less syntax than the dictionary equivalent. It uses an empty\\nclass statement to generate an empty namespace object. Once we make the empty\\nclass, we fill it out by assigning class attributes over time, as before.\\nThis works, but a new class statement will be required for each distinct record we will\\nneed. Perhaps more typically, we can instead generate instances of an empty class to\\nrepresent each distinct entity:\\n>>> class rec: pass\\n...\\n>>> pers1 = rec()                           # Instance-based records\\n>>> pers1.name = 'mel'\\n>>> pers1.job  = 'trainer'\\nThe World’s Simplest Python Class | 639\", metadata={'source': 'python.pdf', 'page': 689}),\n",
       " Document(page_content=\">>> pers1.age   = 40\\n>>>\\n>>> pers2 = rec()\\n>>> pers2.name = 'vls'\\n>>> pers2.job  = 'developer'\\n>>>\\n>>> pers1.name, pers2.name\\n('mel', 'vls')\\nHere, we make \\ntwo records from the same class. Instances start out life empty, just like\\nclasses. We then fill in the records by assigning to attributes. This time, though, there\\nare two separate objects, and hence two separate name attributes. In fact, instances of\\nthe same class don’t even have to have the same set of attribute names; in this example,\\none has a unique age name. Instances really are distinct namespaces, so each has a\\ndistinct attribute dictionary. Although they are normally filled out consistently by class\\nmethods, they are more flexible than you might expect.\\nFinally, we might instead code a more full-blown class to implement the record and its\\nprocessing:\\n>>> class Person:\\n...     def __init__(self, name, job):      # Class = Data + Logic\\n...         self.name = name\\n...         self.job  = job\\n...     def info(self):\\n...         return (self.name, self.job)\\n...\\n>>> rec1 = Person('mel', 'trainer')\\n>>> rec2 = Person('vls', 'developer')\\n>>>\\n>>> rec1.job, rec2.info()\\n('trainer', ('vls', 'developer'))\\nThis scheme also makes multiple instances, but the class is not empty this time: we’ve\\nadded logic (methods) to initialize instances at construction time and collect attributes\\ninto a tuple. The constructor imposes some consistency on instances here by always\\nsetting the name and job attributes. Together, the class’s methods and instance attributes\\ncreate a package, which combines both data and logic.\\nWe could further extend this code by adding logic to compute salaries, parse names,\\nand so on. Ultimately, we might link the class into a larger hierarchy to inherit an\\nexisting set of methods via the automatic attribute search of classes, or perhaps even\\nstore instances of the class in a file with Python object pickling to make them persistent.\\nIn fact, we will—in the next chapter, we’ll expand on this analogy between classes and\\nrecords with a more realistic running example that demonstrates class basics in action.\\nIn the end, although types like dictionaries are flexible, classes allow us to add behavior\\nto objects in ways that built-in types and simple functions do not directly support.\\nAlthough we can store functions in dictionaries, too, using them to process implied\\ninstances is nowhere near as natural as it is in classes.\\n640 | Chapter 26: \\u2002Class Coding Basics\", metadata={'source': 'python.pdf', 'page': 690}),\n",
       " Document(page_content='Chapter Summary\\nThis chapter introduced \\nthe basics of coding classes in Python. We studied the syntax\\nof the class statement, and we saw how to use it to build up a class inheritance tree.\\nWe also studied how Python automatically fills in the first argument in method func-\\ntions, how attributes are attached to objects in a class tree by simple assignment, and\\nhow specially named operator overloading methods intercept and implement built-in\\noperations for our instances (e.g., expressions and printing).\\nNow that we’ve learned all about the mechanics of coding classes in Python, the next\\nchapter turns to a larger and more realistic example that ties together much of what\\nwe’ve learned about OOP so far. After that, we’ll continue our look at class coding,\\ntaking a second pass over the model to fill in some of the details that were omitted here\\nto keep things simple. First, though, let’s work through a quiz to review the basics we’ve\\ncovered so far.\\nTest Your Knowledge: Quiz\\n1. How are classes related to modules?\\n2.How are instances and classes created?\\n3.\\nWhere and how are class attributes created?\\n4. Where and how are instance attributes created?\\n5. What does self mean in a Python class?\\n6. How is operator overloading coded in a Python class?\\n7. When might you want to support operator overloading in your classes?\\n8. Which operator overloading method is most commonly used?\\n9. What are the two key concepts required to understand Python OOP code?\\nTest Your Knowledge: Answers\\n1. Classes are always nested inside a module; they are attributes of a module object.\\nClasses and modules are both namespaces, but classes correspond to statements\\n(not entire files) and support the OOP notions of multiple instances, inheritance,\\nand operator overloading. In a sense, a module is like a single-instance class, with-\\nout inheritance, which corresponds to an entire file of code.\\n2. Classes are made by running class statements; instances are created by calling a\\nclass as though it were a function.\\nTest Your Knowledge: Answers | 641', metadata={'source': 'python.pdf', 'page': 691}),\n",
       " Document(page_content='3. Class attributes are created by assigning attributes to a class object. They are nor-\\nmally generated \\nby top-level assignments nested in a class statement—each name\\nassigned in the class statement block becomes an attribute of the class object\\n(technically, the class statement scope morphs into the class object’s attribute\\nnamespace). Class attributes can also be created, though, by assigning attributes\\nto the class anywhere a reference to the class object exists—i.e., even outside the\\nclass statement.\\n4. Instance attributes are created by assigning attributes to an instance object. They\\nare normally created within class method functions inside the class statement by\\nassigning attributes to the self argument (which is always the implied instance).\\nAgain, though, they may be created by assignment anywhere a reference to the\\ninstance appears, even outside the class statement. Normally, all instance\\nattributes are initialized in the __init__ constructor method; that way, later\\nmethod calls can assume the attributes already exist.\\n5.self is the name commonly given to the first (leftmost) argument in a class method\\nfunction; Python automatically fills it in with the instance object that is the implied\\nsubject of the method call. This argument need not be called self (though this is\\na very strong convention); its position is what is significant. (Ex-C++ or Java pro-\\ngrammers might prefer to call it this because in those languages that name reflects\\nthe same idea; in Python, though, this argument must always be explicit.)\\n6. Operator overloading is coded in a Python class with specially named methods;\\nthey all begin and end with double underscores to make them unique. These are\\nnot built-in or reserved names; Python just runs them automatically when an in-\\nstance appears in the corresponding operation. Python itself defines the mappings\\nfrom operations to special method names.\\n7. Operator overloading is useful to implement objects that resemble built-in types\\n(e.g., sequences or numeric objects such as matrixes), and to mimic the built-in\\ntype interface expected by a piece of code. Mimicking built-in type interfaces en-\\nables you to pass in class instances that also have state information—i.e., attributes\\nthat remember data between operation calls. You shouldn’t use operator over-\\nloading when a simple named method will suffice, though.\\n8. The __init__ constructor method is the most commonly used; almost every class\\nuses this method to set initial values for instance attributes and perform other\\nstartup tasks.\\n9. The special self argument in method functions and the __init__ constructor\\nmethod are the two cornerstones of OOP code in Python.\\n642 | Chapter 26: \\u2002Class Coding Basics', metadata={'source': 'python.pdf', 'page': 692}),\n",
       " Document(page_content='CHAPTER 27\\nA More Realistic Example\\nWe’ll dig into more class syntax details in the next chapter. Before we do, though, I’d\\nlike to show \\nyou a more realistic example of classes in action that’s more practical than\\nwhat we’ve seen so far. In this chapter, we’re going to build a set of classes that do\\nsomething more concrete—recording and processing information about people. As\\nyou’ll see, what we call instances and classes in Python programming can often serve\\nthe same roles as records and programs in more traditional terms.\\nSpecifically, in this chapter we’re going to code two classes:\\n•Person—a class that creates and processes information about people\\n•Manager—a customization of Person that modifies inherited behavior\\nAlong the way, we’ll make instances of both classes and test out their functionality.\\nWhen we’re done, I’ll show you a nice example use case for classes—we’ll store our\\ninstances in a shelve object-oriented database, to make them permanent. That way, you\\ncan use this code as a template for fleshing out a full-blown personal database written\\nentirely in Python.\\nBesides actual utility, though, our aim here is also educational: this chapter provides a\\ntutorial on object-oriented programming in Python. Often, people grasp the last chap-\\nter’s class syntax on paper, but have trouble seeing how to get started when confronted\\nwith having to code a new class from scratch. Toward this end, we’ll take it one step\\nat a time here, to help you learn the basics; we’ll build up the classes gradually, so you\\ncan see how their features come together in complete programs.\\nIn the end, our classes will still be relatively small in terms of code, but they will dem-\\nonstrate all of the main ideas in Python’s OOP model. Despite its syntax details, Py-\\nthon’s class system really is largely just a matter of searching for an attribute in a tree\\nof objects, along with a special first argument for functions.\\n643', metadata={'source': 'python.pdf', 'page': 693}),\n",
       " Document(page_content='Step 1: Making Instances\\nOK, so much \\nfor the design phase—let’s move on to implementation. Our first task is\\nto start coding the main class, Person. In your favorite text editor, open a new file for\\nthe code we’ll be writing. It’s a fairly strong convention in Python to begin module\\nnames with a lowercase letter and class names with an uppercase letter; like the name\\nof self arguments in methods, this is not required by the language, but it’s so common\\nthat deviating might be confusing to people who later read your code. To conform,\\nwe’ll call our new module file person.py and our class within it Person, like this:\\n# File person.py (start)\\nclass Person:\\nAll our work will be done in this file until later in this chapter. We can code any number\\nof functions and classes in a single module file in Python, and this one’s person.py name\\nmight not make much sense if we add unrelated components to it later. For now, we’ll\\nassume everything in it will be Person-related. It probably should be anyhow—as we’ve\\nlearned, modules tend to work best when they have a single, cohesive purpose.\\nCoding Constructors\\nNow, the first thing we want to do with our Person class is record basic information\\nabout people—to fill out record fields, if you will. Of course, these are known as in-\\nstance object attributes in Python-speak, and they generally are created by assignment\\nto self attributes in class method functions. The normal way to give instance attributes\\ntheir first values is to assign them to self in the __init__ constructor method , which\\ncontains code run automatically by Python each time an instance is created. Let’s add\\none to our class:\\n# Add record field initialization\\nclass Person:\\n    def __init__(self, name, job, pay):      # Constructor takes 3 arguments\\n        self.name = name                     # Fill out fields when created\\n        self.job  = job                      # self is the new instance object\\n        self.pay  = pay\\nThis is a very common coding pattern: we pass in the data to be attached to an instance\\nas arguments to the constructor method and assign them to self to retain them per-\\nmanently. In OO terms, self is the newly created instance object, and name, job, and\\npay become state information —descriptive data saved on an object for later use. Al-\\nthough other techniques (such as enclosing scope references) can save details, too,\\ninstance attributes make this very explicit and easy to understand.\\nNotice that the argument names appear twice here. This code might seem a bit redun-\\ndant at first, but it’s not. The job argument, for example, is a local variable in the scope\\nof the __init__ function, but self.job is an attribute of the instance that’s the implied\\n644 | Chapter 27: \\u2002A More Realistic Example', metadata={'source': 'python.pdf', 'page': 694}),\n",
       " Document(page_content='subject of the method call. They are two different variables, which happen to have the\\nsame name. By \\nassigning the job local to the self.job attribute with self.job=job, we\\nsave the passed-in job on the instance for later use. As usual in Python, where a name\\nis assigned (or what object it is assigned to) determines what it means.\\nSpeaking of arguments, there’s really nothing magical about __init__, apart from the\\nfact that it’s called automatically when an instance is made and has a special first ar-\\ngument. Despite its weird name, it’s a normal function and supports all the features of\\nfunctions we’ve already covered. We can, for example, provide defaults for some of its\\narguments, so they need not be provided in cases where their values aren’t available or\\nuseful.\\nTo demonstrate, let’s make the job argument optional—it will default to None, meaning\\nthe person being created is not (currently) employed. If job defaults to None, we’ll\\nprobably want to default pay to 0, too, for consistency (unless some of the people you\\nknow manage to get paid without having jobs!). In fact, we have to specify a default\\nfor pay because according to Python’s syntax rules, any arguments in a function’s header\\nafter the first default must all have defaults, too:\\n# Add defaults for constructor arguments\\nclass Person:\\n    def __init__(self, name, job=None, pay=0):         # Normal function args\\n        self.name = name\\n        self.job  = job\\n        self.pay  = pay\\nWhat this code means is that we’ll need to pass in a name when making Persons, but\\njob and pay are now optional; they’ll default to None and 0 if omitted. The self argu-\\nment, as usual, is filled in by Python automatically to refer to the instance object—\\nassigning values to attributes of self attaches them to the new instance.\\nTesting As You Go\\nThis class doesn’t do much yet—it essentially just fills out the fields of a new record—\\nbut it’s a real working class. At this point we could add more code to it for more features,\\nbut we won’t do that yet. As you’ve probably begun to appreciate already, programming\\nin Python is really a matter of incremental prototyping —you write some code, test it,\\nwrite more code, test again, and so on. Because Python provides both an interactive\\nsession and nearly immediate turnaround after code changes, it’s more natural to test\\nas you go than to write a huge amount of code to test all at once.\\nBefore adding more features, then, let’s test what we’ve got so far by making a few\\ninstances of our class and displaying their attributes as created by the constructor. We\\ncould do this interactively, but as you’ve also probably surmised by now, interactive\\ntesting has its limits—it gets tedious to have to reimport modules and retype test cases\\neach time you start a new testing session. More commonly, Python programmers use\\nStep 1: Making Instances | 645', metadata={'source': 'python.pdf', 'page': 695}),\n",
       " Document(page_content=\"the interactive prompt for simple one-off tests but do more substantial testing by writing\\ncode at the bottom of the file that contains the objects to be tested, like this:\\n# Add incremental self-test code\\nclass Person:\\n    def __init__(self, name, job=None, pay=0):\\n        self.name = name\\n        self.job  = job\\n        self.pay  = pay\\nbob = Person('Bob Smith')                         # Test the class\\nsue = Person('Sue Jones', job='dev', pay=100000)  # Runs __init__ automatically\\nprint(bob.name, bob.pay)                          # Fetch attached attributes\\nprint(sue.name, sue.pay)                          # sue's and bob's attrs differ\\nNotice here that \\nthe bob object accepts the defaults for job and pay, but sue provides\\nvalues explicitly. Also note how we use keyword arguments  when making sue; we could\\npass by position instead, but the keywords may help remind us later what the data is\\n(and they allow us to pass the arguments in any left-to-right order we like). Again,\\ndespite its unusual name, __init__ is a normal function, supporting everything you\\nalready know about functions—including both defaults and pass-by-name keyword\\narguments.\\nWhen this file runs as a script, the test code at the bottom makes two instances of our\\nclass and prints two attributes of each (name and pay):\\nC:\\\\misc> person.py\\nBob Smith 0\\nSue Jones 100000\\nYou can also type this file’s test code at Python’s interactive prompt (assuming you\\nimport the Person class there first), but coding canned tests inside the module file like\\nthis makes it much easier to rerun them in the future.\\nAlthough this is fairly simple code, it’s already demonstrating something important.\\nNotice that bob’s name is not sue’s, and sue’s pay is not bob’s. Each is an independent\\nrecord of information. Technically, bob and sue are both namespace objects—like all\\nclass instances, they each have their own independent copy of the state information\\ncreated by the class. Because each instance of a class has its own set of self attributes,\\nclasses are a natural for recording information for multiple objects this way; just like\\nbuilt-in types, classes serve as a sort of object factory. Other Python program structures,\\nsuch as functions and modules, have no such concept.\\nUsing Code Two Ways\\nAs is, the test code at the bottom of the file works, but there’s a big catch—its top-level\\nprint statements run both when the file is run as a script and when it is imported as a\\nmodule. This means if we ever decide to import the class in this file in order to use it\\nsomewhere else (and we will later in this chapter), we’ll see the output of its test code\\n646 | Chapter 27: \\u2002A More Realistic Example\", metadata={'source': 'python.pdf', 'page': 696}),\n",
       " Document(page_content=\"every time the file is imported. That’s not very good software citizenship, though: client\\nprograms probably don’t \\ncare about our internal tests and won’t want to see our output\\nmixed in with their own.\\nAlthough we could split the test code off into a separate file, it’s often more convenient\\nto code tests in the same file as the items to be tested. It would be better to arrange to\\nrun the test statements at the bottom only when the file is run for testing, not when the\\nfile is imported. That’s exactly what the module __name__ check is designed for, as you\\nlearned in the preceding part of this book. Here’s what this addition looks like:\\n# Allow this file to be imported as well as run/tested\\nclass Person:\\n    def __init__(self, name, job=None, pay=0):\\n        self.name = name\\n        self.job  = job\\n        self.pay  = pay\\nif __name__ == '__main__':                  # When run for testing only\\n    # self-test code\\n    bob = Person('Bob Smith')\\n    sue = Person('Sue Jones', job='dev', pay=100000)\\n    print(bob.name, bob.pay)\\n    print(sue.name, sue.pay)\\nNow, we get exactly the behavior we’re after—running the file as a top-level script tests\\nit because its __name__ is __main__, but importing it as a library of classes later does not:\\nC:\\\\misc> person.py\\nBob Smith 0\\nSue Jones 100000\\nc:\\\\misc> python\\nPython 3.0.1 (r301:69561, Feb 13 2009, 20:04:18) ...\\n>>> import person\\n>>>\\nWhen imported, the file now defines the class, but does not use it. When run directly,\\nthis file creates two instances of our class as before, and prints two attributes of each;\\nagain, because each instance is an independent namespace object, the values of their\\nattributes differ.\\nVersion Portability Note\\nI’m running all \\nthe code in this chapter under Python 3.0, and using the 3.0 print\\nfunction call syntax. If you run under 2.6 the code will work as-is, but you’ll notice\\nparentheses around some output lines because the extra parentheses in prints turn\\nmultiple items into a tuple:\\nc:\\\\misc> c:\\\\python26\\\\python person.py\\n('Bob Smith', 0)\\n('Sue Jones', 100000)\\nStep 1: Making Instances | 647\", metadata={'source': 'python.pdf', 'page': 697}),\n",
       " Document(page_content=\"If this difference is the sort of detail that might keep you awake at nights, simply remove\\nthe parentheses to use 2.6 print statements. You \\ncan also avoid the extra parentheses\\nportably by using formatting to yield a single object to print. Either of the following\\nworks in both 2.6 and 3.0, though the method form is newer:\\nprint('{0} {1}'.format(bob.name, bob.pay))    # New format method\\nprint('%s %s' % (bob.name, bob.pay))          # Format expression\\nStep 2: Adding Behavior Methods\\nEverything looks good so \\nfar—at this point, our class is essentially a record factory; it\\ncreates and fills out fields of records (attributes of instances, in more Pythonic terms).\\nEven as limited as it is, though, we can still run some operations on its objects. Although\\nclasses add an extra layer of structure, they ultimately do most of their work by em-\\nbedding and processing basic core data types  like lists and strings. In other words, if\\nyou already know how to use Python’s simple core types, you already know much of\\nthe Python class story; classes are really just a minor structural extension.\\nFor example, the name field of our objects is a simple string, so we can extract last names\\nfrom our objects by splitting on spaces and indexing. These are all core data type op-\\nerations, which work whether their subjects are embedded in class instances or not:\\n>>> name = 'Bob Smith'      # Simple string, outside class\\n>>> name.split()            # Extract last name\\n['Bob', 'Smith']\\n>>> name.split()[-1]        # Or [1], if always just two parts\\n'Smith'\\nSimilarly, we can give an object a pay raise by updating its pay field—that is, by changing\\nits state information in-place with an assignment. This task also involves basic opera-\\ntions that work on Python’s core objects, regardless of whether they are standalone or\\nembedded in a class structure:\\n>>> pay = 100000            # Simple variable, outside class\\n>>> pay *= 1.10             # Give a 10% raise\\n>>> print(pay)              # Or: pay = pay * 1.10, if you like to type\\n110000.0                    # Or: pay = pay + (pay * .10), if you _really_ do!\\nTo apply these operations to the Person objects created by our script, simply do to\\nbob.name and sue.pay what we just did to name and pay. The operations are the same,\\nbut the subject objects are attached to attributes in our class structure:\\n# Process embedded built-in types: strings, mutability\\nclass Person:\\n    def __init__(self, name, job=None, pay=0):\\n        self.name = name\\n        self.job  = job\\n        self.pay  = pay\\nif __name__ == '__main__':\\n648 | Chapter 27: \\u2002A More Realistic Example\", metadata={'source': 'python.pdf', 'page': 698}),\n",
       " Document(page_content=\"    bob = Person('Bob Smith')\\n    sue = Person('Sue Jones', job='dev', pay=100000)\\n    print(bob.name, bob.pay)\\n    print(sue.name, sue.pay)\\n    print(bob.name.split()[-1])            # Extract object's last name\\n    sue.pay *= 1.10                        # Give this object a raise\\n    print(sue.pay)\\nWe’ve added the \\nlast two lines here; when they’re run, we extract bob’s last name by\\nusing basic string and list operations and give sue a pay raise by modifying her pay\\nattribute in-place with basic number operations. In a sense, sue is also a mutable\\nobject—her state changes in-place just like a list after an append call:\\nBob Smith 0\\nSue Jones 100000\\nSmith\\n110000.0\\nThe preceding code works as planned, but if you show it to a veteran software developer\\nhe’ll probably tell you that its general approach is not a great idea in practice. Hard-\\ncoding operations like these outside of the class can lead to maintenance problems in\\nthe future.\\nFor example, what if you’ve hardcoded the last-name-extraction formula at many dif-\\nferent places in your program? If you ever need to change the way it works (to support\\na new name structure, for instance), you’ll need to hunt down and update every oc-\\ncurrence. Similarly, if the pay-raise code ever changes (e.g., to require approval or\\ndatabase updates), you may have multiple copies to modify. Just finding all the ap-\\npearances of such code may be problematic in larger programs—they may be scattered\\nacross many files, split into individual steps, and so on.\\nCoding Methods\\nWhat we really want to do here is employ a software design concept known as encap-\\nsulation. The idea with encapsulation is to wrap up operation logic behind interfaces,\\nsuch that each operation is coded only once in our program. That way, if our needs\\nchange in the future, there is just one copy to update. Moreover, we’re free to change\\nthe single copy’s internals almost arbitrarily, without breaking the code that uses it.\\nIn Python terms, we want to code operations on objects in class methods, instead of\\nlittering them throughout our program. In fact, this is one of the things that classes are\\nvery good at— factoring code to remove redundancy and thus optimize maintainability.\\nAs an added bonus, turning operations into methods enables them to be applied to any\\ninstance of the class, not just those that they’ve been hardcoded to process.\\nThis is all simpler in code than it may sound in theory. The following achieves encap-\\nsulation by moving the two operations from code outside the class into class methods.\\nWhile we’re at it, let’s change our self-test code at the bottom to use the new methods\\nwe’re creating, instead of hardcoding operations:\\nStep 2: Adding Behavior Methods | 649\", metadata={'source': 'python.pdf', 'page': 699}),\n",
       " Document(page_content=\"# Add methods to encapsulate operations for maintainability\\nclass Person:\\n    def __init__(self, name, job=None, pay=0):\\n        self.name = name\\n        self.job  = job\\n        self.pay  = pay\\n    def lastName(self):                               # Behavior methods\\n        return self.name.split()[-1]                  # self is implied subject\\n    def giveRaise(self, percent):\\n        self.pay = int(self.pay * (1 + percent))      # Must change here only\\nif __name__ == '__main__':\\n    bob = Person('Bob Smith')\\n    sue = Person('Sue Jones', job='dev', pay=100000)\\n    print(bob.name, bob.pay)\\n    print(sue.name, sue.pay)\\n    print(bob.lastName(), sue.lastName())             # Use the new methods\\n    sue.giveRaise(.10)                                # instead of hardcoding\\n    print(sue.pay)\\nAs we’ve learned, methods\\n are simply normal functions that are attached to classes and\\ndesigned to process instances of those classes. The instance is the subject of the method\\ncall and is passed to the method’s self argument automatically.\\nThe transformation to the methods in this version is straightforward. The new\\nlastName method, for example, simply does to self what the previous version hardco-\\nded for bob, because self is the implied subject when the method is called. lastName\\nalso returns the result, because this operation is a called function now; it computes a\\nvalue for its caller to use, even if it is just to be printed. Similarly, the new giveRaise\\nmethod just does to self what we did to sue before.\\nWhen run now, our file’s output is similar to before—we’ve mostly just refactored the\\ncode to allow for easier changes in the future, not altered its behavior:\\nBob Smith 0\\nSue Jones 100000\\nSmith Jones\\n110000\\nA few coding details are worth pointing out here. First, notice that sue’s pay is now still\\nan integer after a pay raise—we convert the math result back to an integer by calling\\nthe int built-in within the method. Changing the value to either int or float is probably\\nnot a significant concern for most purposes (integer and floating-point objects have the\\nsame interfaces and can be mixed within expressions), but we may need to address\\nrounding issues in a real system (money probably matters to Persons!).\\nAs we learned in Chapter 5, we might handle this by using the round(N, 2) built-in to\\nround and retain cents, using the decimal type to fix precision, or storing monetary\\nvalues as full floating-point numbers and displaying them with a %.2f or {0:.2f} for-\\nmatting string to show cents. For this example, we’ll simply truncate any cents with\\n650 | Chapter 27: \\u2002A More Realistic Example\", metadata={'source': 'python.pdf', 'page': 700}),\n",
       " Document(page_content='int. (For another idea, also see the money function in the formats.py module of Chap-\\nter 24; you can import this tool to show pay with commas, cents, and dollar signs.)\\nSecond, notice that we’re also printing sue’s last name this time—because the last-name\\nlogic has been encapsulated in a method, we get to use it on any instance  of the class.\\nAs we’ve seen, Python tells a method which instance to process by automatically pass-\\ning it in to the first argument, usually called self. Specifically:\\n• In the first call, bob.lastName(), bob is the implied subject passed to self.\\n• In the second call, sue.lastName(), sue goes to self instead.\\nTrace through these calls to see how the instance winds up in self. The net effect is\\nthat the method fetches the name of the implied subject each time. The same happens\\nfor giveRaise. We could, for example, give bob a raise by calling giveRaise for both\\ninstances this way, too; but unfortunately, bob’s zero pay will prevent him from getting\\na raise as the program is currently coded (something we may want to address in a future\\n2.0 release of our software).\\nFinally, notice that the giveRaise method assumes that percent is passed in as a floating-\\npoint number between zero and one. That may be too radical an assumption in the real\\nworld (a 1000% raise would probably be a bug for most of us!); we’ll let it pass for this\\nprototype, but we might want to test or at least document this in a future iteration of\\nthis code. Stay tuned for a rehash of this idea in a later chapter in this book, where we’ll\\ncode something called function decorators and explore Python’s assert statement—\\nalternatives that can do the validity test for us automatically during development.\\nStep 3: Operator Overloading\\nAt this point, we have a fairly full-featured class that generates and initializes instances,\\nalong with two new bits of behavior for processing instances (in the form of methods).\\nSo far, so good.\\nAs it stands, though, testing is still a bit less convenient than it needs to be—to trace\\nour objects, we have to manually fetch and print individual attributes (e.g., bob.name,\\nsue.pay). It would be nice if displaying an instance all at once actually gave us some\\nuseful information. Unfortunately, the default display format for an instance object\\nisn’t very good—it displays the object’s class name, and its address in memory (which\\nis essentially useless in Python, except as a unique identifier).\\nTo see this, change the last line in the script to print(sue) so it displays the object as a\\nwhole. Here’s what you’ll get (the output says that sue is an “object” in 3.0 and an\\n“instance” in 2.6):\\nBob Smith 0\\nSue Jones 100000\\nSmith Jones\\n<__main__.Person object at 0x02614430>\\nStep 3: Operator Overloading | 651', metadata={'source': 'python.pdf', 'page': 701}),\n",
       " Document(page_content=\"Providing Print Displays\\nFortunately, it’s easy \\nto do better by employing operator overloading—coding methods\\nin a class that intercept and process built-in operations when run on the class’s\\ninstances. Specifically, we can make use of what is probably the second most commonly\\nused operator overloading method in Python, after __init__: the __str__ method in-\\ntroduced in the preceding chapter. __str__ is run automatically every time an instance\\nis converted to its print string. Because that’s what printing an object does, the net\\ntransitive effect is that printing an object displays whatever is returned by the object’s\\n__str__ method, if it either defines one itself or inherits one from a superclass (double-\\nunderscored names are inherited just like any other).\\nTechnically speaking, the __init__ constructor method we’ve already coded is operator\\noverloading too—it is run automatically at construction time to initialize a newly cre-\\nated instance. Constructors are so common, though, that they almost seem like a special\\ncase. More focused methods like __str__ allow us to tap into specific operations and\\nprovide specialized behavior when our objects are used in those contexts.\\nLet’s put this into code. The following extends our class to give a custom display that\\nlists attributes when our class’s instances are displayed as a whole, instead of relying\\non the less useful default display:\\n# Add __str__ overload method for printing objects\\nclass Person:\\n    def __init__(self, name, job=None, pay=0):\\n        self.name = name\\n        self.job  = job\\n        self.pay  = pay\\n    def lastName(self):\\n        return self.name.split()[-1]\\n    def giveRaise(self, percent):\\n        self.pay = int(self.pay * (1 + percent))\\n    def __str__(self):                                         # Added method\\n        return '[Person: %s, %s]' % (self.name, self.pay)      # String to print\\nif __name__ == '__main__':\\n    bob = Person('Bob Smith')\\n    sue = Person('Sue Jones', job='dev', pay=100000)\\n    print(bob)\\n    print(sue)\\n    print(bob.lastName(), sue.lastName())\\n    sue.giveRaise(.10)\\n    print(sue)\\nNotice that we’re doing string % formatting to build the display string in __str__ here;\\nat the bottom, classes use built-in type objects and operations like these to get their\\nwork done. Again, everything you’ve already learned about both built-in types and\\nfunctions applies to class-based code. Classes largely just add an additional layer of\\nstructure that packages functions and data together and supports extensions.\\n652 | Chapter 27: \\u2002A More Realistic Example\", metadata={'source': 'python.pdf', 'page': 702}),\n",
       " Document(page_content='We’ve also changed our self-test code to print objects directly, instead of printing in-\\ndividual attributes. When \\nrun, the output is more coherent and meaningful now; the\\n“[...]” lines are returned by our new __str__, run automatically by print operations:\\n[Person: Bob Smith, 0]\\n[Person: Sue Jones, 100000]\\nSmith Jones\\n[Person: Sue Jones, 110000]\\nHere’s a subtle point: as we’ll learn in the next chapter, a related overloading method,\\n__repr__, provides an as-code low-level display of an object when present. Sometimes\\nclasses provide both a __str__ for user-friendly displays and a __repr__ with extra de-\\ntails for developers to view. Because printing runs __str__ and the interactive prompt\\nechoes results with __repr__, this can provide both target audiences with an appropriate\\ndisplay. Since we’re not interested in displaying an as-code format, __str__ is sufficient\\nfor our class.\\nStep 4: Customizing Behavior by Subclassing\\nAt this point, our class captures much of the OOP machinery in Python: it makes\\ninstances, provides behavior in methods, and even does a bit of operator overloading\\nnow to intercept print operations in __str__. It effectively packages our data and logic\\ntogether into a single, self-contained software component, making it easy to locate code\\nand straightforward to change it in the future. By allowing us to encapsulate behavior,\\nit also allows us to factor that code to avoid redundancy and its associated maintenance\\nheadaches.\\nThe only major OOP concept it does not yet capture is customization by inheritance.\\nIn some sense, we’re already doing inheritance, because instances inherit methods from\\ntheir classes. To demonstrate the real power of OOP, though, we need to define a\\nsuperclass/subclass relationship that allows us to extend our software and replace bits\\nof inherited behavior. That’s the main idea behind OOP, after all; by fostering a coding\\nmodel based upon customization of work already done, it can dramatically cut devel-\\nopment time.\\nCoding Subclasses\\nAs a next step, then, let’s put OOP’s methodology to use and customize our Person\\nclass by extending our software hierarchy. For the purpose of this tutorial, we’ll define\\na subclass of Person called Manager that replaces the inherited giveRaise method with\\na more specialized version. Our new class begins as follows:\\nclass Manager(Person):                          # Define a subclass of Person\\nThis code means that we’re defining a new class named Manager, which inherits from\\nand may add customizations to the superclass Person. In plain terms, a Manager is almost\\nStep 4: Customizing Behavior by Subclassing | 653', metadata={'source': 'python.pdf', 'page': 703}),\n",
       " Document(page_content='like a Person (admittedly, a very long journey for a very small joke...), but Manager has\\na custom way to give raises.\\nFor the sake \\nof argument, let’s assume that when a Manager gets a raise, it receives the\\npassed-in percentage as usual, but also gets an extra bonus that defaults to 10%. For\\ninstance, if a Manager’s raise is specified as 10%, it will really get 20%. (Any relation to\\nPersons living or dead is, of course, strictly coincidental.) Our new method begins as\\nfollows; because this redefinition of giveRaise will be closer in the class tree to\\nManager instances than the original version in Person, it effectively replaces, and thereby\\ncustomizes, the operation. Recall that according to the inheritance search rules, the\\nlowest version of the name wins:\\nclass Manager(Person):                          # Inherit Person attrs\\n    def giveRaise(self, percent, bonus=.10):    # Redefine to customize\\nAugmenting Methods: The Bad Way\\nNow, there are two ways we might code this Manager customization: a good way and a\\nbad way. Let’s start with the bad way , since it might be a bit easier to understand. The\\nbad way is to cut and paste the code of giveRaise in Person and modify it for Manager,\\nlike this:\\nclass Manager(Person):\\n    def giveRaise(self, percent, bonus=.10):\\n        self.pay = int(self.pay * (1 + percent + bonus))   # Bad: cut-and-paste\\nThis works as advertised—when we later call the giveRaise method of a Manager in-\\nstance, it will run this custom version, which tacks on the extra bonus. So what’s wrong\\nwith something that runs correctly?\\nThe problem here is a very general one: any time you copy code with cut and paste,\\nyou essentially double your maintenance effort in the future. Think about it: because\\nwe copied the original version, if we ever have to change the way raises are given (and\\nwe probably will), we’ll have to change the code in two places, not one. Although this\\nis a small and artificial example, it’s also representative of a universal issue—any time\\nyou’re tempted to program by copying code this way, you probably want to look for a\\nbetter approach.\\nAugmenting Methods: The Good Way\\nWhat we really want to do here is somehow augment the original giveRaise, instead of\\nreplacing it altogether. The good way  to do that in Python is by calling to the original\\nversion directly, with augmented arguments, like this:\\nclass Manager(Person):\\n    def giveRaise(self, percent, bonus=.10):\\n        Person.giveRaise(self, percent + bonus)            # Good: augment original\\n654 | Chapter 27: \\u2002A More Realistic Example', metadata={'source': 'python.pdf', 'page': 704}),\n",
       " Document(page_content=\"This code leverages the fact that a class method can always be called either through an\\ninstance (the usual \\nway, where Python sends the instance to the self argument auto-\\nmatically) or through the class (the less common scheme, where you must pass the\\ninstance manually). In more symbolic terms, recall that a normal method call of this\\nform:\\ninstance.method(args...)\\nis automatically translated by Python into this equivalent form:\\nclass.method(instance, args...)\\nwhere the class containing the method to be run is determined by the inheritance search\\nrule applied to the method’s name. You can code either form in your script, but there\\nis a slight asymmetry between the two—you must remember to pass along the instance\\nmanually if you call through the class directly. The method always needs a subject\\ninstance one way or another, and Python provides it automatically only for calls made\\nthrough an instance. For calls through the class name, you need to send an instance to\\nself yourself; for code inside a method like giveRaise, self already is the subject of the\\ncall, and hence the instance to pass along.\\nCalling through the class directly effectively subverts inheritance and kicks the call\\nhigher up the class tree to run a specific version. In our case, we can use this technique\\nto invoke the default giveRaise in Person, even though it’s been redefined at the\\nManager level. In some sense, we must call through Person this way, because a\\nself.giveRaise() inside Manager’s giveRaise code would loop—since self already is a\\nManager, self.giveRaise() would resolve again to Manager.giveRaise, and so on and so\\nforth until available memory is exhausted.\\nThis “good” version may seem like a small difference in code, but it can make a huge\\ndifference for future code maintenance —because the giveRaise logic lives in just one\\nplace now ( Person’s method), we have only one version to change in the future as needs\\nevolve. And really, this form captures our intent more directly anyhow—we want to\\nperform the standard giveRaise operation, but simply tack on an extra bonus. Here’s\\nour entire module file with this step applied:\\n# Add customization of one behavior in a subclass\\nclass Person:\\n    def __init__(self, name, job=None, pay=0):\\n        self.name = name\\n        self.job  = job\\n        self.pay  = pay\\n    def lastName(self):\\n        return self.name.split()[-1]\\n    def giveRaise(self, percent):\\n        self.pay = int(self.pay * (1 + percent))\\n    def __str__(self):\\n        return '[Person: %s, %s]' % (self.name, self.pay)\\nclass Manager(Person):\\nStep 4: Customizing Behavior by Subclassing | 655\", metadata={'source': 'python.pdf', 'page': 705}),\n",
       " Document(page_content=\"    def giveRaise(self, percent, bonus=.10):           # Redefine at this level\\n        Person.giveRaise(self, percent + bonus)        # Call Person's version\\nif __name__ == '__main__':\\n    bob = Person('Bob Smith')\\n    sue = Person('Sue Jones', job='dev', pay=100000)\\n    print(bob)\\n    print(sue)\\n    print(bob.lastName(), sue.lastName())\\n    sue.giveRaise(.10)\\n    print(sue)\\n    tom = Manager('Tom Jones', 'mgr', 50000)           # Make a Manager: __init__\\n    tom.giveRaise(.10)                                 # Runs custom version\\n    print(tom.lastName())                              # Runs inherited method\\n    print(tom)                                         # Runs inherited __str__\\nTo test our Manager\\n subclass customization, we’ve also added self-test code that makes\\na Manager, calls its methods, and prints it. Here’s the new version’s output:\\n[Person: Bob Smith, 0]\\n[Person: Sue Jones, 100000]\\nSmith Jones\\n[Person: Sue Jones, 110000]\\nJones\\n[Person: Tom Jones, 60000]\\nEverything looks good here: bob and sue are as before, and when tom the Manager is\\ngiven a 10% raise, he really gets 20% (his pay goes from $50K to $60K), because the\\ncustomized giveRaise in Manager is run for him only. Also notice how printing tom as a\\nwhole at the end of the test code displays the nice format defined in Person’s __str__:\\nManager objects get this, lastName, and the __init__ constructor method’s code “for\\nfree” from Person, by inheritance.\\nPolymorphism in Action\\nTo make this acquisition of inherited behavior even more striking, we can add the\\nfollowing code at the end of our file:\\nif __name__ == '__main__':\\n    ...\\n    print('--All three--')\\n    for object in (bob, sue, tom):            # Process objects generically\\n        object.giveRaise(.10)                 # Run this object's giveRaise\\n        print(object)                         # Run the common __str__\\nHere’s the resulting output:\\n[Person: Bob Smith, 0]\\n[Person: Sue Jones, 100000]\\nSmith Jones\\n[Person: Sue Jones, 110000]\\nJones\\n[Person: Tom Jones, 60000]\\n--All three--\\n656 | Chapter 27: \\u2002A More Realistic Example\", metadata={'source': 'python.pdf', 'page': 706}),\n",
       " Document(page_content='[Person: Bob Smith, 0]\\n[Person: Sue Jones, 121000]\\n[Person: Tom Jones, 72000]\\nIn the added \\ncode, object is either a Person or a Manager, and Python runs the appro-\\npriate giveRaise automatically—our original version in Person for bob and sue, and our\\ncustomized version in Manager for tom. Trace the method calls yourself to see how Py-\\nthon selects the right giveRaise method for each object.\\nThis is just Python’s notion of polymorphism, which we met earlier in the book, at work\\nagain—what giveRaise does depends on what you do it to. Here, it’s made all the more\\nobvious when it selects from code we’ve written ourselves in classes. The practical effect\\nin this code is that sue gets another 10% but tom gets another 20%, because\\ngiveRaise is dispatched based upon the object’s type. As we’ve learned, polymorphism\\nis at the heart of Python’s flexibility. Passing any of our three objects to a function that\\ncalls a giveRaise method, for example, would have the same effect: the appropriate\\nversion would be run automatically, depending on which type of object was passed.\\nOn the other hand, printing runs the same __str__ for all three objects, because it’s\\ncoded just once in Person. Manager both specializes and applies the code we originally\\nwrote in Person. Although this example is small, it’s already leveraging OOP’s talent\\nfor code customization and reuse; with classes, this almost seems automatic at times.\\nInherit, Customize, and Extend\\nIn fact, classes can be even more flexible than our example implies. In general, classes\\ncan inherit, customize, or extend existing code in superclasses. For example, although\\nwe’re focused on customization here, we can also add unique methods to Manager that\\nare not present in Person, if Managers require something completely different (Python\\nnamesake reference intended). The following snippet illustrates. Here, giveRaise re-\\ndefines a superclass method to customize it, but someThingElse defines something new\\nto extend:\\nclass Person:\\n    def lastName(self): ...\\n    def giveRaise(self): ...\\n    def __str__(self): ...\\nclass Manager(Person):                        # Inherit\\n    def giveRaise(self, ...): ...             # Customize\\n    def someThingElse(self, ...): ...         # Extend\\ntom = Manager()\\ntom.lastName()                                # Inherited verbatim\\ntom.giveRaise()                               # Customized version\\ntom.someThingElse()                           # Extension here\\nprint(tom)                                    # Inherited overload method\\nExtra methods like this code’s someThingElse extend the existing software and are avail-\\nable on Manager objects only, not on Persons. For the purposes of this tutorial, however,\\nStep 4: Customizing Behavior by Subclassing | 657', metadata={'source': 'python.pdf', 'page': 707}),\n",
       " Document(page_content='we’ll limit our scope to customizing some of Person’s behavior by redefining it, not\\nadding to it.\\nOOP: The Big Idea\\nAs is, our code may be small, but it’s fairly functional. And really, it already illustrates\\nthe main point behind OOP in general: in OOP, we program by customizing what has\\nalready been done, rather than copying or changing existing code. This isn’t always an\\nobvious win to newcomers at first glance, especially given the extra coding requirements\\nof classes. But overall, the programming style implied by classes can cut development\\ntime radically compared to other approaches.\\nFor instance, in our example we could theoretically have implemented a custom\\ngiveRaise operation without subclassing, but none of the other options yield code as\\noptimal as ours:\\n• Although we could have simply coded Manager from scratch  as new, independent\\ncode, we would have had to reimplement all the behaviors in Person that are the\\nsame for Managers.\\n• Although we could have simply changed the existing Person class in-place for the\\nrequirements of Manager’s giveRaise, doing so would probably break the places\\nwhere we still need the original Person behavior.\\n• Although we could have simply copied the Person class in its entirety, renamed the\\ncopy to Manager, and changed its giveRaise, doing so would introduce code re-\\ndundancy that would double our work in the future—changes made to Person in\\nthe future would not be picked up automatically, but would have to be manually\\npropagated to Manager’s code. As usual, the cut-and-paste approach may seem\\nquick now, but it doubles your work in the future.\\nThe customizable hierarchies  we can build with classes provide a much better solution\\nfor software that will evolve over time. No other tools in Python support this develop-\\nment mode. Because we can tailor and extend our prior work by coding new subclasses,\\nwe can leverage what we’ve already done, rather than starting from scratch each time,\\nbreaking what already works, or introducing multiple copies of code that may all have\\nto be updated in the future. When done right, OOP is a powerful programmer’s ally.\\nStep 5: Customizing Constructors, Too\\nOur code works as it is, but if you study the current version closely, you may be struck\\nby something a bit odd—it seems pointless to have to provide a mgr job name for\\nManager objects when we create them: this is already implied by the class itself. It would\\nbe better if we could somehow fill in this value automatically when a Manager is made.\\nThe trick we need to improve on this turns out to be the same as the one we employed\\nin the prior section: we want to customize the constructor logic for Managers in such a\\n658 | Chapter 27: \\u2002A More Realistic Example', metadata={'source': 'python.pdf', 'page': 708}),\n",
       " Document(page_content=\"way as to provide a job name automatically. In terms of code, we want to redefine an\\n__init__ method in Manager\\n that provides the mgr string for us. And like with the\\ngiveRaise customization, we also want to run the original __init__ in Person by calling\\nthrough the class name, so it still initializes our objects’ state information attributes.\\nThe following extension will do the job—we’ve coded the new Manager constructor and\\nchanged the call that creates tom to not pass in the mgr job name:\\n# Add customization of constructor in a subclass\\nclass Person:\\n    def __init__(self, name, job=None, pay=0):\\n        self.name = name\\n        self.job  = job\\n        self.pay  = pay\\n    def lastName(self):\\n        return self.name.split()[-1]\\n    def giveRaise(self, percent):\\n        self.pay = int(self.pay * (1 + percent))\\n    def __str__(self):\\n        return '[Person: %s, %s]' % (self.name, self.pay)\\nclass Manager(Person):\\n    def __init__(self, name, pay):                     # Redefine constructor\\n        Person.__init__(self, name, 'mgr', pay)        # Run original with 'mgr'\\n    def giveRaise(self, percent, bonus=.10):\\n        Person.giveRaise(self, percent + bonus)\\nif __name__ == '__main__':\\n    bob = Person('Bob Smith')\\n    sue = Person('Sue Jones', job='dev', pay=100000)\\n    print(bob)\\n    print(sue)\\n    print(bob.lastName(), sue.lastName())\\n    sue.giveRaise(.10)\\n    print(sue)\\n    tom = Manager('Tom Jones', 50000)                   # Job name not needed:\\n    tom.giveRaise(.10)                                  # Implied/set by class\\n    print(tom.lastName())\\n    print(tom)\\nAgain, we’re using the same technique to augment the __init__ constructor here that\\nwe used for giveRaise earlier—running the superclass version by calling through the\\nclass name directly and passing the self instance along explicitly. Although the con-\\nstructor has a strange name, the effect is identical. Because we need Person’s construc-\\ntion logic to run too (to initialize instance attributes), we really have to call it this way;\\notherwise, instances would not have any attributes attached.\\nCalling superclass constructors from redefinitions this way turns out to be a very\\ncommon coding pattern in Python. By itself, Python uses inheritance to look for and\\ncall only one __init__ method at construction time—the lowest one in the class tree. If\\nyou need higher __init__ methods to be run at construction time (and you usually do),\\nStep 5: Customizing Constructors, Too | 659\", metadata={'source': 'python.pdf', 'page': 709}),\n",
       " Document(page_content='you must call them manually through the superclass’s name. The upside to this is that\\nyou can be \\nexplicit about which argument to pass up to the superclass’s constructor\\nand can choose to not call it at all: not calling the superclass constructor allows you to\\nreplace its logic altogether, rather than augmenting it.\\nThe output of this file’s self-test code is the same as before—we haven’t changed what\\nit does, we’ve simply restructured to get rid of some logical redundancy:\\n[Person: Bob Smith, 0]\\n[Person: Sue Jones, 100000]\\nSmith Jones\\n[Person: Sue Jones, 110000]\\nJones\\n[Person: Tom Jones, 60000]\\nOOP Is Simpler Than You May Think\\nIn this complete form, despite their sizes, our classes capture nearly all the important\\nconcepts in Python’s OOP machinery:\\n• Instance creation—filling out instance attributes\\n• Behavior methods—encapsulating logic in class methods\\n• Operator overloading—providing behavior for built-in operations like printing\\n• Customizing behavior—redefining methods in subclasses to specialize them\\n• Customizing constructors—adding initialization logic to superclass steps\\nMost of these concepts are based upon just three simple ideas: the inheritance search\\nfor attributes in object trees, the special self argument in methods, and operator over-\\nloading’s automatic dispatch to methods.\\nAlong the way, we’ve also made our code easy to change in the future, by harnessing\\nthe class’s propensity for factoring code to reduce redundancy. For example, we wrap-\\nped up logic in methods and called back to superclass methods from extensions to\\navoid having multiple copies of the same code. Most of these steps were a natural\\noutgrowth of the structuring power of classes.\\nBy and large, that’s all there is to OOP in Python. Classes certainly can become larger\\nthan this, and there are some more advanced class concepts, such as decorators and\\nmetaclasses, which we will meet in later chapters. In terms of the basics, though, our\\nclasses already do it all. In fact, if you’ve grasped the workings of the classes we’ve\\nwritten, most OOP Python code should now be within your reach.\\nOther Ways to Combine Classes\\nHaving said that, I should also tell you that although the basic mechanics of OOP are\\nsimple in Python, some of the art in larger programs lies in the way that classes are put\\ntogether. We’re focusing on inheritance in this tutorial because that’s the mechanism\\n660 | Chapter 27: \\u2002A More Realistic Example', metadata={'source': 'python.pdf', 'page': 710}),\n",
       " Document(page_content=\"the Python language provides, but programmers sometimes combine classes in other\\nways, too. For \\nexample, a common coding pattern involves nesting objects inside each\\nother to build up composites. We’ll explore this pattern in more detail in Chapter 30 ,\\nwhich is really more about design than about Python; as a quick example, though, we\\ncould use this composition idea to code our Manager extension by embedding a\\nPerson, instead of inheriting from it.\\nThe following alternative does so by using the __getattr__ operator overloading\\nmethod we will meet in Chapter 29 to intercept undefined attribute fetches and delegate\\nthem to the embedded object with the getattr built-in. The giveRaise method here\\nstill achieves customization, by changing the argument passed along to the embedded\\nobject. In effect, Manager becomes a controller layer that passes calls down to the em-\\nbedded object, rather than up to superclass methods:\\n# Embedding-based Manager alternative\\nclass Person:\\n    ...same...\\nclass Manager:\\n    def __init__(self, name, pay):\\n        self.person = Person(name, 'mgr', pay)      # Embed a Person object\\n    def giveRaise(self, percent, bonus=.10):\\n        self.person.giveRaise(percent + bonus)      # Intercept and delegate\\n    def __getattr__(self, attr):\\n        return getattr(self.person, attr)           # Delegate all other attrs\\n    def __str__(self):\\n        return str(self.person)                     # Must overload again (in 3.0)\\nif __name__ == '__main__':\\n    ...same...\\nIn fact, this Manager alternative is representative of a general coding pattern usually\\nknown as delegation—a composite-based structure that manages a wrapped object and\\npropagates method calls to it. This pattern works in our example, but it requires about\\ntwice as much code and is less well suited than inheritance to the kinds of direct cus-\\ntomizations we meant to express (in fact, no reasonable Python programmer would\\ncode this example this way in practice, except perhaps those writing general tutorials).\\nManager isn’t really a Person here, so we need extra code to manually dispatch method\\ncalls to the embedded object; operator overloading methods like __str__ must be re-\\ndefined (in 3.0, at least, as noted in the upcoming sidebar “Catching Built-in Attributes\\nin 3.0” on page 662), and adding new Manager behavior is less straightforward since\\nstate information is one level removed.\\nStill, object embedding , and design patterns based upon it, can be a very good fit when\\nembedded objects require more limited interaction with the container than direct cus-\\ntomization implies. A controller layer like this alternative Manager, for example, might\\ncome in handy if we want to trace or validate calls to another object’s methods (indeed,\\nwe will use a nearly identical coding pattern when we study class decorators  later in the\\nStep 5: Customizing Constructors, Too | 661\", metadata={'source': 'python.pdf', 'page': 711}),\n",
       " Document(page_content=\"book). Moreover, a hypothetical Department class like the following could aggregate\\nother objects in order to treat them as a set. Add this to the bottom of the person.py file\\nto try this on your own:\\n# Aggregate embedded objects into a composite\\n...\\nbob = Person(...)\\nsue = Person(...)\\ntom = Manager(...)\\nclass Department:\\n    def __init__(self, *args):\\n        self.members = list(args)\\n    def addMember(self, person):\\n        self.members.append(person)\\n    def giveRaises(self, percent):\\n        for person in self.members:\\n            person.giveRaise(percent)\\n    def showAll(self):\\n        for person in self.members:\\n            print(person)\\ndevelopment = Department(bob, sue)          # Embed objects in a composite\\ndevelopment.addMember(tom)\\ndevelopment.giveRaises(.10)                 # Runs embedded objects' giveRaise\\ndevelopment.showAll()                       # Runs embedded objects' __str__s\\nInterestingly, this code uses both inheritance and composition— Department is a com-\\nposite that embeds and controls other objects to aggregate, but the embedded Person\\nand Manager objects themselves use inheritance to customize. As another example, a\\nGUI might similarly use inheritance to customize the behavior or appearance of labels\\nand buttons, but also composition to build up larger packages of embedded widgets,\\nsuch as input forms, calculators, and text editors. The class structure to use depends\\non the objects you are trying to model.\\nDesign issues like composition are explored in Chapter 30 , so we’ll postpone further\\ninvestigations for now. But again, in terms of the basic mechanics of OOP in Python,\\nour Person and Manager classes already tell the entire story. Having mastered the basics\\nof OOP, though, developing general tools for applying it more easily in your scripts is\\noften a natural next step—and the topic of the next section.\\nCatching Built-in Attributes in 3.0\\nIn Python 3.0 (and \\n2.6 if new-style classes are used), the alternative delegation-based\\nManager class we just coded will not be able to intercept and delegate operator over-\\nloading method attributes like __str__ without redefining them. Although we know\\nthat __str__ is the only such name used in our specific example, this a general issue for\\ndelegation-based classes.\\nRecall that built-in operations like printing and indexing implicitly invoke operator\\noverloading methods such as __str__ and __getitem__. In 3.0, built-in operations like\\n662 | Chapter 27: \\u2002A More Realistic Example\", metadata={'source': 'python.pdf', 'page': 712}),\n",
       " Document(page_content='these do not route their implicit attribute fetches through generic attribute managers:\\nneither __getattr__ (run for \\nundefined attributes) nor its cousin __getattribute__ (run\\nfor all attributes) is invoked. This is why we have to redefine __str__ redundantly in\\nthe alternative Manager, in order to ensure that printing is routed to the embedded\\nPerson object when run in Python 3.0.\\nTechnically, this happens because classic classes normally look up operator overloading\\nnames in instances at runtime, but new-style classes do not—they skip the instance\\nentirely and look up such methods in classes. In 2.6 classic classes, built-ins do route\\nattributes generically—printing, for example, routes __str__ through __getattr__.\\nNew-style classes also inherit a default for __str__ that would foil __getattr__, but\\n__getattribute__ doesn’t intercept the name in 3.0 either.\\nThis is a change, but isn’t a show-stopper—delegation-based classes can generally re-\\ndefine operator overloading methods to delegate them to wrapped objects in 3.0, either\\nmanually or via tools or superclasses. This topic is too advanced to explore further in\\nthis tutorial, though, so don’t sweat the details too much here. Watch for it to be\\nrevisited in the attribute management coverage of Chapter 37, and again in the context\\nof Private class decorators in Chapter 38.\\nStep 6: Using Introspection Tools\\nLet’s make one final \\ntweak before we throw our objects onto a database. As they are,\\nour classes are complete and demonstrate most of the basics of OOP in Python. They\\nstill have two remaining issues we probably should iron out, though, before we go live\\nwith them:\\n• First, if you look at the display of the objects as they are right now, you’ll notice\\nthat when you print tom the Manager labels him as a Person. That’s not technically\\nincorrect, since Manager is a kind of customized and specialized Person. Still, it\\nwould be more accurate to display objects with the most specific (that is, lowest)\\nclasses possible.\\n• Second, and perhaps more importantly, the current display format shows only the\\nattributes we include in our __str__, and that might not account for future goals.\\nFor example, we can’t yet verify that tom’s job name has been set to mgr correctly\\nby Manager’s constructor, because the __str__ we coded for Person does not print\\nthis field. Worse, if we ever expand or otherwise change the set of attributes as-\\nsigned to our objects in __init__, we’ll have to remember to also update __str__\\nfor new names to be displayed, or it will become out of sync over time.\\nThe last point means that, yet again, we’ve made potential extra work for ourselves in\\nthe future by introducing redundancy in our code. Because any disparity in __str__ will\\nbe reflected in the program’s output, this redundancy may be more obvious than the\\nother forms we addressed earlier; still, avoiding extra work in the future is generally a\\ngood thing.\\nStep 6: Using Introspection Tools | 663', metadata={'source': 'python.pdf', 'page': 713}),\n",
       " Document(page_content=\"Special Class Attributes\\nWe can address \\nboth issues with Python’s introspection tools—special attributes and\\nfunctions that give us access to some of the internals of objects’ implementations. These\\ntools are somewhat advanced and generally used more by people writing tools for other\\nprogrammers to use than by programmers developing applications. Even so, a basic\\nknowledge of some of these tools is useful because they allow us to write code that\\nprocesses classes in generic ways. In our code, for example, there are two hooks that\\ncan help us out, both of which were introduced near the end of the preceding chapter:\\n• The built-in instance.__class__ attribute provides a link from an instance to the\\nclass from which it was created. Classes in turn have a __name__, just like modules,\\nand a __bases__ sequence that provides access to superclasses. We can use these\\nhere to print the name of the class from which an instance is made rather than one\\nwe’ve hardcoded.\\n• The built-in object.__dict__ attribute provides a dictionary with one key/value\\npair for every attribute attached to a namespace object (including modules, classes,\\nand instances). Because it is a dictionary, we can fetch its keys list, index by key,\\niterate over its keys, and so on, to process all attributes generically. We can use this\\nhere to print every attribute in any instance, not just those we hardcode in custom\\ndisplays.\\nHere’s what these tools look like in action at Python’s interactive prompt. Notice how\\nwe load Person at the interactive prompt with a from statement here—class names live\\nin and are imported from modules, exactly like function names and other variables:\\n>>> from person import Person\\n>>> bob = Person('Bob Smith')\\n>>> print(bob)                                 # Show bob's __str__\\n[Person: Bob Smith, 0]\\n>>> bob.__class__                              # Show bob's class and its name\\n<class 'person.Person'>\\n>>> bob.__class__.__name__\\n'Person'\\n>>> list(bob.__dict__.keys())                  # Attributes are really dict keys\\n['pay', 'job', 'name']                         # Use list to force list in 3.0\\n>>> for key in bob.__dict__:\\n        print(key, '=>', bob.__dict__[key])    # Index manually\\npay => 0\\njob => None\\nname => Bob Smith\\n>>> for key in bob.__dict__:\\n        print(key, '=>', getattr(bob, key))    # obj.attr, but attr is a var\\npay => 0\\n664 | Chapter 27: \\u2002A More Realistic Example\", metadata={'source': 'python.pdf', 'page': 714}),\n",
       " Document(page_content='job => None\\nname => Bob Smith\\nAs noted briefly \\nin the prior chapter, some attributes accessible from an instance might\\nnot be stored in the __dict__ dictionary if the instance’s class defines __slots__, an\\noptional and relatively obscure feature of new-style classes (and all classes in Python\\n3.0) that stores attributes in an array and that we’ll discuss in Chapters 30 and 31. Since\\nslots really belong to classes instead of instances, and since they are very rarely used in\\nany event, we can safely ignore them here and focus on the normal __dict__.\\nA Generic Display Tool\\nWe can put these interfaces to work in a superclass that displays accurate class names\\nand formats all attributes of an instance of any class. Open a new file in your text editor\\nto code the following—it’s a new, independent module named classtools.py that im-\\nplements just such a class. Because its __str__ print overload uses generic introspection\\ntools, it will work on any instance , regardless of its attributes set. And because this is a\\nclass, it automatically becomes a general formatting tool: thanks to inheritance, it can\\nbe mixed into any class  that wishes to use its display format. As an added bonus, if we\\never want to change how instances are displayed we need only change this class, as\\nevery class that inherits its __str__ will automatically pick up the new format when it’s\\nnext run:\\n# File classtools.py (new)\\n\"Assorted class utilities and tools\"\\nclass AttrDisplay:\\n    \"\"\"\\n    Provides an inheritable print overload method that displays\\n    instances with their class names and a name=value pair for\\n    each attribute stored on the instance itself (but not attrs\\n    inherited from its classes). Can be mixed into any class,\\n    and will work on any instance.\\n    \"\"\"\\n    def gatherAttrs(self):\\n        attrs = []\\n        for key in sorted(self.__dict__):\\n            attrs.append(\\'%s=%s\\' % (key, getattr(self, key)))\\n        return \\', \\'.join(attrs)\\n    def __str__(self):\\n        return \\'[%s: %s]\\' % (self.__class__.__name__, self.gatherAttrs())\\nif __name__ == \\'__main__\\':\\n    class TopTest(AttrDisplay):\\n        count = 0\\n        def __init__(self):\\n            self.attr1 = TopTest.count\\n            self.attr2 = TopTest.count+1\\n            TopTest.count += 2\\nStep 6: Using Introspection Tools | 665', metadata={'source': 'python.pdf', 'page': 715}),\n",
       " Document(page_content=\"    class SubTest(TopTest):\\n        pass\\n    X, Y = TopTest(), SubTest()\\n    print(X)                         # Show all instance attrs\\n    print(Y)                         # Show lowest class name\\nNotice the docstrings \\nhere—as a general-purpose tool, we want to add some functional\\ndocumentation for potential users to read. As we saw in Chapter 15 , docstrings can be\\nplaced at the top of simple functions and modules, and also at the start of classes and\\ntheir methods; the help function and the PyDoc tool extracts and displays these auto-\\nmatically (we’ll look at docstrings again in Chapter 28).\\nWhen run directly, this module’s self-test makes two instances and prints them; the\\n__str__ defined here shows the instance’s class, and all its attributes names and values,\\nin sorted attribute name order:\\nC:\\\\misc> classtools.py\\n[TopTest: attr1=0, attr2=1]\\n[SubTest: attr1=2, attr2=3]\\nInstance Versus Class Attributes\\nIf you study the classtools module’s self-test code long enough, you’ll notice that its\\nclass displays only instance attributes , attached to the self object at the bottom of the\\ninheritance tree; that’s what self’s __dict__ contains. As an intended consequence, we\\ndon’t see attributes inherited by the instance from classes above it in the tree (e.g.,\\ncount in this file’s self-test code). Inherited class attributes are attached to the class only,\\nnot copied down to instances.\\nIf you ever do wish to include inherited attributes too, you can climb the __class__ link\\nto the instance’s class, use the __dict__ there to fetch class attributes, and then iterate\\nthrough the class’s __bases__ attribute to climb to even higher superclasses (repeating\\nas necessary). If you’re a fan of simple code, running a built-in dir call on the instance\\ninstead of using __dict__ and climbing would have much the same effect, since dir\\nresults include inherited names in the sorted results list:\\n>>> from person import Person\\n>>> bob = Person('Bob Smith')\\n# In Python 2.6:\\n>>> bob.__dict__.keys()                 # Instance attrs only\\n['pay', 'job', 'name']\\n>>> dir(bob)                            # + inherited attrs in classes\\n['__doc__', '__init__', '__module__', '__str__', 'giveRaise', 'job',\\n'lastName', 'name', 'pay']\\n# In Python 3.0:\\n666 | Chapter 27: \\u2002A More Realistic Example\", metadata={'source': 'python.pdf', 'page': 716}),\n",
       " Document(page_content=\">>> list(bob.__dict__.keys())           # 3.0 keys is a view, not a list\\n['pay', 'job', 'name']\\n>>> dir(bob)                            # 3.0 includes class type methods\\n['__class__', '__delattr__', '__dict__', '__doc__', '__eq__', '__format__',\\n'__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__le__',\\n...more lines omitted...\\n'__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__',\\n'giveRaise', 'job', 'lastName', 'name', 'pay']\\nThe output here \\nvaries between Python 2.6 and 3.0, because 3.0’s dict.keys is not a\\nlist, and 3.0’s dir returns extra class-type implementation attributes. Technically, dir\\nreturns more in 3.0 because classes are all “new style” and inherit a large set of operator\\noverloading names from the class type. In fact, you’ll probably want to filter out most\\nof the __X__ names in the 3.0 dir result, since they are internal implementation details\\nand not something you’d normally want to display.\\nIn the interest of space, we’ll leave optional display of inherited class attributes with\\neither tree climbs or dir as suggested experiments for now. For more hints on this front,\\nthough, watch for the classtree.py inheritance tree climber we will write in Chap-\\nter 28, and the lister.py attribute listers and climbers we’ll code in Chapter 30.\\nName Considerations in Tool Classes\\nOne last subtlety here: because our AttrDisplay class in the classtools module is a\\ngeneral tool designed to be mixed into other arbitrary classes, we have to be aware of\\nthe potential for unintended name collisions  with client classes. As is, I’ve assumed that\\nclient subclasses may want to use both its __str__ and gatherAttrs, but the latter of\\nthese may be more than a subclass expects—if a subclass innocently defines a gather\\nAttrs name of its own, it will likely break our class, because the lower version in the\\nsubclass will be used instead of ours.\\nTo see this for yourself, add a gatherAttrs to TopTest in the file’s self-test code; unless\\nthe new method is identical, or intentionally customizes the original, our tool class will\\nno longer work as planned:\\n    class TopTest(AttrDisplay):\\n        ....\\n        def gatherAttrs(self):         # Replaces method in AttrDisplay!\\n            return 'Spam'\\nThis isn’t necessarily bad—sometimes we want other methods to be available to sub-\\nclasses, either for direct calls or for customization. If we really meant to provide a\\n__str__ only, though, this is less than ideal.\\nTo minimize the chances of name collisions like this, Python programmers often prefix\\nmethods not meant for external use with a single underscore : _gatherAttrs in our case.\\nThis isn’t foolproof (what if another class defines _gatherAttrs, too?), but it’s usually\\nsufficient, and it’s a common Python naming convention for methods internal to a class.\\nStep 6: Using Introspection Tools | 667\", metadata={'source': 'python.pdf', 'page': 717}),\n",
       " Document(page_content='A better and less commonly used solution would be to use two underscores  at the front\\nof the method name only: __gatherAttrs for us. Python automatically expands such\\nnames to include the enclosing class’s name, which makes them truly unique. This is\\na feature usually called pseudoprivate class attributes , which we’ll expand on in Chap-\\nter 30. For now, we’ll make both our methods available.\\nOur Classes’ Final Form\\nNow, to use this generic tool in our classes, all we need to do is import it from its\\nmodule, mix it in by inheritance in our top-level class, and get rid of the more specific\\n__str__ we coded before. The new print overload method will be inherited by instances\\nof Person, as well as Manager; Manager gets __str__ from Person, which now obtains it\\nfrom the AttrDisplay coded in another module. Here is the final version of our\\nperson.py file with these changes applied:\\n# File person.py (final)\\nfrom classtools import AttrDisplay                  # Use generic display tool\\nclass Person(AttrDisplay):\\n    \"\"\"\\n    Create and process person records\\n    \"\"\"\\n    def __init__(self, name, job=None, pay=0):\\n        self.name = name\\n        self.job  = job\\n        self.pay  = pay\\n    def lastName(self):                             # Assumes last is last\\n        return self.name.split()[-1]\\n    def giveRaise(self, percent):                   # Percent must be 0..1\\n        self.pay = int(self.pay * (1 + percent))\\nclass Manager(Person):\\n    \"\"\"\\n    A customized Person with special requirements\\n    \"\"\"\\n    def __init__(self, name, pay):\\n        Person.__init__(self, name, \\'mgr\\', pay)\\n    def giveRaise(self, percent, bonus=.10):\\n        Person.giveRaise(self, percent + bonus)\\nif __name__ == \\'__main__\\':\\n    bob = Person(\\'Bob Smith\\')\\n    sue = Person(\\'Sue Jones\\', job=\\'dev\\', pay=100000)\\n    print(bob)\\n    print(sue)\\n    print(bob.lastName(), sue.lastName())\\n    sue.giveRaise(.10)\\n    print(sue)\\n    tom = Manager(\\'Tom Jones\\', 50000)\\n    tom.giveRaise(.10)\\n668 | Chapter 27: \\u2002A More Realistic Example', metadata={'source': 'python.pdf', 'page': 718}),\n",
       " Document(page_content='    print(tom.lastName())\\n    print(tom)\\nAs this is \\nthe final revision, we’ve added a few comments here to document our work—\\ndocstrings for functional descriptions and # for smaller notes, per best-practice con-\\nventions. When we run this code now, we see all the attributes of our objects, not just\\nthe ones we hardcoded in the original __str__. And our final issue is resolved: because\\nAttrDisplay takes class names off the self instance directly, each object is shown with\\nthe name of its closest (lowest) class— tom displays as a Manager now, not a Person, and\\nwe can finally verify that his job name has been correctly filled in by the Manager\\nconstructor:\\nC:\\\\misc> person.py\\n[Person: job=None, name=Bob Smith, pay=0]\\n[Person: job=dev, name=Sue Jones, pay=100000]\\nSmith Jones\\n[Person: job=dev, name=Sue Jones, pay=110000]\\nJones\\n[Manager: job=mgr, name=Tom Jones, pay=60000]\\nThis is the more useful display we were after. From a larger perspective, though, our\\nattribute display class has become a general tool , which we can mix into any class by\\ninheritance to leverage the display format it defines. Further, all its clients will auto-\\nmatically pick up future changes in our tool. Later in the book, we’ll meet even more\\npowerful class tool concepts, such as decorators and metaclasses; along with Python’s\\nintrospection tools, they allow us to write code that augments and manages classes in\\nstructured and maintainable ways.\\nStep 7 (Final): Storing Objects in a Database\\nAt this point, our work is almost complete. We now have a two-module system that not\\nonly implements our original design goals for representing people, but also provides a\\ngeneral attribute display tool we can use in other programs in the future. By coding\\nfunctions and classes in module files, we’ve ensured that they naturally support reuse.\\nAnd by coding our software as classes, we’ve ensured that it naturally supports\\nextension.\\nAlthough our classes work as planned, though, the objects they create are not real\\ndatabase records. That is, if we kill Python, our instances will disappear—they’re tran-\\nsient objects in memory and are not stored in a more permanent medium like a file, so\\nthey won’t be available in future program runs. It turns out that it’s easy to make\\ninstance objects more permanent, with a Python feature called object persistence—\\nmaking objects live on after the program that creates them exits. As a final step in this\\ntutorial, let’s make our objects permanent.\\nStep 7 (Final): Storing Objects in a Database | 669', metadata={'source': 'python.pdf', 'page': 719}),\n",
       " Document(page_content='Pickles and Shelves\\nObject persistence is \\nimplemented by three standard library modules, available in every \\nPython:\\npickle\\nSerializes arbitrary Python objects to and from a string of bytes\\ndbm (named anydbm in Python 2.6)\\nImplements an access-by-key filesystem for storing strings\\nshelve\\nUses the other two modules to store Python objects on a file by key\\nWe met these modules very briefly in Chapter 9  when we studied file basics. They\\nprovide powerful data storage options. Although we can’t do them complete justice in\\nthis tutorial or book, they are simple enough that a brief introduction is enough to get\\nyou started.\\nThe pickle module is a sort of super-general object formatting and deformatting tool:\\ngiven a nearly arbitrary Python object in memory, it’s clever enough to convert the\\nobject to a string of bytes, which it can use later to reconstruct the original object in\\nmemory. The pickle module can handle almost any object you can create—lists, dic-\\ntionaries, nested combinations thereof, and class instances. The latter are especially\\nuseful things to pickle, because they provide both data (attributes) and behavior (meth-\\nods); in fact, the combination is roughly equivalent to “records” and “programs.” Be-\\ncause pickle is so general, it can replace extra code you might otherwise write to create\\nand parse custom text file representations for your objects. By storing an object’s pickle\\nstring on a file, you effectively make it permanent and persistent: simply load and un-\\npickle it later to re-create the original object.\\nAlthough it’s easy to use pickle by itself to store objects in simple flat files and load\\nthem from there later, the shelve module provides an extra layer of structure that allows\\nyou to store pickled objects by key. shelve translates an object to its pickled string with\\npickle and stores that string under a key in a dbm file; when later loading, shelve fetches\\nthe pickled string by key and re-creates the original object in memory with pickle. This\\nis all quite a trick, but to your script a shelve* of pickled objects looks just like a dic-\\ntionary—you index by key to fetch, assign to keys to store, and use dictionary tools\\nsuch as len, in, and dict.keys to get information. Shelves automatically map dictionary\\noperations to objects stored in a file.\\nIn fact, to your script the only coding difference between a shelve and a normal dic-\\ntionary is that you must open shelves initially and must close them after making changes.\\nThe net effect is that a shelve provides a simple database for storing and fetching native\\nPython objects by keys, and thus makes them persistent across program runs. It does\\n* Yes, we use “shelve” as a noun in Python, much to the chagrin of a variety of editors I’ve worked with over\\nthe years, both electronic and human.\\n670 |\\nChapter 27: \\u2002A More Realistic Example', metadata={'source': 'python.pdf', 'page': 720}),\n",
       " Document(page_content=\"not support query tools such as SQL, and it lacks some advanced features found in\\nenterprise-level databases (such \\nas true transaction processing), but native Python ob-\\njects stored on a shelve may be processed with the full power of the Python language\\nonce they are fetched back by key.\\nStoring Objects on a Shelve Database\\nPickling and shelves are somewhat advanced topics, and we won’t go into all their\\ndetails here; you can read more about them in the standard library manuals, as well as\\napplication-focused books such as Programming Python . This is all simpler in Python\\nthan in English, though, so let’s jump into some code.\\nLet’s write a new script that throws objects of our classes onto a shelve. In your text\\neditor, open a new file we’ll call makedb.py. Since this is a new file, we’ll need to import\\nour classes in order to create a few instances to store. We used from to load a class at\\nthe interactive prompt earlier, but really, as with functions and other variables, there\\nare two ways to load a class from a file (class names are variables like any other, and\\nnot at all magic in this context):\\nimport person                                   # Load class with import\\nbob = person.Person(...)                        # Go through module name\\nfrom person import Person                       # Load class with from\\nbob = Person(...)                               # Use name directly\\nWe’ll use from to load in our script, just because it’s a bit less to type. Copy or retype\\nthis code to make instances of our classes in the new script, so we have something to\\nstore (this is a simple demo, so we won’t worry about the test-code redundancy here).\\nOnce we have some instances, it’s almost trivial to store them on a shelve. We simply\\nimport the shelve module, open a new shelve with an external filename, assign the\\nobjects to keys in the shelve, and close the shelve when we’re done because we’ve made\\nchanges:\\n# File makedb.py: store Person objects on a shelve database\\nfrom person import Person, Manager              # Load our classes\\nbob = Person('Bob Smith')                       # Re-create objects to be stored\\nsue = Person('Sue Jones', job='dev', pay=100000)\\ntom = Manager('Tom Jones', 50000)\\nimport shelve\\ndb = shelve.open('persondb')                    # Filename where objects are stored\\nfor object in (bob, sue, tom):                  # Use object's name attr as key\\n    db[object.name] = object                    # Store object on shelve by key\\ndb.close()                                      # Close after making changes\\nNotice how we assign objects to the shelve using their own names as keys. This is just\\nfor convenience; in a shelve, the key can be any string, including one we might create\\nto be unique using tools such as process IDs and timestamps (available in the os and\\ntime standard library modules). The only rule is that the keys must be strings and should\\nStep 7 (Final): Storing Objects in a Database | 671\", metadata={'source': 'python.pdf', 'page': 721}),\n",
       " Document(page_content=\"be unique, since we can store just one object per key (though that object can be a list\\nor dictionary containing \\nmany objects). The values we store under keys, though, can\\nbe Python objects of almost any sort: built-in types like strings, lists, and dictionaries,\\nas well as user-defined class instances, and nested combinations of all of these.\\nThat’s all there is to it—if this script has no output when run, it means it probably\\nworked; we’re not printing anything, just creating and storing objects:\\nC:\\\\misc> makedb.py\\nExploring Shelves Interactively\\nAt this point, there are one or more real files in the current directory whose names all\\nstart with “persondb”. The actual files created can vary per platform, and just like in\\nthe built-in open function, the filename in shelve.open() is relative to the current work-\\ning directory unless it includes a directory path. Wherever they are stored, these files\\nimplement a keyed-access file that contains the pickled representation of our three\\nPython objects. Don’t delete these files—they are your database, and are what you’ll\\nneed to copy or transfer when you back up or move your storage.\\nYou can look at the shelve’s files if you want to, either from Windows Explorer or the\\nPython shell, but they are binary hash files, and most of their content makes little sense\\noutside the context of the shelve module. With Python 3.0 and no extra software in-\\nstalled, our database is stored in three files (in 2.6, it’s just one file, persondb, because\\nthe bsddb extension module is preinstalled with Python for shelves; in 3.0, bsddb is a\\nthird-party open source add-on):\\n# Directory listing module: verify files are present\\n>>> import glob\\n>>> glob.glob('person*')\\n['person.py', 'person.pyc', 'persondb.bak', 'persondb.dat', 'persondb.dir']\\n# Type the file: text mode for string, binary mode for bytes\\n>>> print(open('persondb.dir').read())\\n'Tom Jones', (1024, 91)\\n...more omitted...\\n>>> print(open('persondb.dat', 'rb').read())\\nb'\\\\x80\\\\x03cperson\\\\nPerson\\\\nq\\\\x00)\\\\x81q\\\\x01}q\\\\x02(X\\\\x03\\\\x00\\\\x00\\\\x00payq\\\\x03K...\\n...more omitted...\\nThis content isn’t impossible to decipher, but it can vary on different platforms and\\ndoesn’t exactly qualify as a user-friendly database interface! To verify our work better,\\nwe can write another script, or poke around our shelve at the interactive prompt. Be-\\ncause shelves are Python objects containing Python objects, we can process them with\\nnormal Python syntax and development modes. Here, the interactive prompt effectively\\nbecomes a database client:\\n672 | Chapter 27: \\u2002A More Realistic Example\", metadata={'source': 'python.pdf', 'page': 722}),\n",
       " Document(page_content=\">>> import shelve\\n>>> db = shelve.open('persondb')                # Reopen the shelve\\n>>> len(db)                                     # Three 'records' stored\\n3\\n>>> list(db.keys())                             # keys is the index\\n['Tom Jones', 'Sue Jones', 'Bob Smith']         # list to make a list in 3.0\\n>>> bob = db['Bob Smith']                       # Fetch bob by key\\n>>> print(bob)                                  # Runs __str__ from AttrDisplay\\n[Person: job=None, name=Bob Smith, pay=0]\\n>>> bob.lastName()                              # Runs lastName from Person\\n'Smith'\\n>>> for key in db:                              # Iterate, fetch, print\\n        print(key, '=>', db[key])\\nTom Jones => [Manager: job=mgr, name=Tom Jones, pay=50000]\\nSue Jones => [Person: job=dev, name=Sue Jones, pay=100000]\\nBob Smith => [Person: job=None, name=Bob Smith, pay=0]\\n>>> for key in sorted(db):\\n        print(key, '=>', db[key])               # Iterate by sorted keys\\nBob Smith => [Person: job=None, name=Bob Smith, pay=0]\\nSue Jones => [Person: job=dev, name=Sue Jones, pay=100000]\\nTom Jones => [Manager: job=mgr, name=Tom Jones, pay=50000]\\nNotice that we \\ndon’t have to import our Person or Manager classes here in order to load\\nor use our stored objects. For example, we can call bob’s lastName method freely, and\\nget his custom print display format automatically, even though we don’t have his\\nPerson class in our scope here. This works because when Python pickles a class instance,\\nit records its self instance attributes, along with the name of the class it was created\\nfrom and the module where the class lives. When bob is later fetched from the shelve\\nand unpickled, Python will automatically reimport the class and link bob to it.\\nThe upshot of this scheme is that class instances automatically acquire all their class\\nbehavior when they are loaded in the future. We have to import our classes only to\\nmake new instances, not to process existing ones. Although a deliberate feature, this\\nscheme has somewhat mixed consequences:\\n• The downside is that classes and their module’s files must be importable when an\\ninstance is later loaded. More formally, pickleable classes must be coded at the top\\nlevel of a module file accessible from a directory listed on the sys.path module\\nsearch path (and shouldn’t live in the most script files’ module __main__ unless\\nthey’re always in that module when used). Because of this external module file\\nrequirement, some applications choose to pickle simpler objects such as dic-\\ntionaries or lists, especially if they are to be transferred across the Internet.\\nStep 7 (Final): Storing Objects in a Database | 673\", metadata={'source': 'python.pdf', 'page': 723}),\n",
       " Document(page_content=\"• The upside is that changes in a class’s source code file are automatically picked up\\nwhen instances of the class are loaded again; there is often no need to update stored\\nobjects themselves, since updating their class’s code changes their behavior.\\nShelves also have well-known limitations (the database suggestions at the end of this\\nchapter mention a few of these). For simple object storage, though, shelves and pickles\\nare remarkably easy-to-use tools.\\nUpdating Objects on a Shelve\\nNow for one last script: let’s write a program that updates an instance (record) each\\ntime it runs, to prove the point that our objects really are persistent (i.e., that their\\ncurrent values are available every time a Python program runs). The following file,\\nupdatedb.py, prints the database and gives a raise to one of our stored objects each time.\\nIf you trace through what’s going on here, you’ll notice that we’re getting a lot of utility\\n“for free”—printing our objects automatically employs the general __str__ overloading\\nmethod, and we give raises by calling the giveRaise method we wrote earlier. This all\\n“just works” for objects based on OOP’s inheritance model, even when they live in a file:\\n# File updatedb.py: update Person object on database\\nimport shelve\\ndb = shelve.open('persondb')               # Reopen shelve with same filename\\nfor key in sorted(db):                     # Iterate to display database objects\\n    print(key, '\\\\t=>', db[key])            # Prints with custom format\\nsue = db['Sue Jones']                      # Index by key to fetch\\nsue.giveRaise(.10)                         # Update in memory using class method\\ndb['Sue Jones'] = sue                      # Assign to key to update in shelve\\ndb.close()                                 # Close after making changes\\nBecause this script prints the database when it starts up, we have to run it a few times\\nto see our objects change. Here it is in action, displaying all records and increasing\\nsue’s pay each time it’s run (it’s a pretty good script for sue...):\\nc:\\\\misc> updatedb.py\\nBob Smith       => [Person: job=None, name=Bob Smith, pay=0]\\nSue Jones       => [Person: job=dev, name=Sue Jones, pay=100000]\\nTom Jones       => [Manager: job=mgr, name=Tom Jones, pay=50000]\\nc:\\\\misc> updatedb.py\\nBob Smith       => [Person: job=None, name=Bob Smith, pay=0]\\nSue Jones       => [Person: job=dev, name=Sue Jones, pay=110000]\\nTom Jones       => [Manager: job=mgr, name=Tom Jones, pay=50000]\\nc:\\\\misc> updatedb.py\\nBob Smith       => [Person: job=None, name=Bob Smith, pay=0]\\nSue Jones       => [Person: job=dev, name=Sue Jones, pay=121000]\\nTom Jones       => [Manager: job=mgr, name=Tom Jones, pay=50000]\\nc:\\\\misc> updatedb.py\\n674 | Chapter 27: \\u2002A More Realistic Example\", metadata={'source': 'python.pdf', 'page': 724}),\n",
       " Document(page_content=\"Bob Smith       => [Person: job=None, name=Bob Smith, pay=0]\\nSue Jones       => [Person: job=dev, name=Sue Jones, pay=133100]\\nTom Jones       => [Manager: job=mgr, name=Tom Jones, pay=50000]\\nAgain, what we \\nsee here is a product of the shelve and pickle tools we get from Python,\\nand of the behavior we coded in our classes ourselves. And once again, we can verify\\nour script’s work at the interactive prompt (the shelve’s equivalent of a database client):\\nc:\\\\misc> python\\n>>> import shelve\\n>>> db = shelve.open('persondb')             # Reopen database\\n>>> rec = db['Sue Jones']                    # Fetch object by key\\n>>> print(rec)\\n[Person: job=dev, name=Sue Jones, pay=146410]\\n>>> rec.lastName()\\n'Jones'\\n>>> rec.pay\\n146410\\nFor another example of object persistence in this book, see the sidebar in Chapter 30\\ntitled “Why You Will Care: Classes and Persistence” on page 744. It stores a some-\\nwhat larger composite object in a flat file with pickle instead of shelve, but the effect\\nis similar. For more details on both pickles and shelves, see other books or Python’s \\nmanuals.\\nFuture Directions\\nAnd that’s a wrap for this tutorial. At this point, you’ve seen all the basics of Python’s\\nOOP machinery in action, and you’ve learned ways to avoid redundancy and its asso-\\nciated maintenance issues in your code. You’ve built full-featured classes that do real\\nwork. As an added bonus, you’ve made them real database records by storing them in\\na Python shelve, so their information lives on persistently.\\nThere is much more we could explore here, of course. For example, we could extend\\nour classes to make them more realistic, add new kinds of behavior to them, and so on.\\nGiving a raise, for instance, should in practice verify that pay increase rates are between\\nzero and one—an extension we’ll add when we meet decorators later in this book. You\\nmight also mutate this example into a personal contacts database, by changing the state\\ninformation stored on objects, as well as the class methods used to process it. We’ll\\nleave this a suggested exercise open to your imagination.\\nWe could also expand our scope to use tools that either come with Python or are freely\\navailable in the open source world:\\nGUIs\\nAs is, we can only process our database with the interactive prompt’s command-\\nbased interface, and scripts. We could also work on expanding our object data-\\nbase’s usability by adding a graphical user interface for browsing and updating its\\nrecords. GUIs can be built portably with either Python’s tkinter ( Tkinter in 2.6)\\nFuture Directions | 675\", metadata={'source': 'python.pdf', 'page': 725}),\n",
       " Document(page_content='standard library support, or third-party toolkits such as WxPython and PyQt.\\ntkinter ships with \\nPython, lets you build simple GUIs quickly, and is ideal for\\nlearning GUI programming techniques; WxPython and PyQt tend to be more\\ncomplex to use but often produce higher-grade GUIs in the end.\\nWebsites\\nAlthough GUIs are convenient and fast, the Web is hard to beat in terms of acces-\\nsibility. We might also implement a website for browsing and updating records,\\ninstead of or in addition to GUIs and the interactive prompt. Websites can be\\nconstructed with either basic CGI scripting tools that come with Python, or full-\\nfeatured third-party web frameworks such as Django, TurboGears, Pylons,\\nweb2Py, Zope, or Google’s App Engine. On the Web, your data can still be stored\\nin a shelve, pickle file, or other Python-based medium; the scripts that process it\\nare simply run automatically on a server in response to requests from web browsers\\nand other clients, and they produce HTML to interact with a user, either directly\\nor by interfacing with Framework APIs.\\nWeb services\\nAlthough web clients can often parse information in the replies from websites (a\\ntechnique colorfully known as “screen scraping”), we might go further and provide\\na more direct way to fetch records on the Web via a web services interface such as\\nSOAP or XML-RPC calls—APIs supported by either Python itself or the third-party\\nopen source domain. Such APIs return data in a more direct form, rather than\\nembedded in the HTML of a reply page.\\nDatabases\\nIf our database becomes higher-volume or critical, we might eventually move it\\nfrom shelves to a more full-featured storage mechanism such as the open source \\nZODB object-oriented database system (OODB), or a more traditional SQL-based\\nrelational database system such as MySQL, Oracle, PostgreSQL, or SQLite. Python\\nitself comes with the in-process SQLite database system built-in, but other open\\nsource options are freely available on the Web. ZODB, for example, is similar to\\nPython’s shelve but addresses many of its limitations, supporting larger databases,\\nconcurrent updates, transaction processing, and automatic write-through on in-\\nmemory changes. SQL-based systems like MySQL offer enterprise-level tools for\\ndatabase storage and may be directly used from a within a Python script.\\nORMs\\nIf we do migrate to a relational database system for storage, we don’t have to sac-\\nrifice Python’s OOP tools. Object-relational mappers (ORMs) like SQLObject and\\nSQLAlchemy can automatically map relational tables and rows to and from Python\\nclasses and instances, such that we can process the stored data using normal Python\\nclass syntax. This approach provides an alternative to OODBs like shelve and\\nZODB and leverages the power of both relational databases and Python’s class\\nmodel.\\n676 | Chapter 27: \\u2002A More Realistic Example', metadata={'source': 'python.pdf', 'page': 726}),\n",
       " Document(page_content='While I hope this introduction whets your appetite for future exploration, all of these\\ntopics are of \\ncourse far beyond the scope of this tutorial and this book at large. If you\\nwant to explore any of them on your own, see the Web, Python’s standard library\\nmanuals, and application-focused books such as Programming Python. In the latter I\\npick up this example where we’ve stopped here, showing how to add both a GUI and\\na website on top of the database to allow for browsing and updating instance records.\\nI hope to see you there eventually, but first, let’s return to class fundamentals and finish\\nup the rest of the core Python language story.\\nChapter Summary\\nIn this chapter, we explored all the fundamentals of Python classes and OOP in action,\\nby building upon a simple but real example, step by step. We added constructors,\\nmethods, operator overloading, customization with subclasses, and introspection\\ntools, and we met other concepts (such as composition, delegation, and polymorphism)\\nalong the way.\\nIn the end, we took objects created by our classes and made them persistent by storing\\nthem on a shelve object database—an easy-to-use system for saving and retrieving na-\\ntive Python objects by key. While exploring class basics, we also encountered multiple\\nways to factor our code to reduce redundancy and minimize future maintenance costs.\\nFinally, we briefly previewed ways to extend our code with application-programming\\ntools such as GUIs and databases, covered in follow-up books.\\nIn the next chapters of this part of the book we’ll return to our study of the details\\nbehind Python’s class model and investigate its application to some of the design con-\\ncepts used to combine classes in larger programs. Before we move ahead, though, let’s\\nwork through this chapter’s quiz to review what we covered here. Since we’ve already\\ndone a lot of hands-on work in this chapter, we’ll close with a set of mostly theory-\\noriented questions designed to make you trace through some of the code and ponder\\nsome of the bigger ideas behind it.\\nTest Your Knowledge: Quiz\\n1. When we fetch \\na Manager object from the shelve and print it, where does the display\\nformat logic come from?\\n2. When we fetch a Person object from a shelve without importing its module, how\\ndoes the object know that it has a giveRaise method that we can call?\\n3. Why is it so important to move processing into methods, instead of hardcoding it\\noutside the class?\\nTest Your Knowledge: Quiz | 677', metadata={'source': 'python.pdf', 'page': 727}),\n",
       " Document(page_content='4. Why is it better to customize by subclassing rather than copying the original and\\nmodifying?\\n5. Why \\nis it better to call back to a superclass method to run default actions, instead\\nof copying and modifying its code in a subclass?\\n6. Why is it better to use tools like __dict__ that allow objects to be processed\\ngenerically than to write more custom code for each type of class?\\n7. In general terms, when might you choose to use object embedding and composition\\ninstead of inheritance?\\n8. How might you modify the classes in this chapter to implement a personal contacts\\ndatabase in Python?\\nTest Your Knowledge: Answers\\n1. In the final version of our classes, Manager ultimately inherits its __str__ printing\\nmethod from AttrDisplay in the separate classtools module. Manager doesn’t have\\none itself, so the inheritance search climbs to its Person superclass; because there\\nis no __str__ there either, the search climbs higher and finds it in AttrDisplay. The\\nclass names listed in parentheses in a class statement’s header line provide\\nthe links to higher superclasses.\\n2. Shelves (really, the pickle module they use) automatically relink an instance to the\\nclass it was created from when that instance is later loaded back into memory.\\nPython reimports the class from its module internally, creates an instance with its\\nstored attributes, and sets the instance’s __class__ link to point to its original class.\\nThis way, loaded instances automatically obtain all their original methods (like\\nlastName, giveRaise, and __str__), even if we have not imported the instance’s class\\ninto our scope.\\n3. It’s important to move processing into methods so that there is only one copy to\\nchange in the future, and so that the methods can be run on any instance. This is\\nPython’s notion of encapsulation—wrapping up logic behind interfaces, to better\\nsupport future code maintenance. If you don’t do so, you create code redundancy\\nthat can multiply your work effort as the code evolves in the future.\\n4. Customizing with subclasses reduces development effort. In OOP, we code by\\ncustomizing what has already been done, rather than copying or changing existing\\ncode. This is the real “big idea” in OOP—because we can easily extend our prior\\nwork by coding new subclasses, we can leverage what we’ve already done. This is\\nmuch better than either starting from scratch each time, or introducing multiple\\nredundant copies of code that may all have to be updated in the future.\\n678 | Chapter 27: \\u2002A More Realistic Example', metadata={'source': 'python.pdf', 'page': 728}),\n",
       " Document(page_content='5. Copying and modifying code doubles your potential work effort in the future, re-\\ngardless of the context. If a subclass needs to perform default actions coded in a\\nsuperclass method, it’s much better to call back to the original through the super-\\nclass’s name than to copy its code. This also holds true for superclass constructors.\\nAgain, copying code creates redundancy, which is a major issue as code evolves.\\n6. Generic tools can avoid hardcoded solutions that must be kept in sync with the\\nrest of the class as it evolves over time. A generic __str__ print method, for example,\\nneed not be updated each time a new attribute is added to instances in an\\n__init__ constructor. In addition, a generic print method inherited by all classes\\nonly appears, and need only be modified, in one place—changes in the generic\\nversion are picked up by all classes that inherit from the generic class. Again, elim-\\ninating code redundancy cuts future development effort; that’s one of the primary\\nassets classes bring to the table.\\n7. Inheritance is best at coding extensions based on direct customization (like our\\nManager specialization of Person). Composition is well suited to scenarios where\\nmultiple objects are aggregated into a whole and directed by a controller layer class.\\nInheritance passes calls up to reuse, and composition passes down to delegate.\\nInheritance and composition are not mutually exclusive; often, the objects em-\\nbedded in a controller are themselves customizations based upon inheritance.\\n8. The classes in this chapter could be used as boilerplate “template” code to\\nimplement a variety of types of databases. Essentially, you can repurpose them by\\nmodifying the constructors to record different attributes and providing whatever\\nmethods are appropriate for the target application. For instance, you might use\\nattributes such as name, address, birthday, phone, email, and so on for a contacts\\ndatabase, and methods appropriate for this purpose. A method named sendmail,\\nfor example, might use Python’s standard library smptlib module to send an email\\nto one of the contacts automatically when called (see Python’s manuals or appli-\\ncation-level books for more details on such tools). The AttrDisplay tool we wrote\\nhere could be used verbatim to print your objects, because it is intentionally ge-\\nneric. Most of the shelve database code here can be used to store your objects, too,\\nwith minor changes.\\nTest Your Knowledge: Answers | 679', metadata={'source': 'python.pdf', 'page': 729}),\n",
       " Document(page_content='', metadata={'source': 'python.pdf', 'page': 730}),\n",
       " Document(page_content='CHAPTER 28\\nClass Coding Details\\nIf you haven’t quite gotten all of Python OOP yet, don’t worry; now that we’ve had a\\nquick tour, we’re \\ngoing to dig a bit deeper and study the concepts introduced earlier in\\nfurther detail. In this and the following chapter, we’ll take another look at class me-\\nchanics. Here, we’re going to study classes, methods, and inheritance, formalizing and\\nexpanding on some of the coding ideas introduced in Chapter 26 . Because the class is\\nour last namespace tool, we’ll summarize Python’s namespace concepts here as well.\\nThe next chapter continues this in-depth second pass over class mechanics by covering\\none specific aspect: operator overloading. Besides presenting the details, this chapter\\nand the next also give us an opportunity to explore some larger classes than those we\\nhave studied so far.\\nThe class Statement\\nAlthough the Python class statement may seem similar to tools in other OOP languages\\non the surface, on closer inspection, it is quite different from what some programmers\\nare used to. For example, as in C++, the class statement is Python’s main OOP tool,\\nbut unlike in C++, Python’s class is not a declaration. Like a def, a class statement is\\nan object builder, and an implicit assignment—when run, it generates a class object\\nand stores a reference to it in the name used in the header. Also like a def, a class\\nstatement is true executable code—your class doesn’t exist until Python reaches and\\nruns the class statement that defines it (typically while importing the module it is coded\\nin, but not before).\\nGeneral Form\\nclass is a compound statement, with a body of indented statements typically appearing\\nunder the header. In the header, superclasses are listed in parentheses after the class\\nname, separated by commas. Listing more than one superclass leads to multiple in-\\nheritance (which we’ll discuss more formally in Chapter 30). Here is the statement’s\\ngeneral form:\\n681', metadata={'source': 'python.pdf', 'page': 731}),\n",
       " Document(page_content=\"class <name>(superclass,...):         # Assign to name\\n    data = value                      # Shared class data\\n    def method(self,...):             # Methods\\n        self.member = value           # Per-instance data\\nWithin the class  \\nstatement, any assignments generate class attributes, and specially\\nnamed methods overload operators; for instance, a function called __init__ is called\\nat instance object construction time, if defined.\\nExample\\nAs we’ve seen, classes are mostly just namespaces—that is, tools for defining names\\n(i.e., attributes) that export data and logic to clients. So, how do you get from the\\nclass statement to a namespace?\\nHere’s how. Just like in a module file, the statements nested in a class statement body\\ncreate its attributes. When Python executes a class statement (not a call to a class), it\\nruns all the statements in its body, from top to bottom. Assignments that happen during\\nthis process create names in the class’s local scope, which become attributes in the\\nassociated class object. Because of this, classes resemble both modules and functions:\\n• Like functions, class statements are local scopes where names created by nested\\nassignments live.\\n• Like names in a module, names assigned in a class statement become attributes\\nin a class object.\\nThe main distinction for classes is that their namespaces are also the basis of inheritance\\nin Python; reference attributes that are not found in a class or instance object are fetched\\nfrom other classes.\\nBecause class is a compound statement, any sort of statement can be nested inside its\\nbody—print, =, if, def, and so on. All the statements inside the class statement run\\nwhen the class statement itself runs (not when the class is later called to make an\\ninstance). Assigning names inside the class statement makes class attributes, and\\nnested defs make class methods, but other assignments make attributes, too.\\nFor example, assignments of simple nonfunction objects to class attributes produce \\ndata attributes, shared by all instances:\\n>>> class SharedData:\\n...     spam = 42          # Generates a class data attribute\\n...\\n>>> x = SharedData()       # Make two instances\\n>>> y = SharedData()\\n>>> x.spam, y.spam         # They inherit and share 'spam'\\n(42, 42)\\n682 | Chapter 28: \\u2002Class Coding Details\", metadata={'source': 'python.pdf', 'page': 732}),\n",
       " Document(page_content=\"Here, because the name spam is assigned at the top level of a class statement, it is\\nattached to the class and so will be shared by all instances. We can change it by going\\nthrough the class name, and we can refer to it through either instances or the class.*\\n>>> SharedData.spam = 99\\n>>> x.spam, y.spam, SharedData.spam\\n(99, 99, 99)\\nSuch class attributes can be used to manage information that spans all the instances—\\na counter of the number of instances generated, for example (we’ll expand on this idea\\nby example in Chapter 31). Now, watch what happens if we assign the name spam\\nthrough an instance instead of the class:\\n>>> x.spam = 88\\n>>> x.spam, y.spam, SharedData.spam\\n(88, 99, 99)\\nAssignments to instance attributes create or change the names in the instance, rather\\nthan in the shared class. More generally, inheritance searches occur only on attribute\\nreferences, not on assignment: assigning to an object’s attribute always changes that\\nobject, and no other.† For example, y.spam is looked up in the class by inheritance, but\\nthe assignment to x.spam attaches a name to x itself.\\nHere’s a more comprehensive example of this behavior that stores the same name in\\ntwo places. Suppose we run the following class:\\nclass MixedNames:                            # Define class\\n    data = 'spam'                            # Assign class attr\\n    def __init__(self, value):               # Assign method name\\n        self.data = value                    # Assign instance attr\\n    def display(self):\\n        print(self.data, MixedNames.data)    # Instance attr, class attr\\nThis class contains two defs, which bind class attributes to method functions. It also\\ncontains an = assignment statement; because this assignment assigns the name data\\ninside the class, it lives in the class’s local scope and becomes an attribute of the class\\nobject. Like all class attributes, this data is inherited and shared by all instances of the\\nclass that don’t have data attributes of their own.\\nWhen we make instances of this class, the name data is attached to those instances by\\nthe assignment to self.data in the constructor method:\\n>>> x = MixedNames(1)          # Make two instance objects\\n>>> y = MixedNames(2)          # Each has its own data\\n* If you’ve used C++ you may recognize this as similar to the notion of C++’s “static” data members—members\\nthat are \\nstored in the class, independent of instances. In Python, it’s nothing special: all class attributes are\\njust names assigned in the class statement, whether they happen to reference functions (C++’s “methods”)\\nor something else (C++’s “members”). In Chapter 31 , we’ll also meet Python static methods (akin to those\\nin C++), which are just self-less functions that usually process class attributes.\\n† Unless the class has redefined the attribute assignment operation to do something unique with the\\n__setattr__ operator overloading method (discussed in Chapter 29).\\nThe class Statement | 683\", metadata={'source': 'python.pdf', 'page': 733}),\n",
       " Document(page_content='>>> x.display(); y.display()   # self.data differs, MixedNames.data is the same\\n1 spam\\n2 spam\\nThe net result \\nis that data lives in two places: in the instance objects (created by the\\nself.data assignment in __init__), and in the class from which they inherit names\\n(created by the data assignment in the class). The class’s display method prints both\\nversions, by first qualifying the self instance, and then the class.\\nBy using these techniques to store attributes in different objects, we determine their\\nscope of visibility. When attached to classes, names are shared; in instances, names\\nrecord per-instance data, not shared behavior or data. Although inheritance searches\\nlook up names for us, we can always get to an attribute anywhere in a tree by accessing\\nthe desired object directly.\\nIn the preceding example, for instance, specifying x.data or self.data will return an\\ninstance name, which normally hides the same name in the class; however, Mixed\\nNames.data grabs the class name explicitly. We’ll see various roles for such coding pat-\\nterns later; the next section describes one of the most common.\\nMethods\\nBecause you already know about functions, you also know about methods in classes.\\nMethods are just function objects created by def statements nested in a class state-\\nment’s body. From an abstract perspective, methods provide behavior for instance\\nobjects to inherit. From a programming perspective, methods work in exactly the same\\nway as simple functions, with one crucial exception: a method’s first argument always\\nreceives the instance object that is the implied subject of the method call.\\nIn other words, Python automatically maps instance method calls to class method\\nfunctions as follows. Method calls made through an instance, like this:\\ninstance.method(args...)\\nare automatically translated to class method function calls of this form:\\nclass.method(instance, args...)\\nwhere the class is determined by locating the method name using Python’s inheritance\\nsearch procedure. In fact, both call forms are valid in Python.\\nBesides the normal inheritance of method attribute names, the special first argument\\nis the only real magic behind method calls. In a class method, the first argument is\\nusually called self by convention (technically, only its position is significant, not its\\nname). This argument provides methods with a hook back to the instance that is the\\nsubject of the call—because classes generate many instance objects, they need to use\\nthis argument to manage data that varies per instance.\\n684 | Chapter 28: \\u2002Class Coding Details', metadata={'source': 'python.pdf', 'page': 734}),\n",
       " Document(page_content=\"C++ programmers may recognize Python’s self argument as being similar to C++’s\\nthis pointer. In Python, though, self is always explicit in your code: methods must\\nalways go through self to fetch or change attributes of the instance being processed\\nby the current method call. This explicit nature of self is by design—the presence of\\nthis name makes it obvious that you are using instance attribute names in your script,\\nnot names in the local or global scope.\\nMethod Example\\nTo clarify these concepts, let’s turn to an example. Suppose we define the following\\nclass:\\nclass NextClass:                            # Define class\\n    def printer(self, text):                # Define method\\n        self.message = text                 # Change instance\\n        print(self.message)                 # Access instance\\nThe name printer references a function object; because it’s assigned in the class state-\\nment’s scope, it becomes a class object attribute and is inherited by every instance made\\nfrom the class. Normally, because methods like printer are designed to process in-\\nstances, we call them through instances:\\n>>> x = NextClass()                         # Make instance\\n>>> x.printer('instance call')              # Call its method\\ninstance call\\n>>> x.message                               # Instance changed\\n'instance call'\\nWhen we call the method by qualifying an instance like this, printer is first located by\\ninheritance, and then its self argument is automatically assigned the instance object\\n(x); the text argument gets the string passed at the call ( 'instance call' ). Notice that\\nbecause Python automatically passes the first argument to self for us, we only actually\\nhave to pass in one argument. Inside printer, the name self is used to access or set\\nper-instance data because it refers back to the instance currently being processed.\\nMethods may be called in one of two ways—through an instance, or through the class\\nitself. For example, we can also call printer by going through the class name, provided\\nwe pass an instance to the self argument explicitly:\\n>>> NextClass.printer(x, 'class call')      # Direct class call\\nclass call\\n>>> x.message                               # Instance changed again\\n'class call'\\nMethods | 685\", metadata={'source': 'python.pdf', 'page': 735}),\n",
       " Document(page_content=\"Calls routed through the instance and the class have the exact same effect, as long as\\nwe pass the \\nsame instance object ourselves in the class form. By default, in fact, you get\\nan error message if you try to call a method without any instance:\\n>>> NextClass.printer('bad call')\\nTypeError: unbound method printer() must be called with NextClass instance...\\nCalling Superclass Constructors\\nMethods are normally called through instances. Calls to methods through a class,\\nthough, do show up in a variety of special roles. One common scenario involves the\\nconstructor method. The __init__ method, like all attributes, is looked up by inheri-\\ntance. This means that at construction time, Python locates and calls just one\\n__init__. If subclass constructors need to guarantee that superclass construction-time\\nlogic runs, too, they generally must call the superclass’s __init__ method explicitly\\nthrough the class:\\nclass Super:\\n    def __init__(self, x):\\n        ...default code...\\nclass Sub(Super):\\n    def __init__(self, x, y):\\n        Super.__init__(self, x)             # Run superclass __init__\\n        ...custom code...                   # Do my init actions\\nI = Sub(1, 2)\\nThis is one of the few contexts in which your code is likely to call an operator over-\\nloading method directly. Naturally, you should only call the superclass constructor this\\nway if you really want it to run—without the call, the subclass replaces it completely.\\nFor a more realistic illustration of this technique in action, see the Manager class example\\nin the prior chapter’s tutorial.‡\\nOther Method Call Possibilities\\nThis pattern of calling methods through a class is the general basis of extending (instead\\nof completely replacing) inherited method behavior. In Chapter 31 , we’ll also meet a\\nnew option added in Python 2.2, static methods , that allow you to code methods that\\ndo not expect instance objects in their first arguments. Such methods can act like simple\\ninstanceless functions, with names that are local to the classes in which they are coded,\\nand may be used to manage class data. A related concept, the class method , receives a\\nclass when called instead of an instance and can be used to manage per-class data. These\\nare advanced and optional extensions, though; normally, you must always pass an\\ninstance to a method, whether it is called through an instance or a class.\\n‡ On a somewhat related note, you can also code multiple __init__ methods within the same class, but only\\nthe last definition will be used; see Chapter 30 for more details on multiple method definitions.\\n686 | Chapter 28: \\u2002Class Coding Details\", metadata={'source': 'python.pdf', 'page': 736}),\n",
       " Document(page_content='Inheritance\\nThe whole point \\nof a namespace tool like the class statement is to support name in-\\nheritance. This section expands on some of the mechanisms and roles of attribute in-\\nheritance in Python.\\nIn Python, inheritance happens when an object is qualified, and it involves searching\\nan attribute definition tree (one or more namespaces). Every time you use an expression\\nof the form object.attr (where object is an instance or class object), Python searches\\nthe namespace tree from bottom to top, beginning with object, looking for the first\\nattr it can find. This includes references to self attributes in your methods. Because\\nlower definitions in the tree override higher ones, inheritance forms the basis of\\nspecialization.\\nAttribute Tree Construction\\nFigure 28-1  summarizes the way namespace trees are constructed and populated with\\nnames. Generally:\\n• Instance attributes are generated by assignments to self attributes in methods.\\n• Class attributes are created by statements (assignments) in class statements.\\n• Superclass links are made by listing classes in parentheses in a class statement\\nheader.\\nThe net result is a tree of attribute namespaces that leads from an instance, to the class\\nit was generated from, to all the superclasses listed in the class header. Python searches\\nupward in this tree, from instances to superclasses, each time you use qualification to\\nfetch an attribute name from an instance object.§\\nSpecializing Inherited Methods\\nThe tree-searching model of inheritance just described turns out to be a great way to\\nspecialize systems. Because inheritance finds names in subclasses before it checks su-\\nperclasses, subclasses can replace default behavior by redefining their superclasses’\\nattributes. In fact, you can build entire systems as hierarchies of classes, which are\\nextended by adding new external subclasses rather than changing existing logic\\nin-place.\\n§ This description isn’t 100% complete, because we can also create instance and class attributes by assigning\\nto objects \\noutside class statements—but that’s a much less common and sometimes more error-prone\\napproach (changes aren’t isolated to class statements). In Python, all attributes are always accessible by\\ndefault. We’ll talk more about attribute name privacy in Chapter 29  when we study __setattr__, in\\nChapter 30 when we meet __X names, and again in Chapter 38, where we’ll implement it with a class\\ndecorator.\\nInheritance | 687', metadata={'source': 'python.pdf', 'page': 737}),\n",
       " Document(page_content=\"The idea of redefining inherited names leads to a variety of specialization techniques.\\nFor instance, subclasses \\nmay replace inherited attributes completely, provide attributes\\nthat a superclass expects to find, and extend superclass methods by calling back to the\\nsuperclass from an overridden method. We’ve already seen replacement in action.\\nHere’s an example that shows how extension works:\\n>>> class Super:\\n...     def method(self):\\n...         print('in Super.method')\\n...\\n>>> class Sub(Super):\\n...     def method(self):                    # Override method\\n...         print('starting Sub.method')     # Add actions here\\n...         Super.method(self)               # Run default action\\n...         print('ending Sub.method')\\n...\\nFigure 28-1. Program code creates a tree of objects in memory to be searched by attribute inheritance.\\nCalling a class \\ncreates a new instance that remembers its class, running a class statement creates a\\nnew class, and superclasses are listed in parentheses in the class statement header. Each attribute\\nreference triggers a new bottom-up tree search—even references to self attributes within a class’s\\nmethods.\\nDirect superclass method calls are the crux of the matter here. The Sub class replaces\\nSuper’s method function with its own specialized version, but within the replacement,\\nSub calls back to the version exported by Super to carry out the default behavior. In\\nother words, Sub.method just extends Super.method’s behavior, rather than replacing it\\ncompletely:\\n688 | Chapter 28: \\u2002Class Coding Details\", metadata={'source': 'python.pdf', 'page': 738}),\n",
       " Document(page_content=\">>> x = Super()                              # Make a Super instance\\n>>> x.method()                               # Runs Super.method\\nin Super.method\\n>>> x = Sub()                                # Make a Sub instance\\n>>> x.method()                               # Runs Sub.method, calls Super.method\\nstarting Sub.method\\nin Super.method\\nending Sub.method\\nThis extension coding \\npattern is also commonly used with constructors; see the section\\n“Methods” on page 684 for an example.\\nClass Interface Techniques\\nExtension is only one way to interface with a superclass. The file shown in this section,\\nspecialize.py, defines multiple classes that illustrate a variety of common techniques:\\nSuper\\nDefines a method function and a delegate that expects an action in a subclass.\\nInheritor\\nDoesn’t provide any new names, so it gets everything defined in Super.\\nReplacer\\nOverrides Super’s method with a version of its own.\\nExtender\\nCustomizes Super’s method by overriding and calling back to run the default.\\nProvider\\nImplements the action method expected by Super’s delegate method.\\nStudy each of these subclasses to get a feel for the various ways they customize their\\ncommon superclass. Here’s the file:\\nclass Super:\\n    def method(self):\\n        print('in Super.method')           # Default behavior\\n    def delegate(self):\\n        self.action()                      # Expected to be defined\\nclass Inheritor(Super):                    # Inherit method verbatim\\n    pass\\nclass Replacer(Super):                     # Replace method completely\\n    def method(self):\\n        print('in Replacer.method')\\nclass Extender(Super):                     # Extend method behavior\\n    def method(self):\\n        print('starting Extender.method')\\n        Super.method(self)\\n        print('ending Extender.method')\\nInheritance | 689\", metadata={'source': 'python.pdf', 'page': 739}),\n",
       " Document(page_content=\"class Provider(Super):                     # Fill in a required method\\n    def action(self):\\n        print('in Provider.action')\\nif __name__ == '__main__':\\n    for klass in (Inheritor, Replacer, Extender):\\n        print('\\\\n' + klass.__name__ + '...')\\n        klass().method()\\n    print('\\\\nProvider...')\\n    x = Provider()\\n    x.delegate()\\nA few things \\nare worth pointing out here. First, the self-test code at the end of this\\nexample creates instances of three different classes in a for loop. Because classes are\\nobjects, you can put them in a tuple and create instances generically (more on this idea\\nlater). Classes also have the special __name__ attribute, like modules; it’s preset to a\\nstring containing the name in the class header. Here’s what happens when we run the\\nfile:\\n% python specialize.py\\nInheritor...\\nin Super.method\\nReplacer...\\nin Replacer.method\\nExtender...\\nstarting Extender.method\\nin Super.method\\nending Extender.method\\nProvider...\\nin Provider.action\\nAbstract Superclasses\\nNotice how the Provider class in the prior example works. When we call the\\ndelegate method through a Provider instance, two independent inheritance searches\\noccur:\\n1. On the initial x.delegate call, Python finds the delegate method in Super by\\nsearching the Provider instance and above. The instance x is passed into the\\nmethod’s self argument as usual.\\n2. Inside the Super.delegate method, self.action invokes a new, independent in-\\nheritance search of self and above. Because self references a Provider instance,\\nthe action method is located in the Provider subclass.\\nThis “filling in the blanks” sort of coding structure is typical of OOP frameworks. At\\nleast in terms of the delegate method, the superclass in this example is what is some-\\ntimes called an abstract superclass —a class that expects parts of its behavior to be\\n690 | Chapter 28: \\u2002Class Coding Details\", metadata={'source': 'python.pdf', 'page': 740}),\n",
       " Document(page_content=\"provided by its subclasses. If an expected method is not defined in a subclass, Python\\nraises an undefined name exception when the inheritance search fails.\\nClass coders sometimes \\nmake such subclass requirements more obvious with assert\\nstatements, or by raising the built-in NotImplementedError exception with raise state-\\nments (we’ll study statements that may trigger exceptions in depth in the next part of\\nthis book). As a quick preview, here’s the assert scheme in action:\\nclass Super:\\n    def delegate(self):\\n        self.action()\\n    def action(self):\\n        assert False, 'action must be defined!'      # If this version is called\\n>>> X = Super()\\n>>> X.delegate()\\nAssertionError: action must be defined!\\nWe’ll meet assert in Chapters 32 and 33; in short, if its first expression evaluates\\nto false, it raises an exception with the provided error message. Here, the expression\\nis always false so as to trigger an error message if a method is not redefined, and in-\\nheritance locates the version here. Alternatively, some classes simply raise a\\nNotImplementedError exception directly in such method stubs to signal the mistake:\\nclass Super:\\n    def delegate(self):\\n        self.action()\\n    def action(self):\\n        raise NotImplementedError('action must be defined!')\\n>>> X = Super()\\n>>> X.delegate()\\nNotImplementedError: action must be defined!\\nFor instances of subclasses, we still get the exception unless the subclass provides the\\nexpected method to replace the default in the superclass:\\n>>> class Sub(Super): pass\\n...\\n>>> X = Sub()\\n>>> X.delegate()\\nNotImplementedError: action must be defined!\\n>>> class Sub(Super):\\n...     def action(self): print('spam')\\n...\\n>>> X = Sub()\\n>>> X.delegate()\\nspam\\nFor a somewhat more realistic example of this section’s concepts in action, see the “Zoo\\nanimal hierarchy” exercise (exercise 8) at the end of Chapter 31 , and its solution in\\n“Part VI, Classes and OOP” on page 1122 in Appendix B. Such taxonomies are a\\nInheritance | 691\", metadata={'source': 'python.pdf', 'page': 741}),\n",
       " Document(page_content=\"traditional way to introduce OOP, but they’re a bit removed from most developers’ job\\ndescriptions.\\nPython 2.6 and 3.0 Abstract Superclasses\\nAs of \\nPython 2.6 and 3.0, the prior section’s abstract superclasses (a.k.a. “abstract base\\nclasses”), which require methods to be filled in by subclasses, may also be implemented\\nwith special class syntax. The way we code this varies slightly depending on the version.\\nIn Python 3.0, we use a keyword argument in a class header, along with special @\\ndecorator syntax, both of which we’ll study in detail later in this book:\\nfrom abc import ABCMeta, abstractmethod\\nclass Super(metaclass=ABCMeta):\\n    @abstractmethod\\n    def method(self, ...):\\n        pass\\nBut in Python 2.6, we use a class attribute instead:\\nclass Super:\\n    __metaclass__ = ABCMeta\\n    @abstractmethod\\n    def method(self, ...):\\n        pass\\nEither way, the effect is the same—we can’t make an instance unless the method is\\ndefined lower in the class tree. In 3.0, for example, here is the special syntax equivalent\\nof the prior section’s example:\\n>>> from abc import ABCMeta, abstractmethod\\n>>>\\n>>> class Super(metaclass=ABCMeta):\\n...     def delegate(self):\\n...         self.action()\\n...     @abstractmethod\\n...     def action(self):\\n...         pass\\n...\\n>>> X = Super()\\nTypeError: Can't instantiate abstract class Super with abstract methods action\\n>>> class Sub(Super): pass\\n...\\n>>> X = Sub()\\nTypeError: Can't instantiate abstract class Sub with abstract methods action\\n>>> class Sub(Super):\\n...     def action(self): print('spam')\\n...\\n>>> X = Sub()\\n>>> X.delegate()\\nspam\\n692 | Chapter 28: \\u2002Class Coding Details\", metadata={'source': 'python.pdf', 'page': 742}),\n",
       " Document(page_content='Coded this way, a class with an abstract method cannot be instantiated (that is, we\\ncannot create an \\ninstance by calling it) unless all of its abstract methods have been\\ndefined in subclasses. Although this requires more code, the advantage of this approach\\nis that errors for missing methods are issued when we attempt to make an instance of\\nthe class, not later when we try to call a missing method. This feature may also be used\\nto define an expected interface, automatically verified in client classes.\\nUnfortunately, this scheme also relies on two advanced language tools we have not met\\nyet—function decorators , introduced \\nin Chapter 31  and covered in depth in Chap-\\nter 38 , as well as metaclass declarations , mentioned in Chapter 31  and covered in\\nChapter 39 —so we will finesse other facets of this option here. See Python’s standard\\nmanuals for more on this, as well as precoded abstract superclasses Python provides.\\nNamespaces: The Whole Story\\nNow that we’ve examined class and instance objects, the Python namespace story is\\ncomplete. For reference, I’ll quickly summarize all the rules used to resolve names here.\\nThe first things you need to remember are that qualified and unqualified names are\\ntreated differently, and that some scopes serve to initialize object namespaces:\\n• Unqualified names (e.g., X) deal with scopes.\\n• Qualified attribute names (e.g., object.X) use object namespaces.\\n• Some scopes initialize object namespaces (for modules and classes).\\nSimple Names: Global Unless Assigned\\nUnqualified simple names follow the LEGB lexical scoping rule outlined for functions\\nin Chapter 17:\\nAssignment (X = value)\\nMakes names local: creates or changes the name X in the current local scope, unless\\ndeclared global.\\nReference (X)\\nLooks for the name X in the current local scope, then any and all enclosing func-\\ntions, then the current global scope, then the built-in scope.\\nAttribute Names: Object Namespaces\\nQualified attribute names refer to attributes of specific objects and obey the rules for\\nmodules and classes. For class and instance objects, the reference rules are augmented\\nto include the inheritance search procedure:\\nNamespaces: The Whole Story | 693', metadata={'source': 'python.pdf', 'page': 743}),\n",
       " Document(page_content='Assignment (object.X = value)\\nCreates or alters \\nthe attribute name X in the namespace of the object being quali-\\nfied, and none other. Inheritance-tree climbing happens only on attribute refer-\\nence, not on attribute assignment.\\nReference (object.X)\\nFor class-based objects, searches for the attribute name X in object, then in all\\naccessible classes above it, using the inheritance search procedure. For nonclass\\nobjects such as modules, fetches X from object directly.\\nThe “Zen” of Python Namespaces: Assignments Classify Names\\nWith distinct search procedures for qualified and unqualified names, and multiple\\nlookup layers for both, it can sometimes be difficult to tell where a name will wind up\\ngoing. In Python, the place where you assign a name is crucial—it fully determines the\\nscope or object in which a name will reside. The file manynames.py illustrates how this\\nprinciple translates to code and summarizes the namespace ideas we have seen through-\\nout this book:\\n# manynames.py\\nX = 11                       # Global (module) name/attribute (X, or manynames.X)\\ndef f():\\n    print(X)                 # Access global X (11)\\ndef g():\\n    X = 22                   # Local (function) variable (X, hides module X)\\n    print(X)\\nclass C:\\n    X = 33                   # Class attribute (C.X)\\n    def m(self):\\n        X = 44               # Local variable in method (X)\\n        self.X = 55          # Instance attribute (instance.X)\\nThis file assigns the same name, X, five times. Because this name is assigned in five\\ndifferent locations, though, all five Xs in this program are completely different variables.\\nFrom top to bottom, the assignments to X here generate: a module attribute ( 11), a local\\nvariable in a function ( 22), a class attribute ( 33), a local variable in a method ( 44), and\\nan instance attribute (55). Although all five are named X, the fact that they are all as-\\nsigned at different places in the source code or to different objects makes all of these\\nunique variables.\\nYou should take the time to study this example carefully because it collects ideas we’ve\\nbeen exploring throughout the last few parts of this book. When it makes sense to you,\\nyou will have achieved a sort of Python namespace nirvana. Of course, an alternative\\nroute to nirvana is to simply run the program and see what happens. Here’s the re-\\nmainder of this source file, which makes an instance and prints all the Xs that it can fetch:\\n694 | Chapter 28: \\u2002Class Coding Details', metadata={'source': 'python.pdf', 'page': 744}),\n",
       " Document(page_content=\"# manynames.py, continued\\nif __name__ == '__main__':\\n    print(X)                 # 11: module (a.k.a. manynames.X outside file)\\n    f()                      # 11: global\\n    g()                      # 22: local\\n    print(X)                 # 11: module name unchanged\\n    obj = C()                # Make instance\\n    print(obj.X)             # 33: class name inherited by instance\\n    obj.m()                  # Attach attribute name X to instance now\\n    print(obj.X)             # 55: instance\\n    print(C.X)               # 33: class (a.k.a. obj.X if no X in instance)\\n    #print(C.m.X)            # FAILS: only visible in method\\n    #print(g.X)              # FAILS: only visible in function\\nThe outputs that \\nare printed when the file is run are noted in the comments in the code;\\ntrace through them to see which variable named X is being accessed each time. Notice\\nin particular that we can go through the class to fetch its attribute ( C.X), but we can\\nnever fetch local variables in functions or methods from outside their def statements.\\nLocals are visible only to other code within the def, and in fact only live in memory\\nwhile a call to the function or method is executing.\\nSome of the names defined by this file are visible outside the file  to other modules, but\\nrecall that we must always import before we can access names in another file—that is\\nthe main point of modules, after all:\\n# otherfile.py\\nimport manynames\\nX = 66\\nprint(X)                     # 66: the global here\\nprint(manynames.X)           # 11: globals become attributes after imports\\nmanynames.f()                # 11: manynames's X, not the one here!\\nmanynames.g()                # 22: local in other file's function\\nprint(manynames.C.X)         # 33: attribute of class in other module\\nI = manynames.C()\\nprint(I.X)                   # 33: still from class here\\nI.m()\\nprint(I.X)                   # 55: now from instance!\\nNotice here how manynames.f() prints the X in manynames, not the X assigned in this file—\\nscopes are always determined by the position of assignments in your source code (i.e.,\\nlexically) and are never influenced by what imports what or who imports whom. Also,\\nnotice that the instance’s own X is not created until we call I.m()—attributes, like all\\nvariables, spring into existence when assigned, and not before. Normally we create\\ninstance attributes by assigning them in class __init__ constructor methods, but this\\nisn’t the only option.\\nNamespaces: The Whole Story | 695\", metadata={'source': 'python.pdf', 'page': 745}),\n",
       " Document(page_content=\"Finally, as we learned in Chapter 17 , it’s also possible for a function to change names\\noutside itself, with global and (in Python 3.0) nonlocal statements—these statements\\nprovide write access, but also modify assignment’s namespace binding rules:\\nX = 11                       # Global in module\\ndef g1():\\n    print(X)                 # Reference global in module\\ndef g2():\\n    global X\\n    X = 22                   # Change global in module\\ndef h1():\\n    X = 33                   # Local in function\\n    def nested():\\n        print(X)             # Reference local in enclosing scope\\ndef h2():\\n    X = 33                   # Local in function\\n    def nested():\\n        nonlocal X           # Python 3.0 statement\\n        X = 44               # Change local in enclosing scope\\nOf course, you generally shouldn’t use the same name for every variable in your script—\\nbut as this example demonstrates, even if you do, Python’s namespaces will work to\\nkeep names used in one context from accidentally clashing with those used in another.\\nNamespace Dictionaries\\nIn Chapter 22, we learned that module namespaces are actually implemented as dic-\\ntionaries and exposed with the built-in __dict__ attribute. The same holds for class and\\ninstance objects: attribute qualification is really a dictionary indexing operation inter-\\nnally, and attribute inheritance is just a matter of searching linked dictionaries. In fact,\\ninstance and class objects are mostly just dictionaries with links inside Python. Python\\nexposes these dictionaries, as well as the links between them, for use in advanced roles\\n(e.g., for coding tools).\\nTo help you understand how attributes work internally, let’s work through an inter-\\nactive session that traces the way namespace dictionaries grow when classes are in-\\nvolved. We saw a simpler version of this type of code in Chapter 26 , but now that we\\nknow more about methods and superclasses, let’s embellish it here. First, let’s define\\na superclass and a subclass with methods that will store data in their instances:\\n>>> class super:\\n...     def hello(self):\\n...         self.data1 = 'spam'\\n...\\n>>> class sub(super):\\n...     def hola(self):\\n696 | Chapter 28: \\u2002Class Coding Details\", metadata={'source': 'python.pdf', 'page': 746}),\n",
       " Document(page_content=\"...         self.data2 = 'eggs'\\n...\\nWhen we make an instance of the subclass, the instance starts out with an empty\\nnamespace dictionary, but \\nit has links back to the class for the inheritance search to\\nfollow. In fact, the inheritance tree is explicitly available in special attributes, which\\nyou can inspect. Instances have a __class__ attribute that links to their class, and classes\\nhave a __bases__ attribute that is a tuple containing links to higher superclasses (I’m\\nrunning this on Python 3.0; name formats and some internal attributes vary slightly in\\n2.6):\\n>>> X = sub()\\n>>> X.__dict__                            # Instance namespace dict\\n{}\\n>>> X.__class__                           # Class of instance\\n<class '__main__.sub'>\\n>>> sub.__bases__                         # Superclasses of class\\n(<class '__main__.super'>,)\\n>>> super.__bases__                       # () empty tuple in Python 2.6\\n(<class 'object'>,)\\nAs classes assign to self attributes, they populate the instance objects—that is, at-\\ntributes wind up in the instances’ attribute namespace dictionaries, not in the classes’.\\nAn instance object’s namespace records data that can vary from instance to instance,\\nand self is a hook into that namespace:\\n>>> Y = sub()\\n>>> X.hello()\\n>>> X.__dict__\\n{'data1': 'spam'}\\n>>> X.hola()\\n>>> X.__dict__\\n{'data1': 'spam', 'data2': 'eggs'}\\n>>> sub.__dict__.keys()\\n['__module__', '__doc__', 'hola']\\n>>> super.__dict__.keys()\\n['__dict__', '__module__', '__weakref__', 'hello', '__doc__']\\n>>> Y.__dict__\\n{}\\nNotice the extra underscore names in the class dictionaries; Python sets these auto-\\nmatically. Most are not used in typical programs, but there are tools that use some of\\nthem (e.g., __doc__ holds the docstrings discussed in Chapter 15).\\nNamespaces: The Whole Story | 697\", metadata={'source': 'python.pdf', 'page': 747}),\n",
       " Document(page_content=\"Also, observe that Y, a second instance made at the start of this series, still has an empty\\nnamespace dictionary at the end, even though X’s dictionary has been populated by\\nassignments in methods. Again, each instance has an independent namespace dic-\\ntionary, which starts out empty and can record completely different attributes than\\nthose recorded by the namespace dictionaries of other instances of the same class.\\nBecause attributes are actually dictionary keys inside Python, there are really two ways\\nto fetch and assign their values—by qualification, or by key indexing:\\n>>> X.data1, X.__dict__['data1']\\n('spam', 'spam')\\n>>> X.data3 = 'toast'\\n>>> X.__dict__\\n{'data1': 'spam', 'data3': 'toast', 'data2': 'eggs'}\\n>>> X.__dict__['data3'] = 'ham'\\n>>> X.data3\\n'ham'\\nThis equivalence applies only to attributes actually attached to the instance, though.\\nBecause attribute fetch qualification also performs an inheritance search, it can access\\nattributes that namespace dictionary indexing cannot. The inherited attribute\\nX.hello, for instance, cannot be accessed by X.__dict__['hello'].\\nFinally, here is the built-in dir function we met in Chapters 4 and 15 at work on class\\nand instance objects. This function works on anything with attributes: dir(object) is\\nsimilar to an object.__dict__.keys() call. Notice, though, that dir sorts its list and\\nincludes some system attributes. As of Python 2.2, dir also collects inherited attributes\\nautomatically, and in 3.0 it includes names inherited from the object class that is an\\nimplied superclass of all classes:‖\\n>>> X.__dict__, Y.__dict__\\n({'data1': 'spam', 'data3': 'ham', 'data2': 'eggs'}, {})\\n>>> list(X.__dict__.keys())                                  # Need list in 3.0\\n['data1', 'data3', 'data2']\\n# In Python 2.6:\\n>>>> dir(X)\\n['__doc__', '__module__', 'data1', 'data2', 'data3', 'hello', 'hola']\\n>>> dir(sub)\\n['__doc__', '__module__', 'hello', 'hola']\\n>>> dir(super)\\n['__doc__', '__module__', 'hello']\\n‖As you can see, the contents of attribute dictionaries and dir call results may change over time. For example,\\nbecause Python now allows built-in types to be subclassed like classes, the contents of dir results for built-\\nin types have expanded to include operator overloading methods, just like our dir results here for user-defined\\nclasses under Python 3.0. In general, attribute names with leading and trailing double underscores are\\ninterpreter-specific. Type subclasses will be discussed further in Chapter 31.\\n698 | Chapter 28: \\u2002Class Coding Details\", metadata={'source': 'python.pdf', 'page': 748}),\n",
       " Document(page_content='# In Python 3.0:\\n>>> dir(X)\\n[\\'__class__\\', \\'__delattr__\\', \\'__dict__\\', \\'__doc__\\', \\'__eq__\\', \\'__format__\\',\\n...more omitted...\\n\\'data1\\', \\'data2\\', \\'data3\\', \\'hello\\', \\'hola\\']\\n>>> dir(sub)\\n[\\'__class__\\', \\'__delattr__\\', \\'__dict__\\', \\'__doc__\\', \\'__eq__\\', \\'__format__\\',\\n...more omitted...\\n\\'hello\\', \\'hola\\']\\n>>> dir(super)\\n[\\'__class__\\', \\'__delattr__\\', \\'__dict__\\', \\'__doc__\\', \\'__eq__\\', \\'__format__\\',\\n...more omitted...\\n\\'hello\\'\\n]\\nExperiment with these \\nspecial attributes on your own to get a better feel for how name-\\nspaces actually do their attribute business. Even if you will never use these in the kinds\\nof programs you write, seeing that they are just normal dictionaries will help demystify\\nthe notion of namespaces in general.\\nNamespace Links\\nThe prior section introduced the special __class__ and __bases__ instance and class\\nattributes, without really explaining why you might care about them. In short, these\\nattributes allow you to inspect inheritance hierarchies within your own code. For ex-\\nample, they can be used to display a class tree, as in the following example:\\n# classtree.py\\n\"\"\"\\nClimb inheritance trees using namespace links,\\ndisplaying higher superclasses with indentation\\n\"\"\"\\ndef classtree(cls, indent):\\n    print(\\'.\\' * indent + cls.__name__)    # Print class name here\\n    for supercls in cls.__bases__:        # Recur to all superclasses\\n        classtree(supercls, indent+3)     # May visit super > once\\ndef instancetree(inst):\\n    print(\\'Tree of %s\\' % inst)            # Show instance\\n    classtree(inst.__class__, 3)          # Climb to its class\\ndef selftest():\\n    class A:      pass\\n    class B(A):   pass\\n    class C(A):   pass\\n    class D(B,C): pass\\n    class E:      pass\\n    class F(D,E): pass\\nNamespaces: The Whole Story | 699', metadata={'source': 'python.pdf', 'page': 749}),\n",
       " Document(page_content=\"    instancetree(B())\\n    instancetree(F())\\nif __name__ == '__main__': selftest()\\nThe classtree function in \\nthis script is recursive—it prints a class’s name using\\n__name__, then climbs up to the superclasses by calling itself. This allows the function\\nto traverse arbitrarily shaped class trees; the recursion climbs to the top, and stops at\\nroot superclasses that have empty __bases__ attributes. When using recursion, each\\nactive level of a function gets its own copy of the local scope; here, this means that\\ncls and indent are different at each classtree level.\\nMost of this file is self-test code. When run standalone in Python 3.0, it builds an empty\\nclass tree, makes two instances from it, and prints their class tree structures:\\nC:\\\\misc> c:\\\\python26\\\\python classtree.py\\nTree of <__main__.B instance at 0x02557328>\\n...B\\n......A\\nTree of <__main__.F instance at 0x02557328>\\n...F\\n......D\\n.........B\\n............A\\n.........C\\n............A\\n......E\\nWhen run under Python 3.0, the tree includes the implied object superclasses that are\\nautomatically added above standalone classes, because all classes are “new style” in 3.0\\n(more on this change in Chapter 31):\\nC:\\\\misc> c:\\\\python30\\\\python classtree.py\\nTree of <__main__.B object at 0x02810650>\\n...B\\n......A\\n.........object\\nTree of <__main__.F object at 0x02810650>\\n...F\\n......D\\n.........B\\n............A\\n...............object\\n.........C\\n............A\\n...............object\\n......E\\n.........object\\nHere, indentation marked by periods is used to denote class tree height. Of course, we\\ncould improve on this output format, and perhaps even sketch it in a GUI display. Even\\nas is, though, we can import these functions anywhere we want a quick class tree\\ndisplay:\\n700 | Chapter 28: \\u2002Class Coding Details\", metadata={'source': 'python.pdf', 'page': 750}),\n",
       " Document(page_content='C:\\\\misc> c:\\\\python30\\\\python\\n>>> class Emp: pass\\n...\\n>>> class Person(Emp): pass\\n>>> bob = Person()\\n>>> import classtree\\n>>> classtree.instancetree(bob)\\nTree of <__main__.Person object at 0x028203B0>\\n...Person\\n......Emp\\n.........object\\nRegardless of whether \\nyou will ever code or use such tools, this example demonstrates\\none of the many ways that you can make use of special attributes that expose interpreter\\ninternals. You’ll see another when we code the lister.py general-purpose class display\\ntools in the section “Multiple Inheritance: “Mix-in” Classes” on page 756—there, we\\nwill extend this technique to also display attributes in each object in a class tree. And\\nin the last part of this book, we’ll revisit such tools in the context of Python tool building\\nat large, to code tools that implement attribute privacy, argument validation, and more.\\nWhile not for every Python programmer, access to internals enables powerful devel-\\nopment tools.\\nDocumentation Strings Revisited\\nThe last section’s example includes a docstring for its module, but remember that doc-\\nstrings can be used for class components as well. Docstrings, which we covered in detail\\nin Chapter 15 , are string literals that show up at the top of various structures and are\\nautomatically saved by Python in the corresponding objects’ __doc__ attributes. This\\nworks for module files, function defs, and classes and methods.\\nNow that we know more about classes and methods, the following file, docstr.py, pro-\\nvides a quick but comprehensive example that summarizes the places where docstrings\\ncan show up in your code. All of these can be triple-quoted blocks:\\n\"I am: docstr.__doc__\"\\ndef func(args):\\n    \"I am: docstr.func.__doc__\"\\n    pass\\nclass spam:\\n    \"I am: spam.__doc__ or docstr.spam.__doc__\"\\n    def method(self, arg):\\n        \"I am: spam.method.__doc__ or self.method.__doc__\"\\n        pass\\nDocumentation Strings Revisited | 701', metadata={'source': 'python.pdf', 'page': 751}),\n",
       " Document(page_content=\"The main advantage of documentation strings is that they stick around at runtime.\\nThus, if it’s \\nbeen coded as a docstring, you can qualify an object with its __doc__ at-\\ntribute to fetch its documentation:\\n>>> import docstr\\n>>> docstr.__doc__\\n'I am: docstr.__doc__'\\n>>> docstr.func.__doc__\\n'I am: docstr.func.__doc__'\\n>>> docstr.spam.__doc__\\n'I am: spam.__doc__ or docstr.spam.__doc__'\\n>>> docstr.spam.method.__doc__\\n'I am: spam.method.__doc__ or self.method.__doc__'\\nA discussion of the PyDoc tool, which knows how to format all these strings in reports,\\nappears in Chapter 15 . Here it is running on our code under Python 2.6 (Python 3.0\\nshows additional attributes inherited from the implied object superclass in the new-\\nstyle class model—run this on your own to see the 3.0 extras, and watch for more about\\nthis difference in Chapter 31):\\n>>> help(docstr)\\nHelp on module docstr:\\nNAME\\n    docstr - I am: docstr.__doc__\\nFILE\\n    c:\\\\misc\\\\docstr.py\\nCLASSES\\n    spam\\n    class spam\\n     |  I am: spam.__doc__ or docstr.spam.__doc__\\n     |\\n     |  Methods defined here:\\n     |\\n     |  method(self, arg)\\n     |      I am: spam.method.__doc__ or self.method.__doc__\\nFUNCTIONS\\n    func(args)\\n        I am: docstr.func.__doc__\\nDocumentation strings are available at runtime, but they are less flexible syntactically\\nthan # comments (which can appear anywhere in a program). Both forms are useful\\ntools, and any program documentation is good (as long as it’s accurate, of course!). As\\na best-practice rule of thumb, use docstrings for functional documentation (what your\\nobjects do) and hash-mark comments for more micro-level documentation (how arcane\\nexpressions work).\\n702 | Chapter 28: \\u2002Class Coding Details\", metadata={'source': 'python.pdf', 'page': 752}),\n",
       " Document(page_content='Classes Versus Modules\\nLet’s wrap up \\nthis chapter by briefly comparing the topics of this book’s last two parts:\\nmodules and classes. Because they’re both about namespaces, the distinction can be\\nconfusing. In short:\\n• Modules\\n— Are data/logic packages\\n— Are created by writing Python files or C extensions\\n— Are used by being imported\\n• Classes\\n— Implement new objects\\n— Are created by class\\n statements\\n— Are used by being called\\n— Always live within a module\\nClasses also support extra features that modules don’t, such as operator overloading,\\nmultiple instance generation, and inheritance. Although both classes and modules are\\nnamespaces, you should be able to tell by now that they are very different things.\\nChapter Summary\\nThis chapter took us on a second, more in-depth tour of the OOP mechanisms of the\\nPython language. We learned more about classes, methods, and inheritance, and we\\nwrapped up the namespace story in Python by extending it to cover its application to\\nclasses. Along the way, we looked at some more advanced concepts, such as abstract\\nsuperclasses, class data attributes, namespace dictionaries and links, and manual calls\\nto superclass methods and constructors.\\nNow that we’ve learned all about the mechanics of coding classes in Python, Chap-\\nter 29 turns to a specific facet of those mechanics: operator overloading. After that we’ll\\nexplore common design patterns, looking at some of the ways that classes are com-\\nmonly used and combined to optimize code reuse. Before you read ahead, though, be\\nsure to work though the usual chapter quiz to review what we’ve covered here.\\nTest Your Knowledge: Quiz\\n1. What is an abstract superclass?\\n2.What \\nhappens when a simple assignment statement appears at the top level of a\\nclass statement?\\nTest Your Knowledge: Quiz | 703', metadata={'source': 'python.pdf', 'page': 753}),\n",
       " Document(page_content='3. Why might a class need to manually call the __init__ method in a superclass?\\n4. How can you augment, instead of completely replacing, an inherited method?\\n5. What...was the capital of Assyria?\\nTest Your Knowledge: Answers\\n1.\\nAn abstract superclass is a class that calls a method, but does not inherit or define\\nit—it expects the method to be filled in by a subclass. This is often used as a way\\nto generalize classes when behavior cannot be predicted until a more specific sub-\\nclass is coded. OOP frameworks also use this as a way to dispatch to client-defined,\\ncustomizable operations.\\n2. When a simple assignment statement ( X = Y) appears at the top level of a class\\nstatement, it attaches a data attribute to the class ( Class.X). Like all class attributes,\\nthis will be shared by all instances; data attributes are not callable method func-\\ntions, though.\\n3. A class must manually call the __init__ method in a superclass if it defines an\\n__init__ constructor of its own, but it also must still kick off the superclass’s con-\\nstruction code. Python itself automatically runs just one constructor—the lowest\\none in the tree. Superclass constructors are called through the class name, passing\\nin the self instance manually: Superclass.__init__(self, ...).\\n4. To augment instead of completely replacing an inherited method, redefine it in a\\nsubclass, but call back to the superclass’s version of the method manually from the\\nnew version of the method in the subclass. That is, pass the self instance to the\\nsuperclass’s version of the method manually: Superclass.method(self, ...).\\n5. Ashur (or Qalat Sherqat), Calah (or Nimrud), the short-lived Dur Sharrukin (or\\nKhorsabad), and finally Nineveh.\\n704 | Chapter 28: \\u2002Class Coding Details', metadata={'source': 'python.pdf', 'page': 754}),\n",
       " Document(page_content='CHAPTER 29\\nOperator Overloading\\nThis chapter continues our in-depth survey of class mechanics by focusing on operator\\noverloading. We looked \\nbriefly at operator overloading in prior chapters; here, we’ll\\nfill in more details and look at a handful of commonly used overloading methods.\\nAlthough we won’t demonstrate each of the many operator overloading methods avail-\\nable, those we will code here are a representative sample large enough to uncover the\\npossibilities of this Python class feature.\\nThe Basics\\nReally “operator overloading” simply means intercepting built-in operations in class\\nmethods—Python automatically invokes your methods when instances of the class\\nappear in built-in operations, and your method’s return value becomes the result of the\\ncorresponding operation. Here’s a review of the key ideas behind overloading:\\n• Operator overloading lets classes intercept normal Python operations.\\n• Classes can overload all Python expression operators.\\n• Classes can also overload built-in operations such as printing, function calls, at-\\ntribute access, etc.\\n• Overloading makes class instances act more like built-in types.\\n• Overloading is implemented by providing specially named class methods.\\nIn other words, when certain specially named methods are provided in a class, Python\\nautomatically calls them when instances of the class appear in their associated expres-\\nsions. As we’ve learned, operator overloading methods are never required and generally\\ndon’t have defaults; if you don’t code or inherit one, it just means that your class does\\nnot support the corresponding operation. When used, though, these methods allow\\nclasses to emulate the interfaces of built-in objects, and so appear more consistent.\\n705', metadata={'source': 'python.pdf', 'page': 755}),\n",
       " Document(page_content='Constructors and Expressions: __init__ and __sub__\\nConsider the following \\nsimple example: its Number class, coded in the file number.py,\\nprovides a method to intercept instance construction ( __init__), as well as one for\\ncatching subtraction expressions ( __sub__). Special methods such as these are the hooks\\nthat let you tie into built-in operations:\\nclass Number:\\n    def __init__(self, start):                  # On Number(start)\\n        self.data = start\\n    def __sub__(self, other):                   # On instance - other\\n        return Number(self.data - other)        # Result is a new instance\\n>>> from number import Number                   # Fetch class from module\\n>>> X = Number(5)                               # Number.__init__(X, 5)\\n>>> Y = X – 2                                   # Number.__sub__(X, 2)\\n>>> Y.data                                      # Y is new Number instance\\n3\\nAs discussed previously, the __init__ constructor method seen in this code is the most\\ncommonly used operator overloading method in Python; it’s present in most classes.\\nIn this chapter, we will tour some of the other tools available in this domain and look\\nat example code that applies them in common use cases.\\nCommon Operator Overloading Methods\\nJust about everything you can do to built-in objects such as integers and lists has a\\ncorresponding specially named method for overloading in classes. Table 29-1  lists a\\nfew of the most common; there are many more. In fact, many overloading methods\\ncome in multiple versions (e.g., __add__, __radd__, and __iadd__ for addition), which\\nis one reason there are so many. See other Python books, or the Python language ref-\\nerence manual, for an exhaustive list of the special method names available.\\nTable 29-1. Common operator overloading methods\\nMethod Implements Called for\\n__init__ Constructor Object creation: X = Class(args)\\n__del__ Destructor Object reclamation of X\\n__add__ Operator + X + Y, X += Y if no __iadd__\\n__or__ Operator | (bitwise OR) X | Y, X |= Y if no __ior__\\n__repr__, __str__ Printing, conversions print(X), repr(X), str(X)\\n__call__ Function calls X(*args, **kargs)\\n__getattr__ Attribute fetch X.undefined\\n__setattr__ Attribute assignment X.any = value\\n__delattr__ Attribute deletion del X.any\\n__getattribute__ Attribute fetch X.any\\n706 | Chapter 29: \\u2002Operator Overloading', metadata={'source': 'python.pdf', 'page': 756}),\n",
       " Document(page_content='Method Implements Called for\\n__getitem__ Indexing, slicing, iteration X[key], X[i:j], for loops and other iterations if no\\n__iter__\\n__setitem__ Index and slice assignment X[key] = value, X[i:j] = sequence\\n__delitem__ Index and slice deletion del X[key], del X[i:j]\\n__len__ Length len(X), truth tests if no __bool__\\n__bool__ Boolean tests bool(X), truth tests (named __nonzero__ in 2.6)\\n__lt__, __gt__,\\n__le__, __ge__,\\n__eq__, __ne__Comparisons X < Y, X > Y, X <= Y, X >= Y, X == Y, X != Y (or\\nelse __cmp__ in 2.6 only)\\n__radd__ Right-side operators Other + X\\n__iadd__ In-place augmented operators X += Y (or else __add__)\\n__iter__, __next__ Iteration contexts I=iter(X), next(I); for loops, in if no\\n__contains__, all comprehensions, map(F,X), others\\n(__next__ is named next in 2.6)\\n__contains__ Membership test item in X (any iterable)\\n__index__ Integer value hex(X), bin(X), oct(X), O[X], O[X:] (replaces Py-\\nthon 2 __oct__, __hex__)\\n__enter__, __exit__ Context manager (Chapter 33) with obj as var:\\n__get__, __set__,\\n__delete__Descriptor attributes (Chapter 37) X.attr, X.attr = value, del X.attr\\n__new__ Creation (Chapter 39) Object creation, before __init__\\nAll overloading methods have names that start and end with two underscores to keep\\nthem distinct from \\nother names you define in your classes. The mappings from special\\nmethod names to expressions or operations are predefined by the Python language (and\\ndocumented in the standard language manual). For example, the name __add__ always\\nmaps to + expressions by Python language definition, regardless of what an __add__\\nmethod’s code actually does.\\nOperator overloading methods may be inherited from superclasses if not defined, just\\nlike any other methods. Operator overloading methods are also all optional—if you\\ndon’t code or inherit one, that operation is simply unsupported by your class, and\\nattempting it will raise an exception. Some built-in operations, like printing, have de-\\nfaults (inherited for the implied object class in Python 3.0), but most built-ins fail for\\nclass instances if no corresponding operator overloading method is present.\\nMost overloading methods are used only in advanced programs that require objects to\\nbehave like built-ins; the __init__ constructor tends to appear in most classes, however,\\nso pay special attention to it. We’ve already met the __init__ initialization-time con-\\nstructor method, and a few of the others in Table 29-1 . Let’s explore some of the ad-\\nditional methods in the table by example.\\nThe Basics | 707', metadata={'source': 'python.pdf', 'page': 757}),\n",
       " Document(page_content=\"Indexing and Slicing: __getitem__ and __setitem__\\nIf defined in a \\nclass (or inherited by it), the __getitem__ method is called automatically\\nfor instance-indexing operations. When an instance X appears in an indexing expression\\nlike X[i], Python calls the __getitem__ method inherited by the instance, passing X to\\nthe first argument and the index in brackets to the second argument. For example, the\\nfollowing class returns the square of an index value:\\n>>> class Indexer:\\n...     def __getitem__(self, index):\\n...         return index ** 2\\n...\\n>>> X = Indexer()\\n>>> X[2]                                # X[i] calls X.__getitem__(i)\\n4\\n>>> for i in range(5):\\n...     print(X[i], end=' ')            # Runs __getitem__(X, i) each time\\n...\\n0 1 4 9 16\\nIntercepting Slices\\nInterestingly, in addition to indexing, __getitem__ is also called for slice expressions.\\nFormally speaking, built-in types handle slicing the same way. Here, for example, is\\nslicing at work on a built-in list, using upper and lower bounds and a stride (see Chap-\\nter 7 if you need a refresher on slicing):\\n>>> L = [5, 6, 7, 8, 9]\\n>>> L[2:4]                              # Slice with slice syntax\\n[7, 8]\\n>>> L[1:]\\n[6, 7, 8, 9]\\n>>> L[:-1]\\n[5, 6, 7, 8]\\n>>> L[::2]\\n[5, 7, 9]\\nReally, though, slicing bounds are bundled up into a slice object  and passed to the list’s\\nimplementation of indexing. In fact, you can always pass a slice object manually—slice\\nsyntax is mostly syntactic sugar for indexing with a slice object:\\n>>> L[slice(2, 4)]                      # Slice with slice objects\\n[7, 8]\\n>>> L[slice(1, None)]\\n[6, 7, 8, 9]\\n>>> L[slice(None, −1)]\\n[5, 6, 7, 8]\\n>>> L[slice(None, None, 2)]\\n[5, 7, 9]\\n708 | Chapter 29: \\u2002Operator Overloading\", metadata={'source': 'python.pdf', 'page': 758}),\n",
       " Document(page_content=\"This matters in classes with a __getitem__ method—the method will be called both for\\nbasic indexing (with an index) and for slicing (with a slice object). Our previous class\\nwon’t handle slicing because its math assumes integer indexes are passed, but the fol-\\nlowing class will. When called for indexing, the argument is an integer as before:\\n>>> class Indexer:\\n...     data = [5, 6, 7, 8, 9]\\n...     def __getitem__(self, index):   # Called for index or slice\\n...         print('getitem:', index)\\n...         return self.data[index]     # Perform index or slice\\n...\\n>>> X = Indexer()\\n>>> X[0]                                # Indexing sends __getitem__ an integer\\ngetitem: 0\\n5\\n>>> X[1]\\ngetitem: 1\\n6\\n>>> X[-1]\\ngetitem: −1\\n9\\nWhen called for slicing, though, the method receives a slice object, which is simply\\npassed along to the embedded list indexer in a new index expression:\\n>>> X[2:4]                              # Slicing sends __getitem__ a slice object\\ngetitem: slice(2, 4, None)\\n[7, 8]\\n>>> X[1:]\\ngetitem: slice(1, None, None)\\n[6, 7, 8, 9]\\n>>> X[:-1]\\ngetitem: slice(None, −1, None)\\n[5, 6, 7, 8]\\n>>> X[::2]\\ngetitem: slice(None, None, 2)\\n[5, 7, 9]\\nIf used, the __setitem__ index assignment method similarly intercepts both index and\\nslice assignments—it receives a slice object for the latter, which may be passed along\\nin another index assignment in the same way:\\ndef __setitem__(self, index, value):    # Intercept index or slice assignment\\n    ...\\n    self.data[index] = value            # Assign index or slice\\nIn fact, __getitem__ may be called automatically in even more contexts than indexing\\nand slicing, as the next section explains.\\nSlicing and Indexing in Python 2.6\\nPrior to Python 3.0, \\nclasses could also define __getslice__ and __setslice__ methods\\nto intercept slice fetches and assignments specifically; they were passed the bounds of\\nthe slice expression and were preferred over __getitem__ and __setitem__ for slices.\\nIndexing and Slicing: __getitem__ and __setitem__ | 709\", metadata={'source': 'python.pdf', 'page': 759}),\n",
       " Document(page_content=\"These slice-specific methods have been removed in 3.0, so you should use\\n__getitem__ and __setitem__ \\ninstead and allow for both indexes and slice objects as\\narguments. In most classes, this works without any special code, because indexing\\nmethods can manually pass along the slice object in the square brackets of another\\nindex expression (as in our example). See the section “Membership: __contains__,\\n__iter__, and __getitem__” on page 716 for another example of slice interception at\\nwork.\\nAlso, don’t confuse the (arguably unfortunately named) __index__ method in Python\\n3.0 for index interception; this method returns an integer value for an instance when\\nneeded and is used by built-ins that convert to digit strings:\\n>>> class C:\\n...     def __index__(self):\\n...         return 255\\n...\\n>>> X = C()\\n>>> hex(X)               # Integer value\\n'0xff'\\n>>> bin(X)\\n'0b11111111'\\n>>> oct(X)\\n'0o377'\\nAlthough this method does not intercept instance indexing like __getitem__, it is also\\nused in contexts that require an integer—including indexing:\\n>>> ('C' * 256)[255]\\n'C'\\n>>> ('C' * 256)[X]       # As index (not X[i])\\n'C'\\n>>> ('C' * 256)[X:]      # As index (not X[i:])\\n'C'\\nThis method works the same way in Python 2.6, except that it is not called for the\\nhex and oct built-in functions (use __hex__ and __oct__ in 2.6 instead to intercept these\\ncalls).\\nIndex Iteration: __getitem__\\nHere’s a trick \\nthat isn’t always obvious to beginners, but turns out to be surprisingly\\nuseful. The for statement works by repeatedly indexing a sequence from zero to higher\\nindexes, until an out-of-bounds exception is detected. Because of that, __getitem__ also\\nturns out to be one way to overload iteration in Python—if this method is defined,\\nfor loops call the class’s __getitem__ each time through, with successively higher off-\\nsets. It’s a case of “buy one, get one free”—any built-in or user-defined object that\\nresponds to indexing also responds to iteration:\\n>>> class stepper:\\n...     def __getitem__(self, i):\\n...         return self.data[i]\\n...\\n710 | Chapter 29: \\u2002Operator Overloading\", metadata={'source': 'python.pdf', 'page': 760}),\n",
       " Document(page_content='>>> X = stepper()                     # X is a stepper object\\n>>> X.data = \"Spam\"\\n>>>\\n>>> X[1]                              # Indexing calls __getitem__\\n\\'p\\'\\n>>> for item in X:                    # for loops call __getitem__\\n...     print(item, end=\\' \\')          # for indexes items 0..N\\n...\\nS p a m\\nIn fact, it’s \\nreally a case of “buy one, get a bunch free.” Any class that supports for loops\\nautomatically supports all iteration contexts in Python, many of which we’ve seen in\\nearlier chapters (iteration contexts were presented in Chapter 14). For example, the\\nin membership test, list comprehensions, the map built-in, list and tuple assignments,\\nand type constructors will also call __getitem__ automatically, if it’s defined:\\n>>> \\'p\\' in X                          # All call __getitem__ too\\nTrue\\n>>> [c for c in X]                    # List comprehension\\n[\\'S\\', \\'p\\', \\'a\\', \\'m\\']\\n>>> list(map(str.upper, X))           # map calls (use list() in 3.0)\\n[\\'S\\', \\'P\\', \\'A\\', \\'M\\']\\n>>> (a, b, c, d) = X                  # Sequence assignments\\n>>> a, c, d\\n(\\'S\\', \\'a\\', \\'m\\')\\n>>> list(X), tuple(X), \\'\\'.join(X)\\n([\\'S\\', \\'p\\', \\'a\\', \\'m\\'], (\\'S\\', \\'p\\', \\'a\\', \\'m\\'), \\'Spam\\')\\n>>> X\\n<__main__.stepper object at 0x00A8D5D0>\\nIn practice, this technique can be used to create objects that provide a sequence interface\\nand to add logic to built-in sequence type operations; we’ll revisit this idea when ex-\\ntending built-in types in Chapter 31.\\nIterator Objects: __iter__ and __next__\\nAlthough the __getitem__ technique of the prior section works, it’s really just a fallback\\nfor iteration. Today, all iteration contexts in Python will try the __iter__ method first,\\nbefore trying __getitem__. That is, they prefer the iteration protocol we learned about\\nin Chapter 14  to repeatedly indexing an object; only if the object does not support the\\niteration protocol is indexing attempted instead. Generally speaking, you should prefer\\n__iter__ too—it supports general iteration contexts better than __getitem__ can.\\nTechnically, iteration contexts work by calling the iter built-in function to try to find\\nan __iter__ method, which is expected to return an iterator object. If it’s provided,\\nPython then repeatedly calls this iterator object’s __next__ method to produce items\\nIterator Objects: __iter__ and __next__ | 711', metadata={'source': 'python.pdf', 'page': 761}),\n",
       " Document(page_content=\"until a StopIteration exception is raised. If no such __iter__ method is found, Python\\nfalls back on the __getitem__ scheme and repeatedly indexes by offsets as before, until\\nan IndexError exception is raised. A next built-in function is also available as a con-\\nvenience for manual iterations: next(I) is the same as I.__next__().\\nVersion skew note: As described in Chapter 14, if you are using Python\\n2.6, the I.__next__() method just \\ndescribed is named I.next() in your\\nPython, and the next(I) built-in is present for portability: it calls\\nI.next() in 2.6 and I.__next__() in 3.0. Iteration works the same in 2.6\\nin all other respects.\\nUser-Defined Iterators\\nIn the __iter__ scheme, classes implement user-defined iterators by simply imple-\\nmenting the iteration protocol introduced in Chapters 14 and 20 (refer back to those\\nchapters for more background details on iterators). For example, the following file,\\niters.py, defines a user-defined iterator class that generates squares:\\nclass Squares:\\n    def __init__(self, start, stop):    # Save state when created\\n        self.value = start - 1\\n        self.stop  = stop\\n    def __iter__(self):                 # Get iterator object on iter\\n        return self\\n    def __next__(self):                 # Return a square on each iteration\\n        if self.value == self.stop:     # Also called by next built-in\\n            raise StopIteration\\n        self.value += 1\\n        return self.value ** 2\\n% python\\n>>> from iters import Squares\\n>>> for i in Squares(1, 5):             # for calls iter, which calls __iter__\\n...     print(i, end=' ')               # Each iteration calls __next__\\n...\\n1 4 9 16 25\\nHere, the iterator object is simply the instance self, because the __next__ method is\\npart of this class. In more complex scenarios, the iterator object may be defined as a\\nseparate class and object with its own state information to support multiple active\\niterations over the same data (we’ll see an example of this in a moment). The end of\\nthe iteration is signaled with a Python raise statement (more on raising exceptions in\\nthe next part of this book). Manual iterations work as for built-in types as well:\\n>>> X = Squares(1, 5)                   # Iterate manually: what loops do\\n>>> I = iter(X)                         # iter calls __iter__\\n>>> next(I)                             # next calls __next__\\n1\\n>>> next(I)\\n4\\n712 | Chapter 29: \\u2002Operator Overloading\", metadata={'source': 'python.pdf', 'page': 762}),\n",
       " Document(page_content=\"...more omitted...\\n>>> next(I)\\n25\\n>>> next(I)                             # Can catch this in try statement\\nStopIteration\\nAn equivalent coding \\nof this iterator with __getitem__ might be less natural, because\\nthe for would then iterate through all offsets zero and higher; the offsets passed in\\nwould be only indirectly related to the range of values produced ( 0..N would need to\\nmap to start..stop). Because __iter__ objects retain explicitly managed state between\\nnext calls, they can be more general than __getitem__.\\nOn the other hand, using iterators based on __iter__ can sometimes be more complex\\nand less convenient than using __getitem__. They are really designed for iteration, not\\nrandom indexing—in fact, they don’t overload the indexing expression at all:\\n>>> X = Squares(1, 5)\\n>>> X[1]\\nAttributeError: Squares instance has no attribute '__getitem__'\\nThe __iter__ scheme is also the implementation for all the other iteration contexts we\\nsaw in action for __getitem__ (membership tests, type constructors, sequence assign-\\nment, and so on). However, unlike our prior __getitem__ example, we also need to be\\naware that a class’s __iter__ may be designed for a single traversal, not many. For\\nexample, the Squares class is a one-shot iteration; once you’ve iterated over an instance\\nof that class, it’s empty. You need to make a new iterator object for each new iteration:\\n>>> X = Squares(1, 5)\\n>>> [n for n in X]                      # Exhausts items\\n[1, 4, 9, 16, 25]\\n>>> [n for n in X]                      # Now it's empty\\n[]\\n>>> [n for n in Squares(1, 5)]          # Make a new iterator object\\n[1, 4, 9, 16, 25]\\n>>> list(Squares(1, 3))\\n[1, 4, 9]\\nNotice that this example would probably be simpler if it were coded with generator\\nfunctions (topics or expressions introduced in Chapter 20 and related to iterators):\\n>>> def gsquares(start, stop):\\n...     for i in range(start, stop+1):\\n...         yield i ** 2\\n...\\n>>> for i in gsquares(1, 5):                      # or: (x ** 2 for x in range(1, 5))\\n...     print(i, end=' ')\\n...\\n1 4 9 16 25\\nUnlike the class, the function automatically saves its state between iterations. Of course,\\nfor this artificial example, you could in fact skip both techniques and simply use a\\nfor loop, map, or a list comprehension to build the list all at once. The best and fastest\\nway to accomplish a task in Python is often also the simplest:\\nIterator Objects: __iter__ and __next__ | 713\", metadata={'source': 'python.pdf', 'page': 763}),\n",
       " Document(page_content=\">>> [x ** 2 for x in range(1, 6)]\\n[1, 4, 9, 16, 25]\\nHowever, classes may \\nbe better at modeling more complex iterations, especially when\\nthey can benefit from state information and inheritance hierarchies. The next section\\nexplores one such use case.\\nMultiple Iterators on One Object\\nEarlier, I mentioned that the iterator object may be defined as a separate class with its\\nown state information to support multiple active iterations over the same data. Con-\\nsider what happens when we step across a built-in type like a string:\\n>>> S = 'ace'\\n>>> for x in S:\\n...     for y in S:\\n...         print(x + y, end=' ')\\n...\\naa ac ae ca cc ce ea ec ee\\nHere, the outer loop grabs an iterator from the string by calling iter, and each nested\\nloop does the same to get an independent iterator. Because each active iterator has its\\nown state information, each loop can maintain its own position in the string, regardless\\nof any other active loops.\\nWe saw related examples earlier, in Chapters 14 and 20. For instance, generator func-\\ntions and expressions, as well as built-ins like map and zip, proved to be single-iterator\\nobjects; by contrast, the range built-in and other built-in types, like lists, support mul-\\ntiple active iterators with independent positions.\\nWhen we code user-defined iterators with classes, it’s up to us to decide whether we\\nwill support a single active iteration or many. To achieve the multiple-iterator effect,\\n__iter__ simply needs to define a new stateful object for the iterator, instead of re-\\nturning self.\\nThe following, for example, defines an iterator class that skips every other item on\\niterations. Because the iterator object is created anew for each iteration, it supports\\nmultiple active loops:\\nclass SkipIterator:\\n    def __init__(self, wrapped):\\n        self.wrapped = wrapped                    # Iterator state information\\n        self.offset  = 0\\n    def __next__(self):\\n        if self.offset >= len(self.wrapped):      # Terminate iterations\\n            raise StopIteration\\n        else:\\n            item = self.wrapped[self.offset]      # else return and skip\\n            self.offset += 2\\n            return item\\nclass SkipObject:\\n714 | Chapter 29: \\u2002Operator Overloading\", metadata={'source': 'python.pdf', 'page': 764}),\n",
       " Document(page_content=\"    def __init__(self, wrapped):                  # Save item to be used\\n        self.wrapped = wrapped\\n    def __iter__(self):\\n        return SkipIterator(self.wrapped)         # New iterator each time\\nif __name__ == '__main__':\\n    alpha = 'abcdef'\\n    skipper = SkipObject(alpha)                   # Make container object\\n    I = iter(skipper)                             # Make an iterator on it\\n    print(next(I), next(I), next(I))              # Visit offsets 0, 2, 4\\n    for x in skipper:               # for calls __iter__ automatically\\n        for y in skipper:           # Nested fors call __iter__ again each time\\n            print(x + y, end=' ')   # Each iterator has its own state, offset\\nWhen run, this \\nexample works like the nested loops with built-in strings. Each active\\nloop has its own position in the string because each obtains an independent iterator\\nobject that records its own state information:\\n% python skipper.py\\na c e\\naa ac ae ca cc ce ea ec ee\\nBy contrast, our earlier Squares example supports just one active iteration, unless we\\ncall Squares again in nested loops to obtain new objects. Here, there is just one\\nSkipObject, with multiple iterator objects created from it.\\nAs before, we could achieve similar results with built-in tools—for example, slicing\\nwith a third bound to skip items:\\n>>> S = 'abcdef'\\n>>> for x in S[::2]:\\n...     for y in S[::2]:            # New objects on each iteration\\n...         print(x + y, end=' ')\\n...\\naa ac ae ca cc ce ea ec ee\\nThis isn’t quite the same, though, for two reasons. First, each slice expression here will\\nphysically store the result list all at once in memory; iterators, on the other hand, pro-\\nduce just one value at a time, which can save substantial space for large result lists.\\nSecond, slices produce new objects, so we’re not really iterating over the same object\\nin multiple places here. To be closer to the class, we would need to make a single object\\nto step across by slicing ahead of time:\\n>>> S = 'abcdef'\\n>>> S = S[::2]\\n>>> S\\n'ace'\\n>>> for x in S:\\n...     for y in S:                 # Same object, new iterators\\n...         print(x + y, end=' ')\\n...\\naa ac ae ca cc ce ea ec ee\\nIterator Objects: __iter__ and __next__ | 715\", metadata={'source': 'python.pdf', 'page': 765}),\n",
       " Document(page_content=\"This is more similar to our class-based solution, but it still stores the slice result in\\nmemory all at \\nonce (there is no generator form of built-in slicing today), and it’s only\\nequivalent for this particular case of skipping every other item.\\nBecause iterators can do anything a class can do, they are much more general than this\\nexample may imply. Regardless of whether our applications require such generality,\\nuser-defined iterators are a powerful tool—they allow us to make arbitrary objects look\\nand feel like the other sequences and iterables we have met in this book. We could use\\nthis technique with a database object, for example, to support iterations over database\\nfetches, with multiple cursors into the same query result.\\nMembership: __contains__, __iter__, and __getitem__\\nThe iteration story is even richer than we’ve seen thus far. Operator overloading is often\\nlayered: classes may provide specific methods, or more general alternatives used as\\nfallback options. For example:\\n• Comparisons in Python 2.6 use specific methods such as __lt__ for less than if\\npresent, or else the general __cmp__. Python 3.0 uses only specific methods, not\\n__cmp__, as discussed later in this chapter.\\n• Boolean tests similarly try a specific __bool__ first (to give an explicit True/False\\nresult), and if it’s absent fall back on the more general __len__ (a nonzero length\\nmeans True). As we’ll also see later in this chapter, Python 2.6 works the same but\\nuses the name __nonzero__ instead of __bool__.\\nIn the iterations domain, classes normally implement the in membership operator as\\nan iteration, using either the __iter__ method or the __getitem__ method. To support\\nmore specific membership, though, classes may code a __contains__ method—when\\npresent, this method is preferred over __iter__, which is preferred over __getitem__.\\nThe __contains__ method should define membership as applying to keys for a map-\\nping (and can use quick lookups), and as a search for sequences.\\nConsider the following class, which codes all three methods and tests membership and\\nvarious iteration contexts applied to an instance. Its methods print trace messages when\\ncalled:\\nclass Iters:\\n    def __init__(self, value):\\n        self.data = value\\n    def __getitem__(self, i):                 # Fallback for iteration\\n        print('get[%s]:' % i, end='')         # Also for index, slice\\n        return self.data[i]\\n    def __iter__(self):                       # Preferred for iteration\\n        print('iter=> ', end='')              # Allows only 1 active iterator\\n        self.ix = 0\\n        return self\\n    def __next__(self):\\n        print('next:', end='')\\n716 | Chapter 29: \\u2002Operator Overloading\", metadata={'source': 'python.pdf', 'page': 766}),\n",
       " Document(page_content=\"        if self.ix == len(self.data): raise StopIteration\\n        item = self.data[self.ix]\\n        self.ix += 1\\n        return item\\n    def __contains__(self, x):                # Preferred for 'in'\\n        print('contains: ', end='')\\n        return x in self.data\\nX = Iters([1, 2, 3, 4, 5])          # Make instance\\nprint(3 in X)                       # Membership\\nfor i in X:                         # For loops\\n    print(i, end=' | ')\\nprint()\\nprint([i ** 2 for i in X])          # Other iteration contexts\\nprint( list(map(bin, X)) )\\nI = iter(X)                         # Manual iteration (what other contexts do)\\nwhile True:\\n    try:\\n        print(next(I), end=' @ ')\\n    except StopIteration:\\n        break\\nWhen run as \\nit is, this script’s output is as follows—the specific __contains__ intercepts\\nmembership, the general __iter__ catches other iteration contexts such that __next__\\nis called repeatedly, and __getitem__ is never called:\\ncontains: True\\niter=> next:1 | next:2 | next:3 | next:4 | next:5 | next:\\niter=> next:next:next:next:next:next:[1, 4, 9, 16, 25]\\niter=> next:next:next:next:next:next:['0b1', '0b10', '0b11', '0b100', '0b101']\\niter=> next:1 @ next:2 @ next:3 @ next:4 @ next:5 @ next:\\nWatch what happens to this code’s output if we comment out its __contains__ method,\\nthough—membership is now routed to the general __iter__ instead:\\niter=> next:next:next:True\\niter=> next:1 | next:2 | next:3 | next:4 | next:5 | next:\\niter=> next:next:next:next:next:next:[1, 4, 9, 16, 25]\\niter=> next:next:next:next:next:next:['0b1', '0b10', '0b11', '0b100', '0b101']\\niter=> next:1 @ next:2 @ next:3 @ next:4 @ next:5 @ next:\\nAnd finally, here is the output if both __contains__ and __iter__ are commented out—\\nthe indexing __getitem__ fallback is called with successively higher indexes for mem-\\nbership and other iteration contexts:\\nget[0]:get[1]:get[2]:True\\nget[0]:1 | get[1]:2 | get[2]:3 | get[3]:4 | get[4]:5 | get[5]:\\nget[0]:get[1]:get[2]:get[3]:get[4]:get[5]:[1, 4, 9, 16, 25]\\nget[0]:get[1]:get[2]:get[3]:get[4]:get[5]:['0b1', '0b10', '0b11', '0b100','0b101']\\nget[0]:1 @ get[1]:2 @ get[2]:3 @ get[3]:4 @ get[4]:5 @ get[5]:\\nMembership: __contains__, __iter__, and __getitem__ | 717\", metadata={'source': 'python.pdf', 'page': 767}),\n",
       " Document(page_content='As we’ve seen, the __getitem__ method is even more general: besides iterations, it also\\nintercepts explicit indexing as well as slicing. Slice expressions trigger __getitem__ with\\na slice object containing bounds, both for built-in types and user-defined classes, so\\nslicing is automatic in our class:\\n>>> X = Iters(\\'spam\\')               # Indexing\\n>>> X[0]                            # __getitem__(0)\\nget[0]:\\'s\\'\\n>>> \\'spam\\'[1:]                      # Slice syntax\\n\\'pam\\'\\n>>> \\'spam\\'[slice(1, None)]          # Slice object\\n\\'pam\\'\\n>>> X[1:]                           # __getitem__(slice(..))\\nget[slice(1, None, None)]:\\'pam\\'\\n>>> X[:-1]\\nget[slice(None, −1, None)]:\\'spa\\'\\nIn more realistic iteration use cases that are not sequence-oriented, though, the\\n__iter__ method may be easier to write since it must not manage an integer index, and\\n__contains__ allows for membership optimization as a special case.\\nAttribute Reference: __getattr__ and __setattr__\\nThe __getattr__ method intercepts attribute qualifications. More specifically, it’s\\ncalled with the attribute name as a string whenever you try to qualify an instance with\\nan undefined (nonexistent) attribute name. It is not called if Python can find the attribute\\nusing its inheritance tree search procedure. Because of its behavior, __getattr__ is use-\\nful as a hook for responding to attribute requests in a generic fashion. For example:\\n>>> class empty:\\n...     def __getattr__(self, attrname):\\n...         if attrname == \"age\":\\n...             return 40\\n...         else:\\n...             raise AttributeError, attrname\\n...\\n>>> X = empty()\\n>>> X.age\\n40\\n>>> X.name\\n...error text omitted...\\nAttributeError: name\\nHere, the empty class and its instance X have no real attributes of their own, so the access\\nto X.age gets routed to the __getattr__ method; self is assigned the instance ( X), and\\nattrname is assigned the undefined attribute name string ( \"age\"). The class makes age\\nlook like a real attribute by returning a real value as the result of the X.age qualification\\nexpression (40). In effect, age becomes a dynamically computed attribute.\\n718 | Chapter 29: \\u2002Operator Overloading', metadata={'source': 'python.pdf', 'page': 768}),\n",
       " Document(page_content=\"For attributes that the class doesn’t know how to handle, __getattr__ raises the built-\\nin AttributeError exception to tell Python that these are bona fide undefined names;\\nasking for X.name triggers the error. You’ll see __getattr__ again when we see delegation\\nand properties at work in the next two chapters, and I’ll say more about exceptions in\\nPart VII.\\nA related overloading method, __setattr__, intercepts all attribute assignments. If this\\nmethod is defined, self.attr = value becomes self.__setattr__('attr', value). This\\nis a bit trickier to use because assigning to any self attributes within __setattr__ calls\\n__setattr__ again, causing an infinite recursion loop (and eventually, a stack overflow\\nexception!). If you want to use this method, be sure that it assigns any instance at-\\ntributes by indexing the attribute dictionary, discussed in the next section. That is, use\\nself.__dict__['name'] = x, not self.name = x:\\n>>> class accesscontrol:\\n...     def __setattr__(self, attr, value):\\n...         if attr == 'age':\\n...             self.__dict__[attr] = value\\n...         else:\\n...             raise AttributeError, attr + ' not allowed'\\n...\\n>>> X = accesscontrol()\\n>>> X.age = 40                                  # Calls __setattr__\\n>>> X.age\\n40\\n>>> X.name = 'mel'\\n...text omitted...\\nAttributeError: name not allowed\\nThese two attribute-access overloading methods allow you to control or specialize ac-\\ncess to attributes in your objects. They tend to play highly specialized roles, some of\\nwhich we’ll explore later in this book.\\nOther Attribute Management Tools\\nFor future reference, also note that there are other ways to manage attribute access in\\nPython:\\n• The __getattribute__ method intercepts all attribute fetches, not just those that\\nare undefined, but when using it you must be more cautious than with\\n__getattr__ to avoid loops.\\n• The property built-in function allows us to associate methods with fetch and set\\noperations on a specific class attribute.\\n•Descriptors provide a protocol for associating __get__ and __set__ methods of a\\nclass with accesses to a specific class attribute.\\nBecause these are somewhat advanced tools not of interest to every Python program-\\nmer, we’ll defer a look at properties until Chapter 31  and detailed coverage of all the\\nattribute management techniques until Chapter 37.\\nAttribute Reference: __getattr__ and __setattr__ | 719\", metadata={'source': 'python.pdf', 'page': 769}),\n",
       " Document(page_content=\"Emulating Privacy for Instance Attributes: Part 1\\nThe following code \\ngeneralizes the previous example, to allow each subclass to have\\nits own list of private names that cannot be assigned to its instances:\\nclass PrivateExc(Exception): pass                   # More on exceptions later\\nclass Privacy:\\n    def __setattr__(self, attrname, value):         # On self.attrname = value\\n        if attrname in self.privates:\\n            raise PrivateExc(attrname, self)\\n        else:\\n            self.__dict__[attrname] = value         # self.attrname = value loops!\\nclass Test1(Privacy):\\n    privates = ['age']\\nclass Test2(Privacy):\\n    privates = ['name', 'pay']\\n    def __init__(self):\\n        self.__dict__['name'] = 'Tom'\\nx = Test1()\\ny = Test2()\\nx.name = 'Bob'\\ny.name = 'Sue'                                      # Fails\\ny.age  = 30\\nx.age  = 40                                         # Fails\\nIn fact, this is a first-cut solution for an implementation of attribute privacy  in Python\\n(i.e., disallowing changes to attribute names outside a class). Although Python doesn’t\\nsupport private declarations per se, techniques like this can emulate much of their\\npurpose. This is a partial solution, though; to make it more effective, it must be aug-\\nmented to allow subclasses to set private attributes more naturally, too, and to use\\n__getattr__ and a wrapper (sometimes called a proxy) class to check for private at-\\ntribute fetches.\\nWe’ll postpone a more complete solution to attribute privacy until Chapter 38 , where\\nwe’ll use class decorators  to intercept and validate attributes more generally. Even\\nthough privacy can be emulated this way, though, it almost never is in practice. Python\\nprogrammers are able to write large OOP frameworks and applications without private\\ndeclarations—an interesting finding about access controls in general that is beyond the\\nscope of our purposes here.\\nCatching attribute references and assignments is generally a useful technique; it sup-\\nports delegation, a design technique that allows controller objects to wrap up embedded\\nobjects, add new behaviors, and route other operations back to the wrapped objects\\n(more on delegation and wrapper classes in Chapter 30).\\n720 | Chapter 29: \\u2002Operator Overloading\", metadata={'source': 'python.pdf', 'page': 770}),\n",
       " Document(page_content=\"String Representation: __repr__ and __str__\\nThe next example \\nexercises the __init__ constructor and the __add__ overload method,\\nboth of which we’ve already seen, as well as defining a __repr__ method that returns a\\nstring representation for instances. String formatting is used to convert the managed\\nself.data object to a string. If defined, __repr__ (or its sibling, __str__) is called auto-\\nmatically when class instances are printed or converted to strings. These methods allow\\nyou to define a better display format for your objects than the default instance display.\\nThe default display of instance objects is neither useful nor pretty:\\n>>> class adder:\\n...     def __init__(self, value=0):\\n...         self.data = value                    # Initialize data\\n...     def __add__(self, other):\\n...         self.data += other                   # Add other in-place (bad!)\\n...\\n>>> x = adder()                                  # Default displays\\n>>> print(x)\\n<__main__.adder object at 0x025D66B0>\\n>>> x\\n<__main__.adder object at 0x025D66B0>\\nBut coding or inheriting string representation methods allows us to customize the\\ndisplay:\\n>>> class addrepr(adder):                        # Inherit __init__, __add__\\n...     def __repr__(self):                      # Add string representation\\n...         return 'addrepr(%s)' % self.data     # Convert to as-code string\\n...\\n>>> x = addrepr(2)                               # Runs __init__\\n>>> x + 1                                        # Runs __add__\\n>>> x                                            # Runs __repr__\\naddrepr(3)\\n>>> print(x)                                     # Runs __repr__\\naddrepr(3)\\n>>> str(x), repr(x)                              # Runs __repr__ for both\\n('addrepr(3)', 'addrepr(3)')\\nSo why two display methods? Mostly, to support different audiences. In full detail:\\n•__str__ is tried first for the print operation and the str built-in function (the in-\\nternal equivalent of which print runs). It generally should return a user-friendly\\ndisplay.\\n•__repr__ is used in all other contexts: for interactive echoes, the repr function, and\\nnested appearances, as well as by print and str if no __str__ is present. It should\\ngenerally return an as-code string that could be used to re-create the object, or a\\ndetailed display for developers.\\nIn a nutshell, __repr__ is used everywhere, except by print and str when a __str__ is\\ndefined. Note, however, that while printing falls back on __repr__ if no __str__ is\\nString Representation: __repr__ and __str__ | 721\", metadata={'source': 'python.pdf', 'page': 771}),\n",
       " Document(page_content=\"defined, the inverse is not true—other contexts, such as interactive echoes, use\\n__repr__ only and don’t try __str__ at all:\\n>>> class addstr(adder):\\n...     def __str__(self):                       # __str__ but no __repr__\\n...         return '[Value: %s]' % self.data     # Convert to nice string\\n...\\n>>> x = addstr(3)\\n>>> x + 1\\n>>> x                                            # Default __repr__\\n<__main__.addstr object at 0x00B35EF0>\\n>>> print(x)                                     # Runs __str__\\n[Value: 4]\\n>>> str(x), repr(x)\\n('[Value: 4]', '<__main__.addstr object at 0x00B35EF0>')\\nBecause of this, __repr__\\n may be best if you want a single display for all contexts. By\\ndefining both methods, though, you can support different displays in different\\ncontexts—for example, an end-user display with __str__, and a low-level display for\\nprogrammers to use during development with __repr__. In effect, __str__ simply over-\\nrides __repr__ for user-friendly display contexts:\\n>>> class addboth(adder):\\n...     def __str__(self):\\n...         return '[Value: %s]' % self.data     # User-friendly string\\n...     def __repr__(self):\\n...         return 'addboth(%s)' % self.data     # As-code string\\n...\\n>>> x = addboth(4)\\n>>> x + 1\\n>>> x                                            # Runs __repr__\\naddboth(5)\\n>>> print(x)                                     # Runs __str__\\n[Value: 5]\\n>>> str(x), repr(x)\\n('[Value: 5]', 'addboth(5)')\\nI should mention two usage notes here. First, keep in mind that __str__ and\\n__repr__ must both return strings; other result types are not converted and raise errors,\\nso be sure to run them through a converter if needed. Second, depending on a con-\\ntainer’s string-conversion logic, the user-friendly display of __str__ might only apply\\nwhen objects appear at the top level of a print operation; objects nested in larger objects\\nmight still print with their __repr__ or its default. The following illustrates both of these\\npoints:\\n>>> class Printer:\\n...     def __init__(self, val):\\n...         self.val = val\\n...     def __str__(self):                  # Used for instance itself\\n...         return str(self.val)            # Convert to a string result\\n...\\n>>> objs = [Printer(2), Printer(3)]\\n>>> for x in objs: print(x)                 # __str__ run when instance printed\\n...                                         # But not when instance in a list!\\n722 | Chapter 29: \\u2002Operator Overloading\", metadata={'source': 'python.pdf', 'page': 772}),\n",
       " Document(page_content=\"2\\n3\\n>>> print(objs)\\n[<__main__.Printer object at 0x025D06F0>, <__main__.Printer object at ...more...\\n>>> objs\\n[<__main__.Printer object at 0x025D06F0>, <__main__.Printer object at ...more...\\nTo ensure that \\na custom display is run in all contexts regardless of the container, code\\n__repr__, not __str__; the former is run in all cases if the latter doesn’t apply:\\n>>> class Printer:\\n...     def __init__(self, val):\\n...         self.val = val\\n...     def __repr__(self):                 # __repr__ used by print if no __str__\\n...         return str(self.val)            # __repr__ used if echoed or nested\\n...\\n>>> objs = [Printer(2), Printer(3)]\\n>>> for x in objs: print(x)                 # No __str__: runs __repr__\\n...\\n2\\n3\\n>>> print(objs)                             # Runs __repr__, not ___str__\\n[2, 3]\\n>>> objs\\n[2, 3]\\nIn practice, __str__ (or its low-level relative, __repr__) seems to be the second most\\ncommonly used operator overloading method in Python scripts, behind __init__. Any\\ntime you can print an object and see a custom display, one of these two tools is probably\\nin use.\\nRight-Side and In-Place Addition: __radd__ and __iadd__\\nTechnically, the __add__ method that appeared in the prior example does not support\\nthe use of instance objects on the right side of the + operator. To implement such\\nexpressions, and hence support commutative-style operators, code the __radd__\\nmethod as well. Python calls __radd__ only when the object on the right side of the + is\\nyour class instance, but the object on the left is not an instance of your class. The\\n__add__ method for the object on the left is called instead in all other cases:\\n>>> class Commuter:\\n...     def __init__(self, val):\\n...         self.val = val\\n...     def __add__(self, other):\\n...         print('add', self.val, other)\\n...         return self.val + other\\n...     def __radd__(self, other):\\n...         print('radd', self.val, other)\\n...         return other + self.val\\n...\\n>>> x = Commuter(88)\\n>>> y = Commuter(99)\\nRight-Side and In-Place Addition: __radd__ and __iadd__ | 723\", metadata={'source': 'python.pdf', 'page': 773}),\n",
       " Document(page_content=\">>> x + 1                      # __add__: instance + noninstance\\nadd 88 1\\n89\\n>>> 1 + y                      # __radd__: noninstance + instance\\nradd 99 1\\n100\\n>>> x + y                      # __add__: instance + instance, triggers __radd__\\nadd 88 <__main__.Commuter object at 0x02630910>\\nradd 99 88\\n187\\nNotice how the \\norder is reversed in __radd__: self is really on the right of the +, and\\nother is on the left. Also note that x and y are instances of the same class here; when\\ninstances of different classes appear mixed in an expression, Python prefers the class\\nof the one on the left. When we add the two instances together, Python runs __add__,\\nwhich in turn triggers __radd__ by simplifying the left operand.\\nIn more realistic classes where the class type may need to be propagated in results,\\nthings can become trickier: type testing may be required to tell whether it’s safe to\\nconvert and thus avoid nesting. For instance, without the isinstance test in the fol-\\nlowing, we could wind up with a Commuter whose val is another Commuter when two\\ninstances are added and __add__ triggers __radd__:\\n>>> class Commuter:                    # Propagate class type in results\\n...     def __init__(self, val):\\n...         self.val = val\\n...     def __add__(self, other):\\n...         if isinstance(other, Commuter): other = other.val\\n...         return Commuter(self.val + other)\\n...     def __radd__(self, other):\\n...         return Commuter(other + self.val)\\n...     def __str__(self):\\n...         return '<Commuter: %s>' % self.val\\n...\\n>>> x = Commuter(88)\\n>>> y = Commuter(99)\\n>>> print(x + 10)                      # Result is another Commuter instance\\n<Commuter: 98>\\n>>> print(10 + y)\\n<Commuter: 109>\\n>>> z = x + y                          # Not nested: doesn't recur to __radd__\\n>>> print(z)\\n<Commuter: 187>\\n>>> print(z + 10)\\n<Commuter: 197>\\n>>> print(z + z)\\n<Commuter: 374>\\n724 | Chapter 29: \\u2002Operator Overloading\", metadata={'source': 'python.pdf', 'page': 774}),\n",
       " Document(page_content=\"In-Place Addition\\nTo also implement +=\\n in-place augmented addition, code either an __iadd__ or an\\n__add__. The latter is used if the former is absent. In fact, the prior section’s Commuter\\nclass supports += already for this reason, but __iadd__ allows for more efficient in-place\\nchanges:\\n>>> class Number:\\n...     def __init__(self, val):\\n...         self.val = val\\n...     def __iadd__(self, other):             # __iadd__ explicit: x += y\\n...         self.val += other                  # Usually returns self\\n...         return self\\n...\\n>>> x = Number(5)\\n>>> x += 1\\n>>> x += 1\\n>>> x.val\\n7\\n>>> class Number:\\n...     def __init__(self, val):\\n...         self.val = val\\n...     def __add__(self, other):              # __add__ fallback: x = (x + y)\\n...         return Number(self.val + other)    # Propagates class type\\n...\\n>>> x = Number(5)\\n>>> x += 1\\n>>> x += 1\\n>>> x.val\\n7\\nEvery binary operator has similar right-side and in-place overloading methods that\\nwork the same (e.g., __mul__, __rmul__, and __imul__). Right-side methods are an ad-\\nvanced topic and tend to be fairly rarely used in practice; you only code them when\\nyou need operators to be commutative, and then only if you need to support such\\noperators at all. For instance, a Vector class may use these tools, but an Employee or\\nButton class probably would not.\\nCall Expressions: __call__\\nThe __call__ method is called when your instance is called. No, this isn’t a circular\\ndefinition—if defined, Python runs a __call__ method for function call expressions\\napplied to your instances, passing along whatever positional or keyword arguments\\nwere sent:\\n>>> class Callee:\\n...     def __call__(self, *pargs, **kargs):       # Intercept instance calls\\n...         print('Called:', pargs, kargs)         # Accept arbitrary arguments\\n...\\n>>> C = Callee()\\n>>> C(1, 2, 3)                                     # C is a callable object\\nCall Expressions: __call__ | 725\", metadata={'source': 'python.pdf', 'page': 775}),\n",
       " Document(page_content='Called: (1, 2, 3) {}\\n>>> C(1, 2, 3, x=4, y=5)\\nCalled: (1, 2, 3) {\\'y\\': 5, \\'x\\': 4}\\nMore formally, all \\nthe argument-passing modes we explored in Chapter 18 are sup-\\nported by the __call__ method—whatever is passed to the instance is passed to this\\nmethod, along with the usual implied instance argument. For example, the method\\ndefinitions:\\nclass C:\\n    def __call__(self, a, b, c=5, d=6): ...        # Normals and defaults\\nclass C:\\n    def __call__(self, *pargs, **kargs): ...       # Collect arbitrary arguments\\nclass C:\\n    def __call__(self, *pargs, d=6, **kargs): ...  # 3.0 keyword-only argument\\nall match all the following instance calls:\\nX = C()\\nX(1, 2)                                            # Omit defaults\\nX(1, 2, 3, 4)                                      # Positionals\\nX(a=1, b=2, d=4)                                   # Keywords\\nX(*[1, 2], **dict(c=3, d=4))                       # Unpack arbitrary arguments\\nX(1, *(2,), c=3, **dict(d=4))                      # Mixed modes\\nThe net effect is that classes and instances with a __call__ support the exact same\\nargument syntax and semantics as normal functions and methods.\\nIntercepting call expression like this allows class instances to emulate the look and feel\\nof things like functions, but also retain state information for use during calls (we saw\\na similar example while exploring scopes in Chapter 17 , but you should be more fa-\\nmiliar with operator overloading here):\\n>>> class Prod:\\n...     def __init__(self, value):                 # Accept just one argument\\n...         self.value = value\\n...     def __call__(self, other):\\n...         return self.value * other\\n...\\n>>> x = Prod(2)                                    # \"Remembers\" 2 in state\\n>>> x(3)                                           # 3 (passed) * 2 (state)\\n6\\n>>> x(4)\\n8\\nIn this example, the __call__ may seem a bit gratuitous at first glance. A simple method\\ncan provide similar utility:\\n>>> class Prod:\\n...     def __init__(self, value):\\n...         self.value = value\\n...     def comp(self, other):\\n...         return self.value * other\\n...\\n726 | Chapter 29: \\u2002Operator Overloading', metadata={'source': 'python.pdf', 'page': 776}),\n",
       " Document(page_content=\">>> x = Prod(3)\\n>>> x.comp(3)\\n9\\n>>> x.comp(4)\\n12\\nHowever, __call__ can become \\nmore useful when interfacing with APIs that expect\\nfunctions—it allows us to code objects that conform to an expected function call in-\\nterface, but also retain state information. In fact, it’s probably the third most commonly\\nused operator overloading method, behind the __init__ constructor and the __str__\\nand __repr__ display-format alternatives.\\nFunction Interfaces and Callback-Based Code\\nAs an example, the tkinter GUI toolkit (named Tkinter in Python 2.6) allows you to\\nregister functions as event handlers (a.k.a. callbacks); when events occur, tkinter calls\\nthe registered objects. If you want an event handler to retain state between events, you\\ncan register either a class’s bound method or an instance that conforms to the expected\\ninterface with __call__. In this section’s code, both x.comp from the second example\\nand x from the first can pass as function-like objects this way.\\nI’ll have more to say about bound methods in the next chapter, but for now, here’s a\\nhypothetical example of __call__ applied to the GUI domain. The following class de-\\nfines an object that supports a function-call interface, but also has state information\\nthat remembers the color a button should change to when it is later pressed:\\nclass Callback:\\n    def __init__(self, color):               # Function + state information\\n        self.color = color\\n    def __call__(self):                      # Support calls with no arguments\\n        print('turn', self.color)\\nNow, in the context of a GUI, we can register instances of this class as event handlers\\nfor buttons, even though the GUI expects to be able to invoke event handlers as simple\\nfunctions with no arguments:\\ncb1 = Callback('blue')                       # Remember blue\\ncb2 = Callback('green')\\nB1 = Button(command=cb1)                     # Register handlers\\nB2 = Button(command=cb2)                     # Register handlers\\nWhen the button is later pressed, the instance object is called as a simple function,\\nexactly like in the following calls. Because it retains state as instance attributes, though,\\nit remembers what to do:\\ncb1()                                        # On events: prints 'blue'\\ncb2()                                        # Prints 'green'\\nIn fact, this is probably the best way to retain state information in the Python\\nlanguage—better than the techniques discussed earlier for functions (global variables,\\nCall Expressions: __call__ | 727\", metadata={'source': 'python.pdf', 'page': 777}),\n",
       " Document(page_content=\"enclosing function scope references, and default mutable arguments). With OOP, the\\nstate remembered is made explicit with attribute assignments.\\nBefore we move \\non, there are two other ways that Python programmers sometimes tie\\ninformation to a callback function like this. One option is to use default arguments in\\nlambda functions:\\ncb3 = (lambda color='red': 'turn ' + color)  # Or: defaults\\nprint(cb3())\\nThe other is to use bound methods of a class. A bound method object is a kind of object\\nthat remembers the self instance and the referenced function. A bound method may\\ntherefore be called as a simple function without an instance later:\\nclass Callback:\\n    def __init__(self, color):               # Class with state information\\n        self.color = color\\n    def changeColor(self):                   # A normal named method\\n        print('turn', self.color)\\ncb1 = Callback('blue')\\ncb2 = Callback('yellow')\\nB1 = Button(command=cb1.changeColor)         # Reference, but don't call\\nB2 = Button(command=cb2.changeColor)         # Remembers function+self\\nIn this case, when this button is later pressed it’s as if the GUI does this, which invokes\\nthe changeColor method to process the object’s state information:\\nobject = Callback('blue')\\ncb = object.changeColor                      # Registered event handler\\ncb()                                         # On event prints 'blue'\\nThis technique is simpler, but less general than overloading calls with __call__; again,\\nwatch for more about bound methods in the next chapter.\\nYou’ll also see another __call__ example in Chapter 31 , where we will use it to imple-\\nment something known as a function decorator —a callable object often used to add a\\nlayer of logic on top of an embedded function. Because __call__ allows us to attach\\nstate information to a callable object, it’s a natural implementation technique for a\\nfunction that must remember and call another function.\\nComparisons: __lt__, __gt__, and Others\\nAs suggested in Table 29-1 , classes can define methods to catch all six comparison\\noperators: <, >, <=, >=, ==, and !=. These methods are generally straightforward to use,\\nbut keep the following qualifications in mind:\\n728 | Chapter 29: \\u2002Operator Overloading\", metadata={'source': 'python.pdf', 'page': 778}),\n",
       " Document(page_content=\"• Unlike the __add__/ __radd__ pairings discussed earlier, there are no right-side\\nvariants of comparison methods. Instead, reflective methods are used when only\\none operand supports comparison (e.g., __lt__ and __gt__ are each other’s\\nreflection).\\n• There are no implicit relationships among the comparison operators. The truth of\\n== does not imply that != is false, for example, so both __eq__ and __ne__ should\\nbe defined to ensure that both operators behave correctly.\\n• In Python 2.6, a __cmp__ method is used by all comparisons if no more specific\\ncomparison methods are defined; it returns a number that is less than, equal to, or\\ngreater than zero, to signal less than, equal, and greater than results for the com-\\nparison of its two arguments ( self and another operand). This method often uses\\nthe cmp(x, y) built-in to compute its result. Both the __cmp__ method and the\\ncmp built-in function are removed in Python 3.0: use the more specific methods\\ninstead.\\nWe don’t have space for an in-depth exploration of comparison methods, but as a quick\\nintroduction, consider the following class and test code:\\nclass C:\\n    data = 'spam'\\n    def __gt__(self, other):               # 3.0 and 2.6 version\\n        return self.data > other\\n    def __lt__(self, other):\\n        return self.data < other\\nX = C()\\nprint(X > 'ham')                           # True  (runs __gt__)\\nprint(X < 'ham')                           # False (runs __lt__)\\nWhen run under Python 3.0 or 2.6, the prints at the end display the expected results\\nnoted in their comments, because the class’s methods intercept and implement com-\\nparison expressions.\\nThe 2.6 __cmp__ Method (Removed in 3.0)\\nIn Python 2.6, the __cmp__ method is used as a fallback if more specific methods are\\nnot defined: its integer result is used to evaluate the operator being run. The following\\nproduces the same result under 2.6, for example, but fails in 3.0 because __cmp__ is no\\nlonger used:\\nclass C:\\n    data = 'spam'                          # 2.6 only\\n    def __cmp__(self, other):              # __cmp__ not used in 3.0\\n        return cmp(self.data, other)       # cmp not defined in 3.0\\nX = C()\\nprint(X > 'ham')                           # True  (runs __cmp__)\\nprint(X < 'ham')                           # False (runs __cmp__)\\nComparisons: __lt__, __gt__, and Others | 729\", metadata={'source': 'python.pdf', 'page': 779}),\n",
       " Document(page_content=\"Notice that this fails in 3.0 because __cmp__ is no longer special, not because the cmp\\nbuilt-in function is no longer present. If we change the prior class to the following to\\ntry to simulate the cmp call, the code still works in 2.6 but fails in 3.0:\\nclass C:\\n    data = 'spam'\\n    def __cmp__(self, other):\\n        return (self.data > other) - (self.data < other)\\nSo why, you might be asking, did I just show you a comparison method\\nthat is no \\nlonger supported in 3.0? While it would be easier to erase\\nhistory entirely, this book is designed to support both 2.6 and 3.0 read-\\ners. Because __cmp__ may appear in code 2.6 readers must reuse or\\nmaintain, it’s fair game in this book. Moreover, __cmp__ was removed\\nmore abruptly than the __getslice__ method described earlier, and so\\nmay endure longer. If you use 3.0, though, or care about running your\\ncode under 3.0 in the future, don’t use __cmp__ anymore: use the more\\nspecific comparison methods instead.\\nBoolean Tests: __bool__ and __len__\\nAs mentioned earlier, classes may also define methods that give the Boolean nature of\\ntheir instances—in Boolean contexts, Python first tries __bool__ to obtain a direct\\nBoolean value and then, if that’s missing, tries __len__ to determine a truth value from\\nthe object length. The first of these generally uses object state or other information to\\nproduce a Boolean result:\\n>>> class Truth:\\n...    def __bool__(self): return True\\n...\\n>>> X = Truth()\\n>>> if X: print('yes!')\\n...\\nyes!\\n>>> class Truth:\\n...    def __bool__(self): return False\\n...\\n>>> X = Truth()\\n>>> bool(X)\\nFalse\\nIf this method is missing, Python falls back on length because a nonempty object is\\nconsidered true (i.e., a nonzero length is taken to mean the object is true, and a zero\\nlength means it is false):\\n>>> class Truth:\\n...    def __len__(self): return 0\\n...\\n>>> X = Truth()\\n>>> if not X: print('no!')\\n730 | Chapter 29: \\u2002Operator Overloading\", metadata={'source': 'python.pdf', 'page': 780}),\n",
       " Document(page_content=\"...\\nno!\\nIf both methods \\nare present Python prefers __bool__ over __len__, because it is more\\nspecific:\\n>>> class Truth:\\n...    def __bool__(self): return True            # 3.0 tries __bool__ first\\n...    def __len__(self): return 0                # 2.6 tries __len__ first\\n...\\n>>> X = Truth()\\n>>> if X: print('yes!')\\n...\\nyes!\\nIf neither truth method is defined, the object is vacuously considered true (which has\\npotential implications for metaphysically inclined readers!):\\n>>> class Truth:\\n...     pass\\n...\\n>>> X = Truth()\\n>>> bool(X)\\nTrue\\nAnd now that we’ve managed to cross over into the realm of philosophy, let’s move on\\nto look at one last overloading context: object demise.\\nBooleans in Python 2.6\\nPython 2.6 users \\nshould use __nonzero__ instead of __bool__ in all of the code in the\\nsection “Boolean Tests: __bool__ and __len__” on page 730. Python 3.0 renamed the\\n2.6 __nonzero__ method to __bool__, but Boolean tests work the same otherwise (both\\n3.0 and 2.6 use __len__ as a fallback).\\nIf you don’t use the 2.6 name, the very first test in this section will work the same for\\nyou anyhow, but only because __bool__ is not recognized as a special method name in\\n2.6, and objects are considered true by default!\\nTo witness this version difference live, you need to return False:\\nC:\\\\misc> c:\\\\python30\\\\python\\n>>> class C:\\n...     def __bool__(self):\\n...         print('in bool')\\n...         return False\\n...\\n>>> X = C()\\n>>> bool(X)\\nin bool\\nFalse\\n>>> if X: print(99)\\n...\\nin bool\\nBoolean Tests: __bool__ and __len__ | 731\", metadata={'source': 'python.pdf', 'page': 781}),\n",
       " Document(page_content=\"This works as advertised in 3.0. In 2.6, though, __bool__ is ignored and the object is\\nalways considered true:\\nC:\\\\misc> c:\\\\python26\\\\python\\n>>> class C:\\n...     def __bool__(self):\\n...         print('in bool')\\n...         return False\\n...\\n>>> X = C()\\n>>> bool(X)\\nTrue\\n>>> if X: print(99)\\n...\\n99\\nIn 2.6, use __nonzero__ for Boolean values (or return 0 from the __len__ fallback method\\nto designate false):\\nC:\\\\misc> c:\\\\python26\\\\python\\n>>> class C:\\n...     def __nonzero__(self):\\n...         print('in nonzero')\\n...         return False\\n...\\n>>> X = C()\\n>>> bool(X)\\nin nonzero\\nFalse\\n>>> if X: print(99)\\n...\\nin nonzero\\nBut keep in mind that __nonzero__ works in 2.6 only; if used in 3.0 it will be silently\\nignored and the object will be classified as true by default—just like using __bool__ in\\n2.6!\\nObject Destruction: __del__\\nWe’ve seen how the __init__ constructor is called whenever an instance is generated.\\nIts counterpart, \\nthe destructor method __del__, is run automatically when an instance’s\\nspace is being reclaimed (i.e., at “garbage collection” time):\\n>>> class Life:\\n...     def __init__(self, name='unknown'):\\n...         print('Hello', name)\\n...         self.name = name\\n...     def __del__(self):\\n...         print('Goodbye', self.name)\\n...\\n>>> brian = Life('Brian')\\nHello Brian\\n>>> brian = 'loretta'\\nGoodbye Brian\\n732 | Chapter 29: \\u2002Operator Overloading\", metadata={'source': 'python.pdf', 'page': 782}),\n",
       " Document(page_content='Here, when brian is assigned a string, we lose the last reference to the Life instance\\nand so trigger its destructor method. This works, and it may be useful for implementing\\nsome cleanup activities (such as terminating server connections). However, destructors\\nare not as commonly used in Python as in some OOP languages, for a number of\\nreasons.\\nFor one thing, because Python automatically reclaims all space held by an instance\\nwhen the instance is reclaimed, destructors are not necessary for space management.*\\nFor another, because you cannot always easily predict when an instance will be\\nreclaimed, it’s often better to code termination activities in an explicitly called method\\n(or try/finally statement, described in the next part of the book); in some cases, there\\nmay be lingering references to your objects in system tables that prevent destructors\\nfrom running.\\nIn fact, __del__ can be tricky to use for even more subtle reasons. Ex-\\nceptions raised within it, for example, simply print a warning message\\nto sys.stderr (the standard error stream) rather than triggering an ex-\\nception event, because of the unpredictable context under which it is\\nrun by the garbage collector. In addition, cyclic (a.k.a. circular) refer-\\nences among objects may prevent garbage collection from happening\\nwhen you expect it to; an optional cycle detector, enabled by default,\\ncan automatically collect such objects eventually, but only if they do not\\nhave __del__ methods. Since this is relatively obscure, we’ll ignore fur-\\nther details here; see Python’s standard manuals’ coverage of both\\n__del__ and the gc garbage collector module for more information.\\nChapter Summary\\nThat’s as many overloading examples as we have space for here. Most of the other\\noperator overloading methods work similarly to the ones we’ve explored, and all are\\njust hooks for intercepting built-in type operations; some overloading methods, for\\nexample, have unique argument lists or return values. We’ll see a few others in action\\nlater in the book:\\n•Chapter 33  uses the __enter__ and __exit__ with statement context manager\\nmethods.\\n•Chapter 37 uses the __get__ and __set__ class descriptor fetch/set methods.\\n•Chapter 39  uses the __new__ object creation method in the context of metaclasses.\\n* In the current C implementation of Python, you also don’t need to close file objects held by the instance in\\ndestructors because \\nthey are automatically closed when reclaimed. However, as mentioned in Chapter 9 , it’s\\nbetter to explicitly call file close methods because auto-close-on-reclaim is a feature of the implementation,\\nnot of the language itself (this behavior can vary under Jython, for instance).\\nChapter Summary | 733', metadata={'source': 'python.pdf', 'page': 783}),\n",
       " Document(page_content='In addition, some of the methods we’ve studied here, such as __call__ and __str__,\\nwill \\nbe employed by later examples in this book. For complete coverage, though, I’ll\\ndefer to other documentation sources—see Python’s standard language manual or ref-\\nerence books for details on additional overloading methods.\\nIn the next chapter, we leave the realm of class mechanics behind to explore common\\ndesign patterns—the ways that classes are commonly used and combined to optimize\\ncode reuse. Before you read on, though, take a moment to work though the chapter\\nquiz below to review the concepts we’ve covered.\\nTest Your Knowledge: Quiz\\n1. What two operator \\noverloading methods can you use to support iteration in your\\nclasses?\\n2. What two operator overloading methods handle printing, and in what contexts?\\n3. How can you intercept slice operations in a class?\\n4. How can you catch in-place addition in a class?\\n5. When should you provide operator overloading?\\nTest Your Knowledge: Answers\\n1. Classes can support iteration by defining (or inheriting) __getitem__ or __iter__.\\nIn all iteration contexts, Python tries to use __iter__ (which returns an object that\\nsupports the iteration protocol with a __next__ method) first: if no __iter__ is\\nfound by inheritance search, Python falls back on the __getitem__ indexing method\\n(which is called repeatedly, with successively higher indexes).\\n2. The __str__ and __repr__ methods implement object print displays. The former is\\ncalled by the print and str built-in functions; the latter is called by print and str\\nif there is no __str__, and always by the repr built-in, interactive echoes, and nested\\nappearances. That is, __repr__ is used everywhere, except by print and str when\\na __str__ is defined. A __str__ is usually used for user-friendly displays;\\n__repr__ gives extra details or the object’s as-code form.\\n3. Slicing is caught by the __getitem__ indexing method: it is called with a slice object,\\ninstead of a simple index. In Python 2.6, __getslice__ (defunct in 3.0) may be used\\nas well.\\n4. In-place addition tries __iadd__ first, and __add__ with an assignment second. The\\nsame pattern holds true for all binary operators. The __radd__ method is also avail-\\nable for right-side addition.\\n734 | Chapter 29: \\u2002Operator Overloading', metadata={'source': 'python.pdf', 'page': 784}),\n",
       " Document(page_content='5. When a class naturally matches, or needs to emulate, a built-in type’s interfaces.\\nFor example, \\ncollections might imitate sequence or mapping interfaces. You gen-\\nerally shouldn’t implement expression operators if they don’t naturally map to\\nyour objects, though—use normally named methods instead.\\nTest Your Knowledge: Answers | 735', metadata={'source': 'python.pdf', 'page': 785}),\n",
       " Document(page_content='', metadata={'source': 'python.pdf', 'page': 786}),\n",
       " Document(page_content='CHAPTER 30\\nDesigning with Classes\\nSo far in this part of the book, we’ve concentrated on using Python’s OOP tool, the\\nclass. But OOP \\nis also about design issues—i.e., how to use classes to model useful\\nobjects. This chapter will touch on a few core OOP ideas and present some additional\\nexamples that are more realistic than those shown so far.\\nAlong the way, we’ll code some common OOP design patterns in Python, such as\\ninheritance, composition, delegation, and factories. We’ll also investigate some design-\\nfocused class concepts, such as pseudoprivate attributes, multiple inheritance, and\\nbound methods. Many of the design terms mentioned here require more explanation\\nthan I can provide in this book; if this material sparks your curiosity, I suggest exploring\\na text on OOP design or design patterns as a next step.\\nPython and OOP\\nLet’s begin with a review—Python’s implementation of OOP can be summarized by\\nthree ideas:\\nInheritance\\nInheritance is based on attribute lookup in Python (in X.name expressions).\\nPolymorphism\\nIn X.method, the meaning of method depends on the type (class) of X.\\nEncapsulation\\nMethods and operators implement behavior; data hiding is a convention by default.\\nBy now, you should have a good feel for what inheritance is all about in Python. We’ve\\nalso talked about Python’s polymorphism a few times already; it flows from Python’s\\nlack of type declarations. Because attributes are always resolved at runtime, objects that\\nimplement the same interfaces are interchangeable; clients don’t need to know what\\nsorts of objects are implementing the methods they call.\\n737', metadata={'source': 'python.pdf', 'page': 787}),\n",
       " Document(page_content='Encapsulation means packaging in Python—that is, hiding implementation details be-\\nhind an object’s \\ninterface. It does not mean enforced privacy, though that can be\\nimplemented with code, as we’ll see in Chapter 38. Encapsulation allows the imple-\\nmentation of an object’s interface to be changed without impacting the users of that\\nobject.\\nOverloading by Call Signatures (or Not)\\nSome OOP languages also define polymorphism to mean overloading functions based\\non the type signatures of their arguments. But because there are no type declarations\\nin Python, this concept doesn’t really apply; polymorphism in Python is based on object\\ninterfaces, not types.\\nYou can try to overload methods by their argument lists, like this:\\nclass C:\\n    def meth(self, x):\\n        ...\\n    def meth(self, x, y, z):\\n        ...\\nThis code will run, but because the def simply assigns an object to a name in the class’s\\nscope, the last definition of the method function is the only one that will be retained\\n(it’s just as if you say X = 1 and then X = 2; X will be 2).\\nType-based selections can always be coded using the type-testing ideas we met in\\nChapters 4 and 9, or the argument list tools introduced in Chapter 18:\\nclass C:\\n    def meth(self, *args):\\n        if len(args) == 1:\\n            ...\\n        elif type(arg[0]) == int:\\n            ...\\nYou normally shouldn’t do this, though—as described in Chapter 16, you should write\\nyour code to expect an object interface, not a specific data type. That way, it will be\\nuseful for a broader category of types and applications, both now and in the future:\\nclass C:\\n    def meth(self, x):\\n        x.operation()                   # Assume x does the right thing\\nIt’s also generally considered better to use distinct method names for distinct opera-\\ntions, rather than relying on call signatures (no matter what language you code in).\\nAlthough Python’s object model is straightforward, much of the art in OOP is in the\\nway we combine classes to achieve a program’s goals. The next section begins a tour\\nof some of the ways larger programs use classes to their advantage.\\n738 | Chapter 30: \\u2002Designing with Classes', metadata={'source': 'python.pdf', 'page': 788}),\n",
       " Document(page_content='OOP and Inheritance: “Is-a” Relationships\\nWe’ve explored the \\nmechanics of inheritance in depth already, but I’d like to show you\\nan example of how it can be used to model real-world relationships. From a program-\\nmer’s point of view, inheritance is kicked off by attribute qualifications, which trigger\\nsearches for names in instances, their classes, and then any superclasses. From a de-\\nsigner’s point of view, inheritance is a way to specify set membership: a class defines a\\nset of properties that may be inherited and customized by more specific sets (i.e.,\\nsubclasses).\\nTo illustrate, let’s put that pizza-making robot we talked about at the start of this part\\nof the book to work. Suppose we’ve decided to explore alternative career paths and\\nopen a pizza restaurant. One of the first things we’ll need to do is hire employees to\\nserve customers, prepare the food, and so on. Being engineers at heart, we’ve decided\\nto build a robot to make the pizzas; but being politically and cybernetically correct,\\nwe’ve also decided to make our robot a full-fledged employee with a salary.\\nOur pizza shop team can be defined by the four classes in the example file,\\nemployees.py. The most general class, Employee, provides common behavior such as\\nbumping up salaries ( giveRaise) and printing ( __repr__). There are two kinds of em-\\nployees, and so two subclasses of Employee: Chef and Server. Both override the inherited\\nwork method to print more specific messages. Finally, our pizza robot is modeled by an\\neven more specific class: PizzaRobot is a kind of Chef, which is a kind of Employee. In\\nOOP terms, we call these relationships “is-a” links: a robot is a chef, which is a(n)\\nemployee. Here’s the employees.py file:\\nclass Employee:\\n    def __init__(self, name, salary=0):\\n        self.name   = name\\n        self.salary = salary\\n    def giveRaise(self, percent):\\n        self.salary = self.salary + (self.salary * percent)\\n    def work(self):\\n        print(self.name, \"does stuff\")\\n    def __repr__(self):\\n        return \"<Employee: name=%s, salary=%s>\" % (self.name, self.salary)\\nclass Chef(Employee):\\n    def __init__(self, name):\\n        Employee.__init__(self, name, 50000)\\n    def work(self):\\n        print(self.name, \"makes food\")\\nclass Server(Employee):\\n    def __init__(self, name):\\n        Employee.__init__(self, name, 40000)\\n    def work(self):\\n        print(self.name, \"interfaces with customer\")\\nclass PizzaRobot(Chef):\\nOOP and Inheritance: “Is-a” Relationships | 739', metadata={'source': 'python.pdf', 'page': 789}),\n",
       " Document(page_content='    def __init__(self, name):\\n        Chef.__init__(self, name)\\n    def work(self):\\n        print(self.name, \"makes pizza\")\\nif __name__ == \"__main__\":\\n    bob = PizzaRobot(\\'bob\\')       # Make a robot named bob\\n    print(bob)                    # Run inherited __repr__\\n    bob.work()                    # Run type-specific action\\n    bob.giveRaise(0.20)           # Give bob a 20% raise\\n    print(bob); print()\\n    for klass in Employee, Chef, Server, PizzaRobot:\\n        obj = klass(klass.__name__)\\n        obj.work()\\nWhen we run \\nthe self-test code included in this module, we create a pizza-making robot\\nnamed bob, which inherits names from three classes: PizzaRobot, Chef, and Employee.\\nFor instance, printing bob runs the Employee.__repr__ method, and giving bob a raise\\ninvokes Employee.giveRaise because that’s where the inheritance search finds that\\nmethod:\\nC:\\\\python\\\\examples> python employees.py\\n<Employee: name=bob, salary=50000>\\nbob makes pizza\\n<Employee: name=bob, salary=60000.0>\\nEmployee does stuff\\nChef makes food\\nServer interfaces with customer\\nPizzaRobot makes pizza\\nIn a class hierarchy like this, you can usually make instances of any of the classes, not\\njust the ones at the bottom. For instance, the for loop in this module’s self-test code\\ncreates instances of all four classes; each responds differently when asked to work be-\\ncause the work method is different in each. Really, these classes just simulate real-world\\nobjects; work prints a message for the time being, but it could be expanded to do real\\nwork later.\\nOOP and Composition: “Has-a” Relationships\\nThe notion of composition was introduced in Chapter 25. From a programmer’s point\\nof view, composition involves embedding other objects in a container object, and ac-\\ntivating them to implement container methods. To a designer, composition is another\\nway to represent relationships in a problem domain. But, rather than set membership,\\ncomposition has to do with components—parts of a whole.\\nComposition also reflects the relationships between parts, called a “has-a” relation-\\nships. Some OOP design texts refer to composition as aggregation (or distinguish be-\\ntween the two terms by using aggregation to describe a weaker dependency between\\n740 | Chapter 30: \\u2002Designing with Classes', metadata={'source': 'python.pdf', 'page': 790}),\n",
       " Document(page_content='container and contained); in this text, a “composition” simply refers to a collection of\\nembedded objects. The \\ncomposite class generally provides an interface all its own and\\nimplements it by directing the embedded objects.\\nNow that we’ve implemented our employees, let’s put them in the pizza shop and let\\nthem get busy. Our pizza shop is a composite object: it has an oven, and it has employees\\nlike servers and chefs. When a customer enters and places an order, the components\\nof the shop spring into action—the server takes the order, the chef makes the pizza,\\nand so on. The following example (the file pizzashop.py) simulates all the objects and\\nrelationships in this scenario:\\nfrom employees import PizzaRobot, Server\\nclass Customer:\\n    def __init__(self, name):\\n        self.name = name\\n    def order(self, server):\\n        print(self.name, \"orders from\", server)\\n    def pay(self, server):\\n        print(self.name, \"pays for item to\", server)\\nclass Oven:\\n    def bake(self):\\n        print(\"oven bakes\")\\nclass PizzaShop:\\n    def __init__(self):\\n        self.server = Server(\\'Pat\\')         # Embed other objects\\n        self.chef   = PizzaRobot(\\'Bob\\')     # A robot named bob\\n        self.oven   = Oven()\\n    def order(self, name):\\n        customer = Customer(name)           # Activate other objects\\n        customer.order(self.server)         # Customer orders from server\\n        self.chef.work()\\n        self.oven.bake()\\n        customer.pay(self.server)\\nif __name__ == \"__main__\":\\n    scene = PizzaShop()                     # Make the composite\\n    scene.order(\\'Homer\\')                    # Simulate Homer\\'s order\\n    print(\\'...\\')\\n    scene.order(\\'Shaggy\\')                   # Simulate Shaggy\\'s order\\nThe PizzaShop class is a container and controller; its constructor makes and embeds\\ninstances of the employee classes we wrote in the last section, as well as an Oven class\\ndefined here. When this module’s self-test code calls the PizzaShop order  method, the\\nembedded objects are asked to carry out their actions in turn. Notice that we make a\\nnew Customer object for each order, and we pass on the embedded Server object to\\nCustomer methods; customers come and go, but the server is part of the pizza shop\\ncomposite. Also notice that employees are still involved in an inheritance relationship;\\ncomposition and inheritance are complementary tools.\\nOOP and Composition: “Has-a” Relationships | 741', metadata={'source': 'python.pdf', 'page': 791}),\n",
       " Document(page_content=\"When we run this module, our pizza shop handles two orders—one from Homer, and\\nthen one from Shaggy:\\nC:\\\\python\\\\examples> python pizzashop.py\\nHomer orders from <Employee: name=Pat, salary=40000>\\nBob makes pizza\\noven bakes\\nHomer pays for item to <Employee: name=Pat, salary=40000>\\n...\\nShaggy orders from <Employee: name=Pat, salary=40000>\\nBob makes pizza\\noven bakes\\nShaggy pays for item to <Employee: name=Pat, salary=40000>\\nAgain, this is \\nmostly just a toy simulation, but the objects and interactions are repre-\\nsentative of composites at work. As a rule of thumb, classes can represent just about\\nany objects and relationships you can express in a sentence; just replace nouns with\\nclasses, and verbs with methods, and you’ll have a first cut at a design.\\nStream Processors Revisited\\nFor a more realistic composition example, recall the generic data stream processor\\nfunction we partially coded in the introduction to OOP in Chapter 25:\\ndef processor(reader, converter, writer):\\n    while 1:\\n        data = reader.read()\\n        if not data: break\\n        data = converter(data)\\n        writer.write(data)\\nRather than using a simple function here, we might code this as a class that uses com-\\nposition to do its work to provide more structure and support inheritance. The fol-\\nlowing file, streams.py, demonstrates one way to code the class:\\nclass Processor:\\n    def __init__(self, reader, writer):\\n        self.reader = reader\\n        self.writer = writer\\n    def process(self):\\n        while 1:\\n            data = self.reader.readline()\\n            if not data: break\\n            data = self.converter(data)\\n            self.writer.write(data)\\n    def converter(self, data):\\n        assert False, 'converter must be defined'       # Or raise exception\\nThis class defines a converter method that it expects subclasses to fill in; it’s an example\\nof the abstract superclass model we outlined in Chapter 28 (more on assert in\\nPart VII ). Coded this way, reader and writer objects are embedded within the class\\ninstance (composition), and we supply the conversion logic in a subclass rather than\\npassing in a converter function (inheritance). The file converters.py shows how:\\n742 | Chapter 30: \\u2002Designing with Classes\", metadata={'source': 'python.pdf', 'page': 792}),\n",
       " Document(page_content=\"from streams import Processor\\nclass Uppercase(Processor):\\n    def converter(self, data):\\n        return data.upper()\\nif __name__ == '__main__':\\n    import sys\\n    obj = Uppercase(open('spam.txt'), sys.stdout)\\n    obj.process()\\nHere, the Uppercase class inherits \\nthe stream-processing loop logic (and anything else\\nthat may be coded in its superclasses). It needs to define only what is unique about it—\\nthe data conversion logic. When this file is run, it makes and runs an instance that reads\\nfrom the file spam.txt and writes the uppercase equivalent of that file to the stdout\\nstream:\\nC:\\\\lp4e> type spam.txt\\nspam\\nSpam\\nSPAM!\\nC:\\\\lp4e> python converters.py\\nSPAM\\nSPAM\\nSPAM!\\nTo process different sorts of streams, pass in different sorts of objects to the class con-\\nstruction call. Here, we use an output file instead of a stream:\\nC:\\\\lp4e> python\\n>>> import converters\\n>>> prog = converters.Uppercase(open('spam.txt'), open('spamup.txt', 'w'))\\n>>> prog.process()\\nC:\\\\lp4e> type spamup.txt\\nSPAM\\nSPAM\\nSPAM!\\nBut, as suggested earlier, we could also pass in arbitrary objects wrapped up in classes\\nthat define the required input and output method interfaces. Here’s a simple example\\nthat passes in a writer class that wraps up the text inside HTML tags:\\nC:\\\\lp4e> python\\n>>> from converters import Uppercase\\n>>>\\n>>> class HTMLize:\\n...      def write(self, line):\\n...         print('<PRE>%s</PRE>' % line.rstrip())\\n...\\n>>> Uppercase(open('spam.txt'), HTMLize()).process()\\n<PRE>SPAM</PRE>\\n<PRE>SPAM</PRE>\\n<PRE>SPAM!</PRE>\\nOOP and Composition: “Has-a” Relationships | 743\", metadata={'source': 'python.pdf', 'page': 793}),\n",
       " Document(page_content=\"If you trace through this example’s control flow, you’ll see that we get both uppercase\\nconversion (by inheritance) \\nand HTML formatting (by composition), even though the\\ncore processing logic in the original Processor superclass knows nothing about either\\nstep. The processing code only cares that writers have a write method and that a method\\nnamed convert is defined; it doesn’t care what those methods do when they are called.\\nSuch polymorphism and encapsulation of logic is behind much of the power of classes.\\nAs is, the Processor superclass only provides a file-scanning loop. In more realistic\\nwork, we might extend it to support additional programming tools for its subclasses,\\nand, in the process, turn it into a full-blown framework. Coding such a tool once in a\\nsuperclass enables you to reuse it in all of your programs. Even in this simple example,\\nbecause so much is packaged and inherited with classes, all we had to code was the\\nHTML formatting step; the rest was free.\\nFor another example of composition at work, see exercise 9 at the end of Chapter 31\\nand its solution in Appendix B ; it’s similar to the pizza shop example. We’ve focused\\non inheritance in this book because that is the main tool that the Python language itself\\nprovides for OOP. But, in practice, composition is used as much as inheritance as a\\nway to structure classes, especially in larger systems. As we’ve seen, inheritance and\\ncomposition are often complementary (and sometimes alternative) techniques. Because\\ncomposition is a design issue outside the scope of the Python language and this book,\\nthough, I’ll defer to other resources for more on this topic.\\nWhy You Will Care: Classes and Persistence\\nI’ve mentioned Python’s pickle\\n and shelve object persistence support a few times in\\nthis part of the book because it works especially well with class instances. In fact, these\\ntools are often compelling enough to motivate the use of classes in general—by picking\\nor shelving a class instance, we get data storage that contains both data and logic\\ncombined.\\nFor example, besides allowing us to simulate real-world interactions, the pizza shop\\nclasses developed in this chapter could also be used as the basis of a persistent restaurant\\ndatabase. Instances of classes can be stored away on disk in a single step using Python’s\\npickle or shelve modules. We used shelves to store instances of classes in the OOP\\ntutorial in Chapter 27 , but the object pickling interface is remarkably easy to use as well:\\nimport pickle\\nobject = someClass()\\nfile   = open(filename, 'wb')     # Create external file\\npickle.dump(object, file)         # Save object in file\\nimport pickle\\nfile   = open(filename, 'rb')\\nobject = pickle.load(file)        # Fetch it back later\\n744 | Chapter 30: \\u2002Designing with Classes\", metadata={'source': 'python.pdf', 'page': 794}),\n",
       " Document(page_content=\"Pickling converts in-memory objects to serialized byte streams (really, strings), which\\nmay be stored \\nin files, sent across a network, and so on; unpickling converts back from\\nbyte streams to identical in-memory objects. Shelves are similar, but they automatically\\npickle objects to an access-by-key database, which exports a dictionary-like interface:\\nimport shelve\\nobject = someClass()\\ndbase  = shelve.open('filename')\\ndbase['key'] = object             # Save under key\\nimport shelve\\ndbase  = shelve.open('filename')\\nobject = dbase['key']             # Fetch it back later\\nIn our pizza shop example, using classes to model employees means we can get a simple\\ndatabase of employees and shops with little extra work—pickling such instance objects\\nto a file makes them persistent across Python program executions:\\n>>> from pizzashop import PizzaShop\\n>>> shop = PizzaShop()\\n>>> shop.server, shop.chef\\n(<Employee: name=Pat, salary=40000>, <Employee: name=Bob, salary=50000>)\\n>>> import pickle\\n>>> pickle.dump(shop, open('shopfile.dat', 'wb'))\\nThis stores an entire composite shop object in a file all at once. To bring it back later in\\nanother session or program, a single step suffices as well. In fact, objects restored this\\nway retain both state and behavior:\\n>>> import pickle\\n>>> obj = pickle.load(open('shopfile.dat', 'rb'))\\n>>> obj.server, obj.chef\\n(<Employee: name=Pat, salary=40000>, <Employee: name=Bob, salary=50000>)\\n>>> obj.order('Sue')\\nSue orders from <Employee: name=Pat, salary=40000>\\nBob makes pizza\\noven bakes\\nSue pays for item to <Employee: name=Pat, salary=40000>\\nSee the standard library manual and later examples for more on pickles and shelves.\\nOOP and Delegation: “Wrapper” Objects\\nBeside inheritance and \\ncomposition, object-oriented programmers often also talk about\\nsomething called delegation, which usually implies controller objects that embed other\\nobjects to which they pass off operation requests. The controllers can take care of\\nadministrative activities, such as keeping track of accesses and so on. In Python, dele-\\ngation is often implemented with the __getattr__ method hook; because it intercepts\\naccesses to nonexistent attributes, a wrapper class (sometimes called a proxy class) can\\nuse __getattr__ to route arbitrary accesses to a wrapped object. The wrapper class\\nretains the interface of the wrapped object and may add additional operations of its\\nown.\\nOOP and Delegation: “Wrapper” Objects | 745\", metadata={'source': 'python.pdf', 'page': 795}),\n",
       " Document(page_content='Consider the file trace.py, for instance:\\nclass wrapper:\\n    def __init__(self, object):\\n        self.wrapped = object                    # Save object\\n    def __getattr__(self, attrname):\\n        print(\\'Trace:\\', attrname)                # Trace fetch\\n        return getattr(self.wrapped, attrname)   # Delegate fetch\\nRecall from Chapter 29  that __getattr__ gets the \\nattribute name as a string. This code\\nmakes use of the getattr built-in function to fetch an attribute from the wrapped object\\nby name string— getattr(X,N) is like X.N, except that N is an expression that evaluates\\nto a string at runtime, not a variable. In fact, getattr(X,N) is similar to X.__dict__[N],\\nbut the former also performs an inheritance search, like X.N, while the latter does not\\n(see “Namespace Dictionaries” on page 696 for more on the __dict__ attribute).\\nYou can use the approach of this module’s wrapper class to manage access to any object\\nwith attributes—lists, dictionaries, and even classes and instances. Here, the wrapper\\nclass simply prints a trace message on each attribute access and delegates the attribute\\nrequest to the embedded wrapped object:\\n>>> from trace import wrapper\\n>>> x = wrapper([1,2,3])                         # Wrap a list\\n>>> x.append(4)                                  # Delegate to list method\\nTrace: append\\n>>> x.wrapped                                    # Print my member\\n[1, 2, 3, 4]\\n>>> x = wrapper({\"a\": 1, \"b\": 2})                # Wrap a dictionary\\n>>> x.keys()                                     # Delegate to dictionary method\\nTrace: keys\\n[\\'a\\', \\'b\\']\\nThe net effect is to augment the entire interface of the wrapped object, with additional\\ncode in the wrapper class. We can use this to log our method calls, route method calls\\nto extra or custom logic, and so on.\\nWe’ll revive the notions of wrapped objects and delegated operations as one way to\\nextend built-in types in Chapter 31 . If you are interested in the delegation design pat-\\ntern, also watch for the discussions in Chapters 31 and 38 of function decorators , a\\nstrongly related concept designed to augment a specific function or method call rather\\nthan the entire interface of an object, and class decorators , which serve as a way to\\nautomatically add such delegation-based wrappers to all instances of a class.\\n746 | Chapter 30: \\u2002Designing with Classes', metadata={'source': 'python.pdf', 'page': 796}),\n",
       " Document(page_content='Version skew note : In Python 2.6, operator overloading methods run by\\nbuilt-in operations are routed through generic attribute interception\\nmethods like __getattr__. Printing a wrapped object directly, for ex-\\nample, calls this method for __repr__ or __str__, which then passes the\\ncall on to the wrapped object. In Python 3.0, this no longer happens:\\nprinting does not trigger __getattr__, and a default display is used in-\\nstead. In 3.0, new-style classes look up operator overloading methods\\nin classes and skip the normal instance lookup entirely. We’ll return to\\nthis issue in Chapter 37 , in the context of managed attributes; for now,\\nkeep in mind that you may need to redefine operator overloading meth-\\nods in wrapper classes (either by hand, by tools, or by superclasses) if\\nyou want them to be intercepted in 3.0.\\nPseudoprivate Class Attributes\\nBesides larger structuring goals, class designs often must address name usage too. In\\nPart V, we learned that every name assigned at the top level of a module file is exported.\\nBy default, the same holds for classes—data hiding is a convention, and clients may\\nfetch or change any class or instance attribute they like. In fact, attributes are all “pub-\\nlic” and “virtual,” in C++ terms; they’re all accessible everywhere and are looked up\\ndynamically at runtime.*\\nThat said, Python today does support the notion of name “mangling” (i.e., expansion)\\nto localize some names in classes. Mangled names are sometimes misleadingly called\\n“private attributes,” but really this is just a way to localize a name to the class that\\ncreated it—name mangling does not prevent access by code outside the class. This\\nfeature is mostly intended to avoid namespace collisions in instances, not to restrict\\naccess to names in general; mangled names are therefore better called “pseudoprivate”\\nthan “private.”\\nPseudoprivate names are an advanced and entirely optional feature, and you probably\\nwon’t find them very useful until you start writing general tools or larger class hierar-\\nchies for use in multiprogrammer projects. In fact, they are not always used even when\\nthey probably should be—more commonly, Python programmers code internal names\\nwith a single underscore (e.g., _X), which is just an informal convention to let you know\\nthat a name shouldn’t be changed (it means nothing to Python itself).\\nBecause you may see this feature in other people’s code, though, you need to be some-\\nwhat aware of it, even if you don’t use it yourself.\\n* This tends to scare people with a C++ background unnecessarily. In Python, it’s even possible to change or\\ncompletely delete \\na class method at runtime. On the other hand, almost nobody ever does this in practical\\nprograms. As a scripting language, Python is more about enabling than restricting. Also, recall from our\\ndiscussion of operator overloading in Chapter 29  that __getattr__ and __setattr__ can be used to emulate\\nprivacy, but are generally not used for this purpose in practice. More on this when we code a more realistic\\nprivacy decorator Chapter 38.\\nPseudoprivate Class Attributes | 747', metadata={'source': 'python.pdf', 'page': 797}),\n",
       " Document(page_content='Name Mangling Overview\\nHere’s how name \\nmangling works: names inside a class statement that start with two\\nunderscores but don’t end with two underscores are automatically expanded to include\\nthe name of the enclosing class. For instance, a name like __X within a class named\\nSpam is changed to _Spam__X automatically: the original name is prefixed with a single\\nunderscore and the enclosing class’s name. Because the modified name contains the\\nname of the enclosing class, it’s somewhat unique; it won’t clash with similar names\\ncreated by other classes in a hierarchy.\\nName mangling happens only in class statements, and only for names that begin with\\ntwo leading underscores. However, it happens for every name preceded with double\\nunderscores—both class attributes (like method names) and instance attribute names\\nassigned to self attributes. For example, in a class named Spam, a method named\\n__meth is mangled to _Spam__meth, and an instance attribute reference self.__X is trans-\\nformed to self._Spam__X. Because more than one class may add attributes to an in-\\nstance, this mangling helps avoid clashes—but we need to move on to an example to\\nsee how.\\nWhy Use Pseudoprivate Attributes?\\nOne of the main problems that the pseudoprivate attribute feature is meant to alleviate\\nhas to do with the way instance attributes are stored. In Python, all instance attributes\\nwind up in the single instance object at the bottom of the class tree. This is different\\nfrom the C++ model, where each class gets its own space for data members it defines.\\nWithin a class method in Python, whenever a method assigns to a self attribute (e.g.,\\nself.attr = value), it changes or creates an attribute in the instance (inheritance\\nsearches happen only on reference, not on assignment). Because this is true even if\\nmultiple classes in a hierarchy assign to the same attribute, collisions are possible.\\nFor example, suppose that when a programmer codes a class, she assumes that she\\nowns the attribute name X in the instance. In this class’s methods, the name is set, and\\nlater fetched:\\nclass C1:\\n    def meth1(self): self.X = 88         # I assume X is mine\\n    def meth2(self): print(self.X)\\nSuppose further that another programmer, working in isolation, makes the same as-\\nsumption in a class that he codes:\\nclass C2:\\n    def metha(self): self.X = 99         # Me too\\n    def methb(self): print(self.X)\\nBoth of these classes work by themselves. The problem arises if the two classes are ever\\nmixed together in the same class tree:\\n748 | Chapter 30: \\u2002Designing with Classes', metadata={'source': 'python.pdf', 'page': 798}),\n",
       " Document(page_content=\"class C3(C1, C2): ...\\nI = C3()                                 # Only 1 X in I!\\nNow, the value \\nthat each class gets back when it says self.X will depend on which class\\nassigned it last. Because all assignments to self.X refer to the same single instance,\\nthere is only one X attribute— I.X—no matter how many classes use that attribute name.\\nTo guarantee that an attribute belongs to the class that uses it, prefix the name with\\ndouble underscores everywhere it is used in the class, as in this file, private.py:\\nclass C1:\\n    def meth1(self): self.__X = 88       # Now X is mine\\n    def meth2(self): print(self.__X)     # Becomes _C1__X in I\\nclass C2:\\n    def metha(self): self.__X = 99       # Me too\\n    def methb(self): print(self.__X)     # Becomes _C2__X in I\\nclass C3(C1, C2): pass\\nI = C3()                                 # Two X names in I\\nI.meth1(); I.metha()\\nprint(I.__dict__)\\nI.meth2(); I.methb()\\nWhen thus prefixed, the X attributes will be expanded to include the names of their\\nclasses before being added to the instance. If you run a dir call on I or inspect its\\nnamespace dictionary after the attributes have been assigned, you’ll see the expanded\\nnames, _C1__X and _C2__X, but not X. Because the expansion makes the names unique\\nwithin the instance, the class coders can safely assume that they truly own any names\\nthat they prefix with two underscores:\\n% python private.py\\n{'_C2__X': 99, '_C1__X': 88}\\n88\\n99\\nThis trick can avoid potential name collisions in the instance, but note that it does not\\namount to true privacy. If you know the name of the enclosing class, you can still access\\neither of these attributes anywhere you have a reference to the instance by using the\\nfully expanded name (e.g., I._C1__X = 77). On the other hand, this feature makes it\\nless likely that you will accidentally step on a class’s names.\\nPseudoprivate attributes are also useful in larger frameworks or tools, both to avoid\\nintroducing new method names that might accidentally hide definitions elsewhere in\\nthe class tree and to reduce the chance of internal methods being replaced by names\\ndefined lower in the tree. If a method is intended for use only within a class that may\\nbe mixed into other classes, the double underscore prefix ensures that the method won’t\\ninterfere with other names in the tree, especially in multiple-inheritance scenarios:\\nclass Super:\\n    def method(self): ...                  # A real application method\\nclass Tool:\\nPseudoprivate Class Attributes | 749\", metadata={'source': 'python.pdf', 'page': 799}),\n",
       " Document(page_content=\"    def __method(self): ...                # Becomes _Tool__method\\n    def other(self): self.__method()       # Use my internal method\\nclass Sub1(Tool, Super): ...\\n    def actions(self): self.method()       # Runs Super.method as expected\\nclass Sub2(Tool):\\n    def __init__(self): self.method = 99   # Doesn't break Tool.__method\\nWe met multiple \\ninheritance briefly in Chapter 25 and will explore it in more detail\\nlater in this chapter. Recall that superclasses are searched according to their left-to-right\\norder in class header lines. Here, this means Sub1 prefers Tool attributes to those in\\nSuper. Although in this example we could force Python to pick the application class’s\\nmethods first by switching the order of the superclasses listed in the Sub1 class header,\\npseudoprivate attributes resolve the issue altogether. Pseudoprivate names also prevent\\nsubclasses from accidentally redefining the internal method’s names, as in Sub2.\\nAgain, I should note that this feature tends to be of use primarily for larger,\\nmultiprogrammer projects, and then only for selected names. Don’t be tempted to\\nclutter your code unnecessarily; only use this feature for names that truly need to be\\ncontrolled by a single class. For simpler programs, it’s probably overkill.\\nFor more examples that make use of the __X naming feature, see the lister.py\\nmix-in classes introduced later in this chapter, in the section on multiple inheritance,\\nas well as the discussion of Private class decorators in Chapter 38. If you\\ncare about privacy in general, you might want to review the emulation of\\nprivate instance attributes sketched in the section “Attribute Reference: __getattr__\\nand __setattr__” on page 718 in Chapter 29, and watch for the Private class decorator\\nin Chapter 38 that we will base upon this special method. Although it’s possible to\\nemulate true access controls in Python classes, this is rarely done in practice, even for\\nlarge systems.\\nMethods Are Objects: Bound or Unbound\\nMethods in general, and bound methods in particular, simplify the implementation of\\nmany design goals in Python. We met bound methods briefly while studying __call__ in\\nChapter 29 . The full story, which we’ll flesh out here, turns out to be more general and\\nflexible than you might expect.\\nIn Chapter 19, we learned how functions can be processed as normal objects. Methods\\nare a kind of object too, and can be used generically in much the same way as other\\nobjects—they can be assigned, passed to functions, stored in data structures, and so\\non. Because class methods can be accessed from an instance or a class, though, they\\nactually come in two flavors in Python:\\n750 | Chapter 30: \\u2002Designing with Classes\", metadata={'source': 'python.pdf', 'page': 800}),\n",
       " Document(page_content=\"Unbound class method objects: no self\\nAccessing a function \\nattribute of a class by qualifying the class returns an unbound\\nmethod object. To call the method, you must provide an instance object explicitly\\nas the first argument. In Python 3.0, an unbound method is the same as a simple\\nfunction and can be called though the class’s name; in 2.6 it’s a distinct type and\\ncannot be called without providing an instance.\\nBound instance method objects: self + function pairs\\nAccessing a function attribute of a class by qualifying an instance returns a bound\\nmethod object. Python automatically packages the instance with the function in\\nthe bound method object, so you don’t need to pass an instance to call the method.\\nBoth kinds of methods are full-fledged objects; they can be transferred around a pro-\\ngram at will, just like strings and numbers. Both also require an instance in their first\\nargument when run (i.e., a value for self). This is why we had to pass in an instance\\nexplicitly when calling superclass methods from subclass methods in the previous\\nchapter; technically, such calls produce unbound method objects.\\nWhen calling a bound method object, Python provides an instance for you automati-\\ncally—the instance used to create the bound method object. This means that bound\\nmethod objects are usually interchangeable with simple function objects, and makes\\nthem especially useful for interfaces originally written for functions (see the sidebar\\n“Why You Will Care: Bound Methods and Callbacks” on page 756 for a realistic\\nexample).\\nTo illustrate, suppose we define the following class:\\nclass Spam:\\n    def doit(self, message):\\n        print(message)\\nNow, in normal operation, we make an instance and call its method in a single step to\\nprint the passed-in argument:\\nobject1 = Spam()\\nobject1.doit('hello world')\\nReally, though, a bound method object is generated along the way, just before the\\nmethod call’s parentheses. In fact, we can fetch a bound method without actually call-\\ning it. An object.name qualification is an object expression. In the following, it returns\\na bound method object that packages the instance ( object1) with the method function\\n(Spam.doit). We can assign this bound method pair to another name and then call it as\\nthough it were a simple function:\\nobject1 = Spam()\\nx = object1.doit        # Bound method object: instance+function\\nx('hello world')        # Same effect as object1.doit('...')\\nMethods Are Objects: Bound or Unbound | 751\", metadata={'source': 'python.pdf', 'page': 801}),\n",
       " Document(page_content=\"On the other hand, if we qualify the class to get to doit, we get back an unbound method\\nobject, which is simply a reference to the function object. To call this type of method,\\nwe must pass in an instance as the leftmost argument:\\nobject1 = Spam()\\nt = Spam.doit           # Unbound method object (a function in 3.0: see ahead)\\nt(object1, 'howdy')     # Pass in instance (if the method expects one in 3.0)\\nBy extension, the same rules apply within a class’s method if we reference self attributes\\nthat refer to functions in the class. A self.method expression is a bound method object\\nbecause self is an instance object:\\nclass Eggs:\\n    def m1(self, n):\\n        print(n)\\n    def m2(self):\\n        x = self.m1     # Another bound method object\\n        x(42)           # Looks like a simple function\\nEggs().m2()             # Prints 42\\nMost of the time, you call methods immediately after fetching them with attribute\\nqualification, so you don’t always notice the method objects generated along the way.\\nBut if you start writing code that calls objects generically, you need to be careful to treat\\nunbound methods specially—they normally require an explicit instance object to be\\npassed in.†\\nUnbound Methods are Functions in 3.0\\nIn Python 3.0, the language has dropped the notion of unbound methods . What we\\ndescribe as an unbound method here is treated as a simple function in 3.0. For most\\npurposes, this makes no difference to your code; either way, an instance will be passed\\nto a method’s first argument when it’s called through an instance.\\nPrograms that do explicit type testing might be impacted, though—if you print the type\\nof an instance-less class method, it displays “unbound method” in 2.6, and “function”\\nin 3.0.\\nMoreover, in 3.0 it is OK to call a method without an instance, as long as the method\\ndoes not expect one and you call it only through the class and never through an instance.\\nThat is, Python 3.0 will pass along an instance to methods only for through-instance\\ncalls. When calling through a class, you must pass an instance manually only if the\\nmethod expects one:\\nC:\\\\misc> c:\\\\python30\\\\python\\n>>> class Selfless:\\n† See the discussion of static and class methods in Chapter 31  for an optional exception to this rule. Like bound\\nmethods, static methods can masquerade as basic functions because they do not expect instances when called.\\nPython supports three kinds of class methods—instance, static, and class—and 3.0 allows simple functions\\nin classes, too.\\n752 | Chapter 30: \\u2002Designing with Classes\", metadata={'source': 'python.pdf', 'page': 802}),\n",
       " Document(page_content='...     def __init__(self, data):\\n...         self.data = data\\n...     def selfless(arg1, arg2):               # A simple function in 3.0\\n...         return arg1 + arg2\\n...     def normal(self, arg1, arg2):           # Instance expected when called\\n...         return self.data + arg1 + arg2\\n...\\n>>> X = Selfless(2)\\n>>> X.normal(3, 4)                  # Instance passed to self automatically\\n9\\n>>> Selfless.normal(X, 3, 4)        # self expected by method: pass manually\\n9\\n>>> Selfless.selfless(3, 4)         # No instance: works in 3.0, fails in 2.6!\\n7\\nThe last test \\nin this fails in 2.6, because unbound methods require an instance to be\\npassed by default; it works in 3.0 because such methods are treated as simple functions\\nnot requiring an instance. Although this removes some potential error trapping in 3.0\\n(what if a programmer accidentally forgets to pass an instance?), it allows class methods\\nto be used as simple functions as long as they are not passed and do not expect a “self”\\ninstance argument.\\nThe following two calls still fail in both 3.0 and 2.6, though—the first (calling through\\nan instance) automatically passes an instance to a method that does not expect one,\\nwhile the second (calling through a class) does not pass an instance to a method that\\ndoes expect one:\\n>>> X.selfless(3, 4)\\nTypeError: selfless() takes exactly 2 positional arguments (3 given)\\n>>> Selfless.normal(3, 4)\\nTypeError: normal() takes exactly 3 positional arguments (2 given)\\nBecause of this change, the staticmethod decorator described in the next chapter is not\\nneeded in 3.0 for methods without a self argument that are called only through the\\nclass name, and never through an instance—such methods are run as simple functions,\\nwithout receiving an instance argument. In 2.6, such calls are errors unless an instance\\nis passed manually (more on static methods in the next chapter).\\nIt’s important to be aware of the differences in behavior in 3.0, but bound methods are\\ngenerally more important from a practical perspective anyway. Because they pair to-\\ngether the instance and function in a single object, they can be treated as callables\\ngenerically. The next section demonstrates what this means in code.\\nFor a more visual illustration of unbound method treatment in Python\\n3.0 and 2.6, \\nsee also the lister.py example in the multiple inheritance\\nsection later in this chapter. Its classes print the value of methods fetched\\nfrom both instances and classes, in both versions of Python.\\nMethods Are Objects: Bound or Unbound | 753', metadata={'source': 'python.pdf', 'page': 803}),\n",
       " Document(page_content='Bound Methods and Other Callable Objects\\nAs mentioned earlier, \\nbound methods can be processed as generic objects, just like\\nsimple functions—they can be passed around a program arbitrarily. Moreover, because\\nbound methods combine both a function and an instance in a single package, they can\\nbe treated like any other callable object and require no special syntax when invoked.\\nThe following, for example, stores four bound method objects in a list and calls them\\nlater with normal call expressions:\\n>>> class Number:\\n...     def __init__(self, base):\\n...         self.base = base\\n...     def double(self):\\n...         return self.base * 2\\n...     def triple(self):\\n...         return self.base * 3\\n...\\n>>> x = Number(2)                                       # Class instance objects\\n>>> y = Number(3)                                       # State + methods\\n>>> z = Number(4)\\n>>> x.double()                                          # Normal immediate calls\\n4\\n>>> acts = [x.double, y.double, y.triple, z.double]     # List of bound methods\\n>>> for act in acts:                                    # Calls are deferred\\n...     print(act())                                    # Call as though functions\\n...\\n4\\n6\\n9\\n8\\nLike simple functions, bound method objects have introspection information of their\\nown, including attributes that give access to the instance object and method function\\nthey pair. Calling the bound method simply dispatches the pair:\\n>>> bound = x.double\\n>>> bound.__self__, bound.__func__\\n(<__main__.Number object at 0x0278F610>, <function double at 0x027A4ED0>)\\n>>> bound.__self__.base\\n2\\n>>> bound()                             # Calls bound.__func__(bound.__self__, ...)\\n4\\nIn fact, bound methods are just one of a handful of callable object types in Python. As\\nthe following demonstrates, simple functions coded with a def or lambda, instances that\\ninherit a __call__, and bound instance methods can all be treated and called the same\\nway:\\n>>> def square(arg):\\n...     return arg ** 2                          # Simple functions (def or lambda)\\n...\\n>>> class Sum:\\n...     def __init__(self, val):                 # Callable instances\\n754 | Chapter 30: \\u2002Designing with Classes', metadata={'source': 'python.pdf', 'page': 804}),\n",
       " Document(page_content=\"...         self.val = val\\n...     def __call__(self, arg):\\n...         return self.val + arg\\n...\\n>>> class Product:\\n...     def __init__(self, val):                 # Bound methods\\n...         self.val = val\\n...     def method(self, arg):\\n...         return self.val * arg\\n...\\n>>> sobject = Sum(2)\\n>>> pobject = Product(3)\\n>>> actions = [square, sobject, pobject.method]  # Function, instance, method\\n>>> for act in actions:                          # All 3 called same way\\n...     print(act(5))                            # Call any 1-arg callable\\n...\\n25\\n7\\n15\\n>>> actions[-1](5)                               # Index, comprehensions, maps\\n15\\n>>> [act(5) for act in actions]\\n[25, 7, 15]\\n>>> list(map(lambda act: act(5), actions))\\n[25, 7, 15]\\nTechnically speaking, classes \\nbelong in the callable objects category too, but we nor-\\nmally call them to generate instances rather than to do actual work, as shown here:\\n>>> class Negate:\\n...     def __init__(self, val):                 # Classes are callables too\\n...         self.val = -val                      # But called for object, not work\\n...     def __repr__(self):                      # Instance print format\\n...         return str(self.val)\\n...\\n>>> actions = [square, sobject, pobject.method, Negate]     # Call a class too\\n>>> for act in actions:\\n...     print(act(5))\\n...\\n25\\n7\\n15\\n-5\\n>>> [act(5) for act in actions]                     # Runs __repr__ not __str__!\\n[25, 7, 15, −5]\\n>>> table = {act(5): act for act in actions}        # 2.6/3.0 dict comprehension\\n>>> for (key, value) in table.items():\\n...     print('{0:2} => {1}'.format(key, value))    # 2.6/3.0 str.format\\n...\\n-5 => <class '__main__.Negate'>\\n25 => <function square at 0x025D4978>\\n15 => <bound method Product.method of <__main__.Product object at 0x025D0F90>>\\n 7 => <__main__.Sum object at 0x025D0F70>\\nMethods Are Objects: Bound or Unbound | 755\", metadata={'source': 'python.pdf', 'page': 805}),\n",
       " Document(page_content=\"As you can see, bound methods, and Python’s callable objects model in general, are\\nsome of the \\nmany ways that Python’s design makes for an incredibly flexible language.\\nYou should now understand the method object model. For other examples of bound\\nmethods at work, see the upcoming sidebar “Why You Will Care: Bound Methods and\\nCallbacks” as well as the prior chapter’s discussion of callback handlers in the section\\non the method __call__.\\nWhy You Will Care: Bound Methods and Callbacks\\nBecause bound methods \\nautomatically pair an instance with a class method function,\\nyou can use them anywhere a simple function is expected. One of the most common\\nplaces you’ll see this idea put to work is in code that registers methods as event callback\\nhandlers in the tkinter GUI interface (named Tkinter in Python 2.6). Here’s the simple\\ncase:\\ndef handler():\\n    ...use globals for state...\\n...\\nwidget = Button(text='spam', command=handler)\\nTo register a handler for button click events, we usually pass a callable object that takes\\nno arguments to the command keyword argument. Function names (and lambdas) work\\nhere, and so do class methods, as long as they are bound methods:\\nclass MyWidget:\\n    def handler(self):\\n        ...use self.attr for state...\\n    def makewidgets(self):\\n        b = Button(text='spam', command=self.handler)\\nHere, the event handler is self.handler—a bound method object that remembers both\\nself and MyGui.handler. Because self will refer to the original instance when handler\\nis later invoked on events, the method will have access to instance attributes that can\\nretain state between events. With simple functions, state normally must be retained in\\nglobal variables or enclosing function scopes instead. See also the discussion of\\n__call__ operator overloading in Chapter 29  for another way to make classes compat-\\nible with function-based APIs.\\nMultiple Inheritance: “Mix-in” Classes\\nMany class-based designs \\ncall for combining disparate sets of methods. In a class\\nstatement, more than one superclass can be listed in parentheses in the header line.\\nWhen you do this, you use something called multiple inheritance —the class and its\\ninstances inherit names from all the listed superclasses.\\n756 | Chapter 30: \\u2002Designing with Classes\", metadata={'source': 'python.pdf', 'page': 806}),\n",
       " Document(page_content='When searching for an attribute, Python’s inheritance search traverses all superclasses\\nin the class \\nheader from left to right until a match is found. Technically, because any\\nof the superclasses may have superclasses of its own, this search can be a bit more\\ncomplex for larger class tress:\\n• In classic classes (the default until Python 3.0), the attribute search proceeds depth-\\nfirst all the way to the top of the inheritance tree, and then from left to right.\\n• In new-style classes (and all classes in 3.0), the attribute search proceeds across by\\ntree levels, in a more breadth-first fashion (see the new-style class discussion in the\\nnext chapter).\\nIn either model, though, when a class has multiple superclasses, they are searched from\\nleft to right according to the order listed in the class statement header lines.\\nIn general, multiple inheritance is good for modeling objects that belong to more than\\none set. For instance, a person may be an engineer, a writer, a musician, and so on, and\\ninherit properties from all such sets. With multiple inheritance, objects obtain the\\nunion of the behavior in all their superclasses.\\nPerhaps the most common way multiple inheritance is used is to “mix in” general-\\npurpose methods from superclasses. Such superclasses are usually called mix-in\\nclasses—they provide methods you add to application classes by inheritance. In a sense,\\nmix-in classes are similar to modules: they provide packages of methods for use in their\\nclient subclasses. Unlike simple functions in modules, though, methods in mix-ins also\\nhave access to the self instance, for using state information and other methods. The\\nnext section demonstrates one common use case for such tools.\\nCoding Mix-in Display Classes\\nAs we’ve seen, Python’s default way to print a class instance object isn’t incredibly\\nuseful:\\n>>> class Spam:\\n...     def __init__(self):                   # No __repr__ or __str__\\n...         self.data1 = \"food\"\\n...\\n>>> X = Spam()\\n>>> print(X)                                  # Default: class, address\\n<__main__.Spam object at 0x00864818>          # Displays \"instance\" in Python 2.6\\nAs you saw in Chapter 29 when studying operator overloading, you can provide a\\n__str__ or __repr__ method to implement a custom string representation of your own.\\nBut, rather than coding one of these in each and every class you wish to print, why not\\ncode it once in a general-purpose tool class and inherit it in all your classes?\\nThat’s what mix-ins are for. Defining a display method in a mix-in superclass once\\nenables us to reuse it anywhere we want to see a custom display format. We’ve already\\nseen tools that do related work:\\nMultiple Inheritance: “Mix-in” Classes | 757', metadata={'source': 'python.pdf', 'page': 807}),\n",
       " Document(page_content='•Chapter 27 ’s AttrDisplay class formatted instance attributes in a generic __str__\\nmethod, but it did not climb class trees and was used in single-inheritance mode\\nonly.\\n•Chapter 28’s classtree.py module defined functions for climbing and sketching\\nclass trees, but it did not display object attributes along the way and was not ar-\\nchitected as an inheritable class.\\nHere, we’re going to revisit these examples’ techniques and expand upon them to code\\na set of three mix-in classes that serve as generic display tools for listing instance at-\\ntributes, inherited attributes, and attributes on all objects in a class tree. We’ll also use\\nour tools in multiple-inheritance mode and deploy coding techniques that make classes\\nbetter suited to use as generic tools.\\nListing instance attributes with __dict__\\nLet’s get started with the simple case—listing attributes attached to an instance. The\\nfollowing class, coded in the file lister.py, defines a mix-in called ListInstance that\\noverloads the __str__ method for all classes that include it in their header lines. Because\\nthis is coded as a class, ListInstance is a generic tool whose formatting logic can be\\nused for instances of any subclass:\\n# File lister.py\\nclass ListInstance:\\n    \"\"\"\\n    Mix-in class that provides a formatted print() or str() of\\n    instances via inheritance of __str__, coded here; displays\\n    instance attrs only; self is the instance of lowest class;\\n    uses __X names to avoid clashing with client\\'s attrs\\n    \"\"\"\\n    def __str__(self):\\n        return \\'<Instance of %s, address %s:\\\\n%s>\\' % (\\n                           self.__class__.__name__,         # My class\\'s name\\n                           id(self),                        # My address\\n                           self.__attrnames())              # name=value list\\n    def __attrnames(self):\\n        result = \\'\\'\\n        for attr in sorted(self.__dict__):                  # Instance attr dict\\n            result += \\'\\\\tname %s=%s\\\\n\\' % (attr, self.__dict__ [attr])\\n        retubrn result\\nListInstance uses some previously explored tricks to extract the instance’s class name\\nand attributes:\\n• Each instance has a built-in __class__ attribute that references the class from which\\nit was created, and each class has a __name__ attribute that references the name in\\nthe header, so the expression self.__class__.__name__ fetches the name of an in-\\nstance’s class.\\n758 | Chapter 30: \\u2002Designing with Classes', metadata={'source': 'python.pdf', 'page': 808}),\n",
       " Document(page_content=\"• This class does most of its work by simply scanning the instance’s attribute dic-\\ntionary (remember, \\nit’s exported in __dict__) to build up a string showing the\\nnames and values of all instance attributes. The dictionary’s keys are sorted to\\nfinesse any ordering differences across Python releases.\\nIn these respects, ListInstance is similar to Chapter 27 ’s attribute display; in fact, it’s\\nlargely just a variation on a theme. Our class here uses two additional techniques,\\nthough:\\n• It displays the instance’s memory address by calling the id built-function, which\\nreturns any object’s address (by definition, a unique object identifier, which will\\nbe useful in later mutations of this code).\\n• It uses the pseudoprivate naming pattern for its worker method: __attrnames. As\\nwe learned earlier in his chapter, Python automatically localizes any such name to\\nits enclosing class by expanding the attribute name to include the class name (in\\nthis case, it becomes _ListInstance__attrnames). This holds true for both class\\nattributes (like methods) and instance attributes attached to self. This behavior is\\nuseful in a general tool like this, as it ensures that its names don’t clash with any\\nnames used in its client subclasses.\\nBecause ListInstance defines a __str__ operator overloading method, instances de-\\nrived from this class display their attributes automatically when printed, giving a bit\\nmore information than a simple address. Here is the class in action, in single-inheritance\\nmode (this code works the same in both Python 3.0 and 2.6):\\n>>> from lister import ListInstance\\n>>> class Spam(ListInstance):                    # Inherit a __str__ method\\n...     def __init__(self):\\n...         self.data1 = 'food'\\n...\\n>>> x = Spam()\\n>>> print(x)                                     # print() and str() run __str__\\n<Instance of Spam, address 40240880:\\n        name data1=food\\n>\\nYou can also fetch the listing output as a string without printing it with str, and inter-\\nactive echoes still use the default format:\\n>>> str(x)\\n'<Instance of Spam, address 40240880:\\\\n\\\\tname data1=food\\\\n>'\\n>>> x                                            # The __repr__ still is a default\\n<__main__.Spam object at 0x026606F0>\\nThe ListInstance class is useful for any classes you write—even classes that already\\nhave one or more superclasses. This is where multiple inheritance  comes in handy: by\\nadding ListInstance to the list of superclasses in a class header (i.e., mixing it in), you\\nget its __str__ “for free” while still inheriting from the existing superclass(es). The file\\ntestmixin.py demonstrates:\\nMultiple Inheritance: “Mix-in” Classes | 759\", metadata={'source': 'python.pdf', 'page': 809}),\n",
       " Document(page_content=\"# File testmixin.py\\nfrom lister import *                  # Get lister tool classes\\nclass Super:\\n    def __init__(self):               # Superclass __init__\\n        self.data1 = 'spam'           # Create instance attrs\\n    def ham(self):\\n        pass\\nclass Sub(Super, ListInstance):       # Mix in ham and a __str__\\n    def __init__(self):               # listers have access to self\\n        Super.__init__(self)\\n        self.data2 = 'eggs'           # More instance attrs\\n        self.data3 = 42\\n    def spam(self):                   # Define another method here\\n        pass\\nif __name__ == '__main__':\\n    X = Sub()\\n    print(X)                          # Run mixed-in __str__\\nHere, Sub inherits names \\nfrom both Super and ListInstance; it’s a composite of its own\\nnames and names in both its superclasses. When you make a Sub instance and print it,\\nyou automatically get the custom representation mixed in from ListInstance (in this\\ncase, this script’s output is the same under both Python 3.0 and 2.6, except for object\\naddresses):\\nC:\\\\misc> C:\\\\python30\\\\python testmixin.py\\n<Instance of Sub, address 40962576:\\n        name data1=spam\\n        name data2=eggs\\n        name data3=42\\n>\\nListInstance works in any class it’s mixed into because self refers to an instance of\\nthe subclass that pulls this class in, whatever that may be. In a sense, mix-in classes are\\nthe class equivalent of modules—packages of methods useful in a variety of clients. For\\nexample, here is Lister working again in single-inheritance mode on a different class’s\\ninstances, with import and attributes set outside the class:\\n>>> import lister\\n>>> class C(lister.ListInstance): pass\\n...\\n>>> x = C()\\n>>> x.a = 1; x.b = 2; x.c = 3\\n>>> print(x)\\n<Instance of C, address 40961776:\\n        name a=1\\n        name b=2\\n        name c=3\\n>\\n760 | Chapter 30: \\u2002Designing with Classes\", metadata={'source': 'python.pdf', 'page': 810}),\n",
       " Document(page_content='Besides the utility they provide, mix-ins optimize code maintenance, like all classes do.\\nFor example, if \\nyou later decide to extend ListInstance’s __str__ to also print all the\\nclass attributes that an instance inherits, you’re safe; because it’s an inherited method,\\nchanging __str__ automatically updates the display of each subclass that imports the\\nclass and mixes it in. Since it’s now officially “later,” let’s move on to the next section\\nto see what such an extension might look like.\\nListing inherited attributes with dir\\nAs it is, our Lister mix-in displays instance attributes only (i.e., names attached to the\\ninstance object itself). It’s trivial to extend the class to display all the attributes acces-\\nsible from an instance, though—both its own and those it inherits from its classes. The\\ntrick is to use the dir built-in function instead of scanning the instance’s __dict__ dic-\\ntionary; the latter holds instance attributes only, but the former also collects all inheri-\\nted attributes in Python 2.2 and later.\\nThe following mutation codes this scheme; I’ve renamed it to facilitate simple testing,\\nbut if this were to replace the original version, all existing clients would pick up the new\\ndisplay automatically:\\n# File lister.py, continued\\nclass ListInherited:\\n    \"\"\"\\n    Use dir() to collect both instance attrs and names\\n    inherited from its classes; Python 3.0 shows more\\n    names than 2.6 because of the implied object superclass\\n    in the new-style class model; getattr() fetches inherited\\n    names not in self.__dict__; use __str__, not __repr__,\\n    or else this loops when printing bound methods!\\n    \"\"\"\\n    def __str__(self):\\n        return \\'<Instance of %s, address %s:\\\\n%s>\\' % (\\n                           self.__class__.__name__,         # My class\\'s name\\n                           id(self),                        # My address\\n                           self.__attrnames())              # name=value list\\n    def __attrnames(self):\\n        result = \\'\\'\\n        for attr in dir(self):                              # Instance dir()\\n            if attr[:2] == \\'__\\' and attr[-2:] == \\'__\\':      # Skip internals\\n                result += \\'\\\\tname %s=<>\\\\n\\' % attr\\n            else:\\n                result += \\'\\\\tname %s=%s\\\\n\\' % (attr, getattr(self, attr))\\n        return result\\nNotice that this code skips __X__ names’ values; most of these are internal names that\\nwe don’t generally care about in a generic listing like this. This version also must use\\nthe getattr built-in function to fetch attributes by name string instead of using instance\\nattribute dictionary indexing—getattr employs the inheritance search protocol, and\\nsome of the names we’re listing here are not stored on the instance itself.\\nMultiple Inheritance: “Mix-in” Classes | 761', metadata={'source': 'python.pdf', 'page': 811}),\n",
       " Document(page_content='To test the new version, change the testmixin.py file to use this new class instead:\\nclass Sub(Super, ListInherited):                            # Mix in a __str__\\nThis file’s output \\nvaries per release. In Python 2.6, we get the following; notice the name\\nmangling at work in the lister’s method name (I shortened its full value display to fit\\non this page):\\nC:\\\\misc> c:\\\\python26\\\\python testmixin.py\\n<Instance of Sub, address 40073136:\\n        name _ListInherited__attrnames=<bound method Sub.__attrnames of <...more...>>\\n        name __doc__=<>\\n        name __init__=<>\\n        name __module__=<>\\n        name __str__=<>\\n        name data1=spam\\n        name data2=eggs\\n        name data3=42\\n        name ham=<bound method Sub.ham of <__main__.Sub instance at 0x026377B0>>\\n        name spam=<bound method Sub.spam of <__main__.Sub instance at 0x026377B0>>\\n>\\nIn Python 3.0, more attributes are displayed because all classes are “new-style” and\\ninherit names from the implied object superclass (more on this in Chapter 31). Because\\nso many names are inherited from the default superclass, I’ve omitted many here; run\\nthis on your own for the full listing:\\nC:\\\\misc> c:\\\\python30\\\\python testmixin.py\\n<Instance of Sub, address 40831792:\\n        name _ListInherited__attrnames=<bound method Sub.__attrnames of <...more...>>\\n        name __class__=<>\\n        name __delattr__=<>\\n        name __dict__=<>\\n        name __doc__=<>\\n        name __eq__=<>\\n        ...more names omitted...\\n        name __repr__=<>\\n        name __setattr__=<>\\n        name __sizeof__=<>\\n        name __str__=<>\\n        name __subclasshook__=<>\\n        name __weakref__=<>\\n        name data1=spam\\n        name data2=eggs\\n        name data3=42\\n        name ham=<bound method Sub.ham of <__main__.Sub object at 0x026F0B30>>\\n        name spam=<bound method Sub.spam of <__main__.Sub object at 0x026F0B30>>\\n>\\nOne caution here—now that we’re displaying inherited methods too, we have to use\\n__str__ instead of __repr__ to overload printing. With __repr__, this code will loop—\\ndisplaying the value of a method triggers the __repr__ of the method’s class, in order\\nto display the class. That is, if the lister’s __repr__ tries to display a method, displaying\\nthe method’s class will trigger the lister’s __repr__ again. Subtle, but true! Change\\n762 | Chapter 30: \\u2002Designing with Classes', metadata={'source': 'python.pdf', 'page': 812}),\n",
       " Document(page_content='__str__ to __repr__ here to see this for yourself. If you must use __repr__ in such a\\ncontext, you can avoid the loops by using isinstance to compare the type of attribute\\nvalues against types.MethodType in the standard library, to know which items to skip.\\nListing attributes per object in class trees\\nLet’s code one last extension. As it is, our lister doesn’t tell us which class an inherited\\nname comes from. As we saw in the classtree.py example near the end of Chapter 28 ,\\nthough, it’s straightforward to climb class inheritance trees in code. The following mix-\\nin class makes use of this same technique to display attributes grouped by the classes\\nthey live in—it sketches the full class tree, displaying attributes attached to each object\\nalong the way. It does so by traversing the inheritance tree from an instance’s\\n__class__ to its class, and then from the class’s __bases__ to all superclasses recursively,\\nscanning object __dicts__s along the way:\\n# File lister.py, continued\\nclass ListTree:\\n    \"\"\"\\n    Mix-in that returns an __str__ trace of the entire class\\n    tree and all its objects\\' attrs at and above self;\\n    run by print(), str() returns constructed string;\\n    uses __X attr names to avoid impacting clients;\\n    uses generator expr to recurse to superclasses;\\n    uses str.format() to make substitutions clearer\\n    \"\"\"\\n    def __str__(self):\\n        self.__visited = {}\\n        return \\'<Instance of {0}, address {1}:\\\\n{2}{3}>\\'.format(\\n                           self.__class__.__name__,\\n                           id(self),\\n                           self.__attrnames(self, 0),\\n                           self.__listclass(self.__class__, 4))\\n    def __listclass(self, aClass, indent):\\n        dots = \\'.\\' * indent\\n        if aClass in self.__visited:\\n            return \\'\\\\n{0}<Class {1}:, address {2}: (see above)>\\\\n\\'.format(\\n                           dots,\\n                           aClass.__name__,\\n                           id(aClass))\\n        else:\\n            self.__visited[aClass] = True\\n            genabove = (self.__listclass(c, indent+4) for c in aClass.__bases__)\\n            return \\'\\\\n{0}<Class {1}, address {2}:\\\\n{3}{4}{5}>\\\\n\\'.format(\\n                           dots,\\n                           aClass.__name__,\\n                           id(aClass),\\n                           self.__attrnames(aClass, indent),\\n                           \\'\\'.join(genabove),\\n                           dots)\\n    def __attrnames(self, obj, indent):\\nMultiple Inheritance: “Mix-in” Classes | 763', metadata={'source': 'python.pdf', 'page': 813}),\n",
       " Document(page_content=\"        spaces = ' ' * (indent + 4)\\n        result = ''\\n        for attr in sorted(obj.__dict__):\\n            if attr.startswith('__') and attr.endswith('__'):\\n                result += spaces + '{0}=<>\\\\n'.format(attr)\\n            else:\\n                result += spaces + '{0}={1}\\\\n'.format(attr, getattr(obj, attr))\\n        return result\\nNote the use \\nof a generator expression  to direct the recursive calls for superclasses; it’s\\nactivated by the nested string join method. Also see how this version uses the Python\\n3.0 and 2.6 string format method instead of % formatting expressions, to make substi-\\ntutions clearer; when many substitutions are applied like this, explicit argument num-\\nbers may make the code easier to decipher. In short, in this version we exchange the\\nfirst of the following lines for the second:\\n        return '<Instance of %s, address %s:\\\\n%s%s>' % (...)          # Expression\\n        return '<Instance of {0}, address {1}:\\\\n{2}{3}>'.format(...)  # Method\\nNow, change testmixin.py to inherit from this new class again to test:\\nclass Sub(Super, ListTree):         # Mix in a __str__\\nThe file’s tree-sketcher output in Python 2.6 is then as follows:\\nC:\\\\misc> c:\\\\python26\\\\python testmixin.py\\n<Instance of Sub, address 40728496:\\n    _ListTree__visited={}\\n    data1=spam\\n    data2=eggs\\n    data3=42\\n....<Class Sub, address 40701168:\\n        __doc__=<>\\n        __init__=<>\\n        __module__=<>\\n        spam=<unbound method Sub.spam>\\n........<Class Super, address 40701120:\\n            __doc__=<>\\n            __init__=<>\\n            __module__=<>\\n            ham=<unbound method Super.ham>\\n........>\\n........<Class ListTree, address 40700688:\\n            _ListTree__attrnames=<unbound method ListTree.__attrnames>\\n            _ListTree__listclass=<unbound method ListTree.__listclass>\\n            __doc__=<>\\n            __module__=<>\\n            __str__=<>\\n........>\\n....>\\n>\\n764 | Chapter 30: \\u2002Designing with Classes\", metadata={'source': 'python.pdf', 'page': 814}),\n",
       " Document(page_content='Notice in this output how methods are unbound now under 2.6, because we fetch them\\nfrom classes directly, instead of from instances. Also observe how the lister’s\\n__visited table has its name mangled in the instance’s attribute dictionary; unless we’re\\nvery unlucky, this won’t clash with other data there.\\nUnder Python 3.0, we get extra attributes and superclasses again. Notice that unbound\\nmethods are simple functions in 3.0, as described in an earlier note in this chapter (and\\nthat again, I’ve deleted most built-in attributes in object to save space here; run this on\\nyour own for the complete listing):\\nC:\\\\misc> c:\\\\python30\\\\python testmixin.py\\n<Instance of Sub, address 40635216:\\n    _ListTree__visited={}\\n    data1=spam\\n    data2=eggs\\n    data3=42\\n....<Class Sub, address 40914752:\\n        __doc__=<>\\n        __init__=<>\\n        __module__=<>\\n        spam=<function spam at 0x026D53D8>\\n........<Class Super, address 40829952:\\n            __dict__=<>\\n            __doc__=<>\\n            __init__=<>\\n            __module__=<>\\n            __weakref__=<>\\n            ham=<function ham at 0x026D5228>\\n............<Class object, address 505114624:\\n                __class__=<>\\n                __delattr__=<>\\n                __doc__=<>\\n                __eq__=<>\\n                ...more omitted...\\n                __repr__=<>\\n                __setattr__=<>\\n                __sizeof__=<>\\n                __str__=<>\\n                __subclasshook__=<>\\n............>\\n........>\\n........<Class ListTree, address 40829496:\\n            _ListTree__attrnames=<function __attrnames at 0x026D5660>\\n            _ListTree__listclass=<function __listclass at 0x026D56A8>\\n            __dict__=<>\\n            __doc__=<>\\n            __module__=<>\\n            __str__=<>\\n            __weakref__=<>\\nMultiple Inheritance: “Mix-in” Classes | 765', metadata={'source': 'python.pdf', 'page': 815}),\n",
       " Document(page_content=\"............<Class object:, address 505114624: (see above)>\\n........>\\n....>\\n>\\nThis version avoids \\nlisting the same class object twice by keeping a table of classes\\nvisited so far (this is why an object’s id is included—to serve as a key for a previously\\ndisplayed item). Like the transitive module reloader of Chapter 24 , a dictionary works\\nto avoid repeats and cycles here because class objects may be dictionary keys; a set\\nwould provide similar functionality.\\nThis version also takes care to avoid large internal objects by skipping __X__ names\\nagain. If you comment out the test for these names, their values will display normally.\\nHere’s an excerpt from the output in 2.6 with this temporary change made (it’s much\\nlarger in its entirety, and it gets even worse in 3.0, which is why these names are probably\\nbetter skipped!):\\nC:\\\\misc> c:\\\\python26\\\\python testmixin.py\\n...more omitted...\\n........<Class ListTree, address 40700688:\\n            _ListTree__attrnames=<unbound method ListTree.__attrnames>\\n            _ListTree__listclass=<unbound method ListTree.__listclass>\\n            __doc__=\\n    Mix-in that returns the __str__ trace of the entire class\\n    tree and all its objects' attrs at and above self;\\n    run by print, str returns constructed string;\\n    uses __X attr names to avoid impacting clients;\\n    uses generator expr to recurse to superclasses;\\n    uses str.format() to make substitutions clearer\\n            __module__=lister\\n            __str__=<unbound method ListTree.__str__>\\n........>\\nFor more fun, try mixing this class into something more substantial, like the Button\\nclass of Python’s tkinter GUI toolkit module. In general, you’ll want to name List\\nTree first (leftmost) in a class header, so its __str__ is picked up; Button has one, too,\\nand the leftmost superclass is searched first in multiple inheritance. The output of\\nthe following is fairly massive (18K characters), so run this code on your own to see\\nthe full listing (and if you’re using Python 2.6, recall that you should use Tkinter for\\nthe module name instead of tkinter):\\n>>> from lister import ListTree\\n>>> from tkinter import Button                  # Both classes have a __str__\\n>>> class MyButton(ListTree, Button): pass      # ListTree first: use its __str__\\n...\\n>>> B = MyButton(text='spam')\\n>>> open('savetree.txt', 'w').write(str(B))     # Save to a file for later viewing\\n18247\\n>>> print(B)                                    # Print the display here\\n<Instance of MyButton, address 44355632:\\n    _ListTree__visited={}\\n766 | Chapter 30: \\u2002Designing with Classes\", metadata={'source': 'python.pdf', 'page': 816}),\n",
       " Document(page_content=\"    _name=44355632\\n    _tclCommands=[]\\n    ...much more omitted...\\n>\\nOf course, there’s much more we could do here (sketching the tree in a GUI might be\\na natural next \\nstep), but we’ll leave further work as a suggested exercise. We’ll also\\nextend this code in the exercises at the end of this part of the book, to list superclass\\nnames in parentheses at the start of instance and class displays.\\nThe main point here is that OOP is all about code reuse, and mix-in classes are a\\npowerful example. Like almost everything else in programming, multiple inheritance\\ncan be a useful device when applied well. In practice, though, it is an advanced feature\\nand can become complicated if used carelessly or excessively. We’ll revisit this topic as\\na gotcha at the end of the next chapter. In that chapter, we’ll also meet the new-style\\nclass model, which modifies the search order for one special multiple inheritance case.\\nSupporting slots: Because they scan instance dictionaries, the\\nListInstance and ListTree classes presented here don’t directly support\\nattributes stored in slots—a newer and relatively rarely used option we’ll\\nmeet in the next chapter, where instance attributes are declared in a\\n__slots__ class attribute. For example, if in textmixin.py we assign\\n__slots__=['data1'] in Super and __slots__=['data3'] in Sub, only the\\ndata2 attribute is displayed in the instance by these two lister classes;\\nListTree also displays data1 and data3, but as attributes of the Super\\nand Sub class objects and with a special format for their values (techni-\\ncally, they are class-level descriptors).\\nTo better support slot attributes in these classes, change the __dict__\\nscanning loops to also iterate through __slots__ lists using code the next\\nchapter will present, and use the getattr built-in function to fetch values\\ninstead of __dict__ indexing (ListTree already does). Since instances\\ninherit only the lowest class’s __slots__, you may also need to come up\\nwith a policy when __slots__ lists appear in multiple superclasses\\n(ListTree already displays them as class attributes). ListInherited is\\nimmune to all this, because dir results combine both __dict__ names\\nand all classes’ __slots__ names.\\nAlternatively, as a policy we could simply let our code handle slot-based\\nattributes as it currently does, rather than complicating it for a rare,\\nadvanced feature. Slots and normal instance attributes are different\\nkinds of names. We’ll investigate slots further in the next chapter; I\\nomitted addressing them in these examples to avoid a forward\\ndependency (not counting this note, of course!)—not exactly a valid\\ndesign goal, but reasonable for a book.\\nMultiple Inheritance: “Mix-in” Classes | 767\", metadata={'source': 'python.pdf', 'page': 817}),\n",
       " Document(page_content='Classes Are Objects: Generic Object Factories\\nSometimes, class-based designs require \\nobjects to be created in response to conditions\\nthat can’t be predicted when a program is written. The factory design pattern allows\\nsuch a deferred approach. Due in large part to Python’s flexibility, factories can take\\nmultiple forms, some of which don’t seem special at all.\\nBecause classes are objects, it’s easy to pass them around a program, store them in data\\nstructures, and so on. You can also pass classes to functions that generate arbitrary\\nkinds of objects; such functions are sometimes called factories in OOP design circles.\\nFactories are a major undertaking in a strongly typed language such as C++ but are\\nalmost trivial to implement in Python. The call syntax we met in Chapter 18  can call\\nany class with any number of constructor arguments in one step to generate any sort\\nof instance:‡\\ndef factory(aClass, *args):           # Varargs tuple\\n    return aClass(*args)              # Call aClass (or apply in 2.6 only)\\nclass Spam:\\n    def doit(self, message):\\n        print(message)\\nclass Person:\\n    def __init__(self, name, job):\\n        self.name = name\\n        self.job  = job\\nobject1 = factory(Spam)                      # Make a Spam object\\nobject2 = factory(Person, \"Guido\", \"guru\")   # Make a Person object\\nIn this code, we define an object generator function called factory. It expects to be\\npassed a class object (any class will do) along with one or more arguments for the class’s\\nconstructor. The function uses special “varargs” call syntax to call the function and\\nreturn an instance.\\nThe rest of the example simply defines two classes and generates instances of both by\\npassing them to the factory function. And that’s the only factory function you’ll ever\\nneed to write in Python; it works for any class and any constructor arguments.\\nOne possible improvement worth noting is that to support keyword arguments in con-\\nstructor calls, the factory can collect them with a **args argument and pass them along\\nin the class call, too:\\ndef factory(aClass, *args, **kwargs):        # +kwargs dict\\n    return aClass(*args, **kwargs)           # Call aClass\\n‡ Actually, this syntax can invoke any callable object, including functions, classes, and methods. Hence, the\\nfactory \\nfunction here can also run any callable object, not just a class (despite the argument name). Also, as\\nwe learned in Chapter 18 , Python 2.6 has an alternative to aClass(*args): the apply(aClass, args)  built-in\\ncall, which has been removed in Python 3.0 because of its redundancy and limitations.\\n768 | Chapter 30: \\u2002Designing with Classes', metadata={'source': 'python.pdf', 'page': 818}),\n",
       " Document(page_content='By now, you should know that everything is an “object” in Python, including things\\nlike classes, which \\nare just compiler input in languages like C++. However, as men-\\ntioned at the start of this part of the book, only objects derived from classes are OOP\\nobjects in Python.\\nWhy Factories?\\nSo what good is the factory function (besides providing an excuse to illustrate class\\nobjects in this book)? Unfortunately, it’s difficult to show applications of this design\\npattern without listing much more code than we have space for here. In general, though,\\nsuch a factory might allow code to be insulated from the details of dynamically con-\\nfigured object construction.\\nFor instance, recall the processor example presented in the abstract in Chapter 25 , and\\nthen again as a composition example in this chapter. It accepts reader and writer objects\\nfor processing arbitrary data streams. The original version of this example manually\\npassed in instances of specialized classes like FileWriter and SocketReader to customize\\nthe data streams being processed; later, we passed in hardcoded file, stream, and\\nformatter objects. In a more dynamic scenario, external devices such as configuration\\nfiles or GUIs might be used to configure the streams.\\nIn such a dynamic world, we might not be able to hardcode the creation of stream\\ninterface objects in our scripts, but might instead create them at runtime according to\\nthe contents of a configuration file.\\nFor example, the file might simply give the string name of a stream class to be imported\\nfrom a module, plus an optional constructor call argument. Factory-style functions or\\ncode might come in handy here because they would allow us to fetch and pass in classes\\nthat are not hardcoded in our program ahead of time. Indeed, those classes might not\\neven have existed at all when we wrote our code:\\nclassname = ...parse from config file...\\nclassarg  = ...parse from config file...\\nimport streamtypes                           # Customizable code\\naclass = getattr(streamtypes, classname)     # Fetch from module\\nreader = factory(aclass, classarg)           # Or aclass(classarg)\\nprocessor(reader, ...)\\nHere, the getattr built-in is again used to fetch a module attribute given a string name\\n(it’s like saying obj.attr, but attr is a string). Because this code snippet assumes a\\nsingle constructor argument, it doesn’t strictly need factory or apply—we could make\\nan instance with just aclass(classarg). They may prove more useful in the presence\\nof unknown argument lists, however, and the general factory coding pattern can im-\\nprove the code’s flexibility.\\nClasses Are Objects: Generic Object Factories | 769', metadata={'source': 'python.pdf', 'page': 819}),\n",
       " Document(page_content='Other Design-Related Topics\\nIn this chapter, \\nwe’ve seen inheritance, composition, delegation, multiple inheritance,\\nbound methods, and factories—all common patterns used to combine classes in Python\\nprograms. We’ve really only scratched the surface here in the design patterns domain,\\nthough. Elsewhere in this book you’ll find coverage of other design-related topics, such\\nas:\\n•Abstract superclasses (Chapter 28)\\n•Decorators (Chapters 31 and 38)\\n•Type subclasses (Chapter 31)\\n•Static and class methods (Chapter 31)\\n•Managed attributes (Chapter 37)\\n•Metaclasses (Chapters 31 and 39)\\nFor more details on design patterns, though, we’ll delegate to other resources on OOP\\nat large. Although patterns are important in OOP work, and are often more natural in\\nPython than other languages, they are not specific to Python itself.\\nChapter Summary\\nIn this chapter, we sampled common ways to use and combine classes to optimize their\\nreusability and factoring benefits—what are usually considered design issues that are\\noften independent of any particular programming language (though Python can make\\nthem easier to implement). We studied delegation (wrapping objects in proxy classes),\\ncomposition (controlling embedded objects), and inheritance (acquiring behavior from\\nother classes), as well as some more esoteric concepts such as pseudoprivate attributes,\\nmultiple inheritance, bound methods, and factories.\\nThe next chapter ends our look at classes and OOP by surveying more advanced class-\\nrelated topics; some of its material may be of more interest to tool writers than appli-\\ncation programmers, but it still merits a review by most people who will do OOP in\\nPython. First, though, another quick chapter quiz.\\nTest Your Knowledge: Quiz\\n1. What is multiple inheritance?\\n2.What is delegation?\\n3.\\nWhat is composition?\\n770 | Chapter 30: \\u2002Designing with Classes', metadata={'source': 'python.pdf', 'page': 820}),\n",
       " Document(page_content='4. What are bound methods?\\n5. What are pseudoprivate attributes used for?\\nTest Your Knowledge: Answers\\n1. Multiple \\ninheritance occurs when a class inherits from more than one superclass;\\nit’s useful for mixing together multiple packages of class-based code. The left-to-\\nright order in class statement headers determines the order of attribute searches.\\n2. Delegation involves wrapping an object in a proxy class, which adds extra behavior\\nand passes other operations to the wrapped object. The proxy retains the interface\\nof the wrapped object.\\n3. Composition is a technique whereby a controller class embeds and directs a num-\\nber of objects, and provides an interface all its own; it’s a way to build up larger\\nstructures with classes.\\n4. Bound methods combine an instance and a method function; you can call them\\nwithout passing in an instance object explicitly because the original instance is still\\navailable.\\n5. Pseudoprivate attributes (whose names begin with two leading underscores: __X)\\nare used to localize names to the enclosing class. This includes both class attributes\\nlike methods defined inside the class, and self instance attributes assigned inside\\nthe class. Such names are expanded to include the class name, which makes them\\nunique.\\nTest Your Knowledge: Answers | 771', metadata={'source': 'python.pdf', 'page': 821}),\n",
       " Document(page_content='', metadata={'source': 'python.pdf', 'page': 822}),\n",
       " Document(page_content='CHAPTER 31\\nAdvanced Class Topics\\nThis chapter concludes our look at OOP in Python by presenting a few more advanced\\nclass-related topics: we \\nwill survey subclassing built-in types, “new-style” class changes\\nand extensions, static and class methods, function decorators, and more.\\nAs we’ve seen, Python’s OOP model is, at its core, very simple, and some of the topics\\npresented in this chapter are so advanced and optional that you may not encounter\\nthem very often in your Python applications-programming career. In the interest of\\ncompleteness, though, we’ll round out our discussion of classes with a brief look at\\nthese advanced tools for OOP work.\\nAs usual, because this is the last chapter in this part of the book, it ends with a section\\non class-related “gotchas,” and the set of lab exercises for this part. I encourage you to\\nwork through the exercises to help cement the ideas we’ve studied here. I also suggest\\nworking on or studying larger OOP Python projects as a supplement to this book. As\\nwith much in computing, the benefits of OOP tend to become more apparent with\\npractice.\\nContent note : This chapter collects advanced class topics, but some are\\neven too advanced for this chapter to cover well. Topics such as prop-\\nerties, descriptors, decorators, and metaclasses are only briefly men-\\ntioned here, and are covered more fully in the final part of this book. Be\\nsure to look ahead for more complete examples and extended coverage\\nof some of the subjects that fall into this chapter’s category.\\nExtending Built-in Types\\nBesides implementing new kinds of objects, classes are sometimes used to extend the\\nfunctionality of Python’s built-in types to support more exotic data structures. For\\ninstance, to add queue insert and delete methods to lists, you can code classes that wrap\\n(embed) a list object and export insert and delete methods that process the list specially,\\nlike the delegation technique we studied in Chapter 30 . As of Python 2.2, you can also\\n773', metadata={'source': 'python.pdf', 'page': 823}),\n",
       " Document(page_content=\"use inheritance to specialize built-in types. The next two sections show both techniques\\nin action.\\nExtending Types by Embedding\\nRemember those set functions \\nwe wrote in Chapters 16 and 18? Here’s what they look\\nlike brought back to life as a Python class. The following example (the file\\nsetwrapper.py) implements a new set object type by moving some of the set functions\\nto methods and adding some basic operator overloading. For the most part, this class\\njust wraps a Python list with extra set operations. But because it’s a class, it also supports\\nmultiple instances and customization by inheritance in subclasses. Unlike our earlier\\nfunctions, using classes here allows us to make multiple self-contained set objects with\\npreset data and behavior, rather than passing lists into functions manually:\\nclass Set:\\n   def __init__(self, value = []):    # Constructor\\n       self.data = []                 # Manages a list\\n       self.concat(value)\\n   def intersect(self, other):        # other is any sequence\\n       res = []                       # self is the subject\\n       for x in self.data:\\n           if x in other:             # Pick common items\\n               res.append(x)\\n       return Set(res)                # Return a new Set\\n   def union(self, other):            # other is any sequence\\n       res = self.data[:]             # Copy of my list\\n       for x in other:                # Add items in other\\n           if not x in res:\\n               res.append(x)\\n       return Set(res)\\n   def concat(self, value):           # value: list, Set...\\n       for x in value:                # Removes duplicates\\n          if not x in self.data:\\n               self.data.append(x)\\n   def __len__(self):          return len(self.data)            # len(self)\\n   def __getitem__(self, key): return self.data[key]            # self[i]\\n   def __and__(self, other):   return self.intersect(other)     # self & other\\n   def __or__(self, other):    return self.union(other)         # self | other\\n   def __repr__(self):         return 'Set:' + repr(self.data)  # print()\\nTo use this class, we make instances, call methods, and run defined operators as usual:\\nx = Set([1, 3, 5, 7])\\nprint(x.union(Set([1, 4, 7])))       # prints Set:[1, 3, 5, 7, 4]\\nprint(x | Set([1, 4, 6]))            # prints Set:[1, 3, 5, 7, 4, 6]\\n774 | Chapter 31: \\u2002Advanced Class Topics\", metadata={'source': 'python.pdf', 'page': 824}),\n",
       " Document(page_content=\"Overloading operations such as indexing enables instances of our Set class to mas-\\nquerade as real lists. Because you will interact with and extend this class in an exercise\\nat the end of this chapter, I won’t say much more about this code until Appendix B.\\nExtending Types by Subclassing\\nBeginning with Python 2.2, all the built-in types in the language can now be subclassed\\ndirectly. Type-conversion functions such as list, str, dict, and tuple have become\\nbuilt-in type names—although transparent to your script, a type-conversion call (e.g.,\\nlist('spam')) is now really an invocation of a type’s object constructor.\\nThis change allows you to customize or extend the behavior of built-in types with user-\\ndefined class statements: simply subclass the new type names to customize them. In-\\nstances of your type subclasses can be used anywhere that the original built-in type can\\nappear. For example, suppose you have trouble getting used to the fact that Python list\\noffsets begin at 0 instead of 1. Not to worry—you can always code your own subclass\\nthat customizes this core behavior of lists. The file typesubclass.py shows how:\\n# Subclass built-in list type/class\\n# Map 1..N to 0..N-1; call back to built-in version.\\nclass MyList(list):\\n    def __getitem__(self, offset):\\n        print('(indexing %s at %s)' % (self, offset))\\n        return list.__getitem__(self, offset - 1)\\nif __name__ == '__main__':\\n    print(list('abc'))\\n    x = MyList('abc')               # __init__ inherited from list\\n    print(x)                        # __repr__ inherited from list\\n    print(x[1])                     # MyList.__getitem__\\n    print(x[3])                     # Customizes list superclass method\\n    x.append('spam'); print(x)      # Attributes from list superclass\\n    x.reverse();      print(x)\\nIn this file, the MyList subclass extends the built-in list’s __getitem__ indexing method\\nonly to map indexes 1 to N back to the required 0 to N−1. All it really does is decrement\\nthe submitted index and call back to the superclass’s version of indexing, but it’s\\nenough to do the trick:\\n% python typesubclass.py\\n['a', 'b', 'c']\\n['a', 'b', 'c']\\n(indexing ['a', 'b', 'c'] at 1)\\na\\n(indexing ['a', 'b', 'c'] at 3)\\nc\\n['a', 'b', 'c', 'spam']\\n['spam', 'c', 'b', 'a']\\nExtending Built-in Types | 775\", metadata={'source': 'python.pdf', 'page': 825}),\n",
       " Document(page_content=\"This output also includes tracing text the class prints on indexing. Of course, whether\\nchanging indexing this \\nway is a good idea in general is another issue—users of your\\nMyList class may very well be confused by such a core departure from Python sequence\\nbehavior. The ability to customize built-in types this way can be a powerful asset,\\nthough.\\nFor instance, this coding pattern gives rise to an alternative way to code a set—as a\\nsubclass of the built-in list type, rather than a standalone class that manages an em-\\nbedded list object, as shown earlier in this section. As we learned in Chapter 5 , Python\\ntoday comes with a powerful built-in set object, along with literal and comprehension\\nsyntax for making new sets. Coding one yourself, though, is still a great way to learn\\nabout type subclassing in general.\\nThe following class, coded in the file setsubclass.py, customizes lists to add just methods\\nand operators related to set processing. Because all other behavior is inherited from the\\nbuilt-in list superclass, this makes for a shorter and simpler alternative:\\nclass Set(list):\\n    def __init__(self, value = []):      # Constructor\\n        list.__init__([])                # Customizes list\\n        self.concat(value)               # Copies mutable defaults\\n    def intersect(self, other):          # other is any sequence\\n        res = []                         # self is the subject\\n        for x in self:\\n            if x in other:               # Pick common items\\n                res.append(x)\\n        return Set(res)                  # Return a new Set\\n    def union(self, other):              # other is any sequence\\n        res = Set(self)                  # Copy me and my list\\n        res.concat(other)\\n        return res\\n    def concat(self, value):             # value: list, Set . . .\\n        for x in value:                  # Removes duplicates\\n            if not x in self:\\n                self.append(x)\\n    def __and__(self, other): return self.intersect(other)\\n    def __or__(self, other):  return self.union(other)\\n    def __repr__(self):       return 'Set:' + list.__repr__(self)\\nif __name__ == '__main__':\\n    x = Set([1,3,5,7])\\n    y = Set([2,1,4,5,6])\\n    print(x, y, len(x))\\n    print(x.intersect(y), y.union(x))\\n    print(x & y, x | y)\\n    x.reverse(); print(x)\\n776 | Chapter 31: \\u2002Advanced Class Topics\", metadata={'source': 'python.pdf', 'page': 826}),\n",
       " Document(page_content='Here is the output of the self-test code at the end of this file. Because subclassing core\\ntypes is an \\nadvanced feature, I’ll omit further details here, but I invite you to trace\\nthrough these results in the code to study its behavior:\\n% python setsubclass.py\\nSet:[1, 3, 5, 7] Set:[2, 1, 4, 5, 6] 4\\nSet:[1, 5] Set:[2, 1, 4, 5, 6, 3, 7]\\nSet:[1, 5] Set:[1, 3, 5, 7, 2, 4, 6]\\nSet:[7, 5, 3, 1]\\nThere are more efficient ways to implement sets with dictionaries in Python, which\\nreplace the linear scans in the set implementations shown here with dictionary index\\noperations (hashing) and so run much quicker. (For more details, see Programming\\nPython.) If you’re interested in sets, also take another look at the set object type we\\nexplored in Chapter 5 ; this type provides extensive set operations as built-in tools. Set\\nimplementations are fun to experiment with, but they are no longer strictly required in\\nPython today.\\nFor another type subclassing example, see the implementation of the bool type in Py-\\nthon 2.3 and later. As mentioned earlier in the book, bool is a subclass of int with two\\ninstances (True and False) that behave like the integers 1 and 0 but inherit custom string-\\nrepresentation methods that display their names.\\nThe “New-Style” Class Model\\nIn Release 2.2, Python introduced a new flavor of classes, known as “new-style” classes;\\nclasses following the original model became known as “classic classes” when compared\\nto the new kind. In 3.0 the class story has merged, but it remains split for Python 2.X\\nusers:\\n• As of Python 3.0, all classes are automatically what we used to call “new-style,”\\nwhether they explicitly inherit from object or not. All classes inherit from object,\\nwhether implicitly or explicitly, and all objects are instances of object.\\n• In Python 2.6 and earlier, classes must inherit from object (or another built-in type)\\nto be considered “new-style” and obtain all new-style features.\\nBecause all classes are automatically new-style in 3.0, the features of new-style classes\\nare simply normal class features. I’ve opted to keep their descriptions in this section\\nseparate, however, in deference to users of Python 2.X code—classes in such code\\nacquire new-style features only when they are derived from object.\\nIn other words, when Python 3.0 users see descriptions of “new-style” features in this\\nsection, they should take them to be descriptions of existing features of their classes.\\nFor 2.6 readers, these are a set of optional extensions.\\nIn Python 2.6 and earlier, the only syntactic difference for new-style classes is that they\\nare derived from either a built-in type, such as list, or a special built-in class known\\nThe “New-Style” Class Model | 777', metadata={'source': 'python.pdf', 'page': 827}),\n",
       " Document(page_content='as object. The built-in name object is provided to serve as a superclass for new-style\\nclasses if no other built-in type is appropriate to use:\\nclass newstyle(object):\\n    ...normal code...\\nAny class derived from object, or any other built-in type, is automatically treated as a\\nnew-style class. As long as a built-in type is somewhere in the superclass tree, the new\\nclass is treated as a new-style class. Classes not derived from built-ins such as object\\nare considered classic.\\nNew-style classes are only slightly different from classic classes, and the ways in which\\nthey differ are irrelevant to the vast majority of Python users. Moreover, the classic class\\nmodel still available in 2.6 works exactly as it has for almost two decades.\\nIn fact, new-style classes are almost completely backward compatible with classic\\nclasses in syntax and behavior; they mostly just add a few advanced new features.\\nHowever, because they modify a handful of class behaviors, they had to be introduced\\nas a distinct tool so as to avoid impacting any existing code that depends on the prior\\nbehaviors. For example, some subtle differences, such as diamond pattern inheritance\\nsearch and the behavior of built-in operations with managed attribute methods such\\nas __getattr__, can cause some legacy code to fail if left unchanged.\\nThe next two sections provide overviews of the ways the new-style classes differ and\\nthe new tools they provide. Again, because all classes are new-style today, these topics\\nrepresent changes to Python 2.X readers but simply additional advanced class topics\\nto Python 3.0 readers.\\nNew-Style Class Changes\\nNew-style classes differ from classic classes in a number of ways, some of which are\\nsubtle but can impact existing 2.X code and coding styles. Here are some of the most\\nprominent ways they differ:\\nClasses and types merged\\nClasses are now types, and types are now classes. In fact, the two are essentially\\nsynonyms. The type(I) built-in returns the class an instance is made from, instead\\nof a generic instance type, and is normally the same as I.__class__. Moreover,\\nclasses are instances of the type class, type may be subclassed to customize class\\ncreation, and all classes (and hence types) inherit from object.\\nInheritance search order\\nDiamond patterns of multiple inheritance have a slightly different search order—\\nroughly, they are searched across before up, and more breadth-first than depth-\\nfirst.\\n778 | Chapter 31: \\u2002Advanced Class Topics', metadata={'source': 'python.pdf', 'page': 828}),\n",
       " Document(page_content=\"Attribute fetch for built-ins\\nThe __getattr__ and __getattribute__ \\nmethods are no longer run for attributes\\nimplicitly fetched by built-in operations. This means that they are not called for\\n__X__ operator overloading method names—the search for such names begins at\\nclasses, not instances.\\nNew advanced tools\\nNew-style classes have a set of new class tools, including slots, properties, descrip-\\ntors, and the __getattribute__ method. Most of these have very specific tool-\\nbuilding purposes.\\nWe discussed the third of these changes briefly in a sidebar in Chapter 27, and we’ll\\nrevisit it in depth in the contexts of attribute management in Chapter 37  and privacy\\ndecorators in Chapter 38. Because the first and second of the changes just listed can\\nbreak existing 2.X code, though, let’s explore these in more detail before moving on to\\nnew-style additions.\\nType Model Changes\\nIn new-style classes, the distinction between type and class has vanished entirely.\\nClasses themselves are types: the type object generates classes as its instances, and\\nclasses generate instances of their type. If fact, there is no real difference between built-\\nin types like lists and strings and user-defined types coded as classes. This is why we\\ncan subclass built-in types, as shown earlier in this chapter—because subclassing a\\nbuilt-in type such as list qualifies a class as new-style, it becomes a user-defined type.\\nBesides allowing us to subclass built-in types, one of the contexts where this becomes\\nmost obvious is when we do explicit type testing. With Python 2.6’s classic classes, the\\ntype of a class instance is a generic “instance,” but the types of built-in objects are more\\nspecific:\\nC:\\\\misc> c:\\\\python26\\\\python\\n>>> class C: pass                       # Classic classes in 2.6\\n...\\n>>> I = C()\\n>>> type(I)                             # Instances are made from classes\\n<type 'instance'>\\n>>> I.__class__\\n<class __main__.C at 0x025085A0>\\n>>> type(C)                             # But classes are not the same as types\\n<type 'classobj'>\\n>>> C.__class__\\nAttributeError: class C has no attribute '__class__'\\n>>> type([1, 2, 3])\\n<type 'list'>\\n>>> type(list)\\n<type 'type'>\\nNew-Style Class Changes | 779\", metadata={'source': 'python.pdf', 'page': 829}),\n",
       " Document(page_content=\">>> list.__class__\\n<type 'type'>\\nBut with new-style \\nclasses in 2.6, the type of a class instance is the class it’s created\\nfrom, since classes are simply user-defined types—the type of an instance is its class,\\nand the type of a user-defined class is the same as the type of a built-in object type.\\nClasses have a __class__ attribute now, too, because they are instances of type:\\nC:\\\\misc> c:\\\\python26\\\\python\\n>>> class C(object): pass               # New-style classes in 2.6\\n...\\n>>> I = C()\\n>>> type(I)                             # Type of instance is class it's made from\\n<class '__main__.C'>\\n>>> I.__class__\\n<class '__main__.C'>\\n>>> type(C)                             # Classes are user-defined types\\n<type 'type'>\\n>>> C.__class__\\n<type 'type'>\\n>>> type([1, 2, 3])                     # Built-in types work the same way\\n<type 'list'>\\n>>> type(list)\\n<type 'type'>\\n>>> list.__class__\\n<type 'type'>\\nThe same is true for all classes in Python 3.0, since all classes are automatically new-\\nstyle, even if they have no explicit superclasses. In fact, the distinction between built-\\nin types and user-defined class types melts away altogether in 3.0:\\nC:\\\\misc> c:\\\\python30\\\\python\\n>>> class C: pass                       # All classes are new-style in 3.0\\n...\\n>>> I = C()\\n>>> type(I)                             # Type of instance is class it's made from\\n<class '__main__.C'>\\n>>> I.__class__\\n<class '__main__.C'>\\n>>> type(C)                             # Class is a type, and type is a class\\n<class 'type'>\\n>>> C.__class__\\n<class 'type'>\\n>>> type([1, 2, 3])                     # Classes and built-in types work the same\\n<class 'list'>\\n>>> type(list)\\n<class 'type'>\\n>>> list.__class__\\n<class 'type'>\\n780 | Chapter 31: \\u2002Advanced Class Topics\", metadata={'source': 'python.pdf', 'page': 830}),\n",
       " Document(page_content=\"As you can see, in 3.0 classes are types, but types are also classes. Technically, each\\nclass is generated \\nby a metaclass—a class that is normally either type itself, or a subclass\\nof it customized to augment or manage generated classes. Besides impacting code that\\ndoes type testing, this turns out to be an important hook for tool developers. We’ll talk\\nmore about metaclasses later in this chapter, and again in more detail in Chapter 39.\\nImplications for type testing\\nBesides providing for built-in type customization and metaclass hooks, the merging of\\nclasses and types in the new-style class model can impact code that does type testing.\\nIn Python 3.0, for example, the types of class instances compare directly and mean-\\ningfully, and in the same way as built-in type objects. This follows from the fact that\\nclasses are now types, and an instance’s type is the instance’s class:\\nC:\\\\misc> c:\\\\python30\\\\python\\n>>> class C: pass\\n...\\n>>> class D: pass\\n...\\n>>> c = C()\\n>>> d = D()\\n>>> type(c) == type(d)                 # 3.0: compares the instances' classes\\nFalse\\n>>> type(c), type(d)\\n(<class '__main__.C'>, <class '__main__.D'>)\\n>>> c.__class__, d.__class__\\n(<class '__main__.C'>, <class '__main__.D'>)\\n>>> c1, c2 = C(), C()\\n>>> type(c1) == type(c2)\\nTrue\\nWith classic classes in 2.6 and earlier, though, comparing instance types is almost use-\\nless, because all instances have the same “instance” type. To truly compare types, the\\ninstance __class__ attributes must be compared (if you care about portability, this\\nworks in 3.0, too, but it’s not required there):\\nC:\\\\misc> c:\\\\python26\\\\python\\n>>> class C: pass\\n...\\n>>> class D: pass\\n...\\n>>> c = C()\\n>>> d = D()\\n>>> type(c) == type(d)                 # 2.6: all instances are same type\\nTrue\\n>>> c.__class__ == d.__class__         # Must compare classes explicitly\\nFalse\\n>>> type(c), type(d)\\n(<type 'instance'>, <type 'instance'>)\\nNew-Style Class Changes | 781\", metadata={'source': 'python.pdf', 'page': 831}),\n",
       " Document(page_content=\">>> c.__class__, d.__class__\\n(<class __main__.C at 0x024585A0>, <class __main__.D at 0x024588D0>)\\nAnd as you \\nshould expect by now, new-style classes in 2.6 work the same as all classes\\nin 3.0 in this regard—comparing instance types compares the instances’ classes\\nautomatically:\\nC:\\\\misc> c:\\\\python26\\\\python\\n>>> class C(object): pass\\n...\\n>>> class D(object): pass\\n...\\n>>> c = C()\\n>>> d = D()\\n>>> type(c) == type(d)                 # 2.6 new-style: same as all in 3.0\\nFalse\\n>>> type(c), type(d)\\n(<class '__main__.C'>, <class '__main__.D'>)\\n>>> c.__class__, d.__class__\\n(<class '__main__.C'>, <class '__main__.D'>)\\nOf course, as I’ve pointed out numerous times in this book, type checking is usually\\nthe wrong thing to do in Python programs (we code to object interfaces, not object\\ntypes), and the more general isinstance built-in is more likely what you’ll want to use\\nin the rare cases where instance class types must be queried. However, knowledge of\\nPython’s type model can help demystify the class model in general.\\nAll objects derive from “object”\\nOne other ramification of the type change in the new-style class model is that because\\nall classes derive (inherit) from the class object either implicitly or explicitly, and be-\\ncause all types are now classes, every object derives from the object built-in class,\\nwhether directly or through a superclass. Consider the following interaction in Python\\n3.0 (code an explicit object superclass in 2.6 to make this work equivalently):\\n>>> class C: pass\\n...\\n>>> X = C()\\n>>> type(X)                           # Type is now class instance was created from\\n<class '__main__.C'>\\n>>> type(C)\\n<class 'type'>\\nAs before, the type of a class instance is the class it was made from, and the type of a\\nclass is the type class because classes and types have merged. It is also true, though,\\nthat the instance and class are both derived from the built-in object class, since this is\\nan implicit or explicit superclass of every class:\\n782 | Chapter 31: \\u2002Advanced Class Topics\", metadata={'source': 'python.pdf', 'page': 832}),\n",
       " Document(page_content=\">>> isinstance(X, object)\\nTrue\\n>>> isinstance(C, object)             # Classes always inherit from object\\nTrue\\nThe same holds \\ntrue for built-in types like lists and strings, because types are classes in\\nthe new-style model—built-in types are now classes, and their instances derive from\\nobject, too:\\n>>> type('spam')\\n<class 'str'>\\n>>> type(str)\\n<class 'type'>\\n>>> isinstance('spam', object)        # Same for  built-in types (classes)\\nTrue\\n>>> isinstance(str, object)\\nTrue\\nIn fact, type itself derives from object, and object derives from type, even though the\\ntwo are different objects—a circular relationship that caps the object model and stems\\nfrom the fact that types are classes that generate classes:\\n>>> type(type)                        # All classes are types, and vice versa\\n<class 'type'>\\n>>> type(object)\\n<class 'type'>\\n>>> isinstance(type, object)          # All classes derive from object, even type\\nTrue\\n>>> isinstance(object, type)          # Types make classes, and type is a class\\nTrue\\n>>> type is object\\nFalse\\nIn practical terms, this model makes for fewer special cases than the prior type/class\\ndistinction of classic classes, and it allows us to write code that assumes and uses an\\nobject superclass. We’ll see examples of the latter later in the book; for now, let’s move\\non to explore other new-style changes.\\nDiamond Inheritance Change\\nOne of the most visible changes in new-style classes is their slightly different inheritance\\nsearch procedures for the so-called diamond pattern of multiple inheritance trees, where\\nmore than one superclass leads to the same higher superclass further above. The dia-\\nmond pattern is an advanced design concept, is coded only rarely in Python practice,\\nand has not been discussed in this book, so we won’t dwell on this topic in depth.\\nIn short, though, with classic classes, the inheritance search procedure is strictly depth\\nfirst, and then left to right—Python climbs all the way to the top, hugging the left side\\nof the tree, before it backs up and begins to look further to the right. In new-style classes,\\nthe search is more breadth-first in such cases—Python first looks in any superclasses\\nNew-Style Class Changes | 783\", metadata={'source': 'python.pdf', 'page': 833}),\n",
       " Document(page_content='to the right of the first one searched before ascending all the way to the common\\nsuperclass at the \\ntop. In other words, the search proceeds across by levels before moving\\nup. The search algorithm is a bit more complex than this, but this is as much as most\\nprogrammers need to know.\\nBecause of this change, lower superclasses can overload attributes of higher super-\\nclasses, regardless of the sort of multiple inheritance trees they are mixed into. More-\\nover, the new-style search rule avoids visiting the same superclass more than once when\\nit is accessible from multiple subclasses.\\nDiamond inheritance example\\nTo illustrate, consider this simplistic incarnation of the diamond multiple inheritance\\npattern for classic classes. Here, D’s superclasses B and C both lead to the same common\\nancestor, A:\\n>>> class A:\\n        attr = 1         # Classic (Python 2.6)\\n>>> class B(A):          # B and C both lead to A\\n        pass\\n>>> class C(A):\\n        attr = 2\\n>>> class D(B, C):\\n        pass             # Tries A before C\\n>>> x = D()\\n>>> x.attr               # Searches x, D, B, A\\n1\\nThe attribute here is found in superclass A, because with classic classes, the inheritance\\nsearch climbs as high as it can before backing up and moving right—Python will search\\nD, B, A, and then C, but will stop when attr is found in A, above B.\\nHowever, with new-style classes derived from a built-in like object, and all classes in\\n3.0, the search order is different: Python looks in C (to the right of B) before A (above\\nB). That is, it searches D, B, C, and then A, and in this case, stops in C:\\n>>> class A(object):\\n        attr = 1         # New-style (\"object\" not required in 3.0)\\n>>> class B(A):\\n        pass\\n>>> class C(A):\\n        attr = 2\\n>>> class D(B, C):\\n        pass             # Tries C before A\\n>>> x = D()\\n784 | Chapter 31: \\u2002Advanced Class Topics', metadata={'source': 'python.pdf', 'page': 834}),\n",
       " Document(page_content='>>> x.attr               # Searches x, D, B, C\\n2\\nThis change in \\nthe inheritance search procedure is based upon the assumption that if\\nyou mix in C lower in the tree, you probably intend to grab its attributes in preference\\nto A’s. It also assumes that C is always intended to override A’s attributes in all contexts,\\nwhich is probably true when it’s used standalone but may not be when it’s mixed into\\na diamond with classic classes—you might not even know that C may be mixed in like\\nthis when you code it.\\nSince it is most likely that the programmer meant that C should override A in this case,\\nthough, new-style classes visit C first. Otherwise, C could be essentially pointless in a\\ndiamond context: it could not customize A and would be used only for names unique\\nto C.\\nExplicit conflict resolution\\nOf course, the problem with assumptions is that they assume things. If this search order\\ndeviation seems too subtle to remember, or if you want more control over the search\\nprocess, you can always force the selection of an attribute from anywhere in the tree\\nby assigning or otherwise naming the one you want at the place where the classes are\\nmixed together:\\n>>> class A:\\n        attr = 1         # Classic\\n>>> class B(A):\\n        pass\\n>>> class C(A):\\n        attr = 2\\n>>> class D(B, C):\\n        attr = C.attr    # Choose C, to the right\\n>>> x = D()\\n>>> x.attr               # Works like new-style (all 3.0)\\n2\\nHere, a tree of classic classes is emulating the search order of new-style classes: the\\nassignment to the attribute in D picks the version in C, thereby subverting the normal\\ninheritance search path ( D.attr will be lowest in the tree). New-style classes can simi-\\nlarly emulate classic classes by choosing the attribute above at the place where the\\nclasses are mixed together:\\n>>> class A(object):\\n        attr = 1         # New-style\\n>>> class B(A):\\n        pass\\n>>> class C(A):\\nNew-Style Class Changes | 785', metadata={'source': 'python.pdf', 'page': 835}),\n",
       " Document(page_content=\"        attr = 2\\n>>> class D(B, C):\\n        attr = B.attr    # Choose A.attr, above\\n>>> x = D()\\n>>> x.attr               # Works like classic (default 2.6)\\n1\\nIf you are \\nwilling to always resolve conflicts like this, you can largely ignore the search\\norder difference and not rely on assumptions about what you meant when you coded\\nyour classes.\\nNaturally, attributes picked this way can also be method functions—methods are nor-\\nmal, assignable objects:\\n>>> class A:\\n        def meth(s): print('A.meth')\\n>>> class C(A):\\n        def meth(s): print('C.meth')\\n>>> class B(A):\\n        pass\\n>>> class D(B, C): pass            # Use default search order\\n>>> x = D()                        # Will vary per class type\\n>>> x.meth()                       # Defaults to classic order in 2.6\\nA.meth\\n>>> class D(B, C): meth = C.meth   # Pick C's method: new-style (and 3.0)\\n>>> x = D()\\n>>> x.meth()\\nC.meth\\n>>> class D(B, C): meth = B.meth   # Pick B's method: classic\\n>>> x = D()\\n>>> x.meth()\\nA.meth\\nHere, we select methods by explicitly assigning to names lower in the tree. We might\\nalso simply call the desired class explicitly; in practice, this pattern might be more\\ncommon, especially for things like constructors:\\nclass D(B, C):\\n    def meth(self):                # Redefine lower\\n        ...\\n        C.meth(self)               # Pick C's method by calling\\nSuch selections by assignment or call at mix-in points can effectively insulate your code\\nfrom this difference in class flavors. Explicitly resolving the conflicts this way ensures\\nthat your code won’t vary per Python version in the future (apart from perhaps needing\\nto derive classes from object or a built-in type for the new-style tools in 2.6).\\n786 | Chapter 31: \\u2002Advanced Class Topics\", metadata={'source': 'python.pdf', 'page': 836}),\n",
       " Document(page_content='Even without the classic/new-style class divergence, the explicit method\\nresolution technique shown \\nhere may come in handy in multiple inher-\\nitance scenarios in general. For instance, if you want part of a superclass\\non the left and part of a superclass on the right, you might need to tell\\nPython which same-named attributes to choose by using explicit as-\\nsignments in subclasses. We’ll revisit this notion in a “gotcha” at the\\nend of this chapter.\\nAlso note that diamond inheritance patterns might be more problematic\\nin some cases than I’ve implied here (e.g., what if B and C both have\\nrequired constructors that call to the constructor in A?). Since such con-\\ntexts are rare in real-world Python, we’ll leave this topic outside this\\nbook’s scope (but see the super built-in function for hints—besides\\nproviding generic access to superclasses in single inheritance trees,\\nsuper supports a cooperative mode for resolving some conflicts in mul-\\ntiple inheritance trees).\\nScope of search order change\\nIn sum, by default, the diamond pattern is searched differently for classic and new-style\\nclasses, and this is a nonbackward-compatible change. Keep in mind, though, that this\\nchange primarily affects diamond pattern cases of multiple inheritance; new-style class\\ninheritance works unchanged for most other inheritance tree structures. Further, it’s\\nnot impossible that this entire issue may be of more theoretical than practical\\nimportance—because the new-style search wasn’t significant enough to address until\\nPython 2.2 and didn’t become standard until 3.0, it seems unlikely to impact much\\nPython code.\\nHaving said that, I should also note that even though you might not code diamond\\npatterns in classes you write yourself, because the implied object superclass is above\\nevery class in 3.0, every case of multiple inheritance exhibits the diamond pattern today.\\nThat is, in new-style classes, object automatically plays the role that the class A does in\\nthe example we just considered. Hence the new-style search rule not only modifies\\nlogical semantics, but also optimizes performance by avoiding visiting the same class\\nmore than once.\\nJust as important, the implied object superclass in the new-style model provides default\\nmethods for a variety of built-in operations, including the __str__ and __repr__ display\\nformat methods. Run a dir(object) to see which methods are provided. Without the\\nnew-style search order, in multiple inheritance cases the defaults in object would al-\\nways override redefinitions in user-coded classes, unless they were always made in the\\nleftmost superclass. In other words, the new-style class model itself makes using the\\nnew-style search order more critical!\\nFor a more visual example of the implied object superclass in 3.0, and other examples\\nof diamond patterns created by it, see the ListTree class’s output in the lister.py example\\nin the preceding chapter, as well as the classtree.py tree walker example in Chapter 28 .\\nNew-Style Class Changes | 787', metadata={'source': 'python.pdf', 'page': 837}),\n",
       " Document(page_content=\"New-Style Class Extensions\\nBeyond the changes \\ndescribed in the prior section (which, frankly, may be too academic\\nand obscure to matter to many readers of this book), new-style classes provide a handful\\nof more advanced class tools that have more direct and practical application. The fol-\\nlowing sections provide an overview of each of these additional features, available for\\nnew-style class in Python 2.6 and all classes in Python 3.0.\\nInstance Slots\\nBy assigning a sequence of string attribute names to a special __slots__ class attribute,\\nit is possible for a new-style class to both limit the set of legal attributes that instances\\nof the class will have and optimize memory and speed performance.\\nThis special attribute is typically set by assigning a sequence of string names to the\\nvariable __slots__ at the top level of a class statement: only those names in the\\n__slots__ list can be assigned as instance attributes. However, like all names in Python,\\ninstance attribute names must still be assigned before they can be referenced, even if\\nthey’re listed in __slots__. For example:\\n>>> class limiter(object):\\n...     __slots__ = ['age', 'name', 'job']\\n...\\n>>> x = limiter()\\n>>> x.age                                           # Must assign before use\\nAttributeError: age\\n>>> x.age = 40\\n>>> x.age\\n40\\n>>> x.ape = 1000                                    # Illegal: not in __slots__\\nAttributeError: 'limiter' object has no attribute 'ape'\\nSlots are something of a break with Python’s dynamic nature, which dictates that any\\nname may be created by assignment. However, this feature is envisioned as both a way\\nto catch “typo” errors like this (assignments to illegal attribute names not in\\n__slots__ are detected), as well as an optimization mechanism. Allocating a namespace\\ndictionary for every instance object can become expensive in terms of memory if many\\ninstances are created and only a few attributes are required. To save space and speed\\nexecution (to a degree that can vary per program), instead of allocating a dictionary for\\neach instance, slot attributes are stored sequentially for quicker lookup.\\nSlots and generic code\\nIn fact, some instances with slots may not have a __dict__ attribute dictionary at all,\\nwhich can make some metaprograms more complex (including some coded in this\\nbook). Tools that generically list attributes or access attributes by string name, for\\nexample, must be careful to use more storage-neutral tools than __dict__, such as the\\n788 | Chapter 31: \\u2002Advanced Class Topics\", metadata={'source': 'python.pdf', 'page': 838}),\n",
       " Document(page_content=\"getattr, setattr, and dir built-in functions, which apply to attributes based on either\\n__dict__ or __slots__ storage. In some cases, both attribute sources may need to be\\nqueried for completeness.\\nFor example, when slots are used, instances do not normally have an attribute dic-\\ntionary—Python uses the class descriptors feature covered in Chapter 37  to allocate\\nspace for slot attributes in the instance instead. Only names in the slots list can be\\nassigned to instances, but slot-based attributes can still be fetched and set by name\\nusing generic tools. In Python 3.0 (and in 2.6 for classes derived from object):\\n>>> class C:\\n...     __slots__ = ['a', 'b']           # __slots__ means no __dict__ by default\\n...\\n>>> X = C()\\n>>> X.a = 1\\n>>> X.a\\n1\\n>>> X.__dict__\\nAttributeError: 'C' object has no attribute '__dict__'\\n>>> getattr(X, 'a')\\n1\\n>>> setattr(X, 'b', 2)                   # But getattr() and setattr() still work\\n>>> X.b\\n2\\n>>> 'a' in dir(X)                        # And dir() finds slot attributes too\\nTrue\\n>>> 'b' in dir(X)\\nTrue\\nWithout an attribute namespaces dictionary, it’s not possible to assign new names to\\ninstances that are not names in the slots list:\\n>>> class D:\\n...     __slots__ = ['a', 'b']\\n...     def __init__(self): self.d = 4   # Cannot add new names if no __dict__\\n...\\n>>> X = D()\\nAttributeError: 'D' object has no attribute 'd'\\nHowever, extra attributes can still be accommodated by including __dict__ in\\n__slots__, in order to allow for an attribute namespace dictionary. In this case, both\\nstorage mechanisms are used, but generic tools such as getattr allow us to treat them\\nas a single set of attributes:\\n>>> class D:\\n...     __slots__ = ['a', 'b', '__dict__']    # List __dict__ to include one too\\n...     c = 3                                 # Class attrs work normally\\n...     def __init__(self): self.d = 4        # d put in __dict__, a in __slots__\\n...\\n>>> X = D()\\n>>> X.d\\n4\\n>>> X.__dict__                   # Some objects have both __dict__ and __slots__\\n{'d': 4}                         # getattr() can fetch either type of attr\\nNew-Style Class Extensions | 789\", metadata={'source': 'python.pdf', 'page': 839}),\n",
       " Document(page_content=\">>> X.__slots__\\n['a', 'b', '__dict__']\\n>>> X.c\\n3\\n>>> X.a                          # All instance attrs undefined until assigned\\nAttributeError: a\\n>>> X.a = 1\\n>>> getattr(X, 'a',), getattr(X, 'c'), getattr(X, 'd')\\n(1, 3, 4)\\nCode that wishes \\nto list all instance attributes generically, though, may still need to\\nallow for both storage forms, since dir also returns inherited attributes (this relies on\\ndictionary iterators to collect keys):\\n>>> for attr in list(X.__dict__) + X.__slots__:\\n...     print(attr, '=>', getattr(X, attr))\\nd => 4\\na => 1\\nb => 2\\n__dict__ => {'d': 4}\\nSince either can be omitted, this is more correctly coded as follows ( getattr allows for\\ndefaults):\\n>>> for attr in list(getattr(X, '__dict__', [])) + getattr(X, '__slots__', []):\\n...     print(attr, '=>', getattr(X, attr))\\nd => 4\\na => 1\\nb => 2\\n__dict__ => {'d': 4}\\nMultiple __slot__ lists in superclasses\\nNote, however, that this code addresses only slot names in the lowest __slots__ at-\\ntribute inherited by an instance. If multiple classes in a class tree have their own\\n__slots__ attributes, generic programs must develop other policies for listing attributes\\n(e.g., classifying slot names as attributes of classes, not instances).\\nSlot declarations can appear in multiple classes in a class tree, but they are subject to a\\nnumber of constraints that are somewhat difficult to rationalize unless you understand\\nthe implementation of slots as class-level descriptors (a tool we’ll study in detail in the\\nlast part of this book):\\n• If a subclass inherits from a superclass without a __slots__, the __dict__ attribute\\nof the superclass will always be accessible, making a __slots__ in the subclass\\nmeaningless.\\n• If a class defines the same slot name as a superclass, the version of the name defined\\nby the superclass slot will be accessible only by fetching its descriptor directly from\\nthe superclass.\\n790 | Chapter 31: \\u2002Advanced Class Topics\", metadata={'source': 'python.pdf', 'page': 840}),\n",
       " Document(page_content=\"• Because the meaning of a __slots__ declaration is limited to the class in which it\\nappears, subclasses will have a __dict__ unless they also define a __slots__.\\nIn terms of listing instance attributes generically, slots in multiple classes might require\\nmanual class tree climbs, dir usage, or a policy that treats slot names as a different\\ncategory of names altogether:\\n>>> class E:\\n...     __slots__ = ['c', 'd']            # Superclass has slots\\n...\\n>>> class D(E):\\n...     __slots__ = ['a', '__dict__']     # So does its subclass\\n...\\n>>> X = D()\\n>>> X.a = 1; X.b = 2; X.c = 3             # The instance is the union\\n>>> X.a, X.c\\n(1, 3)\\n>>> E.__slots__                           # But slots are not concatenated\\n['c', 'd']\\n>>> D.__slots__\\n['a', '__dict__']\\n>>> X.__slots__                           # Instance inherits *lowest* __slots__\\n['a', '__dict__']\\n>>> X.__dict__                            # And has its own an attr dict\\n{'b': 2}\\n>>> for attr in list(getattr(X, '__dict__', [])) + getattr(X, '__slots__', []):\\n...     print(attr, '=>', getattr(X, attr))\\n...\\nb => 2                                    # Superclass slots missed!\\na => 1\\n__dict__ => {'b': 2}\\n>>> dir(X)                                # dir() includes all slot names\\n[...many names omitted... 'a', 'b', 'c', 'd']\\nWhen such generality is possible, slots are probably best treated as class attributes,\\nrather than trying to mold them to appear the same as normal instance attributes. For\\nmore on slots in general, see the Python standard manual set. Also watch for an example\\nthat allows for attributes based on both __slots__ and __dict__ storage in the\\nPrivate decorator discussion of Chapter 38.\\nFor a prime example of why generic programs may need to care about slots, see the\\nlister.py display mix-in classes example in the multiple inheritance section of the prior\\nchapter; a note there describes the example’s slot concerns. In such a tool that attempts\\nto list attributes generically, slot usage requires either extra code or the implementation\\nof policies regarding the handling of slot-based attributes in general.\\nNew-Style Class Extensions | 791\", metadata={'source': 'python.pdf', 'page': 841}),\n",
       " Document(page_content=\"Class Properties\\nA mechanism known \\nas properties provides another way for new-style classes to define\\nautomatically called methods for access or assignment to instance attributes. At least\\nfor specific attributes, this feature is an alternative to many current uses of the\\n__getattr__ and __setattr__ overloading methods we studied in Chapter 29 . Proper-\\nties have a similar effect to these two methods, but they incur an extra method call for\\nany accesses to names that require dynamic computation. Properties (and slots) are\\nbased on a new notion of attribute descriptors, which is too advanced for us to cover\\nhere.\\nIn short, a property is a type of object assigned to a class attribute name. A property is\\ngenerated by calling the property built-in with three methods (handlers for get, set, and\\ndelete operations), as well as a docstring; if any argument is passed as None or omitted,\\nthat operation is not supported. Properties are typically assigned at the top level of a\\nclass statement [e.g., name = property(...)]. When thus assigned, accesses to the class\\nattribute itself (e.g., obj.name) are automatically routed to one of the accessor methods\\npassed into the property. For example, the __getattr__ method allows classes to in-\\ntercept undefined attribute references:\\n>>> class classic:\\n...     def __getattr__(self, name):\\n...         if name == 'age':\\n...             return 40\\n...         else:\\n...             raise AttributeError\\n...\\n>>> x = classic()\\n>>> x.age                                         # Runs __getattr__\\n40\\n>>> x.name                                        # Runs __getattr__\\nAttributeError\\nHere is the same example, coded with properties instead (note that properties are\\navailable for all classes but require the new-style object derivation in 2.6 to work prop-\\nerly for intercepting attribute assignments):\\n>>> class newprops(object):\\n...     def getage(self):\\n...         return 40\\n...     age = property(getage, None, None, None)  # get, set, del, docs\\n...\\n>>> x = newprops()\\n>>> x.age                                         # Runs getage\\n40\\n>>> x.name                                        # Normal fetch\\nAttributeError: newprops instance has no attribute 'name'\\n792 | Chapter 31: \\u2002Advanced Class Topics\", metadata={'source': 'python.pdf', 'page': 842}),\n",
       " Document(page_content=\"For some coding tasks, properties can be less complex and quicker to run than the\\ntraditional techniques. For \\nexample, when we add attribute assignment support,\\nproperties become more attractive—there’s less code to type, and no extra method calls\\nare incurred for assignments to attributes we don’t wish to compute dynamically:\\n>>> class newprops(object):\\n...     def getage(self):\\n...         return 40\\n...     def setage(self, value):\\n...         print('set age:', value)\\n...         self._age = value\\n...     age = property(getage, setage, None, None)\\n...\\n>>> x = newprops()\\n>>> x.age                                         # Runs getage\\n40\\n>>> x.age = 42                                    # Runs setage\\nset age: 42\\n>>> x._age                                        # Normal fetch; no getage call\\n42\\n>>> x.job = 'trainer'                             # Normal assign; no setage call\\n>>> x.job                                         # Normal fetch; no getage call\\n'trainer'\\nThe equivalent classic class incurs extra method calls for assignments to attributes not\\nbeing managed and needs to route attribute assignments through the attribute dic-\\ntionary (or, for new-style classes, to the object superclass’s __setattr__) to avoid loops:\\n>>> class classic:\\n...     def __getattr__(self, name):              # On undefined reference\\n...         if name == 'age':\\n...             return 40\\n...         else:\\n...             raise AttributeError\\n...     def __setattr__(self, name, value):       # On all assignments\\n...         print('set:', name, value)\\n...         if name == 'age':\\n...             self.__dict__['_age'] = value\\n...         else:\\n...             self.__dict__[name] = value\\n...\\n>>> x = classic()\\n>>> x.age                                         # Runs __getattr__\\n40\\n>>> x.age = 41                                    # Runs __setattr__\\nset: age 41\\n>>> x._age                                        # Defined: no __getattr__ call\\n41\\n>>> x.job = 'trainer'                             # Runs __setattr__ again\\n>>> x.job                                         # Defined: no __getattr__ call\\nNew-Style Class Extensions | 793\", metadata={'source': 'python.pdf', 'page': 843}),\n",
       " Document(page_content='Properties seem like a win for this simple example. However, some applications of\\n__getattr__ and __setattr__ \\nmay still require more dynamic or generic interfaces than\\nproperties directly provide. For example, in many cases, the set of attributes to be\\nsupported cannot be determined when the class is coded, and may not even exist in\\nany tangible form (e.g., when delegating arbitrary method references to a wrapped/\\nembedded object generically). In such cases, a generic __getattr__ or a __setattr__\\nattribute handler with a passed-in attribute name may be preferable. Because such ge-\\nneric handlers can also handle simpler cases, properties are often an optional extension.\\nFor more details on both options, stay tuned for Chapter 37  in the final part of this\\nbook. As we’ll see there, it’s also possible to code properties using function decorator\\nsyntax, a topic introduced later in this chapter.\\n__getattribute__ and Descriptors\\nThe __getattribute__ method, available for new-style classes only, allows a class to\\nintercept all attribute references, not just undefined references, like __getattr__. It is\\nalso somewhat trickier to use than __getattr__: it is prone to loops, much like\\n__setattr__, but in different ways.\\nIn addition to properties and operator overloading methods, Python supports the no-\\ntion of attribute descriptors—classes with __get__ and __set__ methods, assigned to\\nclass attributes and inherited by instances, that intercept read and write accesses to\\nspecific attributes. Descriptors are in a sense a more general form of properties; in fact,\\nproperties are a simplified way to define a specific type of descriptor, one that runs\\nfunctions on access. Descriptors are also used to implement the slots feature we met\\nearlier.\\nBecause properties, __getattribute__, and descriptors are somewhat advanced topics,\\nwe’ll defer the rest of their coverage, as well as more on properties, to Chapter 37 in\\nthe final part of this book.\\nMetaclasses\\nMost of the changes and feature additions of new-style classes integrate with the notion\\nof subclassable types mentioned earlier in this chapter, because subclassable types and\\nnew-style classes were introduced in conjunction with a merging of the type/class di-\\nchotomy in Python 2.2 and beyond. As we’ve seen, in 3.0, this merging is complete:\\nclasses are now types, and types are classes.\\nAlong with these changes, Python also grew a more coherent protocol for coding\\nmetaclasses, which are classes that subclass the type object and intercept class creation\\ncalls. As such, they provide a well-defined hook for management and augmentation of\\nclass objects. They are also an advanced topic that is optional for most Python pro-\\ngrammers, so we’ll postpone further details here. We’ll meet metaclasses briefly later\\n794 | Chapter 31: \\u2002Advanced Class Topics', metadata={'source': 'python.pdf', 'page': 844}),\n",
       " Document(page_content='in this chapter in conjunction with class decorators, and we’ll explore them in full detail\\nin Chapter 39, in the final part of this book.\\nStatic and Class Methods\\nAs of Python 2.2, \\nit is possible to define two kinds of methods within a class that can\\nbe called without an instance: static methods work roughly like simple instance-less\\nfunctions inside a class, and class methods are passed a class instead of an instance.\\nAlthough this feature was added in conjunction with the new-style classes discussed in\\nthe prior sections, static and class methods work for classic classes too.\\nTo enable these method modes, special built-in functions called staticmethod and\\nclassmethod must be called within the class, or invoked with the decoration syntax we’ll\\nmeet later in this chapter. In Python 3.0, instance-less methods called only through a\\nclass name do not require a staticmethod declaration, but such methods called through\\ninstances do.\\nWhy the Special Methods?\\nAs we’ve learned, a class method is normally passed an instance object in its first ar-\\ngument, to serve as the implied subject of the method call. Today, though, there are\\ntwo ways to modify this model. Before I explain what they are, I should explain why\\nthis might matter to you.\\nSometimes, programs need to process data associated with classes instead of instances.\\nConsider keeping track of the number of instances created from a class, or maintaining\\na list of all of a class’s instances that are currently in memory. This type of information\\nand its processing are associated with the class rather than its instances. That is, the\\ninformation is usually stored on the class itself and processed in the absence of any\\ninstance.\\nFor such tasks, simple functions coded outside a class can often suffice—because they\\ncan access class attributes through the class name, they have access to class data and\\nnever require access to an instance. However, to better associate such code with a class,\\nand to allow such processing to be customized with inheritance as usual, it would be\\nbetter to code these types of functions inside the class itself. To make this work, we\\nneed methods in a class that are not passed, and do not expect, a self instance\\nargument.\\nPython supports such goals with the notion of static methods —simple functions with\\nno self argument that are nested in a class and are designed to work on class attributes\\ninstead of instance attributes. Static methods never receive an automatic self argument,\\nwhether called through a class or an instance. They usually keep track of information\\nthat spans all instances, rather than providing behavior for instances.\\nStatic and Class Methods | 795', metadata={'source': 'python.pdf', 'page': 845}),\n",
       " Document(page_content='Although less commonly used, Python also supports the notion of class methods—\\nmethods \\nof a class that are passed a class object in their first argument instead of an\\ninstance, regardless of whether they are called through an instance or a class. Such\\nmethods can access class data through their self class argument even if called through\\nan instance. Normal methods (now known in formal circles as instance methods ) still\\nreceive a subject instance when called; static and class methods do not.\\nStatic Methods in 2.6 and 3.0\\nThe concept of static methods is the same in both Python 2.6 and 3.0, but its imple-\\nmentation requirements have evolved somewhat in Python 3.0. Since this book covers\\nboth versions, I need to explain the differences in the two underlying models before we\\nget to the code.\\nReally, we already began this story in the preceding chapter, when we explored the\\nnotion of unbound methods. Recall that both Python 2.6 and 3.0 always pass an in-\\nstance to a method that is called through an instance. However, Python 3.0 treats\\nmethods fetched directly from a class differently than 2.6:\\n• In Python 2.6, fetching a method from a class produces an unbound method, which\\ncannot be called without manually passing an instance.\\n• In Python 3.0, fetching a method from a class produces a simple function , which\\ncan be called normally with no instance present.\\nIn other words, Python 2.6 class methods always require an instance to be passed in,\\nwhether they are called through an instance or a class. By contrast, in Python 3.0 we\\nare required to pass an instance to a method only if the method expects one—methods\\nwithout a self instance argument can be called through the class without passing an\\ninstance. That is, 3.0 allows simple functions in a class, as long as they do not expect\\nand are not passed an instance argument. The net effect is that:\\n• In Python 2.6, we must always declare a method as static in order to call it without\\nan instance, whether it is called through a class or an instance.\\n• In Python 3.0, we need not declare such methods as static if they will be called\\nthrough a class only, but we must do so in order to call them through an instance.\\nTo illustrate, suppose we want to use class attributes to count how many instances are\\ngenerated from a class. The following file, spam.py, makes a first attempt—its class has\\na counter stored as a class attribute, a constructor that bumps up the counter by one\\neach time a new instance is created, and a method that displays the counter’s value.\\nRemember, class attributes are shared by all instances. Therefore, storing the counter\\nin the class object itself ensures that it effectively spans all instances:\\nclass Spam:\\n    numInstances = 0\\n    def __init__(self):\\n        Spam.numInstances = Spam.numInstances + 1\\n796 | Chapter 31: \\u2002Advanced Class Topics', metadata={'source': 'python.pdf', 'page': 846}),\n",
       " Document(page_content='    def printNumInstances():\\n        print(\"Number of instances created: \", Spam.numInstances)\\nThe printNumInstances method is \\ndesigned to process class data, not instance data—\\nit’s about all the instances, not any one in particular. Because of that, we want to be\\nable to call it without having to pass an instance. Indeed, we don’t want to make an\\ninstance to fetch the number of instances, because this would change the number of\\ninstances we’re trying to fetch! In other words, we want a self-less “static” method.\\nWhether this code works or not, though, depends on which Python you use, and which\\nway you call the method—through the class or through an instance. In 2.6 (and 2.X in\\ngeneral), calls to a self-less method function through both the class and instances fail\\n(I’ve omitted some error text here for space):\\nC:\\\\misc> c:\\\\python26\\\\python\\n>>> from spam import Spam\\n>>> a = Spam()                   # Cannot call unbound class methods in 2.6\\n>>> b = Spam()                   # Methods expect a self object by default\\n>>> c = Spam()\\n>>> Spam.printNumInstances()\\nTypeError: unbound method printNumInstances() must be called with Spam instance\\nas first argument (got nothing instead)\\n>>> a.printNumInstances()\\nTypeError: printNumInstances() takes no arguments (1 given)\\nThe problem here is that unbound instance methods aren’t exactly the same as simple\\nfunctions in 2.6. Even though there are no arguments in the def header, the method\\nstill expects an instance to be passed in when it’s called, because the function is asso-\\nciated with a class. In Python 3.0 (and later 3.X releases), calls to self-less methods made\\nthrough classes work, but calls from instances fail:\\nC:\\\\misc> c:\\\\python30\\\\python\\n>>> from spam import Spam\\n>>> a = Spam()                       # Can call functions in class in 3.0\\n>>> b = Spam()                       # Calls through instances still pass a self\\n>>> c = Spam()\\n>>> Spam.printNumInstances()         # Differs in 3.0\\nNumber of instances created:  3\\n>>> a.printNumInstances()\\nTypeError: printNumInstances() takes no arguments (1 given)\\nThat is, calls to instance-less methods like printNumInstances made through the class\\nfail in Python 2.6 but work in Python 3.0. On the other hand, calls made through an\\ninstance fail in both Pythons, because an instance is automatically passed to a method\\nthat does not have an argument to receive it:\\nSpam.printNumInstances()             # Fails in 2.6, works in 3.0\\ninstance.printNumInstances()         # Fails in both 2.6 and 3.0\\nIf you’re able to use 3.0 and stick with calling self-less methods through classes only,\\nyou already have a static method feature. However, to allow self-less methods to be\\nStatic and Class Methods | 797', metadata={'source': 'python.pdf', 'page': 847}),\n",
       " Document(page_content='called through classes in 2.6 and through instances in both 2.6 and 3.0, you need to\\neither adopt other \\ndesigns or be able to somehow mark such methods as special. Let’s\\nlook at both options in turn.\\nStatic Method Alternatives\\nShort of marking a self-less method as special, there are a few different coding structures\\nthat can be tried. If you want to call functions that access class members without an\\ninstance, perhaps the simplest idea is to just make them simple functions outside the\\nclass, not class methods. This way, an instance isn’t expected in the call. For example,\\nthe following mutation of spam.py works the same in Python 3.0 and 2.6 (albeit dis-\\nplaying extra parentheses in 2.6 for its print statement):\\ndef printNumInstances():\\n    print(\"Number of instances created: \", Spam.numInstances)\\nclass Spam:\\n    numInstances = 0\\n    def __init__(self):\\n        Spam.numInstances = Spam.numInstances + 1\\n>>> import spam\\n>>> a = spam.Spam()\\n>>> b = spam.Spam()\\n>>> c = spam.Spam()\\n>>> spam.printNumInstances()           # But function may be too far removed\\nNumber of instances created:  3        # And cannot be changed via inheritance\\n>>> spam.Spam.numInstances\\n3\\nBecause the class name is accessible to the simple function as a global variable, this\\nworks fine. Also, note that the name of the function becomes global, but only to this\\nsingle module; it will not clash with names in other files of the program.\\nPrior to static methods in Python, this structure was the general prescription. Because\\nPython already provides modules as a namespace-partitioning tool, one could argue\\nthat there’s not typically any need to package functions in classes unless they implement\\nobject behavior. Simple functions within modules like the one here do much of what\\ninstance-less class methods could, and are already associated with the class because\\nthey live in the same module.\\nUnfortunately, this approach is still less than ideal. For one thing, it adds to this file’s\\nscope an extra name that is used only for processing a single class. For another, the\\nfunction is much less directly associated with the class; in fact, its definition could be\\nhundreds of lines away. Perhaps worse, simple functions like this cannot be customized\\nby inheritance, since they live outside a class’s namespace: subclasses cannot directly\\nreplace or extend such a function by redefining it.\\n798 | Chapter 31: \\u2002Advanced Class Topics', metadata={'source': 'python.pdf', 'page': 848}),\n",
       " Document(page_content='We might try to make this example work in a version-neutral way by using a normal\\nmethod and always calling it through (or with) an instance, as usual:\\nclass Spam:\\n    numInstances = 0\\n    def __init__(self):\\n        Spam.numInstances = Spam.numInstances + 1\\n    def printNumInstances(self):\\n        print(\"Number of instances created: \", Spam.numInstances)\\n>>> from spam import Spam\\n>>> a, b, c = Spam(), Spam(), Spam()\\n>>> a.printNumInstances()\\nNumber of instances created:  3\\n>>> Spam.printNumInstances(a)\\nNumber of instances created:  3\\n>>> Spam().printNumInstances()         # But fetching counter changes counter!\\nNumber of instances created:  4\\nUnfortunately, as mentioned \\nearlier, such an approach is completely unworkable if we\\ndon’t have an instance available, and making an instance changes the class data, as\\nillustrated in the last line here. A better solution would be to somehow mark a method\\ninside a class as never requiring an instance. The next section shows how.\\nUsing Static and Class Methods\\nToday, there is another option for coding simple functions associated with a class that\\nmay be called through either the class or its instances. As of Python 2.2, we can code\\nclasses with static and class methods, neither of which requires an instance argument\\nto be passed in when invoked. To designate such methods, classes call the built-in\\nfunctions staticmethod and classmethod, as hinted in the earlier discussion of new-style\\nclasses. Both mark a function object as special—i.e., as requiring no instance if static\\nand requiring a class argument if a class method. For example:\\nclass Methods:\\n    def imeth(self, x):            # Normal instance method: passed a self\\n        print(self, x)\\n    def smeth(x):                  # Static: no instance passed\\n        print(x)\\n    def cmeth(cls, x):             # Class: gets class, not instance\\n        print(cls, x)\\n    smeth = staticmethod(smeth)    # Make smeth a static method\\n    cmeth = classmethod(cmeth)     # Make cmeth a class method\\nNotice how the last two assignments in this code simply reassign the method names\\nsmeth and cmeth. Attributes are created and changed by any assignment in a class\\nstatement, so these final assignments simply overwrite the assignments made earlier by\\nthe defs.\\nStatic and Class Methods | 799', metadata={'source': 'python.pdf', 'page': 849}),\n",
       " Document(page_content=\"Technically, Python now supports three kinds of class-related methods: instance,\\nstatic, and class. \\nMoreover, Python 3.0 extends this model by also allowing simple\\nfunctions in a class to serve the role of static methods without extra protocol, when\\ncalled through a class.\\nInstance methods are the normal (and default) case that we’ve seen in this book. An\\ninstance method must always be called with an instance object. When you call it\\nthrough an instance, Python passes the instance to the first (leftmost) argument auto-\\nmatically; when you call it through a class, you must pass along the instance manually\\n(for simplicity, I’ve omitted some class imports in interactive sessions like this one):\\n>>> obj = Methods()                # Make an instance\\n>>> obj.imeth(1)                   # Normal method, call through instance\\n<__main__.Methods object...> 1     # Becomes imeth(obj, 1)\\n>>> Methods.imeth(obj, 2)          # Normal method, call through class\\n<__main__.Methods object...> 2     # Instance passed explicitly\\nBy contrast, static methods are called without an instance argument. Unlike simple\\nfunctions outside a class, their names are local to the scopes of the classes in which they\\nare defined, and they may be looked up by inheritance. Instance-less functions can be\\ncalled through a class normally in Python 3.0, but never by default in 2.6. Using the\\nstaticmethod built-in allows such methods to also be called through an instance in 3.0\\nand through both a class and an instance in Python 2.6 (the first of these works in 3.0\\nwithout staticmethod, but the second does not):\\n>>> Methods.smeth(3)               # Static method, call through class\\n3                                  # No instance passed or expected\\n>>> obj.smeth(4)                   # Static method, call through instance\\n4                                  # Instance not passed\\nClass methods  are similar, but Python automatically passes the class (not an instance)\\nin to a class method’s first (leftmost) argument, whether it is called through a class or\\nan instance:\\n>>> Methods.cmeth(5)               # Class method, call through class\\n<class '__main__.Methods'> 5       # Becomes cmeth(Methods, 5)\\n>>> obj.cmeth(6)                   # Class method, call through instance\\n<class '__main__.Methods'> 6       # Becomes cmeth(Methods, 6)\\nCounting Instances with Static Methods\\nNow, given these built-ins, here is the static method equivalent of this section’s\\ninstance-counting example—it marks the method as special, so it will never be passed\\nan instance automatically:\\n800 | Chapter 31: \\u2002Advanced Class Topics\", metadata={'source': 'python.pdf', 'page': 850}),\n",
       " Document(page_content='class Spam:\\n    numInstances = 0                         # Use static method for class data\\n    def __init__(self):\\n        Spam.numInstances += 1\\n    def printNumInstances():\\n        print(\"Number of instances:\", Spam.numInstances)\\n    printNumInstances = staticmethod(printNumInstances)\\nUsing the static \\nmethod built-in, our code now allows the self-less method to be called\\nthrough the class or any instance of it, in both Python 2.6 and 3.0:\\n>>> a = Spam()\\n>>> b = Spam()\\n>>> c = Spam()\\n>>> Spam.printNumInstances()                 # Call as simple function\\nNumber of instances: 3\\n>>> a.printNumInstances()                    # Instance argument not passed\\nNumber of instances: 3\\nCompared to simply moving printNumInstances outside the class, as prescribed earlier,\\nthis version requires an extra staticmethod call; however, it localizes the function name\\nin the class scope (so it won’t clash with other names in the module), moves the function\\ncode closer to where it is used (inside the class statement), and allows subclasses to\\ncustomize the static method with inheritance—a more convenient approach than im-\\nporting functions from the files in which superclasses are coded. The following subclass\\nand new testing session illustrate:\\nclass Sub(Spam):\\n    def printNumInstances():                 # Override a static method\\n        print(\"Extra stuff...\")              # But call back to original\\n        Spam.printNumInstances()\\n    printNumInstances = staticmethod(printNumInstances)\\n>>> a = Sub()\\n>>> b = Sub()\\n>>> a.printNumInstances()                    # Call from subclass instance\\nExtra stuff...\\nNumber of instances: 2\\n>>> Sub.printNumInstances()                  # Call from subclass itself\\nExtra stuff...\\nNumber of instances: 2\\n>>> Spam.printNumInstances()\\nNumber of instances: 2\\nMoreover, classes can inherit the static method without redefining it—it is run without\\nan instance, regardless of where it is defined in a class tree:\\n>>> class Other(Spam): pass                  # Inherit static method verbatim\\n>>> c = Other()\\n>>> c.printNumInstances()\\nNumber of instances: 3\\nStatic and Class Methods | 801', metadata={'source': 'python.pdf', 'page': 851}),\n",
       " Document(page_content='Counting Instances with Class Methods\\nInterestingly, a class method  \\ncan do similar work here—the following has the same\\nbehavior as the static method version listed earlier, but it uses a class method that\\nreceives the instance’s class in its first argument. Rather than hardcoding the class\\nname, the class method uses the automatically passed class object generically:\\nclass Spam:\\n    numInstances = 0                         # Use class method instead of static\\n    def __init__(self):\\n        Spam.numInstances += 1\\n    def printNumInstances(cls):\\n        print(\"Number of instances:\", cls.numInstances)\\n    printNumInstances = classmethod(printNumInstances)\\nThis class is used in the same way as the prior versions, but its printNumInstances\\nmethod receives the class, not the instance, when called from both the class and an\\ninstance:\\n>>> a, b = Spam(), Spam()\\n>>> a.printNumInstances()                    # Passes class to first argument\\nNumber of instances: 2\\n>>> Spam.printNumInstances()                 # Also passes class to first argument\\nNumber of instances: 2\\nWhen using class methods, though, keep in mind that they receive the most specific\\n(i.e., lowest) class of the call’s subject. This has some subtle implications when trying\\nto update class data through the passed-in class. For example, if in module test.py we\\nsubclass to customize as before, augment Spam.printNumInstances to also display its\\ncls argument, and start a new testing session:\\nclass Spam:\\n    numInstances = 0                         # Trace class passed in\\n    def __init__(self):\\n        Spam.numInstances += 1\\n    def printNumInstances(cls):\\n        print(\"Number of instances:\", cls.numInstances, cls)\\n    printNumInstances = classmethod(printNumInstances)\\nclass Sub(Spam):\\n    def printNumInstances(cls):              # Override a class method\\n        print(\"Extra stuff...\", cls)         # But call back to original\\n        Spam.printNumInstances()\\n    printNumInstances = classmethod(printNumInstances)\\nclass Other(Spam): pass                      # Inherit class method verbatim\\nthe lowest class is passed in whenever a class method is run, even for subclasses that\\nhave no class methods of their own:\\n>>> x, y = Sub(), Spam()\\n>>> x.printNumInstances()                    # Call from subclass instance\\nExtra stuff... <class \\'test.Sub\\'>\\nNumber of instances: 2 <class \\'test.Spam\\'>\\n802 | Chapter 31: \\u2002Advanced Class Topics', metadata={'source': 'python.pdf', 'page': 852}),\n",
       " Document(page_content=\">>> Sub.printNumInstances()                  # Call from subclass itself\\nExtra stuff... <class 'test.Sub'>\\nNumber of instances: 2 <class 'test.Spam'>\\n>>> y.printNumInstances()\\nNumber of instances: 2 <class 'test.Spam'>\\nIn the first \\ncall here, a class method call is made through an instance of the Sub subclass,\\nand Python passes the lowest class, Sub, to the class method. All is well in this case—\\nsince Sub’s redefinition of the method calls the Spam superclass’s version explicitly, the\\nsuperclass method in Spam receives itself in its first argument. But watch what happens\\nfor an object that simply inherits the class method:\\n>>> z = Other()\\n>>> z.printNumInstances()\\nNumber of instances: 3 <class 'test.Other'>\\nThis last call here passes Other to Spam’s class method. This works in this example\\nbecause fetching the counter finds it in Spam by inheritance. If this method tried to\\nassign to the passed class’s data, though, it would update Object, not Spam! In this\\nspecific case, Spam is probably better off hardcoding its own class name to update its\\ndata, rather than relying on the passed-in class argument.\\nCounting instances per class with class methods\\nIn fact, because class methods always receive the lowest class in an instance’s tree:\\n•Static methods and explicit class names may be a better solution for processing\\ndata local to a class.\\n•Class methods may be better suited to processing data that may differ for each class\\nin a hierarchy.\\nCode that needs to manage per-class instance counters, for example, might be best off\\nleveraging class methods. In the following, the top-level superclass uses a class method\\nto manage state information that varies for and is stored on each class in the tree—\\nsimilar in spirit to the way instance methods manage state information in class\\ninstances:\\nclass Spam:\\n    numInstances = 0\\n    def count(cls):                    # Per-class instance counters\\n        cls.numInstances += 1          # cls is lowest class above instance\\n    def __init__(self):\\n        self.count()                   # Passes self.__class__ to count\\n    count = classmethod(count)\\nclass Sub(Spam):\\n    numInstances = 0\\n    def __init__(self):                # Redefines __init__\\n        Spam.__init__(self)\\nclass Other(Spam):                     # Inherits __init__\\n    numInstances = 0\\nStatic and Class Methods | 803\", metadata={'source': 'python.pdf', 'page': 853}),\n",
       " Document(page_content='>>> x = Spam()\\n>>> y1, y2 = Sub(), Sub()\\n>>> z1, z2, z3 = Other(), Other(), Other()\\n>>> x.numInstances, y1.numInstances, z1.numInstances\\n(1, 2, 3)\\n>>> Spam.numInstances, Sub.numInstances, Other.numInstances\\n(1, 2, 3)\\nStatic and class \\nmethods have additional advanced roles, which we will finesse here;\\nsee other resources for more use cases. In recent Python versions, though, the static\\nand class method designations have become even simpler with the advent of function\\ndecoration syntax—a way to apply one function to another that has roles well beyond\\nthe static method use case that was its motivation. This syntax also allows us to augment\\nclasses in Python 2.6 and 3.0—to initialize data like the numInstances counter in the\\nlast example, for instance. The next section explains how.\\nDecorators and Metaclasses: Part 1\\nBecause the staticmethod call technique described in the prior section initially seemed\\nobscure to some users, a feature was eventually added to make the operation simpler.\\nFunction decorators  provide a way to specify special operation modes for functions, by\\nwrapping them in an extra layer of logic implemented as another function.\\nFunction decorators turn out to be general tools: they are useful for adding many types\\nof logic to functions besides the static method use case. For instance, they may be used\\nto augment functions with code that logs calls made to them, checks the types of passed\\narguments during debugging, and so on. In some ways, function decorators are similar\\nto the delegation design pattern we explored in Chapter 30 , but they are designed to\\naugment a specific function or method call, not an entire object interface.\\nPython provides some built-in function decorators for operations such as marking static\\nmethods, but programmers can also code arbitrary decorators of their own. Although\\nthey are not strictly tied to classes, user-defined function decorators often are coded as\\nclasses to save the original functions, along with other data, as state information.\\nThere’s also a more recent related extension available in Python 2.6 and 3.0: class dec-\\norators are directly tied to the class model, and their roles overlap with metaclasses.\\nFunction Decorator Basics\\nSyntactically, a function decorator is a sort of runtime declaration about the function\\nthat follows. A function decorator is coded on a line by itself just before the def state-\\nment that defines a function or method. It consists of the @ symbol, followed by what\\nwe call a metafunction—a function (or other callable object) that manages another\\nfunction. Static methods today, for example, may be coded with decorator syntax like\\nthis:\\n804 | Chapter 31: \\u2002Advanced Class Topics', metadata={'source': 'python.pdf', 'page': 854}),\n",
       " Document(page_content='class C:\\n   @staticmethod                                 # Decoration syntax\\n   def meth():\\n       ...\\nInternally, this syntax \\nhas the same effect as the following (passing the function through\\nthe decorator and assigning the result back to the original name):\\nclass C:\\n   def meth():\\n       ...\\n   meth = staticmethod(meth)                     # Rebind name\\nDecoration rebinds the method name to the decorator’s result. The net effect is that\\ncalling the method function’s name later actually triggers the result of its\\nstaticmethod decorator first. Because a decorator can return any sort of object, this\\nallows the decorator to insert a layer of logic to be run on every call. The decorator\\nfunction is free to return either the original function itself, or a new object that saves\\nthe original function passed to the decorator to be invoked indirectly after the extra\\nlogic layer runs.\\nWith this addition, here’s a better way to code our static method example from the\\nprior section in either Python 2.6 or 3.0 (the classmethod decorator is used the same\\nway):\\nclass Spam:\\n    numInstances = 0\\n    def __init__(self):\\n        Spam.numInstances = Spam.numInstances + 1\\n    @staticmethod\\n    def printNumInstances():\\n        print(\"Number of instances created: \", Spam.numInstances)\\na = Spam()\\nb = Spam()\\nc = Spam()\\nSpam.printNumInstances()      # Calls from both classes and instances work now!\\na.printNumInstances()         # Both print \"Number of instances created:  3\"\\nKeep in mind that staticmethod is still a built-in function; it may be used in decoration\\nsyntax, just because it takes a function as argument and returns a callable. In fact, any\\nsuch function can be used in this way—even user-defined functions we code ourselves,\\nas the next section explains.\\nA First Function Decorator Example\\nAlthough Python provides a handful of built-in functions that can be used as decorators,\\nwe can also write custom decorators of our own. Because of their wide utility, we’re\\ngoing to devote an entire chapter to coding decorators in the next part of this book. As\\na quick example, though, let’s look at a simple user-defined decorator at work.\\nDecorators and Metaclasses: Part 1 | 805', metadata={'source': 'python.pdf', 'page': 855}),\n",
       " Document(page_content=\"Recall from Chapter 29  that the __call__  operator overloading method implements a\\nfunction-call interface for class instances. The following code uses this to define a class\\nthat saves the decorated function in the instance and catches calls to the original name.\\nBecause this is a class, it also has state information (a counter of calls made):\\nclass tracer:\\n    def __init__(self, func):\\n        self.calls = 0\\n        self.func  = func\\n    def __call__(self, *args):\\n        self.calls += 1\\n        print('call %s to %s' % (self.calls, self.func.__name__))\\n        self.func(*args)\\n@tracer                       # Same as spam = tracer(spam)\\ndef spam(a, b, c):            # Wrap spam in a decorator object\\n    print(a, b, c)\\nspam(1, 2, 3)                 # Really calls the tracer wrapper object\\nspam('a', 'b', 'c')           # Invokes __call__ in class\\nspam(4, 5, 6)                 # __call__ adds logic and runs original object\\nBecause the spam function is run through the tracer decorator, when the original\\nspam name is called it actually triggers the __call__ method in the class. This method\\ncounts and logs the call, and then dispatches it to the original wrapped function. Note\\nhow the *name argument syntax is used to pack and unpack the passed-in arguments;\\nbecause of this, this decorator can be used to wrap any function with any number of\\npositional arguments.\\nThe net effect, again, is to add a layer of logic to the original spam function. Here is the\\nscript’s output—the first line comes from the tracer class, and the second comes from\\nthe spam function:\\ncall 1 to spam\\n1 2 3\\ncall 2 to spam\\na b c\\ncall 3 to spam\\n4 5 6\\nTrace through this example’s code for more insight. As it is, this decorator works for\\nany function that takes positional arguments, but it does not return the decorated\\nfunction’s result, doesn’t handle keyword arguments, and cannot decorate class\\nmethod functions (in short, for methods its __call__ would be passed a tracer instance\\nonly). As we’ll see in Part VIII , there are a variety of ways to code function decorators,\\nincluding nested def statements; some of the alternatives are better suited to methods\\nthan the version shown here.\\n806 | Chapter 31: \\u2002Advanced Class Topics\", metadata={'source': 'python.pdf', 'page': 856}),\n",
       " Document(page_content='Class Decorators and Metaclasses\\nFunction decorators turned out \\nto be so useful that Python 2.6 and 3.0 expanded the\\nmodel, allowing decorators to be applied to classes as well as functions. In short, class\\ndecorators are similar to function decorators, but they are run at the end of a class\\nstatement to rebind a class name to a callable. As such, they can be used to either\\nmanage classes just after they are created, or insert a layer of wrapper logic to manage\\ninstances when they are later created. Symbolically, the code structure:\\ndef decorator(aClass): ...\\n@decorator\\nclass C: ...\\nis mapped to the following equivalent:\\ndef decorator(aClass): ...\\nclass C: ...\\nC = decorator(C)\\nThe class decorator is free to augment the class itself, or return an object that intercepts\\nlater instance construction calls. For instance, in the example in the section “Counting\\ninstances per class with class methods” on page 803, we could use this hook to auto-\\nmatically augment the classes with instance counters and any other data required:\\ndef count(aClass):\\n    aClass.numInstances = 0\\n    return aClass                  # Return class itself, instead of a wrapper\\n@count\\nclass Spam: ...                    # Same as Spam = count(Spam)\\n@count\\nclass Sub(Spam): ...               # numInstances = 0 not needed here\\n@count\\nclass Other(Spam): ...\\nMetaclasses are a similarly advanced class-based tool whose roles often intersect with\\nthose of class decorators. They provide an alternate model, which routes the creation\\nof a class object to a subclass of the top-level type class, at the conclusion of a class\\nstatement:\\nclass Meta(type):\\n    def __new__(meta, classname, supers, classdict): ...\\nclass C(metaclass=Meta): ...\\nDecorators and Metaclasses: Part 1 | 807', metadata={'source': 'python.pdf', 'page': 857}),\n",
       " Document(page_content='In Python 2.6, the effect is the same, but the coding differs—use a class attribute instead\\nof a keyword argument in the class header:\\nclass C:\\n    __metaclass__ = Meta\\n    ...\\nThe metaclass generally redefines the __new__ or __init__ method of the type class, in\\norder to assume \\ncontrol of the creation or initialization of a new class object. The net\\neffect, as with class decorators, is to define code to be run automatically at class creation\\ntime. Both schemes are free to augment a class or return an arbitrary object to replace\\nit—a protocol with almost limitless class-based possibilities.\\nFor More Details\\nNaturally, there’s much more to the decorator and metaclass stories than I’ve shown\\nhere. Although they are a general mechanism, decorators and metaclasses are advanced\\nfeatures of interest primarily to tool writers, not application programmers, so we’ll defer\\nadditional coverage until the final part of this book:\\n•Chapter 37 shows how to code properties using function decorator syntax.\\n•Chapter 38 has much more on decorators, including more comprehensive\\nexamples.\\n•Chapter 39  covers metaclasses, and more on the class and instance management\\nstory.\\nAlthough these chapters cover advanced topics, they’ll also provide us with a chance\\nto see Python at work in more substantial examples than much of the rest of the book\\nwas able to provide.\\nClass Gotchas\\nMost class issues can be boiled down to namespace issues (which makes sense, given\\nthat classes are just namespaces with a few extra tricks). Some of the topics we’ll cover\\nin this section are more like case studies of advanced class usage than real problems,\\nand one or two of these gotchas have been eased by recent Python releases.\\nChanging Class Attributes Can Have Side Effects\\nTheoretically speaking, classes (and class instances) are mutable objects. Like built-in\\nlists and dictionaries, they can be changed in-place by assigning to their attributes—\\nand as with lists and dictionaries, this means that changing a class or instance object\\nmay impact multiple references to it.\\n808 | Chapter 31: \\u2002Advanced Class Topics', metadata={'source': 'python.pdf', 'page': 858}),\n",
       " Document(page_content=\"That’s usually what we want (and is how objects change their state in general), but\\nawareness of this \\nissue becomes especially critical when changing class attributes. Be-\\ncause all instances generated from a class share the class’s namespace, any changes at\\nthe class level are reflected in all instances, unless they have their own versions of the\\nchanged class attributes.\\nBecause classes, modules, and instances are all just objects with attribute namespaces,\\nyou can normally change their attributes at runtime by assignments. Consider the fol-\\nlowing class. Inside the class body, the assignment to the name a generates an attribute\\nX.a, which lives in the class object at runtime and will be inherited by all of X’s instances:\\n>>> class X:\\n...     a = 1       # Class attribute\\n...\\n>>> I = X()\\n>>> I.a             # Inherited by instance\\n1\\n>>> X.a\\n1\\nSo far, so good—this is the normal case. But notice what happens when we change the\\nclass attribute dynamically outside the class statement: it also changes the attribute in\\nevery object that inherits from the class. Moreover, new instances created from the class\\nduring this session or program run also get the dynamically set value, regardless of what\\nthe class’s source code says:\\n>>> X.a = 2         # May change more than X\\n>>> I.a             # I changes too\\n2\\n>>> J = X()         # J inherits from X's runtime values\\n>>> J.a             # (but assigning to J.a changes a in J, not X or I)\\n2\\nIs this a useful feature or a dangerous trap? You be the judge. As we learned in Chap-\\nter 26 , you can actually get work done by changing class attributes without ever making\\na single instance; this technique can simulate the use of “records” or “structs” in other\\nlanguages. As a refresher, consider the following unusual but legal Python program:\\nclass X: pass                       # Make a few attribute namespaces\\nclass Y: pass\\nX.a = 1                             # Use class attributes as variables\\nX.b = 2                             # No instances anywhere to be found\\nX.c = 3\\nY.a = X.a + X.b + X.c\\nfor X.i in range(Y.a): print(X.i)   # Prints 0..5\\nHere, the classes X and Y work like “fileless” modules—namespaces for storing variables\\nwe don’t want to clash. This is a perfectly legal Python programming trick, but it’s less\\nappropriate when applied to classes written by others; you can’t always be sure that\\nclass attributes you change aren’t critical to the class’s internal behavior. If you’re out\\nClass Gotchas | 809\", metadata={'source': 'python.pdf', 'page': 859}),\n",
       " Document(page_content=\"to simulate a C struct, you may be better off changing instances than classes, as that\\nway only one object is affected:\\nclass Record: pass\\nX = Record()\\nX.name = 'bob'\\nX.job  = 'Pizza maker'\\nChanging Mutable Class Attributes Can Have Side Effects, Too\\nThis gotcha is \\nreally an extension of the prior. Because class attributes are shared by all\\ninstances, if a class attribute references a mutable object, changing that object in-place\\nfrom any instance impacts all instances at once:\\n>>> class C:\\n...     shared = []                 # Class attribute\\n...     def __init__(self):\\n...         self.perobj = []        # Instance attribute\\n...\\n>>> x = C()                         # Two instances\\n>>> y = C()                         # Implicitly share class attrs\\n>>> y.shared, y.perobj\\n([], [])\\n>>> x.shared.append('spam')         # Impacts y's view too!\\n>>> x.perobj.append('spam')         # Impacts x's data only\\n>>> x.shared, x.perobj\\n(['spam'], ['spam'])\\n>>> y.shared, y.perobj              # y sees change made through x\\n(['spam'], [])\\n>>> C.shared                        # Stored on class and shared\\n['spam']\\nThis effect is no different than many we’ve seen in this book already: mutable objects\\nare shared by simple variables, globals are shared by functions, module-level objects\\nare shared by multiple importers, and mutable function arguments are shared by the\\ncaller and the callee. All of these are cases of general behavior—multiple references to\\na mutable object—and all are impacted if the shared object is changed in-place from\\nany reference. Here, this occurs in class attributes shared by all instances via inheri-\\ntance, but it’s the same phenomenon at work. It may be made more subtle by the\\ndifferent behavior of assignments to instance attributes themselves:\\nx.shared.append('spam')    # Changes shared object attached to class in-place\\nx.shared = 'spam'          # Changed or creates instance attribute attached to x\\nbut again, this is not a problem, it’s just something to be aware of; shared mutable class\\nattributes can have many valid uses in Python programs.\\n810 | Chapter 31: \\u2002Advanced Class Topics\", metadata={'source': 'python.pdf', 'page': 860}),\n",
       " Document(page_content=\"Multiple Inheritance: Order Matters\\nThis may be obvious \\nby now, but it’s worth underscoring: if you use multiple inheri-\\ntance, the order in which superclasses are listed in the class statement header can be\\ncritical. Python always searches superclasses from left to right, according to their order\\nin the header line.\\nFor instance, in the multiple inheritance example we studied in Chapter 30 , suppose\\nthat the Super class implemented a __str__ method, too:\\nclass ListTree:\\n    def __str__(self): ...\\nclass Super:\\n    def __str__(self): ...\\nclass Sub(ListTree, Super):    # Get ListTree's __str__ by listing it first\\nx = Sub()                      # Inheritance searches ListTree before Super\\nWhich class would we inherit it from— ListTree or Super? As inheritance searches pro-\\nceed from left to right, we would get the method from whichever class is listed first\\n(leftmost) in Sub’s class header. Presumably, we would list ListTree first because its\\nwhole purpose is its custom __str__ (indeed, we had to do this in Chapter 30  when\\nmixing this class with a tkinter.Button that had a __str__ of its own).\\nBut now suppose Super and ListTree have their own versions of other same-named\\nattributes, too. If we want one name from Super and another from ListTree, the order\\nin which we list them in the class header won’t help—we will have to override inher-\\nitance by manually assigning to the attribute name in the Sub class:\\nclass ListTree:\\n    def __str__(self): ...\\n    def other(self): ...\\nclass Super:\\n    def __str__(self): ...\\n    def other(self): ...\\nclass Sub(ListTree, Super):    # Get ListTree's __str__ by listing it first\\n    other = Super.other        # But explicitly pick Super's version of other\\n    def __init__(self):\\n        ...\\nx = Sub()                      # Inheritance searches Sub before ListTree/Super\\nHere, the assignment to other within the Sub class creates Sub.other—a reference back\\nto the Super.other object. Because it is lower in the tree, Sub.other effectively hides\\nListTree.other, the attribute that the inheritance search would normally find. Simi-\\nlarly, if we listed Super first in the class header to pick up its other, we would need to\\nselect ListTree’s method explicitly:\\nClass Gotchas | 811\", metadata={'source': 'python.pdf', 'page': 861}),\n",
       " Document(page_content=\"class Sub(Super, ListTree):               # Get Super's other by order\\n    __str__ = Lister.__str__              # Explicitly pick Lister.__str__\\nMultiple inheritance is \\nan advanced tool. Even if you understood the last paragraph,\\nit’s still a good idea to use it sparingly and carefully. Otherwise, the meaning of a name\\nmay come to depend on the order in which classes are mixed in an arbitrarily\\nfar-removed subclass. (For another example of the technique shown here in action, see\\nthe discussion of explicit conflict resolution in “The “New-Style” Class\\nModel” on page 777.)\\nAs a rule of thumb, multiple inheritance works best when your mix-in classes are as\\nself-contained as possible—because they may be used in a variety of contexts, they\\nshould not make assumptions about names related to other classes in a tree. The\\npseudoprivate __X attributes feature we studied in Chapter 30  can help by localizing\\nnames that a class relies on owning and limiting the names that your mix-in classes add\\nto the mix. In this example, for instance, if ListTree only means to export its custom\\n__str__, it can name its other method __other to avoid clashing with like-named classes\\nin the tree.\\nMethods, Classes, and Nested Scopes\\nThis gotcha went away in Python 2.2 with the introduction of nested function scopes,\\nbut I’ve retained it here for historical perspective, for readers working with older Python\\nreleases, and because it demonstrates what happens to the new nested function scope\\nrules when one layer of the nesting is a class.\\nClasses introduce local scopes, just as functions do, so the same sorts of scope behavior\\ncan happen in a class statement body. Moreover, methods are further nested functions,\\nso the same issues apply. Confusion seems to be especially common when classes are\\nnested.\\nIn the following example (the file nester.py), the generate function returns an instance\\nof the nested Spam class. Within its code, the class name Spam is assigned in the\\ngenerate function’s local scope. However, in versions of Python prior to 2.2, within the\\nclass’s method function the class name Spam is not visible— method has access only to its\\nown local scope, the module surrounding generate, and built-in names:\\ndef generate():                  # Fails prior to Python 2.2, works later\\n    class Spam:\\n        count = 1\\n        def method(self):        # Name Spam not visible:\\n            print(Spam.count)    # not local (def), global (module), built-in\\n    return Spam()\\ngenerate().method()\\nC:\\\\python\\\\examples> python nester.py\\n...error text omitted...\\n812 | Chapter 31: \\u2002Advanced Class Topics\", metadata={'source': 'python.pdf', 'page': 862}),\n",
       " Document(page_content='    Print(Spam.count)            # Not local (def), global (module), built-in\\nNameError: Spam\\nThis example works \\nin Python 2.2 and later because the local scopes of all enclosing\\nfunction defs are automatically visible to nested defs (including nested method defs,\\nas in this example). However, it doesn’t work before 2.2 (we’ll look at some possible\\nsolutions momentarily).\\nNote that even in 2.2 and later, method defs cannot see the local scope of the enclosing\\nclass; they can only see the local scopes of enclosing defs. That’s why methods must\\ngo through the self instance or the class name to reference methods and other attributes\\ndefined in the enclosing class statement. For example, code in the method must use\\nself.count or Spam.count, not just count.\\nIf you’re using a release prior to 2.2, there are a variety of ways to get the preceding\\nexample to work. One of the simplest is to move the name Spam out to the enclosing\\nmodule’s scope with a global declaration. Because method sees global names in the\\nenclosing module, references to Spam will work:\\ndef generate():\\n    global Spam                 # Force Spam to module scope\\n    class Spam:\\n        count = 1\\n        def method(self):\\n            print(Spam.count)   # Works: in global (enclosing module)\\n    return Spam()\\ngenerate().method()             # Prints 1\\nA better alternative would be to restructure the code such that the class Spam is defined\\nat the top level of the module by virtue of its nesting level, rather than using global\\ndeclarations. The nested method function and the top-level generate will then find\\nSpam in their global scopes:\\ndef generate():\\n    return Spam()\\nclass Spam:                    # Define at top level of module\\n    count = 1\\n    def method(self):\\n        print(Spam.count)      # Works: in global (enclosing module)\\ngenerate().method()\\nIn fact, this approach is recommended for all Python releases—code tends to be simpler\\nin general if you avoid nesting classes and functions.\\nIf you want to get complicated and tricky, you can also get rid of the Spam reference in\\nmethod altogether by using the special __class__ attribute, which returns an instance’s\\nclass object:\\ndef generate():\\n    class Spam:\\nClass Gotchas | 813', metadata={'source': 'python.pdf', 'page': 863}),\n",
       " Document(page_content='        count = 1\\n        def method(self):\\n            print(self.__class__.count)      # Works: qualify to get class\\n    return Spam()\\ngenerate().method()\\nDelegation-Based Classes in 3.0: __getattr__ and built-ins\\nWe met this \\nissue briefly in our class tutorial in Chapter 27 and our delegation coverage\\nin Chapter 30: classes that use the __getattr__ operator overloading method to delegate\\nattribute fetches to wrapped objects will fail in Python 3.0 unless operator overloading\\nmethods are redefined in the wrapper class. In Python 3.0 (and 2.6, when new-style\\nclasses are used), the names of operator overloading methods implicitly fetched by\\nbuilt-in operations are not routed through generic attribute-interception methods. The\\n__str__ method used by printing, for example, never invokes __getattr__. Instead,\\nPython 3.0 looks up such names in classes and skips the normal runtime instance\\nlookup mechanism entirely. To work around this, such methods must be redefined in\\nwrapper classes, either by hand, with tools, or by definition in superclasses. We’ll revisit\\nthis gotcha in Chapters 37 and 38.\\n“Overwrapping-itis”\\nWhen used well, the code reuse features of OOP make it excel at cutting development\\ntime. Sometimes, though, OOP’s abstraction potential can be abused to the point of\\nmaking code difficult to understand. If classes are layered too deeply, code can become\\nobscure; you may have to search through many classes to discover what an operation\\ndoes.\\nFor example, I once worked in a C++ shop with thousands of classes (some machine-\\ngenerated), and up to 15 levels of inheritance. Deciphering method calls in such a\\ncomplex system was often a monumental task: multiple classes had to be consulted for\\neven the most basic of operations. In fact, the logic of the system was so deeply wrapped\\nthat understanding a piece of code in some cases required days of wading through\\nrelated files.\\nThe most general rule of thumb of Python programming applies here, too: don’t make\\nthings complicated unless they truly must be. Wrapping your code in multiple layers\\nof classes to the point of incomprehensibility is always a bad idea. Abstraction is the\\nbasis of polymorphism and encapsulation, and it can be a very effective tool when used\\nwell. However, you’ll simplify debugging and aid maintainability if you make your class\\ninterfaces intuitive, avoid making your code overly abstract, and keep your class hier-\\narchies short and flat unless there is a good reason to do otherwise.\\n814 | Chapter 31: \\u2002Advanced Class Topics', metadata={'source': 'python.pdf', 'page': 864}),\n",
       " Document(page_content='Chapter Summary\\nThis chapter presented \\na handful of advanced class-related topics, including subclass-\\ning built-in types, new-style classes, static methods, and decorators. Most of these are\\noptional extensions to the OOP model in Python, but they may become more useful\\nas you start writing larger object-oriented programs. As mentioned earlier, our discus-\\nsion of some of the more advanced class tools continues in the final part of this book;\\nbe sure to look ahead if you need more details on properties, descriptors, decorators,\\nand metaclasses.\\nThis is the end of the class part of this book, so you’ll find the usual lab exercises at the\\nend of the chapter—be sure to work through them to get some practice coding real\\nclasses. In the next chapter, we’ll begin our look at our last core language topic, ex-\\nceptions. Exceptions are Python’s mechanism for communicating errors and other\\nconditions to your code. This is a relatively lightweight topic, but I’ve saved it for last\\nbecause exceptions are supposed to be coded as classes today. Before we tackle that\\nfinal core subject, though, take a look at this chapter’s quiz and the lab exercises.\\nTest Your Knowledge: Quiz\\n1. Name two ways to extend a built-in object type.\\n2.What are function decorators used for?\\n3.\\nHow do you code a new-style class?\\n4. How are new-style and classic classes different?\\n5. How are normal and static methods different?\\n6. How long should you wait before lobbing a “Holy Hand Grenade”?\\nTest Your Knowledge: Answers\\n1. You can embed a built-in object in a wrapper class, or subclass the built-in type\\ndirectly. The latter approach tends to be simpler, as most original behavior is au-\\ntomatically inherited.\\n2. Function decorators are generally used to add to an existing function a layer of\\nlogic that is run each time the function is called. They can be used to log or count\\ncalls to a function, check its argument types, and so on. They are also used to\\n“declare” static methods—simple functions in a class that are not passed an in-\\nstance when called.\\nTest Your Knowledge: Answers | 815', metadata={'source': 'python.pdf', 'page': 865}),\n",
       " Document(page_content='3. New-style classes are coded by inheriting from the object built-in class (or any\\nother built-in type). In Python 3.0, all classes are new-style automatically, so this\\nderivation is not required; in 2.6, classes with this derivation are new-style and\\nthose without it are “classic.”\\n4. New-style classes search the diamond pattern of multiple inheritance trees differ-\\nently—they essentially search breadth-first (across), instead of depth-first (up).\\nNew-style classes also change the result of the type built-in for instances and\\nclasses, do not run generic attribute fetch methods such as __getattr__ for built-\\nin operation methods, and support a set of advanced extra tools including prop-\\nerties, descriptors, and __slots__ instance attribute lists.\\n5. Normal (instance) methods receive a self argument (the implied instance), but\\nstatic methods do not. Static methods are simple functions nested in class objects.\\nTo make a method static, it must either be run through a special built-in function\\nor be decorated with decorator syntax. Python 3.0 allows simple functions in a\\nclass to be called through the class without this step, but calls through instances\\nstill require static method declaration.\\n6. Three seconds. (Or, more accurately: “And the Lord spake, saying, ‘First shalt thou\\ntake out the Holy Pin. Then, shalt thou count to three, no more, no less. Three\\nshalt be the number thou shalt count, and the number of the counting shall be\\nthree. Four shalt thou not count, nor either count thou two, excepting that thou\\nthen proceed to three. Five is right out. Once the number three, being the third\\nnumber, be reached, then lobbest thou thy Holy Hand Grenade of Antioch towards\\nthy foe, who, being naughty in my sight, shall snuff it.’”)*\\nTest Your Knowledge: Part VI Exercises\\nThese exercises ask you to write a few classes and experiment with some existing code.\\nOf course, the problem with existing code is that it must be existing. To work with the\\nset class in exercise 5, either pull the class source code off this book’s website  (see the\\nPreface for a pointer) or type it up by hand (it’s fairly brief). These programs are starting\\nto get more sophisticated, so be sure to check the solutions at the end of the book for\\npointers. You’ll find them in Appendix B, under “Part VI, Classes and\\nOOP” on page 1122.\\n1.Inheritance. Write a class called Adder that exports a method add(self, x, y) that\\nprints a “Not Implemented” message. Then, define two subclasses of Adder that\\nimplement the add method:\\nListAdder\\nWith an add method that returns the concatenation of its two list arguments\\n* This quote is from Monty Python and the Holy Grail.\\n816 | Chapter 31: \\u2002Advanced Class Topics', metadata={'source': 'python.pdf', 'page': 866}),\n",
       " Document(page_content='DictAdder\\nWith an add \\nmethod that returns a new dictionary containing the items in both\\nits two dictionary arguments (any definition of addition will do)\\nExperiment by making instances of all three of your classes interactively and calling\\ntheir add methods.\\nNow, extend your Adder superclass to save an object in the instance with a con-\\nstructor (e.g., assign self.data a list or a dictionary), and overload the + operator\\nwith an __add__ method to automatically dispatch to your add methods (e.g., X +\\nY triggers X.add(X.data,Y)). Where is the best place to put the constructors and\\noperator overloading methods (i.e., in which classes)? What sorts of objects can\\nyou add to your class instances?\\nIn practice, you might find it easier to code your add methods to accept just one\\nreal argument (e.g., add(self,y)), and add that one argument to the instance’s\\ncurrent data (e.g., self.data + y). Does this make more sense than passing two\\narguments to add? Would you say this makes your classes more “object-oriented”?\\n2.Operator overloading . Write a class called Mylist that shadows (“wraps”) a Python\\nlist: it should overload most list operators and operations, including +, indexing,\\niteration, slicing, and list methods such as append and sort. See the Python reference\\nmanual for a list of all possible methods to support. Also, provide a constructor\\nfor your class that takes an existing list (or a Mylist instance) and copies its com-\\nponents into an instance member. Experiment with your class interactively. Things\\nto explore:\\na. Why is copying the initial value important here?\\nb. Can you use an empty slice (e.g., start[:]) to copy the initial value if it’s a\\nMylist instance?\\nc. Is there a general way to route list method calls to the wrapped list?\\nd. Can you add a Mylist and a regular list? How about a list and a Mylist instance?\\ne. What type of object should operations like + and slicing return? What about\\nindexing operations?\\nf. If you are working with a more recent Python release (version 2.2 or later), you\\nmay implement this sort of wrapper class by embedding a real list in a stand-\\nalone class, or by extending the built-in list type with a subclass. Which is\\neasier, and why?\\n3.Subclassing. Make a subclass of Mylist from exercise 2 called MylistSub, which\\nextends Mylist to print a message to stdout before each overloaded operation is\\ncalled and counts the number of calls. MylistSub should inherit basic method be-\\nhavior from Mylist. Adding a sequence to a MylistSub should print a message,\\nincrement the counter for + calls, and perform the superclass’s method. Also, in-\\ntroduce a new method that prints the operation counters to stdout, and experiment\\nwith your class interactively. Do your counters count calls per instance, or per class\\n(for all instances of the class)? How would you program the other option)?\\nTest Your Knowledge: Part VI Exercises | 817', metadata={'source': 'python.pdf', 'page': 867}),\n",
       " Document(page_content='(Hint: it depends on which object the count members are assigned to: class mem-\\nbers are shared by instances, but self\\n members are per-instance data.)\\n4.Metaclass methods. Write a class called Meta with methods that intercept every\\nattribute qualification (both fetches and assignments), and print messages listing\\ntheir arguments to stdout. Create a Meta instance, and experiment with qualifying\\nit interactively. What happens when you try to use the instance in expressions? Try\\nadding, indexing, and slicing the instance of your class. (Note: a fully generic ap-\\nproach based upon __getattr__ will work in 2.6 but not 3.0, for reasons noted in\\nChapter 30 and restated in the solution to this exercise.)\\n5.Set objects . Experiment with the set class described in “Extending Types by Em-\\nbedding” on page 774. Run commands to do the following sorts of operations:\\na. Create two sets of integers, and compute their intersection and union by using\\n& and | operator expressions.\\nb. Create a set from a string, and experiment with indexing your set. Which\\nmethods in the class are called?\\nc. Try iterating through the items in your string set using a for loop. Which\\nmethods run this time?\\nd. Try computing the intersection and union of your string set and a simple Py-\\nthon string. Does it work?\\ne. Now, extend your set by subclassing to handle arbitrarily many operands using\\nthe *args argument form. (Hint: see the function versions of these algorithms\\nin Chapter 18 .) Compute intersections and unions of multiple operands with\\nyour set subclass. How can you intersect three or more sets, given that & has\\nonly two sides?\\nf. How would you go about emulating other list operations in the set class? (Hint:\\n__add__ can catch concatenation, and __getattr__ can pass most list method\\ncalls to the wrapped list.)\\n6.Class tree links . In “Namespaces: The Whole Story” on page 693 in Chapter 28\\nand in “Multiple Inheritance: “Mix-in” Classes” on page 756 in Chapter 30 , I\\nmentioned that classes have a __bases__ attribute that returns a tuple of their su-\\nperclass objects (the ones listed in parentheses in the class header). Use\\n__bases__ to extend the lister.py mix-in classes we wrote in Chapter 30 so that they\\nprint the names of the immediate superclasses of the instance’s class. When you’re\\ndone, the first line of the string representation should look like this (your address\\nmay vary):\\n<Instance of Sub(Super, Lister), address 7841200:\\n7.Composition. Simulate a fast-food ordering scenario by defining four classes:\\nLunch\\nA container and controller class\\n818 | Chapter 31: \\u2002Advanced Class Topics', metadata={'source': 'python.pdf', 'page': 868}),\n",
       " Document(page_content='Customer\\nThe actor who buys food\\nEmployee\\nThe actor from whom a customer orders\\nFood\\nWhat the customer buys\\nTo get you started, here are the classes and methods you’ll be defining:\\nclass Lunch:\\n    def __init__(self)               # Make/embed Customer and Employee\\n    def order(self, foodName)        # Start a Customer order simulation\\n    def result(self)                 # Ask the Customer what Food it has\\nclass Customer:\\n    def __init__(self)                        # Initialize my food to None\\n    def placeOrder(self, foodName, employee)  # Place order with an Employee\\n    def printFood(self)                       # Print the name of my food\\nclass Employee:\\n    def takeOrder(self, foodName)    # Return a Food, with requested name\\nclass Food:\\n    def __init__(self, name)         # Store food name\\nThe order simulation should work as follows:\\na. The Lunch class’s constructor \\nshould make and embed an instance of\\nCustomer and an instance of Employee, and it should export a method called\\norder. When called, this order method should ask the Customer to place an\\norder by calling its placeOrder method. The Customer’s placeOrder method\\nshould in turn ask the Employee object for a new Food object by calling\\nEmployee’s takeOrder method.\\nb.Food objects should store a food name string (e.g., “burritos”), passed down\\nfrom Lunch.order, to Customer.placeOrder, to Employee.takeOrder, and finally\\nto Food’s constructor. The top-level Lunch class should also export a method\\ncalled result, which asks the customer to print the name of the food it received\\nfrom the Employee via the order (this can be used to test your simulation).\\nNote that Lunch needs to pass either the Employee or itself to the Customer to allow\\nthe Customer to call Employee methods.\\nExperiment with your classes interactively by importing the Lunch class, calling its\\norder method to run an interaction, and then calling its result method to verify\\nthat the Customer got what he or she ordered. If you prefer, you can also simply\\ncode test cases as self-test code in the file where your classes are defined, using the\\nmodule __name__ trick of Chapter 24 . In this simulation, the Customer is the active\\nagent; how would your classes change if Employee were the object that initiated\\ncustomer/employee interaction instead?\\nTest Your Knowledge: Part VI Exercises | 819', metadata={'source': 'python.pdf', 'page': 869}),\n",
       " Document(page_content='Figure 31-1. A zoo hierarchy composed of classes linked into a tree to be searched by attribute\\ninheritance. Animal has \\na common “reply” method, but each class may have its own custom “speak”\\nmethod called by “reply”.\\n3.Zoo animal hierarchy. Consider the class tree shown in Figure 31-1.\\nCode a set of six class statements to model this taxonomy with Python inheritance.\\nThen, add a speak method to each of your classes that prints a unique message,\\nand a reply method in your top-level Animal superclass that simply calls\\nself.speak to invoke the category-specific message printer in a subclass below (this\\nwill kick off an independent inheritance search from self). Finally, remove the\\nspeak method from your Hacker class so that it picks up the default above it. When\\nyou’re finished, your classes should work this way:\\n% python\\n>>> from zoo import Cat, Hacker\\n>>> spot = Cat()\\n>>> spot.reply()                   # Animal.reply; calls Cat.speak\\nmeow\\n>>> data = Hacker()                # Animal.reply; calls Primate.speak\\n>>> data.reply()\\nHello world!\\n4.The Dead Parrot Sketch. Consider the object embedding structure captured in\\nFigure 31-2.\\nCode a set of Python classes to implement this structure with composition. Code\\nyour Scene object to define an action method, and embed instances of the Customer,\\nClerk, and Parrot classes (each of which should define a line method that prints\\na unique message). The embedded objects may either inherit from a common su-\\nperclass that defines line and simply provide message text, or define line them-\\nselves. In the end, your classes should operate like this:\\n% python\\n>>> import parrot\\n>>> parrot.Scene().action()        # Activate nested objects\\ncustomer: \"that\\'s one ex-bird!\"\\n820 | Chapter 31: \\u2002Advanced Class Topics', metadata={'source': 'python.pdf', 'page': 870}),\n",
       " Document(page_content='clerk: \"no it isn\\'t...\"\\nparrot: None\\nFigure 31-2. A scene composite with a controller class (Scene) that embeds and directs instances of\\nthree other classes \\n(Customer, Clerk, Parrot). The embedded instance’s classes may also participate\\nin an inheritance hierarchy; composition and inheritance are often equally useful ways to structure\\nclasses for code reuse.\\nWhy You Will Care: OOP by the Masters\\nWhen I teach \\nPython classes, I invariably find that about halfway through the class,\\npeople who have used OOP in the past are following along intensely, while people who\\nhave not are beginning to glaze over (or nod off completely). The point behind the\\ntechnology just isn’t apparent.\\nIn a book like this, I have the luxury of including material like the new Big Picture\\noverview in Chapter 25 , and the gradual tutorial of Chapter 27 —in fact, you should\\nprobably review that section if you’re starting to feel like OOP is just some computer\\nscience mumbo-jumbo.\\nIn real classes, however, to help get the newcomers on board (and keep them awake),\\nI have been known to stop and ask the experts in the audience why they use OOP. The\\nanswers they’ve given might help shed some light on the purpose of OOP, if you’re new\\nto the subject.\\nHere, then, with only a few embellishments, are the most common reasons to use OOP,\\nas cited by my students over the years:\\nCode reuse\\nThis one’s easy (and is the main reason for using OOP). By supporting inheritance,\\nclasses allow you to program by customization instead of starting each project from\\nscratch.\\nEncapsulation\\nWrapping up implementation details behind object interfaces insulates users of a\\nclass from code changes.\\nStructure\\nClasses provide new local scopes, which minimizes name clashes. They also pro-\\nvide a natural place to write and look for implementation code, and to manage\\nobject state.\\nTest Your Knowledge: Part VI Exercises | 821', metadata={'source': 'python.pdf', 'page': 871}),\n",
       " Document(page_content='Maintenance\\nClasses naturally promote \\ncode factoring, which allows us to minimize redun-\\ndancy. Thanks both to the structure and code reuse support of classes, usually only\\none copy of the code needs to be changed.\\nConsistency\\nClasses and inheritance allow you to implement common interfaces, and hence\\ncreate a common look and feel in your code; this eases debugging, comprehension,\\nand maintenance.\\nPolymorphism\\nThis is more a property of OOP than a reason for using it, but by supporting code\\ngenerality, polymorphism makes code more flexible and widely applicable, and\\nhence more reusable.\\nOther\\nAnd, of course, the number one reason students gave for using OOP: it looks good\\non a résumé! (OK, I threw this one in as a joke, but it is important to be familiar\\nwith OOP if you plan to work in the software field today.)\\nFinally, keep in mind what I said at the beginning of this part of the book: you won’t\\nfully appreciate OOP until you’ve used it for awhile. Pick a project, study larger exam-\\nples, work through the exercises—do whatever it takes to get your feet wet with OO\\ncode; it’s worth the effort.\\n822 | Chapter 31: \\u2002Advanced Class Topics', metadata={'source': 'python.pdf', 'page': 872}),\n",
       " Document(page_content='PART VII\\nExceptions and Tools', metadata={'source': 'python.pdf', 'page': 873}),\n",
       " Document(page_content='', metadata={'source': 'python.pdf', 'page': 874}),\n",
       " Document(page_content='CHAPTER 32\\nException Basics\\nThis part of the book deals with exceptions, which are events that can modify the flow\\nof control through a program. In Python, exceptions are triggered automatically on\\nerrors, and they can be triggered and intercepted by your code. They are processed by\\nfour statements we’ll study in this part, the first of which has two variations (listed\\nseparately here) and the last of which was an optional extension until Python 2.6 and\\n3.0:\\ntry/except\\nCatch and recover from exceptions raised by Python, or by you.\\ntry/finally\\nPerform cleanup actions, whether exceptions occur or not.\\nraise\\nTrigger an exception manually in your code.\\nassert\\nConditionally trigger an exception in your code.\\nwith/as\\nImplement context managers in Python 2.6 and 3.0 (optional in 2.5).\\nThis topic was saved until nearly the end of the book because you need to know about\\nclasses to code exceptions of your own. With a few exceptions (pun intended), though,\\nyou’ll find that exception handling is simple in Python because it’s integrated into the\\nlanguage itself as another high-level tool.\\nWhy Use Exceptions?\\nIn a nutshell, exceptions let us jump out of arbitrarily large chunks of a program. Con-\\nsider the hypothetical pizza-making robot we discussed earlier in the book. Suppose\\nwe took the idea seriously and actually built such a machine. To make a pizza, our\\nculinary automaton would need to execute a plan, which we would implement as a\\n825', metadata={'source': 'python.pdf', 'page': 875}),\n",
       " Document(page_content='Python program: it would take an order, prepare the dough, add toppings, bake the\\npie, and so on.\\nNow, suppose that \\nsomething goes very wrong during the “bake the pie” step. Perhaps\\nthe oven is broken, or perhaps our robot miscalculates its reach and spontaneously\\ncombusts. Clearly, we want to be able to jump to code that handles such states quickly.\\nAs we have no hope of finishing the pizza task in such unusual cases, we might as well\\nabandon the entire plan.\\nThat’s exactly what exceptions let you do: you can jump to an exception handler in a\\nsingle step, abandoning all function calls begun since the exception handler was en-\\ntered. Code in the exception handler can then respond to the raised exception as ap-\\npropriate (by calling the fire department, for instance!).\\nOne way to think of an exception is as a sort of structured “super go to.” An exception\\nhandler ( try statement) leaves a marker and executes some code. Somewhere further\\nahead in the program, an exception is raised that makes Python jump back to that\\nmarker, abandoning any active functions that were called after the marker was left.\\nThis protocol provides a coherent way to respond to unusual events. Moreover, because\\nPython jumps to the handler statement immediately, your code is simpler—there is\\nusually no need to check status codes after every call to a function that could possibly\\nfail.\\nException Roles\\nIn Python programs, exceptions are typically used for a variety of purposes. Here are\\nsome of their most common roles:\\nError handling\\nPython raises exceptions whenever it detects errors in programs at runtime. You\\ncan catch and respond to the errors in your code, or ignore the exceptions that are\\nraised. If an error is ignored, Python’s default exception-handling behavior kicks\\nin: it stops the program and prints an error message. If you don’t want this default\\nbehavior, code a try statement to catch and recover from the exception—Python\\nwill jump to your try handler when the error is detected, and your program will\\nresume execution after the try.\\nEvent notification\\nExceptions can also be used to signal valid conditions without you having to pass\\nresult flags around a program or test them explicitly. For instance, a search routine\\nmight raise an exception on failure, rather than returning an integer result code\\n(and hoping that the code will never be a valid result).\\nSpecial-case handling\\nSometimes a condition may occur so rarely that it’s hard to justify convoluting your\\ncode to handle it. You can often eliminate special-case code by handling unusual\\ncases in exception handlers in higher levels of your program.\\n826 | Chapter 32: \\u2002Exception Basics', metadata={'source': 'python.pdf', 'page': 876}),\n",
       " Document(page_content=\"Termination actions\\nAs you’ll see, \\nthe try/finally statement allows you to guarantee that required\\nclosing-time operations will be performed, regardless of the presence or absence\\nof exceptions in your programs.\\nUnusual control flows\\nFinally, because exceptions are a sort of high-level “go to,” you can use them as\\nthe basis for implementing exotic control flows. For instance, although the lan-\\nguage does not explicitly support backtracking, it can be implemented in Python\\nby using exceptions and a bit of support logic to unwind assignments.* There is no\\n“go to” statement in Python (thankfully!), but exceptions can sometimes serve\\nsimilar roles.\\nWe’ll see such typical use cases in action later in this part of the book. For now, let’s\\nget started with a look at Python’s exception-processing tools.\\nExceptions: The Short Story\\nCompared to some other core language topics we’ve met in this book, exceptions are\\na fairly lightweight tool in Python. Because they are so simple, let’s jump right into\\nsome code.\\nDefault Exception Handler\\nSuppose we write the following function:\\n>>> def fetcher(obj, index):\\n...     return obj[index]\\n...\\nThere’s not much to this function—it simply indexes an object on a passed-in index.\\nIn normal operation, it returns the result of a legal index:\\n>>> x = 'spam'\\n>>> fetcher(x, 3)                         # Like x[3]\\n'm'\\nHowever, if we ask this function to index off the end of the string, an exception will be\\ntriggered when the function tries to run obj[index]. Python detects out-of-bounds in-\\ndexing for sequences and reports it by raising (triggering) the built-in IndexError\\nexception:\\n* True backtracking is an advanced topic that is not part of the Python language, so I won’t say much more\\nabout it \\nhere (even the generator functions and expressions we met in Chapter 20 are not true backtracking—\\nthey simply respond to next(G) requests). Roughly, backtracking undoes all computations before it jumps;\\nPython exceptions do not (i.e., variables assigned between the time a try statement is entered and the time\\nan exception is raised are not reset to their prior values). See a book on artificial intelligence or the Prolog or\\nIcon programming languages if you’re curious.\\nExceptions: The Short Story | 827\", metadata={'source': 'python.pdf', 'page': 877}),\n",
       " Document(page_content='>>> fetcher(x, 4)                         # Default handler - shell interface\\nTraceback (most recent call last):\\n  File \"<stdin>\", line 1, in <module>\\n  File \"<stdin>\", line 2, in fetcher\\nIndexError: string index out of range\\nBecause our code \\ndoes not explicitly catch this exception, it filters back up to the top\\nlevel of the program and invokes the default exception handler , which simply prints the\\nstandard error message. By this point in the book, you’ve probably seen your share of\\nstandard error messages. They include the exception that was raised, along with a stack\\ntrace—a list of all the lines and functions that were active when the exception occurred.\\nThe error message text here was printed by Python 3.0; it can vary slightly per release,\\nand even per interactive shell. When coding interactively in the basic shell interface,\\nthe filename is just “<stdin>,” meaning the standard input stream. When working in\\nthe IDLE GUI’s interactive shell, the filename is “<pyshell>”, and source lines are dis-\\nplayed, too. Either way, file line numbers are not very meaningful when there is no file\\n(we’ll see more interesting error messages later in this part of the book):\\n>>> fetcher(x, 4)                         # Default handler - IDLE GUI interface\\nTraceback (most recent call last):\\n  File \"<pyshell#6>\", line 1, in <module>\\n    fetcher(x, 4)\\n  File \"<pyshell#3>\", line 2, in fetcher\\n    return obj[index]\\nIndexError: string index out of range\\nIn a more realistic program launched outside the interactive prompt, after printing an\\nerror message the default handler at the top also terminates the program immediately.\\nThat course of action makes sense for simple scripts; errors often should be fatal, and\\nthe best you can do when they occur is inspect the standard error message.\\nCatching Exceptions\\nSometimes, this isn’t what you want, though. Server programs, for instance, typically\\nneed to remain active even after internal errors. If you don’t want the default exception\\nbehavior, wrap the call in a try statement to catch exceptions yourself:\\n>>> try:\\n...     fetcher(x, 4)\\n... except IndexError:                    # Catch and recover\\n...     print(\\'got exception\\')\\n...\\ngot exception\\n>>>\\nNow, Python jumps to your handler (the block under the except clause that names the\\nexception raised) automatically when an exception is triggered while the try block is\\nrunning. When working interactively like this, after the except clause runs, we wind\\nup back at the Python prompt. In a more realistic program, try statements not only\\ncatch exceptions, but also recover from them:\\n828 | Chapter 32: \\u2002Exception Basics', metadata={'source': 'python.pdf', 'page': 878}),\n",
       " Document(page_content='>>> def catcher():\\n...     try:\\n...         fetcher(x, 4)\\n...     except IndexError:\\n...         print(\\'got exception\\')\\n...     print(\\'continuing\\')\\n...\\n>>> catcher()\\ngot exception\\ncontinuing\\n>>>\\nThis time, after \\nthe exception is caught and handled, the program resumes execution\\nafter the entire try statement that caught it—which is why we get the “continuing”\\nmessage here. We don’t see the standard error message, and the program continues on\\nits way normally.\\nRaising Exceptions\\nSo far, we’ve been letting Python raise exceptions for us by making mistakes (on pur-\\npose this time!), but our scripts can raise exceptions too—that is, exceptions can be\\nraised by Python or by your program, and can be caught or not. To trigger an exception\\nmanually, simply run a raise statement. User-triggered exceptions are caught the same\\nway as those Python raises. The following may not be the most useful Python code ever\\npenned, but it makes the point:\\n>>> try:\\n...     raise IndexError                  # Trigger exception manually\\n... except IndexError:\\n...     print(\\'got exception\\')\\n...\\ngot exception\\nAs usual, if they’re not caught, user-triggered exceptions are propagated up to the top-\\nlevel default exception handler and terminate the program with a standard error\\nmessage:\\n>>> raise IndexError\\nTraceback (most recent call last):\\n  File \"<stdin>\", line 1, in <module>\\nIndexError\\nAs we’ll see in the next chapter, the assert statement can be used to trigger exceptions,\\ntoo—it’s a conditional raise, used mostly for debugging purposes during development:\\n>>> assert False, \\'Nobody expects the Spanish Inquisition!\\'\\nTraceback (most recent call last):\\n  File \"<stdin>\", line 1, in <module>\\nAssertionError: Nobody expects the Spanish Inquisition!\\nExceptions: The Short Story | 829', metadata={'source': 'python.pdf', 'page': 879}),\n",
       " Document(page_content=\"User-Defined Exceptions\\nThe raise statement introduced in \\nthe prior section raises a built-in exception defined\\nin Python’s built-in scope. As you’ll learn later in this part of the book, you can also\\ndefine new exceptions of your own that are specific to your programs. User-defined\\nexceptions are coded with classes, which inherit from a built-in exception class: usually\\nthe class named Exception. Class-based exceptions allow scripts to build exception\\ncategories, inherit behavior, and have attached state information:\\n>>> class Bad(Exception):                 # User-defined exception\\n...     pass\\n...\\n>>> def doomed():\\n...     raise Bad()                       # Raise an instance\\n...\\n>>> try:\\n...     doomed()\\n... except Bad:                           # Catch class name\\n...     print('got Bad')\\n...\\ngot Bad\\n>>>\\nTermination Actions\\nFinally, try statements can say “finally”—that is, they may include finally blocks.\\nThese look like except handlers for exceptions, but the try/finally combination speci-\\nfies termination actions that always execute “on the way out,” regardless of whether\\nan exception occurs in the try block:\\n>>> try:\\n...     fetcher(x, 3)\\n... finally:                              # Termination actions\\n...     print('after fetch')\\n...\\n'm'\\nafter fetch\\n>>>\\nHere, if the try block finishes without an exception, the finally block will run, and\\nthe program will resume after the entire try. In this case, this statement seems a bit\\nsilly—we might as well have simply typed the print right after a call to the function,\\nand skipped the try altogether:\\nfetcher(x, 3)\\nprint('after fetch')\\nThere is a problem with coding this way, though: if the function call raises an exception,\\nthe print will never be reached. The try/finally combination avoids this pitfall—when\\nan exception does occur in a try block, finally blocks are executed while the program\\nis being unwound:\\n830 | Chapter 32: \\u2002Exception Basics\", metadata={'source': 'python.pdf', 'page': 880}),\n",
       " Document(page_content='>>> def after():\\n...     try:\\n...         fetcher(x, 4)\\n...     finally:\\n...         print(\\'after fetch\\')\\n...     print(\\'after try?\\')\\n...\\n>>> after()\\nafter fetch\\nTraceback (most recent call last):\\n  File \"<stdin>\", line 1, in <module>\\n  File \"<stdin>\", line 3, in after\\n  File \"<stdin>\", line 2, in fetcher\\nIndexError: string index out of range\\n>>>\\nHere, we don’t \\nget the “after try?” message because control does not resume after the\\ntry/finally block when an exception occurs. Instead, Python jumps back to run the\\nfinally action, and then propagates the exception up to a prior handler (in this case,\\nto the default handler at the top). If we change the call inside this function so as not to\\ntrigger an exception, the finally code still runs, but the program continues after the try:\\n>>> def after():\\n...     try:\\n...         fetcher(x, 3)\\n...     finally:\\n...         print(\\'after fetch\\')\\n...     print(\\'after try?\\')\\n...\\n>>> after()\\nafter fetch\\nafter try?\\n>>>\\nIn practice, try/except combinations are useful for catching and recovering from ex-\\nceptions, and try/finally combinations come in handy to guarantee that termination\\nactions will fire regardless of any exceptions that may occur in the try block’s code.\\nFor instance, you might use try/except to catch errors raised by code that you import\\nfrom a third-party library, and try/finally to ensure that calls to close files or terminate\\nserver connections are always run. We’ll see some such practical examples later in this\\npart of the book.\\nAlthough they serve conceptually distinct purposes, as of Python 2.5, we can now mix\\nexcept and finally clauses in the same try statement—the finally is run on the way\\nout regardless of whether an exception was raised, and regardless of whether the ex-\\nception was caught by an except clause.\\nAs we’ll learn in the next chapter, Python 2.6 and 3.0 provide an alternative to try/\\nfinally when using some types of objects. The with/as statement runs an object’s con-\\ntext management logic to guarantee that termination actions occur:\\nExceptions: The Short Story | 831', metadata={'source': 'python.pdf', 'page': 881}),\n",
       " Document(page_content=\">>> with open('lumberjack.txt', 'w') as file:        # Always close file on exit\\n...     file.write('The larch!\\\\n')\\nAlthough this option \\nrequires fewer lines of code, it’s only applicable when processing\\ncertain object types, so try/finally is a more general termination structure. On the\\nother hand, with/as may also run startup actions and supports user-defined context\\nmanagement code.\\nWhy You Will Care: Error Checks\\nOne way to \\nsee how exceptions are useful is to compare coding styles in Python and\\nlanguages without exceptions. For instance, if you want to write robust programs in\\nthe C language, you generally have to test return values or status codes after every\\noperation that could possibly go astray, and propagate the results of the tests as your\\nprograms run:\\ndoStuff()\\n{                                 # C program\\n    if (doFirstThing() == ERROR)  # Detect errors everywhere\\n        return ERROR;             # even if not handled here\\n    if (doNextThing() == ERROR)\\n        return ERROR;\\n    ...\\n    return doLastThing();\\n}\\nmain()\\n{\\n    if (doStuff() == ERROR)\\n        badEnding();\\n    else\\n        goodEnding();\\n}\\nIn fact, realistic C programs often have as much code devoted to error detection as to\\ndoing actual work. But in Python, you don’t have to be so methodical (and neurotic!).\\nYou can instead wrap arbitrarily vast pieces of a program in exception handlers and\\nsimply write the parts that do the actual work, assuming all is well:\\ndef doStuff():        # Python code\\n    doFirstThing()    # We don't care about exceptions here,\\n    doNextThing()     # so we don't need to detect them\\n    ...\\n    doLastThing()\\nif __name__ == '__main__':\\n    try:\\n        doStuff()     # This is where we care about results,\\n    except:           # so it's the only place we must check\\n        badEnding()\\n    else:\\n        goodEnding()\\n832 | Chapter 32: \\u2002Exception Basics\", metadata={'source': 'python.pdf', 'page': 882}),\n",
       " Document(page_content='Because control jumps immediately to a handler when an exception occurs, there’s no\\nneed to instrument \\nall your code to guard for errors. Moreover, because Python detects\\nerrors automatically, your code usually doesn’t need to check for errors in the first\\nplace. The upshot is that exceptions let you largely ignore the unusual cases and avoid\\nerror-checking code.\\nChapter Summary\\nAnd that is the majority of the exception story; exceptions really are a simple tool.\\nTo summarize, Python \\nexceptions are a high-level control flow device. They may be\\nraised by Python, or by your own programs. In both cases, they may be ignored (to\\ntrigger the default error message), or caught by try statements (to be processed by your\\ncode). The try statement comes in two logical formats that, as of Python 2.5, can be\\ncombined—one that handles exceptions, and one that executes finalization code re-\\ngardless of whether exceptions occur or not. Python’s raise and assert statements\\ntrigger exceptions on demand (both built-ins and new exceptions we define with\\nclasses); the with/as statement is an alternative way to ensure that termination actions\\nare carried out for objects that support it.\\nIn the rest of this part of the book, we’ll fill in some of the details about the statements\\ninvolved, examine the other sorts of clauses that can appear under a try, and discuss\\nclass-based exception objects. The next chapter begins our tour by taking a closer look\\nat the statements we introduced here. Before you turn the page, though, here are a few\\nquiz questions to review.\\nTest Your Knowledge: Quiz\\n1. Name three things that exception processing is good for.\\n2. What happens to an exception if you don’t do anything special to handle it?\\n3.\\nHow can your script recover from an exception?\\n4. Name two ways to trigger exceptions in your script.\\n5. Name two ways to specify actions to be run at termination time, whether an ex-\\nception occurs or not.\\nTest Your Knowledge: Answers\\n1. Exception processing is useful for error handling, termination actions, and event\\nnotification. It can also simplify the handling of special cases and can be used to\\nimplement alternative control flows. In general, exception processing also cuts\\nTest Your Knowledge: Answers | 833', metadata={'source': 'python.pdf', 'page': 883}),\n",
       " Document(page_content='down on the amount of error-checking code your program may require—because\\nall errors filter \\nup to handlers, you may not need to test the outcome of every\\noperation.\\n2. Any uncaught exception eventually filters up to the default exception handler Py-\\nthon provides at the top of your program. This handler prints the familiar error\\nmessage and shuts down your program.\\n3. If you don’t want the default message and shutdown, you can code try/except\\nstatements to catch and recover from exceptions that are raised. Once an exception\\nis caught, the exception is terminated and your program continues.\\n4. The raise and assert statements can be used to trigger an exception, exactly as if\\nit had been raised by Python itself. In principle, you can also raise an exception by\\nmaking a programming mistake, but that’s not usually an explicit goal!\\n5. The try/finally statement can be used to ensure actions are run after a block of\\ncode exits, regardless of whether it raises an exception or not. The with/as state-\\nment can also be used to ensure termination actions are run, but only when pro-\\ncessing object types that support it.\\n834 | Chapter 32: \\u2002Exception Basics', metadata={'source': 'python.pdf', 'page': 884}),\n",
       " Document(page_content='CHAPTER 33\\nException Coding Details\\nIn the prior chapter we took a quick look at exception-related statements in action.\\nHere, we’re going \\nto dig a bit deeper—this chapter provides a more formal introduction\\nto exception processing syntax in Python. Specifically, we’ll explore the details behind\\nthe try, raise, assert, and with statements. As we’ll see, although these statements are\\nmostly straightforward, they offer powerful tools for dealing with exceptions in Python\\ncode.\\nOne procedural note up front: The exception story has changed in major\\nways in recent \\nyears. As of Python 2.5, the finally clause can appear in\\nthe same try statement as except and else clauses (previously, they\\ncould not be combined). Also, as of Python 3.0 and 2.6, the new with\\ncontext manager statement has become official, and user-defined ex-\\nceptions must now be coded as class instances, which should inherit\\nfrom a built-in exception superclass. Moreover, 3.0 sports slightly modi-\\nfied syntax for the raise statement and except clauses. I will focus on\\nthe state of exceptions in Python 2.6 and 3.0 in this edition, but because\\nyou are still very likely to see the original techniques in code for some\\ntime to come, along the way I’ll point out how things have evolved in\\nthis domain.\\nThe try/except/else Statement\\nNow that we’ve seen the basics, it’s time for the details. In the following discussion,\\nI’ll first present try/except/else and try/finally as separate statements, because in\\nversions of Python prior to 2.5 they serve distinct roles and cannot be combined. As\\nmentioned in the preceding note, in Python 2.5 and later except and finally can be\\nmixed in a single try statement; I’ll explain the implications of this change after we’ve\\nexplored the two original forms in isolation.\\nThe try is a compound statement; its most complete form is sketched below. It starts\\nwith a try header line, followed by a block of (usually) indented statements, then one\\n835', metadata={'source': 'python.pdf', 'page': 885}),\n",
       " Document(page_content='or more except clauses that identify exceptions to be caught, and an optional else clause\\nat the end. The words try, except, and else are associated by indenting them to the\\nsame level (i.e., lining them up vertically). For reference, here’s the general format in\\nPython 3.0:\\ntry:\\n    <statements>            # Run this main action first\\nexcept <name1>:\\n    <statements>            # Run if name1 is raised during try block\\nexcept (name2, name3):\\n    <statements>            # Run if any of these exceptions occur\\nexcept <name4> as <data>:\\n    <statements>            # Run if name4 is raised, and get instance raised\\nexcept:\\n    <statements>            # Run for all (other) exceptions raised\\nelse:\\n    <statements>            # Run if no exception was raised during try block\\nIn this statement, the block under the try header represents the main action of the\\nstatement—the code you’re trying to run. The except clauses define handlers for ex-\\nceptions raised during the try block, and the else clause (if coded) provides a handler\\nto be run if no exceptions occur. The <data> entry here has to do with a feature of\\nraise statements and exception classes, which we will discuss later in this chapter.\\nHere’s how try statements work. When a try statement is entered, Python marks the\\ncurrent program context so it can return to it if an exception occurs. The statements\\nnested under the try header are run first. What happens next depends on whether\\nexceptions are raised while the try block’s statements are running:\\n• If an exception does occur while the try block’s statements are running, Python\\njumps back to the try and runs the statements under the first except clause that\\nmatches the raised exception. Control resumes below the entire try statement after\\nthe except block runs (unless the except block raises another exception).\\n• If an exception happens in the try block and no except clause matches, the excep-\\ntion is propagated up to the last matching try statement that was entered in the\\nprogram or, if it’s the first such statement, to the top level of the process (in which\\ncase Python kills the program and prints a default error message).\\n• If no exception occurs while the statements under the try header run, Python runs\\nthe statements under the else line (if present), and control then resumes below the\\nentire try statement.\\nIn other words, except clauses catch any exceptions that happen while the try block is\\nrunning, and the else clause runs only if no exceptions happen while the try block runs.\\nexcept clauses are focused exception handlers—they catch exceptions that occur only\\nwithin the statements in the associated try block. However, as the try block’s state-\\nments can call functions coded elsewhere in a program, the source of an exception may\\nbe outside the try statement itself. I’ll have more to say about this when we explore\\ntry nesting in Chapter 35.\\n836 | Chapter 33: \\u2002Exception Coding Details', metadata={'source': 'python.pdf', 'page': 886}),\n",
       " Document(page_content='try Statement Clauses\\nWhen you write \\na try statement, a variety of clauses can appear after the try header.\\nTable 33-1  summarizes all the possible forms—you must use at least one. We’ve already\\nmet some of these: as you know, except clauses catch exceptions, finally clauses run\\non the way out, and else clauses run if no exceptions are encountered.\\nSyntactically, there may be any number of except clauses, but you can code else only\\nif there is at least one except, and there can be only one else and one finally. Through\\nPython 2.4, the finally clause must appear alone (without else or except); the try/\\nfinally is really a different statement. As of Python 2.5, however, a finally can appear\\nin the same statement as except and else (more on the ordering rules later in this chapter\\nwhen we meet the unified try statement).\\nTable 33-1. try statement clause forms\\nClause form Interpretation\\nexcept: Catch all (or all other) exception types.\\nexcept name: Catch a specific exception only.\\nexcept name as value: Catch the listed exception and its instance.\\nexcept (name1, name2): Catch any of the listed exceptions.\\nexcept (name1, name2) as value: Catch any listed exception and its instance.\\nelse: Run if no exceptions are raised.\\nfinally: Always perform this block.\\nWe’ll explore the entries with the extra as value part when we meet the raise statement.\\nThey provide access to the objects that are raised as exceptions.\\nThe first and fourth entries in Table 33-1 are new here:\\n•except clauses that list no exception name (except:) catch all exceptions not pre-\\nviously listed in the try statement.\\n•except clauses that list a set of exceptions in parentheses ( except (e1, e2, e3):)\\ncatch any of the listed exceptions.\\nBecause Python looks for a match within a given try by inspecting the except clauses\\nfrom top to bottom, the parenthesized version has the same effect as listing each ex-\\nception in its own except clause, but you have to code the statement body only once.\\nHere’s an example of multiple except clauses at work, which demonstrates just how\\nspecific your handlers can be:\\ntry:\\n    action()\\nexcept NameError:\\n    ...\\nexcept IndexError:\\n    ...\\nThe try/except/else Statement | 837', metadata={'source': 'python.pdf', 'page': 887}),\n",
       " Document(page_content='except KeyError:\\n    ...\\nexcept (AttributeError, TypeError, SyntaxError):\\n    ...\\nelse:\\n    ...\\nIn this example, \\nif an exception is raised while the call to the action function is running,\\nPython returns to the try and searches for the first except that names the exception\\nraised. It inspects the except clauses from top to bottom and left to right, and runs the\\nstatements under the first one that matches. If none match, the exception is propagated\\npast this try. Note that the else runs only when no exception occurs in action—it does\\nnot run when an exception without a matching except is raised.\\nIf you really want a general “catch-all” clause, an empty except does the trick:\\ntry:\\n    action()\\nexcept NameError:\\n    ...                   # Handle NameError\\nexcept IndexError:\\n    ...                   # Handle IndexError\\nexcept:\\n    ...                   # Handle all other exceptions\\nelse:\\n    ...                   # Handle the no-exception case\\nThe empty except clause is a sort of wildcard feature—because it catches everything, it\\nallows your handlers to be as general or specific as you like. In some scenarios, this\\nform may be more convenient than listing all possible exceptions in a try. For example,\\nthe following catches everything without listing anything:\\ntry:\\n    action()\\nexcept:\\n    ...                   # Catch all possible exceptions\\nEmpty excepts also raise some design issues, though. Although convenient, they may\\ncatch unexpected system exceptions unrelated to your code, and they may inadver-\\ntently intercept exceptions meant for another handler. For example, even system exit\\ncalls in Python trigger exceptions, and you usually want these to pass. That said, this\\nstructure may also catch genuine programming mistakes for you which you probably\\nwant to see an error message. We’ll revisit this as a gotcha at the end of this part of the\\nbook. For now, I’ll just say “use with care.”\\nPython 3.0 introduced an alternative that solves one of these problems—catching an\\nexception named Exception has almost the same effect as an empty except, but ignores\\nexceptions related to system exits:\\ntry:\\n    action()\\nexcept Exception:\\n    ...                   # Catch all possible exceptions, except exits\\n838 | Chapter 33: \\u2002Exception Coding Details', metadata={'source': 'python.pdf', 'page': 888}),\n",
       " Document(page_content='This has most of the same convenience of the empty except, but also most of the same\\ndangers. We’ll explore \\nhow this form works its voodoo in the next chapter, when we\\nstudy exception classes.\\nVersion skew note : Python 3.0 requires the except E as V: handler clause\\nform listed in Table 33-1  and used in this book, rather than the older\\nexcept E, V: form. The latter form is still available (but not\\nrecommended) in Python 2.6: if used, it’s converted to the former. The\\nchange was made to eliminate errors that occur when confusing the\\nolder form with two alternate exceptions, properly coded in 2.6 as\\nexcept (E1, E2): . Because 3.0 supports the as form only, commas in a\\nhandler clause are always taken to mean a tuple, regardless of whether\\nparentheses are used or not, and the values are interpreted as alternative\\nexceptions to be caught. This change also modifies the scoping rules:\\nwith the new as syntax, the variable V is deleted at the end of the\\nexcept block.\\nThe try else Clause\\nThe purpose of the else clause is not always immediately obvious to Python newcom-\\ners. Without it, though, there is no way to tell (without setting and checking Boolean\\nflags) whether the flow of control has proceeded past a try statement because no ex-\\nception was raised, or because an exception occurred and was handled:\\ntry:\\n    ...run code...\\nexcept IndexError:\\n    ...handle exception...\\n# Did we get here because the try failed or not?\\nMuch like the way else clauses in loops make the exit cause more apparent, the else\\nclause provides syntax in a try that makes what has happened obvious and\\nunambiguous:\\ntry:\\n    ...run code...\\nexcept IndexError:\\n    ...handle exception...\\nelse:\\n    ...no exception occurred...\\nYou can almost emulate an else clause by moving its code into the try block:\\ntry:\\n    ...run code...\\n    ...no exception occurred...\\nexcept IndexError:\\n    ...handle exception...\\nThis can lead to incorrect exception classifications, though. If the “no exception oc-\\ncurred” action triggers an IndexError, it will register as a failure of the try block and\\nThe try/except/else Statement | 839', metadata={'source': 'python.pdf', 'page': 889}),\n",
       " Document(page_content='erroneously trigger the exception handler below the try (subtle, but true!). By using an\\nexplicit else clause instead, you make the logic more obvious and guarantee that\\nexcept handlers will run only for real failures in the code you’re wrapping in a try, not\\nfor failures in the else case’s action.\\nExample: Default Behavior\\nBecause the control flow through a program is easier to capture in Python than in\\nEnglish, let’s run some examples that further illustrate exception basics. I’ve mentioned\\nthat exceptions not caught by try statements percolate up to the top level of the Python\\nprocess and run Python’s default exception-handling logic (i.e., Python terminates the\\nrunning program and prints a standard error message). Let’s look at an example. Run-\\nning the following module file, bad.py, generates a divide-by-zero exception:\\ndef gobad(x, y):\\n    return x / y\\ndef gosouth(x):\\n    print(gobad(x, 0))\\ngosouth(1)\\nBecause the program ignores the exception it triggers, Python kills the program and\\nprints a message:\\n% python bad.py\\nTraceback (most recent call last):\\n  File \"bad.py\", line 7, in <module>\\n    gosouth(1)\\n  File \"bad.py\", line 5, in gosouth\\n    print(gobad(x, 0))\\n  File \"bad.py\", line 2, in gobad\\n    return x / y\\nZeroDivisionError: int division or modulo by zero\\nI ran this in a shell widow with Python 3.0. The message consists of a stack trace\\n(“Traceback”) and the name of and details about the exception that was raised. The\\nstack trace lists all lines active when the exception occurred, from oldest to newest.\\nNote that because we’re not working at the interactive prompt, in this case the file and\\nline number information is more useful. For example, here we can see that the bad\\ndivide happens at the last entry in the trace—line 2 of the file bad.py, a return\\nstatement.*\\nBecause Python detects and reports all errors at runtime by raising exceptions, excep-\\ntions are intimately bound up with the ideas of error handling and debugging in general.\\n* As mentioned in the prior chapter, the text of error messages and stack traces tends to vary slightly over time\\nand shells. \\nDon’t be alarmed if your error messages don’t exactly match mine. When I ran this example in\\nPython 3.0’s IDLE GUI, for instance, its error message text showed filenames with full absolute directory\\npaths.\\n840 | Chapter 33: \\u2002Exception Coding Details', metadata={'source': 'python.pdf', 'page': 890}),\n",
       " Document(page_content='If you’ve worked through this book’s examples, you’ve undoubtedly seen an exception\\nor two along \\nthe way—even typos usually generate a SyntaxError or other exception\\nwhen a file is imported or executed (that’s when the compiler is run). By default, you\\nget a useful error display like the one just shown, which helps you track down the\\nproblem.\\nOften, this standard error message is all you need to resolve problems in your code.\\nFor more heavy-duty debugging jobs, you can catch exceptions with try statements,\\nor use one of the debugging tools that I introduced in Chapter 3 and will summarize\\nagain in Chapter 35 (such as the pdb standard library module).\\nExample: Catching Built-in Exceptions\\nPython’s default exception handling is often exactly what you want—especially for\\ncode in a top-level script file, an error generally should terminate your program imme-\\ndiately. For many programs, there is no need to be more specific about errors in your\\ncode.\\nSometimes, though, you’ll want to catch errors and recover from them instead. If you\\ndon’t want your program terminated when Python raises an exception, simply catch it\\nby wrapping the program logic in a try. This is an important capability for programs\\nsuch as network servers, which must keep running persistently. For example, the fol-\\nlowing code catches and recovers from the TypeError Python raises immediately when\\nyou try to concatenate a list and a string (the + operator expects the same sequence type\\non both sides):\\ndef kaboom(x, y):\\n    print(x + y)               # Trigger TypeError\\ntry:\\n    kaboom([0,1,2], \"spam\")\\nexcept TypeError:              # Catch and recover here\\n    print(\\'Hello world!\\')\\nprint(\\'resuming here\\')         # Continue here if exception or not\\nWhen the exception occurs in the function kaboom, control jumps to the try statement’s\\nexcept clause, which prints a message. Since an exception is “dead” after it’s been\\ncaught like this, the program continues executing below the try rather than being ter-\\nminated by Python. In effect, the code processes and clears the error, and your script\\nrecovers:\\n% python kaboom.py\\nHello world!\\nresuming here\\nNotice that once you’ve caught an error, control resumes at the place where you caught\\nit (i.e., after the try); there is no direct way to go back to the place where the exception\\noccurred (here, in the function kaboom). In a sense, this makes exceptions more like\\nThe try/except/else Statement | 841', metadata={'source': 'python.pdf', 'page': 891}),\n",
       " Document(page_content='simple jumps than function calls—there is no way to return to the code that triggered\\nthe error.\\nThe try/finally Statement\\nThe other flavor of \\nthe try statement is a specialization that has to do with finalization\\nactions. If a finally clause is included in a try, Python will always run its block of\\nstatements “on the way out” of the try statement, whether an exception occurred while\\nthe try block was running or not. Its general form is:\\ntry:\\n    <statements>               # Run this action first\\nfinally:\\n    <statements>               # Always run this code on the way out\\nWith this variant, Python begins by running the statement block associated with the\\ntry header line. What happens next depends on whether an exception occurs during\\nthe try block:\\n• If no exception occurs while the try block is running, Python jumps back to run\\nthe finally block and then continues execution past below the try statement.\\n• If an exception does occur during the try block’s run, Python still comes back and\\nruns the finally block, but it then propagates the exception up to a higher try or\\nthe top-level default handler; the program does not resume execution below the\\ntry statement. That is, the finally block is run even if an exception is raised, but\\nunlike an except, the finally does not terminate the exception—it continues being\\nraised after the finally block runs.\\nThe try/finally form is useful when you want to be completely sure that an action will\\nhappen after some code runs, regardless of the exception behavior of the program. In\\npractice, it allows you to specify cleanup actions that always must occur, such as file\\ncloses and server disconnects.\\nNote that the finally clause cannot be used in the same try statement as except and\\nelse in Python 2.4 and earlier, so the try/finally is best thought of as a distinct state-\\nment form if you are using an older release. In Python 2.5, and later, however,\\nfinally can appear in the same statement as except and else, so today there is really a\\nsingle try statement with many optional clauses (more about this shortly). Whichever\\nversion you use, though, the finally clause still serves the same purpose—to specify\\n“cleanup” actions that must always be run, regardless of any exceptions.\\nAs we’ll also see later in this chapter, in Python 2.6 and 3.0, the new \\nwith statement and \\nits context managers provide an object-based way\\nto do similar work for exit actions. Unlike finally, this new statement\\nalso supports entry actions, but it is limited in scope to objects that\\nimplement the context manager protocol.\\n842 | Chapter 33: \\u2002Exception Coding Details', metadata={'source': 'python.pdf', 'page': 892}),\n",
       " Document(page_content=\"Example: Coding Termination Actions with try/finally\\nWe saw some \\nsimple try/finally examples in the prior chapter. Here’s a more realistic\\nexample that illustrates a typical role for this statement:\\nclass MyError(Exception): pass\\ndef stuff(file):\\n    raise MyError()\\nfile = open('data', 'w')     # Open an output file\\ntry:\\n    stuff(file)              # Raises exception\\nfinally:\\n    file.close()             # Always close file to flush output buffers\\nprint('not reached')         # Continue here only if no exception\\nIn this code, we’ve wrapped a call to a file-processing function in a try with a\\nfinally clause to make sure that the file is always closed, and thus finalized, whether\\nthe function triggers an exception or not. This way, later code can be sure that the file’s\\noutput buffer’s content has been flushed from memory to disk. A similar code structure\\ncan guarantee that server connections are closed, and so on.\\nAs we learned in Chapter 9 , file objects are automatically closed on garbage collection;\\nthis is especially useful for temporary files that we don’t assign to variables. However,\\nit’s not always easy to predict when garbage collection will occur, especially in larger\\nprograms. The try statement makes file closes more explicit and predictable and per-\\ntains to a specific block of code. It ensures that the file will be closed on block exit,\\nregardless of whether an exception occurs or not.\\nThis particular example’s function isn’t all that useful (it just raises an exception), but\\nwrapping calls in try/finally statements is a good way to ensure that your closing-time\\n(i.e., termination) activities always run. Again, Python always runs the code in your\\nfinally blocks, regardless of whether an exception happens in the try block.†\\nWhen the function here raises its exception, the control flow jumps back and runs the\\nfinally block to close the file. The exception is then propagated on to either another\\ntry or the default top-level handler, which prints the standard error message and shuts\\ndown the program; the statement after this try is never reached. If the function here\\ndid not raise an exception, the program would still execute the finally block to close\\nthe file, but it would then continue below the entire try statement.\\nNotice that the user-defined exception here is again defined with a class—as we’ll see\\nin the next chapter, exceptions today must all be class instances in both 2.6 and 3.0.\\n† Unless Python crashes completely, of course. It does a good job of avoiding this, though, by checking all\\npossible errors \\nas a program runs. When a program does crash hard, it is usually due to a bug in linked-in C\\nextension code, outside of Python’s scope.\\nThe try/finally Statement | 843\", metadata={'source': 'python.pdf', 'page': 893}),\n",
       " Document(page_content='Unified try/except/finally\\nIn all versions of Python \\nprior to Release 2.5 (for its first 15 years of life, more or less),\\nthe try statement came in two flavors and was really two separate statements—we\\ncould either use a finally to ensure that cleanup code was always run, or write\\nexcept blocks to catch and recover from specific exceptions and optionally specify an\\nelse clause to be run if no exceptions occurred.\\nThat is, the finally clause could not be mixed with except and else. This was partly\\nbecause of implementation issues, and partly because the meaning of mixing the two\\nseemed obscure—catching and recovering from exceptions seemed a disjoint concept\\nfrom performing cleanup actions.\\nIn Python 2.5 and later, though (including 2.6 and 3.0, the versions used in this book),\\nthe two statements have merged. Today, we can mix finally, except, and else clauses\\nin the same statement. That is, we can now write a statement of this form:\\ntry:                               # Merged form\\n    main-action\\nexcept Exception1:\\n    handler1\\nexcept Exception2:\\n    handler2\\n...\\nelse:\\n    else-block\\nfinally:\\n    finally-block\\nThe code in this statement’s main-action block is executed first, as usual. If that code\\nraises an exception, all the except blocks are tested, one after another, looking for a\\nmatch to the exception raised. If the exception raised is Exception1, the handler1 block\\nis executed; if it’s Exception2, handler2 is run, and so on. If no exception is raised, the\\nelse-block is executed.\\nNo matter what’s happened previously, the finally-block is executed once the main\\naction block is complete and any raised exceptions have been handled. In fact, the code\\nin the finally-block will be run even if there is an error in an exception handler or the\\nelse-block and a new exception is raised.\\nAs always, the finally clause does not end the exception—if an exception is active\\nwhen the finally-block is executed, it continues to be propagated after the finally-\\nblock runs, and control jumps somewhere else in the program (to another try, or to\\nthe default top-level handler). If no exception is active when the finally is run, control\\nresumes after the entire try statement.\\nThe net effect is that the finally is always run, regardless of whether:\\n• An exception occurred in the main action and was handled.\\n• An exception occurred in the main action and was not handled.\\n844 | Chapter 33: \\u2002Exception Coding Details', metadata={'source': 'python.pdf', 'page': 894}),\n",
       " Document(page_content='• No exceptions occurred in the main action.\\n• A new exception was triggered in one of the handlers.\\nAgain, the finally\\n serves to specify cleanup actions that must always occur on the way\\nout of the try, regardless of what exceptions have been raised or handled.\\nUnified try Statement Syntax\\nWhen combined like this, the try statement must have either an except or a finally,\\nand the order of its parts must be like this:\\ntry -> except -> else -> finally\\nwhere the else and finally are optional, and there may be zero or more except, but\\nthere must be at least one except if an else appears. Really, the try statement consists\\nof two parts: excepts with an optional else, and/or the finally.\\nIn fact, it’s more accurate to describe the merged statement’s syntactic form this way\\n(square brackets mean optional and star means zero-or-more here):\\ntry:                               # Format 1\\n    statements\\nexcept [type [as value]]:          # [type [, value]] in Python 2\\n    statements\\n[except [type [as value]]:\\n    statements]*\\n[else:\\n    statements]\\n[finally:\\n    statements]\\ntry:                               # Format 2\\n    statements\\nfinally:\\n    statements\\nBecause of these rules, the else can appear only if there is at least one except, and it’s\\nalways possible to mix except and finally, regardless of whether an else appears or\\nnot. It’s also possible to mix finally and else, but only if an except appears too (though\\nthe except can omit an exception name to catch everything and run a raise statement,\\ndescribed later, to reraise the current exception). If you violate any of these ordering\\nrules, Python will raise a syntax error exception before your code runs.\\nCombining finally and except by Nesting\\nPrior to Python 2.5, it is actually possible to combine finally and except clauses in a\\ntry by syntactically nesting a try/except in the try block of a try/finally statement\\n(we’ll explore this technique more fully in Chapter 35 ). In fact, the following has the\\nsame effect as the new merged form shown at the start of this section:\\nUnified try/except/finally | 845', metadata={'source': 'python.pdf', 'page': 895}),\n",
       " Document(page_content=\"try:                               # Nested equivalent to merged form\\n    try:\\n        main-action\\n    except Exception1:\\n        handler1\\n    except Exception2:\\n        handler2\\n    ...\\n    else:\\n        no-error\\nfinally:\\n    cleanup\\nAgain, the finally  \\nblock is always run on the way out, regardless of what happened in\\nthe main action and regardless of any exception handlers run in the nested try (trace\\nthrough the four cases listed previously to see how this works the same). Since an\\nelse always requires an except, this nested form even sports the same mixing con-\\nstraints of the unified statement form outlined in the preceding section.\\nHowever, this nested equivalent is more obscure and requires more code than the new\\nmerged form (one four-character line, at least). Mixing finally into the same statement\\nmakes your code easier to write and read, so this is the generally preferred technique\\ntoday.\\nUnified try Example\\nHere’s a demonstration of the merged try statement form at work. The following file, \\nmergedexc.py, codes four common scenarios, with print statements that describe the\\nmeaning of each:\\nsep = '-' * 32 + '\\\\n'\\nprint(sep + 'EXCEPTION RAISED AND CAUGHT')\\ntry:\\n    x = 'spam'[99]\\nexcept IndexError:\\n    print('except run')\\nfinally:\\n    print('finally run')\\nprint('after run')\\nprint(sep + 'NO EXCEPTION RAISED')\\ntry:\\n    x = 'spam'[3]\\nexcept IndexError:\\n    print('except run')\\nfinally:\\n    print('finally run')\\nprint('after run')\\nprint(sep + 'NO EXCEPTION RAISED, WITH ELSE')\\ntry:\\n846 | Chapter 33: \\u2002Exception Coding Details\", metadata={'source': 'python.pdf', 'page': 896}),\n",
       " Document(page_content='    x = \\'spam\\'[3]\\nexcept IndexError:\\n    print(\\'except run\\')\\nelse:\\n    print(\\'else run\\')\\nfinally:\\n    print(\\'finally run\\')\\nprint(\\'after run\\')\\nprint(sep + \\'EXCEPTION RAISED BUT NOT CAUGHT\\')\\ntry:\\n    x = 1 / 0\\nexcept IndexError:\\n    print(\\'except run\\')\\nfinally:\\n    print(\\'finally run\\')\\nprint(\\'after run\\')\\nWhen this code \\nis run, the following output is produced in Python 3.0 (actually, its\\nbehavior and output are the same in 2.6, because the print calls each print a single\\nitem). Trace through the code to see how exception handling produces the output of\\neach of the four tests here:\\nc:\\\\misc> C:\\\\Python30\\\\python mergedexc.py\\n--------------------------------\\nEXCEPTION RAISED AND CAUGHT\\nexcept run\\nfinally run\\nafter run\\n--------------------------------\\nNO EXCEPTION RAISED\\nfinally run\\nafter run\\n--------------------------------\\nNO EXCEPTION RAISED, WITH ELSE\\nelse run\\nfinally run\\nafter run\\n--------------------------------\\nEXCEPTION RAISED BUT NOT CAUGHT\\nfinally run\\nTraceback (most recent call last):\\n  File \"mergedexc.py\", line 36, in <module>\\n    x = 1 / 0\\nZeroDivisionError: int division or modulo by zero\\nThis example uses built-in operations in the main action to trigger exceptions (or not),\\nand it relies on the fact that Python always checks for errors as code is running. The\\nnext section shows how to raise exceptions manually instead.\\nUnified try/except/finally | 847', metadata={'source': 'python.pdf', 'page': 897}),\n",
       " Document(page_content='The raise Statement\\nTo trigger exceptions explicitly, \\nyou can code raise statements. Their general form is\\nsimple—a raise statement consists of the word raise, optionally followed by the class\\nto be raised or an instance of it:\\nraise <instance>             # Raise instance of class\\nraise <class>                # Make and raise instance of class\\nraise                        # Reraise the most recent exception\\nAs mentioned earlier, exceptions are always instances of classes in Python 2.6 and 3.0.\\nHence, the first raise form here is the most common—we provide an instance directly,\\neither created before the raise or within the raise statement itself. If we pass a class\\ninstead, Python calls the class with no constructor arguments, to create an instance to\\nbe raised; this form is equivalent to adding parentheses after the class reference. The\\nlast form reraises the most recently raised exception; it’s commonly used in exception\\nhandlers to propagate exceptions that have been caught.\\nTo make this clearer, let’s look at some examples. With built-in exceptions, the fol-\\nlowing two forms are equivalent—both raise an instance of the exception class named,\\nbut the first creates the instance implicitly:\\nraise IndexError             # Class (instance created)\\nraise IndexError()           # Instance (created in statement)\\nWe can also create the instance ahead of time—because the raise statement accepts\\nany kind of object reference, the following two examples raise IndexError just like the\\nprior two:\\nexc = IndexError()           # Create instance ahead of time\\nraise exc\\nexcs = [IndexError, TypeError]\\nraise excs[0]\\nWhen an exception is raised, Python sends the raised instance along with the exception.\\nIf a try includes an except name as X: clause, the variable X will be assigned the instance\\nprovided in the raise:\\ntry:\\n    ...\\nexcept IndexError as X:      # X assigned the raised instance object\\n   ...\\nThe as is optional in a try handler (if it’s omitted, the instance is simply not assigned\\nto a name), but including it allows the handler to access both data in the instance and\\nmethods in the exception class.\\nThis model works the same for user-defined exceptions we code with classes—the\\nfollowing, for example, passes to the exception class constructor arguments that be-\\ncome available in the handler through the assigned instance:\\n848 | Chapter 33: \\u2002Exception Coding Details', metadata={'source': 'python.pdf', 'page': 898}),\n",
       " Document(page_content='class MyExc(Exception): pass\\n...\\nraise MyExc(\\'spam\\')          # Exception class with constructor args\\n...\\ntry:\\n    ...\\nexcept MyExc as X:           # Instance attributes available in handler\\n    print(X.args)\\nBecause this encroaches \\non the next chapter’s topic, though, I’ll defer further details\\nuntil then.\\nRegardless of how you name them, exceptions are always identified by instance objects,\\nand at most one is active at any given time. Once caught by an except clause anywhere\\nin the program, an exception dies (i.e., won’t propagate to another try), unless it’s\\nreraised by another raise statement or error.\\nPropagating Exceptions with raise\\nA raise statement that does not include an exception name or extra data value simply\\nreraises the current exception. This form is typically used if you need to catch and\\nhandle an exception but don’t want the exception to die in your code:\\n>>> try:\\n...     raise IndexError(\\'spam\\')         # Exceptions remember arguments\\n... except IndexError:\\n...     print(\\'propagating\\')\\n...     raise                            # Reraise most recent exception\\n...\\npropagating\\nTraceback (most recent call last):\\n  File \"<stdin>\", line 2, in <module>\\nIndexError: spam\\nRunning a raise this way reraises the exception and propagates it to a higher handler\\n(or the default handler at the top, which stops the program with a standard error mes-\\nsage). Notice how the argument we passed to the exception class shows up in the error\\nmessages; you’ll learn why this happens in the next chapter.\\nPython 3.0 Exception Chaining: raise from\\nPython 3.0 (but not 2.6) also allows raise statements to have an optional from clause:\\nraise exception from otherexception\\nWhen the from is used, the second expression specifies another exception class or in-\\nstance to attach to the raised exception’s __cause__ attribute. If the raised exception is\\nnot caught, Python prints both exceptions as part of the standard error message:\\n>>> try:\\n...    1 / 0\\n... except Exception as E:\\nThe raise Statement | 849', metadata={'source': 'python.pdf', 'page': 899}),\n",
       " Document(page_content='...    raise TypeError(\\'Bad!\\') from E\\n...\\nTraceback (most recent call last):\\n  File \"<stdin>\", line 2, in <module>\\nZeroDivisionError: int division or modulo by zero\\nThe above exception was the direct cause of the following exception:\\nTraceback (most recent call last):\\n  File \"<stdin>\", line 4, in <module>\\nTypeError: Bad!\\nWhen an exception \\nis raised inside an exception handler, a similar procedure is fol-\\nlowed implicitly: the previous exception is attached to the new exception’s\\n__context__ attribute and is again displayed in the standard error message if the ex-\\nception goes uncaught. This is an advanced and still somewhat obscure extension, so\\nsee Python’s manuals for more details.\\nVersion skew note : Python 3.0 no longer supports the raise Exc, Args\\nform that is still available in Python 2.6. In 3.0, use the raise\\nExc(Args) instance-creation call form described in this book instead.\\nThe equivalent comma form in 2.6 is legacy syntax provided for com-\\npatibility with the now defunct string-based exceptions model, and it’s\\ndeprecated in 3.0. If used, it is converted to the 3.0 call form. As in earlier\\nreleases, a raise Exc form is also allowed—it is converted to raise\\nExc() in both versions, calling the class constructor with no arguments.\\nThe assert Statement\\nAs a somewhat special case for debugging purposes, Python includes the assert state-\\nment. It is mostly just syntactic shorthand for a common raise usage pattern, and an\\nassert can be thought of as a conditional raise statement. A statement of the form:\\nassert <test>, <data>          # The <data> part is optional\\nworks like the following code:\\nif __debug__:\\n    if not <test>:\\n        raise AssertionError(<data>)\\nIn other words, if the test evaluates to false, Python raises an exception: the data item\\n(if it’s provided) is used as the exception’s constructor argument. Like all exceptions,\\nthe AssertionError exception will kill your program if it’s not caught with a try, in\\nwhich case the data item shows up as part of the error message.\\nAs an added feature, assert statements may be removed from a compiled program’s\\nbyte code if the -O Python command-line flag is used, thereby optimizing the program.\\nAssertionError is a built-in exception, and the __debug__ flag is a built-in name that is\\n850 | Chapter 33: \\u2002Exception Coding Details', metadata={'source': 'python.pdf', 'page': 900}),\n",
       " Document(page_content='automatically set to True unless the -O  flag is used. Use a command line like python –O\\nmain.py to run in optimized mode and disable asserts.\\nExample: Trapping Constraints (but Not Errors!)\\nAssertions are typically used to verify program conditions during development. When\\ndisplayed, their error message text automatically includes source code line information\\nand the value listed in the assert statement. Consider the file asserter.py:\\ndef f(x):\\n    assert x < 0, \\'x must be negative\\'\\n    return x ** 2\\n% python\\n>>> import asserter\\n>>> asserter.f(1)\\nTraceback (most recent call last):\\n  File \"<stdin>\", line 1, in <module>\\n  File \"asserter.py\", line 2, in f\\n    assert x < 0, \\'x must be negative\\'\\nAssertionError: x must be negative\\nIt’s important to keep in mind that assert is mostly intended for trapping user-defined\\nconstraints, not for catching genuine programming errors. Because Python traps pro-\\ngramming errors itself, there is usually no need to code asserts to catch things like out-\\nof-bounds indexes, type mismatches, and zero divides:\\ndef reciprocal(x):\\n    assert x != 0              # A useless assert!\\n    return 1 / x               # Python checks for zero automatically\\nSuch asserts are generally superfluous—because Python raises exceptions on errors\\nautomatically, you might as well let it do the job for you.‡ For another example of\\ncommon assert usage, see the abstract superclass example in Chapter 28 ; there, we\\nused assert to make calls to undefined methods fail with a message.\\nwith/as Context Managers\\nPython 2.6 and 3.0 introduced a new exception-related statement—the with, and its\\noptional as clause. This statement is designed to work with context manager objects,\\nwhich support a new method-based protocol. This feature is also available as an option\\nin 2.5, enabled with an import of this form:\\nfrom __future__ import with_statement\\n‡ In most cases, at least. As suggested earlier in the book, if a function has to perform long-running or\\nunrecoverable actions \\nbefore it reaches the place where an exception will be triggered, you still might want\\nto test for errors. Even in this case, though, be careful not to make your tests overly specific or restrictive, or\\nyou will limit your code’s utility.\\nwith/as Context Managers | 851', metadata={'source': 'python.pdf', 'page': 901}),\n",
       " Document(page_content=\"In short, the with/as statement is designed to be an alternative to a common try/\\nfinally usage idiom; like that statement, it is intended for specifying termination-time\\nor “cleanup” activities that must run regardless of whether an exception occurs in a\\nprocessing step. Unlike try/finally, though, the with statement supports a richer\\nobject-based protocol for specifying both entry and exit actions around a block of code.\\nPython enhances some built-in tools with context managers, such as files that auto-\\nmatically close themselves and thread locks that automatically lock and unlock, but\\nprogrammers can code context managers of their own with classes, too.\\nBasic Usage\\nThe basic format of the with statement looks like this:\\nwith expression [as variable]:\\n    with-block\\nThe expression here is assumed to return an object that supports the context manage-\\nment protocol (more on this protocol in a moment). This object may also return a value\\nthat will be assigned to the name variable if the optional as clause is present.\\nNote that the variable is not necessarily assigned the result of the expression; the result\\nof the expression is the object that supports the context protocol, and the variable may\\nbe assigned something else intended to be used inside the statement. The object re-\\nturned by the expression may then run startup code before the with-block is started,\\nas well as termination code after the block is done, regardless of whether the block\\nraised an exception or not.\\nSome built-in Python objects have been augmented to support the context management\\nprotocol, and so can be used with the with statement. For example, file objects (covered\\nin Chapter 9 ) have a context manager that automatically closes the file after the with\\nblock regardless of whether an exception is raised:\\nwith open(r'C:\\\\misc\\\\data') as myfile:\\n    for line in myfile:\\n        print(line)\\n        ...more code here...\\nHere, the call to open returns a simple file object that is assigned to the name myfile.\\nWe can use myfile with the usual file tools—in this case, the file iterator reads line by\\nline in the for loop.\\nHowever, this object also supports the context management protocol used by the\\nwith statement. After this with statement has run, the context management machinery\\nguarantees that the file object referenced by myfile is automatically closed, even if the\\nfor loop raised an exception while processing the file.\\nAlthough file objects are automatically closed on garbage collection, it’s not always\\nstraightforward to know when that will occur. The with statement in this role is an\\nalternative that allows us to be sure that the close will occur after execution of a specific\\n852 | Chapter 33: \\u2002Exception Coding Details\", metadata={'source': 'python.pdf', 'page': 902}),\n",
       " Document(page_content=\"block of code. As we saw earlier, we can achieve a similar effect with the more general\\nand explicit try/finally \\nstatement, but it requires four lines of administrative code\\ninstead of one in this case:\\nmyfile = open(r'C:\\\\misc\\\\data')\\ntry:\\n    for line in myfile:\\n        print(line)\\n        ...more code here...\\nfinally:\\n    myfile.close()\\nWe won’t cover Python’s multithreading modules in this book (for more on that topic,\\nsee follow-up application-level texts such as Programming Python ), but the lock and\\ncondition synchronization objects they define may also be used with the with statement,\\nbecause they support the context management protocol:\\nlock = threading.Lock()\\nwith lock:\\n    # critical section of code\\n    ...access shared resources...\\nHere, the context management machinery guarantees that the lock is automatically\\nacquired before the block is executed and released once the block is complete, regard-\\nless of exception outcomes.\\nAs introduced in Chapter 5, the decimal module also uses context managers to simplify\\nsaving and restoring the current decimal context, which specifies the precision and\\nrounding characteristics for calculations:\\nwith decimal.localcontext() as ctx:\\n    ctx.prec = 2\\n    x = decimal.Decimal('1.00') / decimal.Decimal('3.00')\\nAfter this statement runs, the current thread’s context manager state is automatically\\nrestored to what it was before the statement began. To do the same with a try/\\nfinally, we would need to save the context before and restore it manually.\\nThe Context Management Protocol\\nAlthough some built-in types come with context managers, we can also write new ones\\nof our own. To implement context managers, classes use special methods that fall into\\nthe operator overloading category to tap into the with statement. The interface expected\\nof objects used in with statements is somewhat complex, and most programmers only\\nneed to know how to use existing context managers. For tool builders who might want\\nto write new application-specific context managers, though, let’s take a quick look at\\nwhat’s involved.\\nHere’s how the with statement actually works:\\nwith/as Context Managers | 853\", metadata={'source': 'python.pdf', 'page': 903}),\n",
       " Document(page_content=\"1. The expression is evaluated, resulting in an object known as a context manager  that\\nmust have __enter__ and __exit__ methods.\\n2. The context manager’s __enter__ method is called. The value it returns is assigned\\nto the variable in the as clause if present, or simply discarded otherwise.\\n3. The code in the nested with block is executed.\\n4. If the with block raises an exception, the __exit__(type, value, traceback) method\\nis called with the exception details. Note that these are the same values returned\\nby sys.exc_info, described in the Python manuals and later in this part of the book.\\nIf this method returns a false value, the exception is reraised; otherwise, the ex-\\nception is terminated. The exception should normally be reraised so that it is\\npropagated outside the with statement.\\n5. If the with block does not raise an exception, the __exit__ method is still called,\\nbut its type, value, and traceback arguments are all passed in as None.\\nLet’s look at a quick demo of the protocol in action. The following defines a context\\nmanager object that traces the entry and exit of the with block in any with statement it\\nis used for:\\nclass TraceBlock:\\n    def message(self, arg):\\n        print('running', arg)\\n    def __enter__(self):\\n        print('starting with block')\\n        return self\\n    def __exit__(self, exc_type, exc_value, exc_tb):\\n        if exc_type is None:\\n            print('exited normally\\\\n')\\n        else:\\n            print('raise an exception!', exc_type)\\n            return False                                  # Propagate\\nwith TraceBlock() as action:\\n    action.message('test 1')\\n    print('reached')\\nwith TraceBlock() as action:\\n    action.message('test 2')\\n    raise TypeError\\n    print('not reached')\\nNotice that this class’s __exit__ method returns False to propagate the exception;\\ndeleting the return statement would have the same effect, as the default None return\\nvalue of functions is False by definition. Also notice that the __enter__ method returns\\nself as the object to assign to the as variable; in other use cases, this might return a\\ncompletely different object instead.\\nWhen run, the context manager traces the entry and exit of the with statement block\\nwith its __enter__ and __exit__ methods. Here’s the script in action being run under\\nPython 3.0 (it runs in 2.6, too, but prints some extra tuple parentheses):\\n854 | Chapter 33: \\u2002Exception Coding Details\", metadata={'source': 'python.pdf', 'page': 904}),\n",
       " Document(page_content='% python withas.py\\nstarting with block\\nrunning test 1\\nreached\\nexited normally\\nstarting with block\\nrunning test 2\\nraise an exception! <class \\'TypeError\\'>\\nTraceback (most recent call last):\\n  File \"withas.py\", line 20, in <module>\\n    raise TypeError\\nTypeError\\nContext managers are \\nsomewhat advanced devices for tool builders, so we’ll skip ad-\\nditional details here (see Python’s standard manuals for the full story—for example,\\nthere’s a new contextlib standard module that provides additional tools for coding\\ncontext managers). For simpler purposes, the try/finally statement provides sufficient\\nsupport for termination-time activities.\\nIn the upcoming Python 3.1 release, the with statement may also specify\\nmultiple (sometimes referred to as “nested”) context managers with new\\ncomma syntax. In the following, for example, both files’ exit actions are\\nautomatically run when the statement block exits, regardless of excep-\\ntion outcomes:\\nwith open(\\'data\\') as fin, open(\\'res\\', \\'w\\') as fout:\\n    for line in fin:\\n        if \\'some key\\' in line:\\n            fout.write(line)\\nAny number of context manager items may be listed, and multiple items\\nwork the same as nested with statements. In general, the 3.1 (and later)\\ncode:\\nwith A() as a, B() as b:\\n    ...statements...\\nis equivalent to the following, which works in 3.1, 3.0, and 2.6:\\nwith A() as a:\\n    with B() as b:\\n        ...statements...\\nSee Python 3.1 release notes for additional details.\\nChapter Summary\\nIn this chapter, we took a more detailed look at exception processing by exploring the\\nstatements related to exceptions in Python: try to catch them, raise to trigger them,\\nassert to raise them conditionally, and with to wrap code blocks in context managers\\nthat specify entry and exit actions.\\nChapter Summary | 855', metadata={'source': 'python.pdf', 'page': 905}),\n",
       " Document(page_content='So far, exceptions probably seem like a fairly lightweight tool, and in fact, they are; the\\nonly substantially complex \\nthing about them is how they are identified. The next chap-\\nter continues our exploration by describing how to implement exception objects of\\nyour own; as you’ll see, classes allow you to code new exceptions specific to your\\nprograms. Before we move ahead, though, let’s work though the following short quiz\\non the basics covered here.\\nTest Your Knowledge: Quiz\\n1. What is the try\\n statement for?\\n2. What are the two common variations of the try statement?\\n3. What is the raise statement for?\\n4. What is the assert statement designed to do, and what other statement is it like?\\n5. What is the with/as statement designed to do, and what other statement is it like?\\nTest Your Knowledge: Answers\\n1. The try statement catches and recovers from exceptions—it specifies a block of\\ncode to run, and one or more handlers for exceptions that may be raised during\\nthe block’s execution.\\n2. The two common variations on the try statement are try/except/else (for catching\\nexceptions) and try/finally (for specifying cleanup actions that must occur\\nwhether an exception is raised or not). In Python 2.4, these were separate state-\\nments that could be combined by syntactic nesting; in 2.5 and later, except and\\nfinally blocks may be mixed in the same statement, so the two statement forms\\nare merged. In the merged form, the finally is still run on the way out of the try,\\nregardless of what exceptions may have been raised or handled.\\n3. The raise statement raises (triggers) an exception. Python raises built-in excep-\\ntions on errors internally, but your scripts can trigger built-in or user-defined ex-\\nceptions with raise, too.\\n4. The assert statement raises an AssertionError exception if a condition is false. It\\nworks like a conditional raise statement wrapped up in an if statement.\\n5. The with/as statement is designed to automate startup and termination activities\\nthat must occur around a block of code. It is roughly like a try/finally statement\\nin that its exit actions run whether an exception occurred or not, but it allows a\\nricher object-based protocol for specifying entry and exit actions.\\n856 | Chapter 33: \\u2002Exception Coding Details', metadata={'source': 'python.pdf', 'page': 906}),\n",
       " Document(page_content='CHAPTER 34\\nException Objects\\nSo far, I’ve been deliberately vague about what an exception actually is. As suggested\\nin the prior chapter, in Python 2.6 and 3.0 both built-in and user-defined exceptions\\nare identified by class instance objects. Although this means you must use object-\\noriented programming to define new exceptions in your programs, classes and OOP\\nin general offer a number of benefits.\\nHere are some of the advantages of class-based exceptions:\\n•They can be organized into categories . Exception classes support future changes\\nby providing categories—adding new exceptions in the future won’t generally re-\\nquire changes in try statements.\\n•They have attached state information . Exception classes provide a natural place\\nfor us to store context information for use in the try handler—they may have both\\nattached state information and callable methods, accessible through instances.\\n•They support inheritance . Class-based exceptions can participate in inheritance\\nhierarchies to obtain and customize common behavior—inherited display meth-\\nods, for example, can provide a common look and feel for error messages.\\nBecause of these advantages, class-based exceptions support program evolution and\\nlarger systems well. In fact, all built-in exceptions are identified by classes and are\\norganized into an inheritance tree, for the reasons just listed. You can do the same with\\nuser-defined exceptions of your own.\\nIn Python 3.0, user-defined exceptions inherit from built-in exception superclasses. As\\nwe’ll see here, because these superclasses provide useful defaults for printing and state\\nretention, the task of coding user-defined exceptions also involves understanding the\\nroles of these built-ins.\\n857', metadata={'source': 'python.pdf', 'page': 907}),\n",
       " Document(page_content='Version skew note : Python 2.6 and 3.0 both require exceptions to be\\ndefined by classes. In addition, 3.0 requires exception classes to be de-\\nrived from the BaseException built-in exception superclass, either di-\\nrectly or indirectly. As we’ll see, most programs inherit from this class’s\\nException subclass, to support catchall handlers for normal exception\\ntypes—naming it in a handler will catch everything most programs\\nshould. Python 2.6 allows standalone classic classes to serve as excep-\\ntions, too, but it requires new-style classes to be derived from built-in\\nexception classes, the same as 3.0.\\nExceptions: Back to the Future\\nOnce upon a time (well, prior to Python 2.6 and 3.0), it was possible to define excep-\\ntions in two different ways. This complicated try statements, raise statements, and\\nPython in general. Today, there is only one way to do it. This is a good thing: it removes\\nfrom the language substantial cruft accumulated for the sake of backward compatibil-\\nity. Because the old way helps explain why exceptions are as they are today, though,\\nand because it’s not really possible to completely erase the history of something that\\nhas been used by a million people over the course of nearly two decades, let’s begin our\\nexploration of the present with a brief look at the past.\\nString Exceptions Are Right Out!\\nPrior to Python 2.6 and 3.0, it was possible to define exceptions with both class in-\\nstances and string objects. String-based exceptions began issuing deprecation warnings\\nin 2.5 and were removed in 2.6 and 3.0, so today you should use class-based exceptions,\\nas shown in this book. If you work with legacy code, though, you might still come\\nacross string exceptions. They might also appear in tutorials and web resources written\\na few years ago (which qualifies as an eternity in Python years!).\\nString exceptions were straightforward to use—any string would do, and they matched\\nby object identity, not value (that is, using is, not ==):\\nC:\\\\misc> C:\\\\Python25\\\\python\\n>>> myexc = \"My exception string\"                 # Were we ever this young?\\n>>> try:\\n...     raise myexc\\n... except myexc:\\n...     print(\\'caught\\')\\n...\\ncaught\\nThis form of exception was removed because it was not as good as classes for larger\\nprograms and code maintenance. Although you can’t use string exceptions today, they\\nactually provide a natural vehicle for introducing the class-based exceptions model.\\n858 | Chapter 34: \\u2002Exception Objects', metadata={'source': 'python.pdf', 'page': 908}),\n",
       " Document(page_content='Class-Based Exceptions\\nStrings were a \\nsimple way to define exceptions. As described earlier, however, classes\\nhave some added advantages that merit a quick look. Most prominently, they allow us\\nto identify exception categories that are more flexible to use and maintain than simple\\nstrings. Moreover, classes naturally allow for attached exception details and support\\ninheritance. Because they are the better approach, they are now required.\\nCoding details aside, the chief difference between string and class exceptions has to do\\nwith the way that exceptions raised are matched against except clauses in try\\nstatements:\\n• String exceptions were matched by simple object identity : the raised exception was\\nmatched to except clauses by Python’s is test.\\n• Class exceptions are matched by superclass relationships : the raised exception\\nmatches an except clause if that except clause names the exception’s class or any\\nsuperclass of it.\\nThat is, when a try statement’s except clause lists a superclass, it catches instances of\\nthat superclass, as well as instances of all its subclasses lower in the class tree. The net\\neffect is that class exceptions support the construction of exception hierarchies: super-\\nclasses become category names, and subclasses become specific kinds of exceptions\\nwithin a category. By naming a general exception superclass, an except clause can catch\\nan entire category of exceptions—any more specific subclass will match.\\nString exceptions had no such concept: because they were matched by simple object\\nidentity, there was no direct way to organize exceptions into more flexible categories\\nor groups. The net result was that exception handlers were coupled with exception sets\\nin a way that made changes difficult.\\nIn addition to this category idea, class-based exceptions better support exception state\\ninformation (attached to instances) and allow exceptions to participate in inheritance\\nhierarchies (to obtain common behaviors). Because they offer all the benefits of classes\\nand OOP in general, they provide a more powerful alternative to the now defunct string-\\nbased exceptions model in exchange for a small amount of additional code.\\nCoding Exceptions Classes\\nLet’s look at an example to see how class exceptions translate to code. In the following\\nfile, classexc.py, we define a superclass called General and two subclasses called\\nSpecific1 and Specific2. This example illustrates the notion of exception categories—\\nGeneral is a category name, and its two subclasses are specific types of exceptions within\\nthe category. Handlers that catch General will also catch any subclasses of it, including\\nSpecific1 and Specific2:\\nclass General(Exception): pass\\nclass Specific1(General): pass\\nExceptions: Back to the Future | 859', metadata={'source': 'python.pdf', 'page': 909}),\n",
       " Document(page_content=\"class Specific2(General): pass\\ndef raiser0():\\n    X = General()          # Raise superclass instance\\n    raise X\\ndef raiser1():\\n    X = Specific1()        # Raise subclass instance\\n    raise X\\ndef raiser2():\\n    X = Specific2()        # Raise different subclass instance\\n    raise X\\nfor func in (raiser0, raiser1, raiser2):\\n    try:\\n        func()\\n    except General:        # Match General or any subclass of it\\n        import sys\\n        print('caught:', sys.exc_info()[0])\\nC:\\\\python30> python classexc.py\\ncaught: <class '__main__.General'>\\ncaught: <class '__main__.Specific1'>\\ncaught: <class '__main__.Specific2'>\\nThis code is mostly straightforward, but here are a few implementation notes:\\nException superclass\\nClasses used to \\nbuild exception category trees have very few requirements—in fact,\\nin this example they are mostly empty, with bodies that do nothing but pass. No-\\ntice, though, how the top-level class here inherits from the built-in Exception class.\\nThis is required in Python 3.0; Python 2.6 allows standalone classic classes to serve\\nas exceptions too, but it requires new-style classes to be derived from built-in ex-\\nception classes just like in 3.0. Although we don’t employ it here, because\\nException provides some useful behavior we’ll meet later, it’s a good idea to inherit\\nfrom it in either Python.\\nRaising instances\\nIn this code, we call classes to make instances for the raise statements. In the class\\nexception model, we always raise and catch a class instance object. If we list a class\\nname without parentheses in a raise, Python calls the class with no constructor\\nargument to make an instance for us. Exception instances can be created before\\nthe raise, as done here, or within the raise statement itself.\\nCatching categories\\nThis code includes functions that raise instances of all three of our classes as ex-\\nceptions, as well as a top-level try that calls the functions and catches General\\nexceptions. The same try also catches the two specific exceptions, because they\\nare subclasses of General.\\n860 | Chapter 34: \\u2002Exception Objects\", metadata={'source': 'python.pdf', 'page': 910}),\n",
       " Document(page_content=\"Exception details\\nThe exception handler \\nhere uses the sys.exc_info call—as we’ll see in more detail\\nin the next chapter, it’s how we can grab hold of the most recently raised exception\\nin a generic fashion. Briefly, the first item in its result is the class of the exception\\nraised, and the second is the actual instance raised. In a general except clause like\\nthe one here that catches all classes in a category, sys.exc_info is one way to de-\\ntermine exactly what’s occurred. In this particular case, it’s equivalent to fetching\\nthe instance’s __class__ attribute. As we’ll see in the next chapter, the\\nsys.exc_info scheme is also commonly used with empty except clauses that catch\\neverything.\\nThe last point merits further explanation. When an exception is caught, we can be sure\\nthat the instance raised is an instance of the class listed in the except, or one of its more\\nspecific subclasses. Because of this, the __class__ attribute of the instance also gives\\nthe exception type. The following variant, for example, works the same as the prior\\nexample:\\nclass General(Exception): pass\\nclass Specific1(General): pass\\nclass Specific2(General): pass\\ndef raiser0(): raise General()\\ndef raiser1(): raise Specific1()\\ndef raiser2(): raise Specific2()\\nfor func in (raiser0, raiser1, raiser2):\\n    try:\\n        func()\\n    except General as X:                     # X is the raised instance\\n        print('caught:', X.__class__)        # Same as sys.exc_info()[0]\\nBecause __class__ can be used like this to determine the specific type of exception\\nraised, sys.exc_info is more useful for empty except clauses that do not otherwise have\\na way to access the instance or its class. Furthermore, more realistic programs usually\\nshould not have to care  about which specific exception was raised at all—by calling\\nmethods of the instance generically, we automatically dispatch to behavior tailored for\\nthe exception raised. More on this and sys.exc_info in the next chapter; also see\\nChapter 28  and Part VI  at large if you’ve forgotten what __class__ means in an instance.\\nWhy Exception Hierarchies?\\nBecause there are only three possible exceptions in the prior section’s example, it\\ndoesn’t really do justice to the utility of class exceptions. In fact, we could achieve the\\nsame effects by coding a list of exception names in parentheses within the except clause:\\ntry:\\n    func()\\nexcept (General, Specific1, Specific2):     # Catch any of these\\n    ...\\nWhy Exception Hierarchies? | 861\", metadata={'source': 'python.pdf', 'page': 911}),\n",
       " Document(page_content='This approach worked for the defunct string exception model too. For large or high\\nexception hierarchies, however, \\nit may be easier to catch categories using class-based\\ncategories than to list every member of a category in a single except clause. Perhaps\\nmore importantly, you can extend exception hierarchies by adding new subclasses\\nwithout breaking existing code.\\nSuppose, for example, you code a numeric programming library in Python, to be used\\nby a large number of people. While you are writing your library, you identify two things\\nthat can go wrong with numbers in your code—division by zero, and numeric overflow.\\nYou document these as the two exceptions that your library may raise:\\n# mathlib.py\\nclass Divzero(Exception): pass\\nclass Oflow(Exception): pass\\ndef func():\\n    ...\\n    raise Divzero()\\nNow, when people use your library, they typically wrap calls to your functions or classes\\nin try statements that catch your two exceptions (if they do not catch your exceptions,\\nexceptions from the library will kill their code):\\n# client.py\\nimport mathlib\\ntry:\\n    mathlib.func(...)\\nexcept (mathlib.Divzero, mathlib.Oflow):\\n    ...handle and recover...\\nThis works fine, and lots of people start using your library. Six months down the road,\\nthough, you revise it (as programmers are prone to do). Along the way, you identify a\\nnew thing that can go wrong—underflow—and add that as a new exception:\\n# mathlib.py\\nclass Divzero(Exception): pass\\nclass Oflow(Exception): pass\\nclass Uflow(Exception): pass\\nUnfortunately, when you re-release your code, you create a maintenance problem for\\nyour users. If they’ve listed your exceptions explicitly, they now have to go back and\\nchange every place they call your library to include the newly added exception name:\\n# client.py\\ntry:\\n    mathlib.func(...)\\nexcept (mathlib.Divzero, mathlib.Oflow, mathlib.Uflow):\\n    ...handle and recover...\\n862 | Chapter 34: \\u2002Exception Objects', metadata={'source': 'python.pdf', 'page': 912}),\n",
       " Document(page_content='This may not be the end of the world. If your library is used only in-house, you can\\nmake the changes \\nyourself. You might also ship a Python script that tries to fix such\\ncode automatically (it would probably be only a few dozen lines, and it would guess\\nright at least some of the time). If many people have to change all their try statements\\neach time you alter your exception set, though, this is not exactly the most polite of\\nupgrade policies.\\nYour users might try to avoid this pitfall by coding empty except clauses to catch all\\npossible exceptions:\\n# client.py\\ntry:\\n    mathlib.func(...)\\nexcept:                           # Catch everything here\\n    ...handle and recover...\\nBut this workaround might catch more than they bargained for—things like running\\nout of memory, keyboard interrupts (Ctrl-C), system exits, and even typos in their own\\ntry block’s code will all trigger exceptions, and such things should pass, not be caught\\nand erroneously classified as library errors.\\nAnd really, in this scenario users want to catch and recover from only the specific ex-\\nceptions the library is defined and documented to raise; if any other exception occurs\\nduring a library call, it’s likely a genuine bug in the library (and probably time to contact\\nthe vendor!). As a rule of thumb, it’s usually better to be specific than general in ex-\\nception handlers—an idea we’ll revisit as a “gotcha” in the next chapter.*\\nSo what to do, then? Class exception hierarchies fix this dilemma completely. Rather\\nthan defining your library’s exceptions as a set of autonomous classes, arrange them\\ninto a class tree with a common superclass to encompass the entire category:\\n# mathlib.py\\nclass NumErr(Exception): pass\\nclass Divzero(NumErr): pass\\nclass Oflow(NumErr): pass\\n...\\ndef func():\\n    ...\\n    raise DivZero()\\nThis way, users of your library simply need to list the common superclass (i.e., category)\\nto catch all of your library’s exceptions, both now and in the future:\\n* As a clever student of mine suggested, the library module could also provide a tuple object that contains all\\nthe exceptions the \\nlibrary can possibly raise—the client could then import the tuple and name it in an\\nexcept clause to catch all the library’s exceptions (recall that including a tuple in an except means catch\\nany of its exceptions). When new exceptions are added later, the library can just expand the exported tuple.\\nThis would work, but you’d still need to keep the tuple up-to-date with raised exceptions inside the library\\nmodule. Also, class hierarchies offer more benefits than just categories—they also support inherited state\\nand methods and a customization model that individual exceptions do not.\\nWhy Exception Hierarchies? | 863', metadata={'source': 'python.pdf', 'page': 913}),\n",
       " Document(page_content='# client.py\\nimport mathlib\\n...\\ntry:\\n    mathlib.func(...)\\nexcept mathlib.NumErr:\\n    ...report and recover...\\nWhen you go \\nback and hack your code again, you can add new exceptions as new\\nsubclasses of the common superclass:\\n# mathlib.py\\n...\\nclass Uflow(NumErr): pass\\nThe end result is that user code that catches your library’s exceptions will keep working,\\nunchanged. In fact, you are free to add, delete, and change exceptions arbitrarily in the\\nfuture—as long as clients name the superclass, they are insulated from changes in your\\nexceptions set. In other words, class exceptions provide a better answer to maintenance\\nissues than strings do.\\nClass-based exception hierarchies also support state retention and inheritance in ways\\nthat make them ideal in larger programs. To understand these roles, though, we first\\nneed to see how user-defined exception classes relate to the built-in exceptions from\\nwhich they inherit.\\nBuilt-in Exception Classes\\nI didn’t really pull the prior section’s examples out of thin air. All built-in exceptions\\nthat Python itself may raise are predefined class objects. Moreover, they are organized\\ninto a shallow hierarchy with general superclass categories and specific subclass types,\\nmuch like the exceptions class tree we developed earlier.\\nIn Python 3.0, all the familiar exceptions you’ve seen (e.g., SyntaxError) are really just\\npredefined classes, available as built-in names in the module named builtins (in Python\\n2.6, they instead live in __builtin__ and are also attributes of the standard library\\nmodule exceptions). In addition, Python organizes the built-in exceptions into a hier-\\narchy, to support a variety of catching modes. For example:\\nBaseException\\nThe top-level root superclass of exceptions. This class is not supposed to be directly\\ninherited by user-defined classes (use Exception instead). It provides default print-\\ning and state retention behavior inherited by subclasses. If the str built-in is called\\non an instance of this class (e.g., by print), the class returns the display strings of\\nthe constructor arguments passed when the instance was created (or an empty\\nstring if there were no arguments). In addition, unless subclasses replace this class’s\\n864 | Chapter 34: \\u2002Exception Objects', metadata={'source': 'python.pdf', 'page': 914}),\n",
       " Document(page_content='constructor, all of the arguments passed to this class at instance construction time\\nare stored in its args attribute as a tuple.\\nException\\nThe top-level root \\nsuperclass of application-related exceptions. This is an imme-\\ndiate subclass of BaseException and is superclass to every other built-in exception,\\nexcept the system exit event classes (SystemExit, KeyboardInterrupt, and\\nGeneratorExit). Almost all user-defined classes should inherit from this class, not\\nBaseException. When this convention is followed, naming Exception in a try state-\\nment’s handler ensures that your program will catch everything but system exit\\nevents, which should normally be allowed to pass. In effect, Exception becomes a\\ncatchall in try statements and is more accurate than an empty except.\\nArithmeticError\\nThe superclass of all numeric errors (and a subclass of Exception).\\nOverflowError\\nA subclass of ArithmeticError that identifies a specific numeric error.\\nAnd so on—you can read further about this structure in reference texts such as Python\\nPocket Reference  or the Python library manual. Note that the exceptions class tree dif-\\nfers slightly between Python 3.0 and 2.6. Also note that you can see the class tree in the\\nhelp text of the exceptions module in Python 2.6 only (this module is removed in 3.0).\\nSee Chapters 4 and 15 for help on help:\\n>>> import exceptions\\n>>> help(exceptions)\\n...lots of text omitted...\\nBuilt-in Exception Categories\\nThe built-in class tree allows you to choose how specific or general your handlers will\\nbe. For example, the built-in exception ArithmeticError is a superclass for more specific\\nexceptions such as OverflowError and ZeroDivisionError. By listing ArithmeticError\\nin a try, you will catch any kind of numeric error raised; by listing just\\nOverflowError, you will intercept just that specific type of error, and no others.\\nSimilarly, because Exception is the superclass of all application-level exceptions in Py-\\nthon 3.0, you can generally use it as a catchall—the effect is much like an empty\\nexcept, but it allows system exit exceptions to pass as they usually should:\\ntry:\\n    action()\\nexcept Exception:\\n    ...handle all application exceptions...\\nelse:\\n    ...handle no-exception case...\\nBuilt-in Exception Classes | 865', metadata={'source': 'python.pdf', 'page': 915}),\n",
       " Document(page_content='This doesn’t quite work universally in Python 2.6, however, because standalone user-\\ndefined exceptions coded \\nas classic classes are not required to be subclasses of the\\nException root class. This technique is more reliable in Python 3.0, since it requires all\\nclasses to derive from built-in exceptions. Even in Python 3.0, though, this scheme\\nsuffers most of the same potential pitfalls as the empty except, as described in the prior\\nchapter—it might intercept exceptions intended for elsewhere, and it might mask gen-\\nuine programming errors. Since this is such a common issue, we’ll revisit it as a “gotcha”\\nin the next chapter.\\nWhether or not you will leverage the categories in the built-in class tree, it serves as a\\ngood example; by using similar techniques for class exceptions in your own code, you\\ncan provide exception sets that are flexible and easily modified.\\nDefault Printing and State\\nBuilt-in exceptions also provide default print displays and state retention, which is often\\nas much logic as user-defined classes require. Unless you redefine the constructors your\\nclasses inherit from them, any constructor arguments you pass to these classes are saved\\nin the instance’s args tuple attribute and are automatically displayed when the instance\\nis printed (an empty tuple and display string are used if no constructor arguments are\\npassed).\\nThis explains why arguments passed to built-in exception classes show up in error\\nmessages—any constructor arguments are attached to the instance and displayed when\\nthe instance is printed:\\n>>> raise IndexError                    # Same as IndexError(): no arguments\\nTraceback (most recent call last):\\n  File \"<stdin>\", line 1, in <module>\\nIndexError\\n>>> raise IndexError(\\'spam\\')            # Constructor argument attached, printed\\nTraceback (most recent call last):\\n  File \"<stdin>\", line 1, in <module>\\nIndexError: spam\\n>>> I = IndexError(\\'spam\\')              # Available in object attribute\\n>>> I.args\\n(\\'spam\\',)\\nThe same holds true for user-defined exceptions, because they inherit the constructor\\nand display methods present in their built-in superclasses:\\n>>> class E(Exception): pass\\n...\\n>>> try:\\n...    raise E(\\'spam\\')\\n... except E as X:\\n...    print(X, X.args)                 # Displays and saves constructor arguments\\n...\\nspam (\\'spam\\',)\\n866 | Chapter 34: \\u2002Exception Objects', metadata={'source': 'python.pdf', 'page': 916}),\n",
       " Document(page_content='>>> try:\\n...    raise E(\\'spam\\', \\'eggs\\', \\'ham\\')\\n... except E as X:\\n...    print(X, X.args)\\n...\\n(\\'spam\\', \\'eggs\\', \\'ham\\') (\\'spam\\', \\'eggs\\', \\'ham\\')\\nNote that exception \\ninstance objects are not strings themselves, but use the __str__\\noperator overloading protocol we studied in Chapter 29 to provide display strings when\\nprinted; to concatenate with real strings, perform manual conversions: str(X) +\\n\"string\".\\nAlthough this automatic state and display support is useful by itself, for more specific\\ndisplay and state retention needs you can always redefine inherited methods such as\\n__str__ and __init__ in Exception subclasses—the next section shows how.\\nCustom Print Displays\\nAs we saw in the preceding section, by default, instances of class-based exceptions\\ndisplay whatever you passed to the class constructor when they are caught and printed:\\n>>> class MyBad(Exception): pass\\n...\\n>>> try:\\n...     raise MyBad(\\'Sorry--my mistake!\\')\\n... except MyBad as X:\\n...     print(X)\\n...\\nSorry--my mistake!\\nThis inherited default display model is also used if the exception is displayed as part of\\nan error message when the exception is not caught:\\n>>> raise MyBad(\\'Sorry--my mistake!\\')\\nTraceback (most recent call last):\\n  File \"<stdin>\", line 1, in <module>\\n__main__.MyBad: Sorry--my mistake!\\nFor many roles, this is sufficient. To provide a more custom display, though, you can\\ndefine one of two string-representation overloading methods in your class ( __repr__ or \\n__str__) to return the string you want to display for your exception. The string the\\nmethod returns will be displayed if the exception either is caught and printed or reaches\\nthe default handler:\\n>>> class MyBad(Exception):\\n...     def __str__(self):\\n...         return \\'Always look on the bright side of life...\\'\\n...\\n>>> try:\\n...     raise MyBad()\\n... except MyBad as X:\\n...     print(X)\\nCustom Print Displays | 867', metadata={'source': 'python.pdf', 'page': 917}),\n",
       " Document(page_content='...\\nAlways look on the bright side of life...\\n>>> raise MyBad()\\nTraceback (most recent call last):\\n  File \"<stdin>\", line 1, in <module>\\n__main__.MyBad: Always look on the bright side of life...\\nA subtle point \\nto note here is that you generally must redefine __str__ for this purpose,\\nbecause the built-in superclasses already have a __str__ method, and __str__ is pre-\\nferred to __repr__ in most contexts (including printing). If you define a __repr__, print-\\ning will happily call the superclass’s __str__ instead! See Chapter 29  for more details\\non these special methods.\\nWhatever your method returns is included in error messages for uncaught exceptions\\nand used when exceptions are printed explicitly. The method returns a hardcoded\\nstring here to illustrate, but it can also perform arbitrary text processing, possibly using\\nstate information attached to the instance object. The next section looks at state in-\\nformation options.\\nCustom Data and Behavior\\nBesides supporting flexible hierarchies, exception classes also provide storage for extra\\nstate information as instance attributes. As we saw earlier, built-in exception super-\\nclasses provide a default constructor that automatically saves constructor arguments\\nin an instance tuple attribute named args. Although the default constructor is adequate\\nfor many cases, for more custom needs we can provide a constructor of our own. In\\naddition, classes may define methods for use in handlers that provide precoded excep-\\ntion processing logic.\\nProviding Exception Details\\nWhen an exception is raised, it may cross arbitrary file boundaries—the raise state-\\nment that triggers an exception and the try statement that catches it may be in com-\\npletely different module files. It is not generally feasible to store extra details in global\\nvariables because the try statement might not know which file the globals reside in.\\nPassing extra state information along in the exception itself allows the try statement\\nto access it more reliably.\\nWith classes, this is nearly automatic. As we’ve seen, when an exception is raised,\\nPython passes the class instance object along with the exception. Code in try statements\\ncan access the raised instance by listing an extra variable after the as keyword in an\\nexcept handler. This provides a natural hook for supplying data and behavior to the\\nhandler.\\n868 | Chapter 34: \\u2002Exception Objects', metadata={'source': 'python.pdf', 'page': 918}),\n",
       " Document(page_content=\"For example, a program that parses data files might signal a formatting error by raising\\nan exception instance that is filled out with extra details about the error:\\n>>> class FormatError(Exception):\\n...     def __init__(self, line, file):\\n...         self.line = line\\n...         self.file = file\\n...\\n>>> def parser():\\n...     raise FormatError(42, file='spam.txt')     # When error  found\\n...\\n>>> try:\\n...     parser()\\n... except FormatError as X:\\n...     print('Error at', X.file, X.line)\\n...\\nError at spam.txt 42\\nIn the except \\nclause here, the variable X is assigned a reference to the instance that was\\ngenerated when the exception was raised.† This gives access to the attributes attached\\nto the instance by the custom constructor. Although we could rely on the default state\\nretention of built-in superclasses, it’s less relevant to our application:\\n>>> class FormatError(Exception): pass             # Inherited constructor\\n...\\n>>> def parser():\\n...     raise FormatError(42, 'spam.txt')          # No keywords allowed!\\n...\\n>>> try:\\n...     parser()\\n... except FormatError as X:\\n...     print('Error at:', X.args[0], X.args[1])   # Not specific to this app\\n...\\nError at: 42 spam.txt\\nProviding Exception Methods\\nBesides enabling application-specific state information, custom constructors also better\\nsupport extra behavior for exception objects. That is, the exception class can also define\\nmethods to be called in the handler. The following, for example, adds a method that\\nuses exception state information to log errors to a file:\\nclass FormatError(Exception):\\n    logfile = 'formaterror.txt'\\n    def __init__(self, line, file):\\n        self.line = line\\n        self.file = file\\n† As suggested earlier, the raised instance object is also available generically as the second item in the result\\ntuple of \\nthe sys.exc_info() call—a tool that returns information about the most recently raised exception.\\nThis interface must be used if you do not list an exception name in an except clause but still need access to\\nthe exception that occurred, or to any of its attached state information or methods. More on sys.exc_info\\nin the next chapter.\\nCustom Data and Behavior | 869\", metadata={'source': 'python.pdf', 'page': 919}),\n",
       " Document(page_content=\"    def logerror(self):\\n        log = open(self.logfile, 'a')\\n        print('Error at', self.file, self.line, file=log)\\ndef parser():\\n    raise FormatError(40, 'spam.txt')\\ntry:\\n    parser()\\nexcept FormatError as exc:\\n    exc.logerror()\\nWhen run, this \\nscript writes its error message to a file in response to method calls in\\nthe exception handler:\\nC:\\\\misc> C:\\\\Python30\\\\python parse.py\\nC:\\\\misc> type formaterror.txt\\nError at spam.txt 40\\nIn such a class, methods (like logerror) may also be inherited from superclasses, and\\ninstance attributes (like line and file) provide a place to save state information that\\nprovides extra context for use in later method calls. Moreover, exception classes are\\nfree to customize and extend inherited behavior. In other words, because they are de-\\nfined with classes, all the benefits of OOP that we studied in Part VI  are available for\\nuse with exceptions in Python.\\nChapter Summary\\nIn this chapter, we explored coding user-defined exceptions. As we learned, exceptions\\nare implemented as class instance objects in Python 2.6 and 3.0 (an earlier string-based\\nexception model alternative was available in earlier releases but has now been depre-\\ncated). Exception classes support the concept of exception hierarchies that ease main-\\ntenance, allow data and behavior to be attached to exceptions as instance attributes\\nand methods, and allow exceptions to inherit data and behavior from superclasses.\\nWe saw that in a try statement, catching a superclass catches that class as well as all\\nsubclasses below it in the class tree—superclasses become exception category names,\\nand subclasses become more specific exception types within those categories. We also\\nsaw that the built-in exception superclasses we must inherit from provide usable de-\\nfaults for printing and state retention, which we can override if desired.\\nThe next chapter wraps up this part of the book by exploring some common use cases\\nfor exceptions and surveying tools commonly used by Python programmers. Before we\\nget there, though, here’s this chapter’s quiz.\\n870 | Chapter 34: \\u2002Exception Objects\", metadata={'source': 'python.pdf', 'page': 920}),\n",
       " Document(page_content='Test Your Knowledge: Quiz\\n1. What are the two new constraints on user-defined exceptions in Python 3.0?\\n2. How are raised class-based exceptions matched to handlers?\\n3.\\nName two ways that you can attach context information to exception objects.\\n4. Name two ways that you can specify the error message text for exception objects.\\n5. Why should you not use string-based exceptions anymore today?\\nTest Your Knowledge: Answers\\n1. In 3.0, exceptions must be defined by classes (that is, a class instance object is raised\\nand caught). In addition, exception classes must be derived from the built-in class\\nBaseException (most programs inherit from its Exception subclass, to support\\ncatchall handlers for normal kinds of exceptions).\\n2. Class-based exceptions match by superclass relationships: naming a superclass in\\nan exception handler will catch instances of that class, as well as instances of any\\nof its subclasses lower in the class tree. Because of this, you can think of superclasses\\nas general exception categories and subclasses as more specific types of exceptions\\nwithin those categories.\\n3. You can attach context information to class-based exceptions by filling out instance\\nattributes in the instance object raised, usually in a custom class constructor. For\\nsimpler needs, built-in exception superclasses provide a constructor that stores its\\narguments on the instance automatically (in the attribute args). In exception han-\\ndlers, you list a variable to be assigned to the raised instance, then go through this\\nname to access attached state information and call any methods defined in the class.\\n4. The error message text in class-based exceptions can be specified with a custom\\n__str__ operator overloading method. For simpler needs, built-in exception su-\\nperclasses automatically display anything you pass to the class constructor. Oper-\\nations like print and str automatically fetch the display string of an exception\\nobject when is it printed either explicitly or as part of an error message.\\n5. Because Guido said so—they have been removed in both Python 2.6 and 3.0.\\nReally, there are good reasons for this: string-based exceptions did not support\\ncategories, state information, or behavior inheritance in the way class-based ex-\\nceptions do. In practice, this made string-based exceptions easier to use at first,\\nwhen programs were small, but more complex to use as programs grew larger.\\nTest Your Knowledge: Answers | 871', metadata={'source': 'python.pdf', 'page': 921}),\n",
       " Document(page_content='', metadata={'source': 'python.pdf', 'page': 922}),\n",
       " Document(page_content='CHAPTER 35\\nDesigning with Exceptions\\nThis chapter rounds out this part of the book with a collection of exception design\\ntopics and common \\nuse case examples, followed by this part’s gotchas and exercises.\\nBecause this chapter also closes out the fundamentals portion of the book at large, it\\nincludes a brief overview of development tools as well to help you as you make the\\nmigration from Python beginner to Python application developer.\\nNesting Exception Handlers\\nOur examples so far have used only a single try to catch exceptions, but what happens\\nif one try is physically nested inside another? For that matter, what does it mean if a\\ntry calls a function that runs another try? Technically, try statements can nest, in terms\\nof syntax and the runtime control flow through your code.\\nBoth of these cases can be understood if you realize that Python stacks try statements\\nat runtime. When an exception is raised, Python returns to the most recently entered\\ntry statement with a matching except clause. Because each try statement leaves a\\nmarker, Python can jump back to earlier trys by inspecting the stacked markers. This\\nnesting of active handlers is what we mean when we talk about propagating exceptions\\nup to “higher” handlers—such handlers are simply try statements entered earlier in\\nthe program’s execution flow.\\nFigure 35-1 illustrates what occurs when try statements with except clauses nest at\\nruntime. The amount of code that goes into a try block can be substantial, and it may\\ncontain function calls that invoke other code watching for the same exceptions. When\\nan exception is eventually raised, Python jumps back to the most recently entered\\ntry statement that names that exception, runs that statement’s except clause, and then\\nresumes execution after that try.\\nOnce the exception is caught, its life is over—control does not jump back to all match-\\ning trys that name the exception; only the first one is given the opportunity to handle\\nit. In Figure 35-1 , for instance, the raise statement in the function func2 sends control\\nback to the handler in func1, and then the program continues within func1.\\n873', metadata={'source': 'python.pdf', 'page': 923}),\n",
       " Document(page_content='By contrast, when try statements that contain only finally clauses are nested, each\\nfinally block is run in turn when an exception occurs—Python continues propagating\\nthe exception up to other trys, and eventually perhaps to the top-level default handler\\n(the standard error message printer). As Figure 35-2  illustrates, the finally clauses do\\nnot kill the exception—they just specify code to be run on the way out of each try\\nduring the exception propagation process. If there are many try/finally clauses active\\nwhen an exception occurs, they will all be run, unless a try/except catches the exception\\nsomewhere along the way.\\nFigure 35-2. Nested try/finally statements: when an exception is raised here, control returns to the\\nmost recently entered \\ntry to run its finally statement, but then the exception keeps propagating to all\\nfinallys in all active try statements and eventually reaches the default top-level handler, where an\\nerror message is printed. finally clauses intercept (but do not stop) an exception—they are for actions\\nto be performed “on the way out.”\\nIn other words, where the program goes when an exception is raised depends entirely\\nupon where it has been—it’s a function of the runtime flow of control through the script,\\nnot just its syntax. The propagation of an exception essentially proceeds backward\\nthrough time to try statements that have been entered but not yet exited. This propa-\\ngation stops as soon as control is unwound to a matching except clause, but not as it\\npasses through finally clauses on the way.\\nFigure 35-1. Nested try/except statements: when an exception is raised (by you or by Python), control\\njumps back to \\nthe most recently entered try statement with a matching except clause, and the program\\nresumes after that try statement. except clauses intercept and stop the exception—they are where you\\nprocess and recover from exceptions.\\n874 | Chapter 35: \\u2002Designing with Exceptions', metadata={'source': 'python.pdf', 'page': 924}),\n",
       " Document(page_content=\"Example: Control-Flow Nesting\\nLet’s turn to \\nan example to make this nesting concept more concrete. The following\\nmodule file, nestexc.py, defines two functions. action2 is coded to trigger an exception\\n(you can’t add numbers and sequences), and action1 wraps a call to action2 in a try\\nhandler, to catch the exception:\\ndef action2():\\n    print(1 + [])            # Generate TypeError\\ndef action1():\\n    try:\\n        action2()\\n    except TypeError:        # Most recent matching try\\n        print('inner try')\\ntry:\\n    action1()\\nexcept TypeError:            # Here, only if action1 re-raises\\n    print('outer try')\\n% python nestexc.py\\ninner try\\nNotice, though, that the top-level module code at the bottom of the file wraps a call to\\naction1 in a try handler, too. When action2 triggers the TypeError exception, there will\\nbe two active try statements—the one in action1, and the one at the top level of the\\nmodule file. Python picks and runs just the most recent try with a matching except,\\nwhich in this case is the try inside action1.\\nAs I’ve mentioned, the place where an exception winds up jumping to depends on the\\ncontrol flow through the program at runtime. Because of this, to know where you will\\ngo, you need to know where you’ve been. In this case, where exceptions are handled\\nis more a function of control flow than of statement syntax. However, we can also nest\\nexception handlers syntactically—an equivalent case we’ll look at next.\\nExample: Syntactic Nesting\\nAs I mentioned when we looked at the new unified try/except/finally statement in\\nChapter 33 , it is possible to nest try statements syntactically by their position in your\\nsource code:\\ntry:\\n    try:\\n        action2()\\n    except TypeError:        # Most recent matching try\\n        print('inner try')\\nexcept TypeError:            # Here, only if nested handler re-raises\\n    print('outer try')\\nNesting Exception Handlers | 875\", metadata={'source': 'python.pdf', 'page': 925}),\n",
       " Document(page_content='Really, this code just sets up the same handler-nesting structure as (and behaves iden-\\ntically to) the \\nprior example. In fact, syntactic nesting works just like the cases sketched\\nin Figures 35-1 and 35-2; the only difference is that the nested handlers are physically\\nembedded in a try block, not coded in functions called elsewhere. For example, nested\\nfinally handlers all fire on an exception, whether they are nested syntactically or by\\nmeans of the runtime flow through physically separated parts of your code:\\n>>> try:\\n...     try:\\n...         raise IndexError\\n...     finally:\\n...         print(\\'spam\\')\\n... finally:\\n...     print(\\'SPAM\\')\\n...\\nspam\\nSPAM\\nTraceback (most recent call last):\\n  File \"<stdin>\", line 3, in <module>\\nIndexError\\nSee Figure 35-2  for a graphic illustration of this code’s operation; the effect is the same,\\nbut the function logic has been inlined as nested statements here. For a more useful\\nexample of syntactic nesting at work, consider the following file, except-finally.py:\\ndef raise1():  raise IndexError\\ndef noraise(): return\\ndef raise2():  raise SyntaxError\\nfor func in (raise1, noraise, raise2):\\n    print(\\'\\\\n\\', func, sep=\\'\\')\\n    try:\\n        try:\\n            func()\\n        except IndexError:\\n            print(\\'caught IndexError\\')\\n    finally:\\n        print(\\'finally run\\')\\nThis code catches an exception if one is raised and performs a finally termination-\\ntime action regardless of whether an exception occurs. This may take a few moments\\nto digest, but the effect is much like combining an except and a finally clause in a\\nsingle try statement in Python 2.5 and later:\\n% python except-finally.py\\n<function raise1 at 0x026ECA98>\\ncaught IndexError\\nfinally run\\n<function noraise at 0x026ECA50>\\nfinally run\\n<function raise2 at 0x026ECBB8>\\nfinally run\\n876 | Chapter 35: \\u2002Designing with Exceptions', metadata={'source': 'python.pdf', 'page': 926}),\n",
       " Document(page_content='Traceback (most recent call last):\\n  File \"except-finally.py\", line 9, in <module>\\n    func()\\n  File \"except-finally.py\", line 3, in raise2\\n    def raise2():  raise SyntaxError\\nSyntaxError: None\\nAs we saw \\nin Chapter 33 , as of Python 2.5, except and finally clauses can be mixed\\nin the same try statement. This makes some of the syntactic nesting described in this\\nsection unnecessary, though it still works, may appear in code written prior to Python\\n2.5 that you may encounter, and can be used as a technique for implementing alter-\\nnative exception-handling behaviors.\\nException Idioms\\nWe’ve seen the mechanics behind exceptions. Now let’s take a look at some of the other\\nways they are typically used.\\nExceptions Aren’t Always Errors\\nIn Python, all errors are exceptions, but not all exceptions are errors. For instance, we\\nsaw in Chapter 9  that file object read methods return an empty string at the end of a\\nfile. In contrast, the built-in input function (which we first met in Chapter 3  and de-\\nployed in an interactive loop in Chapter 10) reads a line of text from the standard input\\nstream, sys.stdin, at each call and raises the built-in EOFError at end-of-file. (This\\nfunction is known as raw_input in Python 2.6.)\\nUnlike file methods, this function does not return an empty string—an empty string\\nfrom input means an empty line. Despite its name, the EOFError exception is just a\\nsignal in this context, not an error. Because of this behavior, unless the end-of-file\\nshould terminate a script, input often appears wrapped in a try handler and nested in\\na loop, as in the following code:\\nwhile True:\\n    try:\\n        line = input()           # Read line from stdin\\n    except EOFError:\\n        break                    # Exit loop at end-of-file\\n    else:\\n        ...process next line here...\\nSeveral other built-in exceptions are similarly signals, not errors—calling sys.exit()\\nand pressing Ctrl-C on your keyboard, respectively, raise SystemExit and Key\\nboardInterrupt, for example. Python also has a set of built-in exceptions that represent\\nwarnings rather than errors; some of these are used to signal use of deprecated (phased\\nout) language features. See the standard library manual’s description of built-in excep-\\ntions for more information, and consult the warnings module’s documentation for more\\non warnings.\\nException Idioms | 877', metadata={'source': 'python.pdf', 'page': 927}),\n",
       " Document(page_content='Functions Can Signal Conditions with raise\\nUser-defined exceptions can \\nalso signal nonerror conditions. For instance, a search\\nroutine can be coded to raise an exception when a match is found instead of returning\\na status flag for the caller to interpret. In the following, the try/except/else exception\\nhandler does the work of an if/else return-value tester:\\nclass Found(Exception): pass\\ndef searcher():\\n    if ...success...:\\n        raise Found()\\n    else:\\n        return\\ntry:\\n    searcher()\\nexcept Found:                    # Exception if item was found\\n    ...success...\\nelse:                            # else returned: not found\\n    ...failure...\\nMore generally, such a coding structure may also be useful for any function that cannot\\nreturn a sentinel value to designate success or failure. For instance, if all objects are\\npotentially valid return values, it’s impossible for any return value to signal unusual\\nconditions. Exceptions provide a way to signal results without a return value:\\nclass Failure(Exception): pass\\ndef searcher():\\n    if ...success...:\\n        return ...founditem...\\n    else:\\n        raise Failure()\\ntry:\\n    item = searcher()\\nexcept Failure:\\n    ...report...\\nelse:\\n    ...use item here...\\nBecause Python is dynamically typed and polymorphic to the core, exceptions, rather\\nthan sentinel return values, are the generally preferred way to signal such conditions.\\nClosing Files and Server Connections\\nWe encountered examples in this category in Chapter 33 . As a summary, though, ex-\\nception processing tools are also commonly used to ensure that system resources are\\nfinalized, regardless of whether an error occurs during processing or not.\\n878 | Chapter 35: \\u2002Designing with Exceptions', metadata={'source': 'python.pdf', 'page': 928}),\n",
       " Document(page_content=\"For example, some servers require connections to be closed in order to terminate a\\nsession. Similarly, output \\nfiles may require close calls to flush their buffers to disk, and\\ninput files may consume file descriptors if not closed; although file objects are auto-\\nmatically closed when garbage collected if still open, it’s sometimes difficult to be sure\\nwhen that will occur.\\nThe most general and explicit way to guarantee termination actions for a specific block\\nof code is the try/finally statement:\\nmyfile = open(r'C:\\\\misc\\\\script', 'w')\\ntry:\\n    ...process myfile...\\nfinally:\\n    myfile.close()\\nAs we saw in Chapter 33 , some objects make this easier in Python 2.6 and 3.0 by\\nproviding context managers run by the with/as statement that terminate or close the\\nobjects for us automatically:\\nwith open(r'C:\\\\misc\\\\script', 'w') as myfile:\\n    ...process myfile...\\nSo which option is better here? As usual, it depends on your programs. Compared to\\nthe try/finally, context managers are more implicit , which runs contrary to Python’s\\ngeneral design philosophy. Context managers are also arguably less general —they are\\navailable only for select objects, and writing user-defined context managers to handle\\ngeneral termination requirements is more complex than coding a try/finally.\\nOn the other hand, using existing context managers requires less code than using try/\\nfinally, as shown by the preceding examples. Moreover, the context manager protocol\\nsupports entry actions in addition to exit actions. Although the try/finally is perhaps\\nthe more widely applicable technique, context managers may be more appropriate\\nwhere they are already available, or where their extra complexity is warranted.\\nDebugging with Outer try Statements\\nYou can also make use of exception handlers to replace Python’s default top-level\\nexception-handling behavior. By wrapping an entire program (or a call to it) in an outer\\ntry in your top-level code, you can catch any exception that may occur while your\\nprogram runs, thereby subverting the default program termination.\\nIn the following, the empty except clause catches any uncaught exception raised while\\nthe program runs. To get hold of the actual exception that occurred, fetch the\\nsys.exc_info function call result from the built-in sys module; it returns a tuple whose\\nfirst two items contain the current exception’s class and the instance object raised (more\\non sys.exc_info in a moment):\\nException Idioms | 879\", metadata={'source': 'python.pdf', 'page': 929}),\n",
       " Document(page_content=\"try:\\n    ...run program...\\nexcept:                         # All uncaught exceptions come here\\n    import sys\\n    print('uncaught!', sys.exc_info()[0], sys.exc_info()[1])\\nThis structure is \\ncommonly used during development, to keep programs active even\\nafter errors occur—it allows you to run additional tests without having to restart. It’s\\nalso used when testing other program code, as described in the next section.\\nRunning In-Process Tests\\nYou might combine some of the coding patterns we’ve just looked at in a test-driver\\napplication that tests other code within the same process:\\nimport sys\\nlog = open('testlog', 'a')\\nfrom testapi import moreTests, runNextTest, testName\\ndef testdriver():\\n    while moreTests():\\n        try:\\n            runNextTest()\\n        except:\\n            print('FAILED', testName(), sys.exc_info()[:2], file=log)\\n        else:\\n            print('PASSED', testName(), file=log)\\ntestdriver()\\nThe testdriver function here cycles through a series of test calls (the module testapi\\nis left abstract in this example). Because an uncaught exception in a test case would\\nnormally kill this test driver, you need to wrap test case calls in a try if you want to\\ncontinue the testing process after a test fails. The empty except catches any uncaught\\nexception generated by a test case as usual, and it uses sys.exc_info to log the exception\\nto a file. The else clause is run when no exception occurs—the test success case.\\nSuch boilerplate code is typical of systems that test functions, modules, and classes by\\nrunning them in the same process as the test driver. In practice, however, testing can\\nbe much more sophisticated than this. For instance, to test external programs, you\\ncould instead check status codes or outputs generated by program-launching tools such\\nas os.system and os.popen, covered in the standard library manual (such tools do not\\ngenerally raise exceptions for errors in the external programs—in fact, the test cases\\nmay run in parallel with the test driver).\\nAt the end of this chapter, we’ll also meet some more complete testing frameworks\\nprovided by Python, such as doctest and PyUnit, which provide tools for comparing\\nexpected outputs with actual results.\\n880 | Chapter 35: \\u2002Designing with Exceptions\", metadata={'source': 'python.pdf', 'page': 930}),\n",
       " Document(page_content='More on sys.exc_info\\nThe sys.exc_info result used \\nin the last two sections allows an exception handler to\\ngain access to the most recently raised exception generically. This is especially useful\\nwhen using the empty except clause to catch everything blindly, to determine what was\\nraised:\\ntry:\\n    ...\\nexcept:\\n    # sys.exc_info()[0:2] are the exception class and instance\\nIf no exception is being handled, this call it returns a tuple containing three None values.\\nOtherwise, the values returned are (type, value, traceback), where:\\n•type is the exception class of the exception being handled.\\n•value is the exception class instance that was raised.\\n•traceback is a traceback object that represents the call stack at the point where the\\nexception originally occurred (see the traceback module’s documentation for tools\\nthat may be used in conjunction with this object to generate error messages\\nmanually).\\nAs we saw in the prior chapter, sys.exc_info can also sometimes be useful to determine\\nthe specific exception type when catching exception category superclasses. As we saw,\\nthough, because in this case you can also get the exception type by fetching the\\n__class__ attribute of the instance obtained with the as clause, sys.exc_info is mostly\\nused by the empty except today:\\ntry:\\n    ...\\nexcept General as instance:\\n    # instance.__class__ is the exception class\\nThat said, using the instance object’s interfaces and polymorphism is often a better\\napproach than testing exception types—exception methods can be defined per class\\nand run generically:\\ntry:\\n    ...\\nexcept General as instance:\\n    # instance.method() does the right thing for this instance\\nAs usual, being too specific in Python can limit your code’s flexibility. A polymorphic\\napproach like the last example here generally supports future evolution better.\\nException Idioms | 881', metadata={'source': 'python.pdf', 'page': 931}),\n",
       " Document(page_content='Version skew note: In Python 2.6, the older tools sys.exc_type and\\nsys.exc_value still work to fetch the most recent exception type and\\nvalue, but they can manage only a single, global exception for the entire\\nprocess. These two names have been removed in Python 3.0. The newer\\nand preferred sys.exc_info() call available in both 2.6 and 3.0 instead\\nkeeps track of each thread’s exception information, and so is thread-\\nspecific. Of course, this distinction matters only when using multiple\\nthreads in Python programs (a subject beyond this book’s scope), but\\n3.0 forces the issue. See other resources for more details.\\nException Design Tips and Gotchas\\nI’m lumping design tips and gotchas together in this chapter, because it turns out that\\nthe most common gotchas largely stem from design issues. By and large, exceptions\\nare easy to use in Python. The real art behind them is in deciding how specific or general\\nyour except clauses should be and how much code to wrap up in try statements. Let’s\\naddress the second of these concerns first.\\nWhat Should Be Wrapped\\nIn principle, you could wrap every statement in your script in its own try, but that\\nwould just be silly (the try statements would then need to be wrapped in try state-\\nments!). What to wrap is really a design issue that goes beyond the language itself, and\\nit will become more apparent with use. But for now, here are a few rules of thumb:\\n• Operations that commonly fail should generally be wrapped in try statements. For\\nexample, operations that interface with system state (file opens, socket calls, and\\nthe like) are prime candidates for trys.\\n• However, there are exceptions to the prior rule—in a simple script, you may\\nwant failures of such operations to kill your program instead of being caught and\\nignored. This is especially true if the failure is a showstopper. Failures in Python\\ntypically result in useful error messages (not hard crashes), and this is often the\\nbest outcome you could hope for.\\n• You should implement termination actions in try/finally statements to guarantee\\ntheir execution, unless a context manager is available as a with/as option. The try/\\nfinally statement form allows you to run code whether exceptions occur or not\\nin arbitrary scenarios.\\n• It is sometimes more convenient to wrap the call to a large function in a single\\ntry statement, rather than littering the function itself with many try statements.\\nThat way, all exceptions in the function percolate up to the try around the call,\\nand you reduce the amount of code within the function.\\nThe types of programs you write will probably influence the amount of exception han-\\ndling you code as well. Servers, for instance, must generally keep running persistently\\n882 | Chapter 35: \\u2002Designing with Exceptions', metadata={'source': 'python.pdf', 'page': 932}),\n",
       " Document(page_content=\"and so will likely require try statements to catch and recover from exceptions. In-\\nprocess testing programs of the kind we saw in this chapter will probably handle ex-\\nceptions as well. Simpler one-shot scripts, though, will often ignore exception handling\\ncompletely because failure at any step requires script shutdown.\\nCatching Too Much: Avoid Empty except and Exception\\nOn to the issue of handler generality. Python lets you pick and choose which exceptions\\nto catch, but you sometimes have to be careful to not be too inclusive. For example,\\nyou’ve seen that an empty except clause catches every exception that might be raised\\nwhile the code in the try block runs.\\nThat’s easy to code, and sometimes desirable, but you may also wind up intercepting\\nan error that’s expected by a try handler higher up in the exception nesting structure.\\nFor example, an exception handler such as the following catches and stops every ex-\\nception that reaches it, regardless of whether another handler is waiting for it:\\ndef func():\\n    try:\\n        ...                      # IndexError is raised in here\\n    except:\\n        ...                      # But everything comes here and dies!\\ntry:\\n    func()\\nexcept IndexError:               # Exception should be processed here\\n    ...\\nPerhaps worse, such code might also catch unrelated system exceptions. Even things\\nlike memory errors, genuine programming mistakes, iteration stops, keyboard inter-\\nrupts, and system exits raise exceptions in Python. Such exceptions should not usually\\nbe intercepted.\\nFor example, scripts normally exit when control falls off the end of the top-level file.\\nHowever, Python also provides a built-in sys.exit(statuscode) call to allow early ter-\\nminations. This actually works by raising a built-in SystemExit exception to end the\\nprogram, so that try/finally handlers run on the way out and special types of programs\\ncan intercept the event.* Because of this, a try with an empty except might unknowingly\\nprevent a crucial exit, as in the following file (exiter.py):\\nimport sys\\ndef bye():\\n    sys.exit(40)                 # Crucial error: abort now!\\ntry:\\n    bye()\\nexcept:\\n    print('got it')              # Oops--we ignored the exit\\n* A related call, os._exit, also ends a program, but via an immediate termination—it skips cleanup actions\\nand cannot be intercepted with try/except or try/finally blocks. It is usually only used in spawned child\\nprocesses, a topic beyond this book’s scope. See the library manual or follow-up texts for details.\\nException Design Tips and Gotchas | 883\", metadata={'source': 'python.pdf', 'page': 933}),\n",
       " Document(page_content=\"print('continuing...')\\n% python exiter.py\\ngot it\\ncontinuing...\\nYou simply might \\nnot expect all the kinds of exceptions that could occur during an\\noperation. Using the built-in exception classes of the prior chapter can help in this\\nparticular case, because the Exception superclass is not a superclass of SystemExit:\\ntry:\\n    bye()\\nexcept Exception:                # Won't catch exits, but _will_ catch many others\\n    ...\\nIn other cases, though, this scheme is no better than an empty except clause—because \\nException is a superclass above all built-in exceptions except system-exit events, it still\\nhas the potential to catch exceptions meant for elsewhere in the program.\\nProbably worst of all, both an empty except and catching the Exception class will also\\ncatch genuine programming errors, which should be allowed to pass most of the time.\\nIn fact, these two techniques can effectively turn off  Python’s error-reporting ma-\\nchinery, making it difficult to notice mistakes in your code. Consider this code, for\\nexample:\\nmydictionary = {...}\\n...\\ntry:\\n    x = myditctionary['spam']    # Oops: misspelled\\nexcept:\\n    x = None                     # Assume we got KeyError\\n...continue here with x...\\nThe coder here assumes that the only sort of error that can happen when indexing a\\ndictionary is a missing key error. But because the name myditctionary is misspelled (it\\nshould say mydictionary), Python raises a NameError instead for the undefined name\\nreference, which the handler will silently catch and ignore. The event handler will in-\\ncorrectly fill in a default for the dictionary access, masking the program error. Moreover,\\ncatching Exception here would have the exact same effect as an empty except. If this\\nhappens in code that is far removed from the place where the fetched values are used,\\nit might make for a very interesting debugging task!\\nAs a rule of thumb, be as specific in your handlers as you can be—empty except clauses\\nand Exception catchers are handy, but potentially error-prone. In the last example, for\\ninstance, you would be better off saying except KeyError: to make your intentions\\nexplicit and avoid intercepting unrelated events. In simpler scripts, the potential for\\nproblems might not be significant enough to outweigh the convenience of a catchall,\\nbut in general, general handlers are generally trouble.\\n884 | Chapter 35: \\u2002Designing with Exceptions\", metadata={'source': 'python.pdf', 'page': 934}),\n",
       " Document(page_content='Catching Too Little: Use Class-Based Categories\\nOn the other \\nhand, neither should handlers be too specific. When you list specific\\nexceptions in a try, you catch only what you actually list. This isn’t necessarily a bad\\nthing, but if a system evolves to raise other exceptions in the future, you may need to\\ngo back and add them to exception lists elsewhere in your code.\\nWe saw this phenomenon at work in the prior chapter. For instance, the following\\nhandler is written to treat MyExcept1 and MyExcept2 as normal cases and everything else\\nas an error. Therefore, if you add a MyExcept3 in the future, it will be processed as an\\nerror unless you update the exception list:\\ntry:\\n    ...\\nexcept (MyExcept1, MyExcept2):   # Breaks if you add a MyExcept3\\n    ...                          # Non-errors\\nelse:\\n    ...                          # Assumed to be an error\\nLuckily, careful use of the class-based exceptions we discussed in Chapter 33 can make\\nthis trap go away completely. As we saw, if you catch a general superclass, you can add\\nand raise more specific subclasses in the future without having to extend except clause\\nlists manually—the superclass becomes an extendible exceptions category:\\ntry:\\n    ...\\nexcept SuccessCategoryName:      # OK if I add a myerror3 subclass\\n    ...                          # Non-errors\\nelse:\\n    ...                          # Assumed to be an error\\nIn other words, a little design goes a long way. The moral of the story is to be careful\\nto be neither too general nor too specific in exception handlers, and to pick the gran-\\nularity of your try statement wrappings wisely. Especially in larger systems, exception\\npolicies should be a part of the overall design.\\nCore Language Summary\\nCongratulations! This concludes your look at the core Python programming language.\\nIf you’ve gotten this far, you may consider yourself an Official Python Programmer (and\\nshould feel free to add Python to your résumé the next time you dig it out). You’ve\\nalready seen just about everything there is to see in the language itself, and all in much\\nmore depth than many practicing Python programmers initially do. You’ve studied\\nbuilt-in types, statements, and exceptions, as well as tools used to build up larger pro-\\ngram units (functions, modules, and classes); you’ve even explored important design\\nissues, OOP, program architecture, and more.\\nCore Language Summary | 885', metadata={'source': 'python.pdf', 'page': 935}),\n",
       " Document(page_content='The Python Toolset\\nFrom this point \\nforward, your future Python career will largely consist of becoming\\nproficient with the toolset available for application-level Python programming. You’ll\\nfind this to be an ongoing task. The standard library, for example, contains hundreds\\nof modules, and the public domain offers still more tools. It’s possible to spend a decade\\nor more seeking proficiency with all these tools, especially as new ones are constantly\\nappearing (trust me on this!).\\nSpeaking generally, Python provides a hierarchy of toolsets:\\nBuilt-ins\\nBuilt-in types like strings, lists, and dictionaries make it easy to write simple pro-\\ngrams fast.\\nPython extensions\\nFor more demanding tasks, you can extend Python by writing your own functions,\\nmodules, and classes.\\nCompiled extensions\\nAlthough we don’t cover this topic in this book, Python can also be extended with\\nmodules written in an external language like C or C++.\\nBecause Python layers its toolsets, you can decide how deeply your programs need to\\ndelve into this hierarchy for any given task—you can use built-ins for simple scripts,\\nadd Python-coded extensions for larger systems, and code compiled extensions for\\nadvanced work. We’ve only covered the first two of these categories in this book, and\\nthat’s plenty to get you started doing substantial programming in Python.\\nTable 35-1 summarizes some of the sources of built-in or existing functionality available\\nto Python programmers, and some topics you’ll probably be busy exploring for the\\nremainder of your Python career. Up until now, most of our examples have been very\\nsmall and self-contained. They were written that way on purpose, to help you master\\nthe basics. But now that you know all about the core language, it’s time to start learning\\nhow to use Python’s built-in interfaces to do real work. You’ll find that with a simple\\nlanguage like Python, common tasks are often much easier than you might expect.\\nTable 35-1. Python’s toolbox categories\\nCategory Examples\\nObject types Lists, dictionaries, files, strings\\nFunctions len, range, open\\nExceptions IndexError, KeyError\\nModules os, tkinter, pickle, re\\nAttributes __dict__, __name__, __class__\\nPeripheral tools NumPy, SWIG, Jython, IronPython, Django, etc.\\n886 | Chapter 35: \\u2002Designing with Exceptions', metadata={'source': 'python.pdf', 'page': 936}),\n",
       " Document(page_content=\"Development Tools for Larger Projects\\nOnce you’ve mastered \\nthe basics, you’ll find your Python programs becoming sub-\\nstantially larger than the examples you’ve experimented with so far. For developing\\nlarger systems, a set of development tools is available in Python and the public domain.\\nYou’ve seen some of these in action, and I’ve mentioned a few others. To help you on\\nyour way, here is a summary of some of the most commonly used tools in this domain:\\nPyDoc and docstrings\\nPyDoc’s help function and HTML interfaces were introduced in Chapter 15. PyDoc\\nprovides a documentation system for your modules and objects and integrates with\\nPython’s docstrings feature. It is a standard part of the Python system—see the\\nlibrary manual for more details. Be sure to also refer back to the documentation\\nsource hints listed in Chapter 4 for information on other Python information\\nresources.\\nPyChecker and PyLint\\nBecause Python is such a dynamic language, some programming errors are not\\nreported until your program runs (e.g., syntax errors are caught when a file is run\\nor imported). This isn’t a big drawback—as with most languages, it just means\\nthat you have to test your Python code before shipping it. At worst, with Python\\nyou essentially trade a compile phase for an initial testing phase. Furthermore,\\nPython’s dynamic nature, automatic error messages, and exception model make it\\neasier and quicker to find and fix errors in Python than it is in some other languages\\n(unlike C, for example, Python does not crash on errors).\\nThe PyChecker and PyLint systems provide support for catching a large set of\\ncommon errors ahead of time, before your script runs. They serve similar roles to\\nthe lint program in C development. Some Python groups run their code through\\nPyChecker prior to testing or delivery, to catch any lurking potential problems. In\\nfact, the Python standard library is regularly run through PyChecker before release.\\nPyChecker and PyLint are third-party open source packages; you can find them at\\nhttp://www.python.org or the PyPI website, or via your friendly neighborhood web\\nsearch engine.\\nPyUnit (a.k.a. unittest)\\nIn Chapter 24 , we learned how to add self-test code to a Python file by using the\\n__name__ == '__main__'  trick at the bottom of the file. For more advanced testing\\npurposes, Python comes with two testing support tools. The first, PyUnit (called\\nunittest in the library manual), provides an object-oriented class framework for\\nspecifying and customizing test cases and expected results. It mimics the JUnit\\nframework for Java. This is a sophisticated class-based unit testing system; see the\\nPython library manual for details.\\ndoctest\\nThe doctest standard library module provides a second and simpler approach to\\nregression testing, based upon Python’s docstrings feature. Roughly, to use\\nCore Language Summary | 887\", metadata={'source': 'python.pdf', 'page': 937}),\n",
       " Document(page_content=\"doctest, you cut and paste a log of an interactive testing session into the docstrings\\nof your \\nsource files. doctest then extracts your docstrings, parses out the test cases\\nand results, and reruns the tests to verify the expected results. doctest’s operation\\ncan be tailored in a variety of ways; see the library manual for more details.\\nIDEs\\nWe discussed IDEs for Python in Chapter 3 . IDEs such as IDLE provide a graphical\\nenvironment for editing, running, debugging, and browsing your Python\\nprograms. Some advanced IDEs (such as Eclipse, Komodo, NetBeans, and Wing\\nIDE) may support additional development tasks, including source control inte-\\ngration, code refactoring, project management tools, and more. See Chapter 3, the\\ntext editors page at http://www.python.org, and your favorite web search engine for\\nmore on available IDEs and GUI builders for Python.\\nProfilers\\nBecause Python is so high-level and dynamic, intuitions about performance\\ngleaned from experience with other languages usually don’t apply to Python code.\\nTo truly isolate performance bottlenecks in your code, you need to add timing logic\\nwith clock tools in the time or timeit modules, or run your code under the\\nprofile module. We saw an example of the timing modules at work when com-\\nparing iteration tools’ speeds in Chapter 20 . Profiling is usually your first optimi-\\nzation step—profile to isolate bottlenecks, then time alternative codings of them.\\nprofile is a standard library module that implements a source code profiler for\\nPython; it runs a string of code you provide (e.g., a script file import, or a call to a\\nfunction) and then, by default, prints a report to the standard output stream that\\ngives performance statistics—number of calls to each function, time spent in each\\nfunction, and more.\\nThe profile module can be run as a script or imported, and it may be customized\\nin various ways; for example, it can save run statistics to a file to be analyzed later\\nwith the pstats module. To profile interactively, import the profile module and\\ncall profile.run('code'), passing in the code you wish to profile as a string (e.g.,\\na call to a function, or an import of an entire file). To profile from a system shell\\ncommand line, use a command of the form python -m profile main.py args...\\n(see Appendix A for more on this format). Also see Python’s standard library man-\\nuals for other profiling options; the cProfile module, for example, has identical\\ninterfaces to profile but runs with less overhead, so it may be better suited to\\nprofiling long-running programs.\\nDebuggers\\nWe also discussed debugging options in Chapter 3  (see its sidebar “Debugging\\nPython Code” on page 67). As a review, most development IDEs for Python support\\nGUI-based debugging, and the Python standard library also includes a source code\\ndebugger module called pdb. This module provides a command-line interface and\\nworks much like common C language debuggers (e.g., dbx, gdb).\\n888 | Chapter 35: \\u2002Designing with Exceptions\", metadata={'source': 'python.pdf', 'page': 938}),\n",
       " Document(page_content='Much like the profiler, the pdb debugger can be run either interactively or from a\\ncommand line and can be imported and called from a Python program. To use it\\ninteractively, import the module, start running code by calling a pdb function (e.g.,\\npdb.run(\"main()\")), and then type debugging commands from pdb’s interactive\\nprompt. To launch pdb from a system shell command line, use a command of the\\nform python -m pdb main.py args... (see Appendix A for more on this format).\\npdb also includes a useful postmortem analysis call, pdb.pm(), which starts the\\ndebugger after an exception has been encountered.\\nBecause IDEs such as IDLE also include point-and-click debugging interfaces,\\npdb isn’t a critical a tool today, except when a GUI isn’t available or when more\\ncontrol is desired. See Chapter 3  for tips on using IDLE’s debugging GUI interfaces.\\nReally, neither pdb nor IDEs seem to be used much in practice—as noted in Chap-\\nter 3 , most programmers either insert print statements or simply read Python’s\\nerror messages (not the most high-tech of approaches, but the practical tends to\\nwin the day in the Python world!).\\nShipping options\\nIn Chapter 2 , we introduced common tools for packaging Python programs.\\npy2exe, PyInstaller, and freeze can package byte code and the Python Virtual Ma-\\nchine into “frozen binary” standalone executables, which don’t require that Python\\nbe installed on the target machine and fully hide your system’s code. In addition,\\nwe learned in Chapter 2  that Python programs may be shipped in their source\\n(.py) or byte code ( .pyc) forms, and that import hooks support special packaging\\ntechniques such as automatic extraction of .zip files and byte code encryption.\\nWe also briefly met the standard library’s distutils modules, which provide pack-\\naging options for Python modules and packages, and C-coded extensions; see the\\nPython manuals for more details. The emerging Python “eggs” third-party pack-\\naging system provides another alternative that also accounts for dependencies;\\nsearch the Web for more details.\\nOptimization options\\nThere are a couple of options for optimizing your programs. The Psyco system\\ndescribed in Chapter 2  provides a just-in-time compiler for translating Python byte\\ncode to binary machine code, and Shedskin offers a Python-to-C++ translator. You\\nmay also occasionally see .pyo optimized byte code files, generated and run with\\nthe -O Python command-line flag (discussed in Chapters 21 and 33); because this\\nprovides a very modest performance boost, however, it is not commonly used.\\nAs a last resort, you can also move parts of your program to a compiled language\\nsuch as C to boost performance; see the book Programming Python  and the Python\\nstandard manuals for more on C extensions. In general, Python’s speed also im-\\nproves over time, so be sure to upgrade to the faster releases when possible.\\nCore Language Summary | 889', metadata={'source': 'python.pdf', 'page': 939}),\n",
       " Document(page_content=\"Other hints for larger projects\\nWe’ve met a \\nvariety of language features in this text that will tend to become more\\nuseful once you start coding larger projects. These include module packages\\n(Chapter 23 ), class-based exceptions ( Chapter 33 ), class pseudoprivate attributes\\n(Chapter 30 ), documentation strings ( Chapter 15 ), module path configuration files\\n(Chapter 21 ), hiding names from from * with __all__ lists and _X-style names\\n(Chapter 24 ), adding self-test code with the __name__ == '__main__'  trick ( Chap-\\nter 24 ), using common design rules for functions and modules (Chapters 17, 19,\\nand 24), using object-oriented design patterns ( Chapter 30 and others), and so on.\\nTo learn about other large-scale Python development tools available in the public do-\\nmain, be sure to browse the pages at the PyPI website at http://www.python.org, and\\nthe Web at large.\\nChapter Summary\\nThis chapter wrapped up the exceptions part of the book with a survey of related state-\\nments, a look at common exception use cases, and a brief summary of commonly used\\ndevelopment tools.\\nThis chapter also wrapped up the core material of this book. At this point, you’ve been\\nexposed to the full subset of Python that most programmers use. In fact, if you have\\nread this far, you should feel free to consider yourself an official Python programmer .\\nBe sure to pick up a t-shirt the next time you’re online.\\nThe next and final part of this book is a collection of chapters dealing with topics that\\nare advanced, but still in the core language category. These chapters are all optional\\nreading, because not every Python programmer must delve into their subjects; indeed,\\nmost of you can stop here and begin exploring Python’s roles in your application do-\\nmains. Frankly, application libraries tend to be more important in practice than ad-\\nvanced (and to some, esoteric) language features.\\nOn the other hand, if you do need to care about things like Unicode or binary data,\\nhave to deal with API-building tools such as descriptors, decorators, and metaclasses,\\nor just want to dig a bit further in general, the next part of the book will help you get\\nstarted. The larger examples in the final part will also give you a chance to see the\\nconcepts you’ve already learned being applied in more realistic ways.\\nAs this is the end of the core material of this book, you get a break on the chapter quiz—\\njust one question this time. As always, though, be sure to work through this part’s\\nclosing exercises to cement what you’ve learned in the past few chapters; because the\\nnext part is optional reading, this is the final end-of-part exercises session. If you want\\nto see some examples of how what you’ve learned comes together in real scripts drawn\\nfrom common applications, check out the “solution” to exercise 4 in Appendix B.\\n890 | Chapter 35: \\u2002Designing with Exceptions\", metadata={'source': 'python.pdf', 'page': 940}),\n",
       " Document(page_content='Test Your Knowledge: Quiz\\n1. (This question \\nis a repeat from the first quiz in Chapter 1 —see, I told you it would\\nbe easy! :-) Why does “spam” show up in so many Python examples in books and\\non the Web?\\nTest Your Knowledge: Answers\\n1. Because Python is named after the British comedy group Monty Python (based on\\nsurveys I’ve conducted in classes, this is a much-too-well-kept secret in the Python\\nworld!). The spam reference comes from a Monty Python skit, where a couple who\\nare trying to order food in a cafeteria keep getting drowned out by a chorus of\\nVikings singing a song about spam. No, really. And if I could insert an audio clip\\nof that song here, I would....\\nTest Your Knowledge: Part VII Exercises\\nAs we’ve reached the end of this part of the book, it’s time for a few exception exercises\\nto give you a chance to practice the basics. Exceptions really are simple tools; if you get\\nthese, you’ve probably mastered exceptions.\\nSee “Part VII, Exceptions and Tools” on page 1130 in Appendix B for the solutions.\\n1.try/except. Write a function called oops that explicitly raises an IndexError excep-\\ntion when called. Then write another function that calls oops inside a try/except\\nstatement to catch the error. What happens if you change oops to raise a\\nKeyError instead of an IndexError? Where do the names KeyError and IndexError\\ncome from? (Hint: recall that all unqualified names come from one of four scopes.)\\n2.Exception objects and lists . Change the oops function you just wrote to raise an\\nexception you define yourself, called MyError. Identify your exception with a class.\\nThen, extend the try statement in the catcher function to catch this exception and\\nits instance in addition to IndexError, and print the instance you catch.\\n3.Error handling . Write a function called safe(func, *args)  that runs any function\\nwith any number of arguments by using the *name arbitrary arguments call syntax,\\ncatches any exception raised while the function runs, and prints the exception using\\nthe exc_info call in the sys module. Then use your safe function to run your\\noops function from exercise 1 or 2. Put safe in a module file called tools.py, and\\npass it the oops function interactively. What kind of error messages do you get?\\nFinally, expand safe to also print a Python stack trace when an error occurs by\\ncalling the built-in print_exc function in the standard traceback module (see the\\nPython library reference manual for details).\\nTest Your Knowledge: Part VII Exercises | 891', metadata={'source': 'python.pdf', 'page': 941}),\n",
       " Document(page_content='4.Self-study examples . At the end of Appendix B , I’ve included a handful of example\\nscripts developed as group exercises in live Python classes for you to study and run\\non your own in conjunction with Python’s standard manual set. These are not\\ndescribed, and they use tools in the Python standard library that you’ll have to\\nresearch on your own. Still, for many readers, it helps to see how the concepts\\nwe’ve discussed in this book come together in real programs. If these whet your\\nappetite for more, you can find a wealth of larger and more realistic\\napplication-level Python program examples in follow-up books like Programming\\nPython and on the Web.\\n892 | Chapter 35: \\u2002Designing with Exceptions', metadata={'source': 'python.pdf', 'page': 942}),\n",
       " Document(page_content='PART VIII\\nAdvanced Topics', metadata={'source': 'python.pdf', 'page': 943}),\n",
       " Document(page_content='', metadata={'source': 'python.pdf', 'page': 944}),\n",
       " Document(page_content='CHAPTER 36\\nUnicode and Byte Strings\\nIn the strings chapter in the core types part of this book ( Chapter 7 ), I deliberately\\nlimited the scope to the subset of string topics that most Python programmers need to\\nknow about. Because the vast majority of programmers deal with simple forms of text\\nlike ASCII, they can happily work with Python’s basic str string type and its associated\\noperations and don’t need to come to grips with more advanced string concepts. In\\nfact, such programmers can largely ignore the string changes in Python 3.0 and continue\\nto use strings as they may have in the past.\\nOn the other hand, some programmers deal with more specialized types of data: non-\\nASCII character sets, image file contents, and so on. For those programmers (and others\\nwho may join them some day), in this chapter we’re going to fill in the rest of the Python\\nstring story and look at some more advanced concepts in Python’s string model.\\nSpecifically, we’ll explore the basics of Python’s support for Unicode text —\\nwide-character strings used in internationalized applications—as well as binary data—\\nstrings that represent absolute byte values. As we’ll see, the advanced string\\nrepresentation story has diverged in recent versions of Python:\\n•Python 3.0  provides an alternative string type for binary data and supports Unicode\\ntext in its normal string type (ASCII is treated as a simple type of Unicode).\\n•Python 2.6  provides an alternative string type for non-ASCII Unicode text and\\nsupports both simple text and binary data in its normal string type.\\nIn addition, because Python’s string model has a direct impact on how you process\\nnon-ASCII files, we’ll explore the fundamentals of that related topic here as well. Fi-\\nnally, we’ll take a brief look at some advanced string and binary tools, such as pattern\\nmatching, object pickling, binary data packing, and XML parsing, and the ways in\\nwhich they are impacted by 3.0’s string changes.\\nThis is officially an advanced topics chapter, because not all programmers will need to\\ndelve into the worlds of Unicode encodings or binary data. If you ever need to care\\nabout processing either of these, though, you’ll find that Python’s string models provide\\nthe support you need.\\n895', metadata={'source': 'python.pdf', 'page': 945}),\n",
       " Document(page_content='String Changes in 3.0\\nOne of the most \\nnoticeable changes in 3.0 is the mutation of string object types. In a\\nnutshell, 2.X’s str and unicode types have morphed into 3.0’s str and bytes types, and\\na new mutable bytearray type has been added. The bytearray type is technically avail-\\nable in Python 2.6 too (though not earlier), but it’s a back-port from 3.0 and does not\\nas clearly distinguish between text and binary content in 2.6.\\nEspecially if you process data that is either Unicode or binary in nature, these changes\\ncan have substantial impacts on your code. In fact, as a general rule of thumb, how\\nmuch you need to care about this topic depends in large part upon which of the fol-\\nlowing categories you fall into:\\n• If you deal with non-ASCII Unicode text —for instance, in the context of interna-\\ntionalized applications and the results of some XML parsers—you will find support\\nfor text encodings to be different in 3.0, but also probably more direct, accessible,\\nand seamless than in 2.6.\\n• If you deal with binary data —for example, in the form of image or audio files or\\npacked data processed with the struct module—you will need to understand 3.0’s\\nnew bytes object and 3.0’s different and sharper distinction between text and bi-\\nnary data and files.\\n• If you fall into neither of the prior two categories, you can generally use strings in\\n3.0 much as you would in 2.6: with the general str string type, text files, and all\\nthe familiar string operations we studied earlier. Your strings will be encoded and\\ndecoded using your platform’s default encoding (e.g., ASCII, or UTF-8 on Win-\\ndows in the U.S.— sys.getdefaultencoding() gives your default if you care to\\ncheck), but you probably won’t notice.\\nIn other words, if your text is always ASCII, you can get by with normal string objects\\nand text files and can avoid most of the following story. As we’ll see in a moment, ASCII\\nis a simple kind of Unicode and a subset of other encodings, so string operations and\\nfiles “just work” if your programs process ASCII text.\\nEven if you fall into the last of the three categories just mentioned, though, a basic\\nunderstanding of 3.0’s string model can help both to demystify some of the underlying\\nbehavior now, and to make mastering Unicode or binary data issues easier if they impact\\nyou in the future.\\nPython 3.0’s support for Unicode and binary data is also available in 2.6, albeit in\\ndifferent forms. Although our main focus in this chapter is on string types in 3.0, we’ll\\nexplore some 2.6 differences along the way too. Regardless of which version you use,\\nthe tools we’ll explore here can become important in many types of programs.\\n896 | Chapter 36: \\u2002Unicode and Byte Strings', metadata={'source': 'python.pdf', 'page': 946}),\n",
       " Document(page_content=\"String Basics\\nBefore we look \\nat any code, let’s begin with a general overview of Python’s string model.\\nTo understand why 3.0 changed the way it did on this front, we have to start with a\\nbrief look at how characters are actually represented in computers.\\nCharacter Encoding Schemes\\nMost programmers think of strings as series of characters used to represent textual data.\\nThe way characters are stored in a computer’s memory can vary, though, depending\\non what sort of character set must be recorded.\\nThe ASCII standard was created in the U.S., and it defines many U.S. programmers’\\nnotion of text strings. ASCII defines character codes from 0 through 127 and allows\\neach character to be stored in one 8-bit byte (only 7 bits of which are actually used).\\nFor example, the ASCII standard maps the character 'a' to the integer value 97 (0x61\\nin hex), which is stored in a single byte in memory and files. If you wish to see how this\\nworks, Python’s ord built-in function gives the binary value for a character, and chr\\nreturns the character for a given integer code value:\\n>>> ord('a')         # 'a' is a byte with binary value 97 in ASCII\\n97\\n>>> hex(97)\\n'0x61'\\n>>> chr(97)          # Binary value 97 stands for character 'a'\\n'a'\\nSometimes one byte per character isn’t enough, though. Various symbols and accented\\ncharacters, for instance, do not fit into the range of possible characters defined by\\nASCII. To accommodate special characters, some standards allow all possible values\\nin an 8-bit byte, 0 through 255, to represent characters, and assign the values 128\\nthrough 255 (outside ASCII’s range) to special characters. One such standard, known\\nas Latin-1, is widely used in Western Europe. In Latin-1, character codes above 127\\nare assigned to accented and otherwise special characters. The character assigned to\\nbyte value 196, for example, is a specially marked non-ASCII character:\\n>>> 0xC4\\n196\\n>>> chr(196)\\n'Ä'\\nThis standard allows for a wide array of extra special characters. Still, some alphabets\\ndefine so many characters that it is impossible to represent each of them as one byte.\\nUnicode allows more flexibility. Unicode text is commonly referred to as\\n“wide-character” strings, because each character may be represented with multiple\\nbytes. Unicode is typically used in internationalized programs, to represent European\\nand Asian character sets that have more characters than 8-bit bytes can represent.\\nString Basics | 897\", metadata={'source': 'python.pdf', 'page': 947}),\n",
       " Document(page_content='To store such rich text in computer memory, we say that characters are translated to\\nand from raw \\nbytes using an encoding—the rules for translating a string of Unicode\\ncharacters into a sequence of bytes, and extracting a string from a sequence of bytes.\\nMore procedurally, this translation back and forth between bytes and strings is defined\\nby two terms:\\n•Encoding is the process of translating a string of characters into its raw bytes form,\\naccording to a desired encoding name.\\n•Decoding is the process of translating a raw string of bytes into is character string\\nform, according to its encoding name.\\nThat is, we encode from string to raw bytes, and decode from raw bytes to string. For\\nsome encodings, the translation process is trivial—ASCII and Latin-1, for instance,\\nmap each character to a single byte, so no translation work is required. For other en-\\ncodings, the mapping can be more complex and yield multiple bytes per character.\\nThe widely used UTF-8 encoding, for example, allows a wide range of characters to be\\nrepresented by employing a variable number of bytes scheme. Character codes less than\\n128 are represented as a single byte; codes between 128 and 0x7ff (2047) are turned\\ninto two bytes, where each byte has a value between 128 and 255; and codes above\\n0x7ff are turned into three- or four-byte sequences having values between 128 and 255.\\nThis keeps simple ASCII strings compact, sidesteps byte ordering issues, and avoids\\nnull (zero) bytes that can cause problems for C libraries and networking.\\nBecause encodings’ character maps assign characters to the same codes for compati-\\nbility, ASCII is a subset of both Latin-1 and UTF-8; that is, a valid ASCII character string\\nis also a valid Latin-1- and UTF-8-encoded string. This is also true when the data is\\nstored in files: every ASCII file is a valid UTF-8 file, because ASCII is a 7-bit subset of\\nUTF-8.\\nConversely, the UTF-8 encoding is binary compatible with ASCII for all character codes\\nless than 128. Latin-1 and UTF-8 simply allow for additional characters: Latin-1 for\\ncharacters mapped to values 128 through 255 within a byte, and UTF-8 for characters\\nthat may be represented with multiple bytes. Other encodings allow wider character\\nsets in similar ways, but all of these—ASCII, Latin-1, UTF-8, and many others—are\\nconsidered to be Unicode.\\nTo Python programmers, encodings are specified as strings containing the encoding’s\\nname. Python comes with roughly 100 different encodings; see the Python library\\nreference for a complete list. Importing the module encodings and running\\nhelp(encodings) shows you many encoding names as well; some are implemented in\\nPython, and some in C. Some encodings have multiple names, too; for example, latin-1,\\niso_8859_1, and 8859 are all synonyms for the same encoding, Latin-1. We’ll revisit\\nencodings later in this chapter, when we study techniques for writing Unicode strings\\nin a script.\\n898 | Chapter 36: \\u2002Unicode and Byte Strings', metadata={'source': 'python.pdf', 'page': 948}),\n",
       " Document(page_content='For more on the Unicode story, see the Python standard manual set. It includes a\\n“Unicode HOWTO” in \\nits “Python HOWTOs” section, which provides additional\\nbackground that we will skip here in the interest of space.\\nPython’s String Types\\nAt a more concrete level, the Python language provides string data types to represent\\ncharacter text in your scripts. The string types you will use in your scripts depend upon\\nthe version of Python you’re using. Python 2.X has a general string type for representing\\nbinary data and simple 8-bit text like ASCII, along with a specific type for representing\\nmultibyte Unicode text:\\n•str for representing 8-bit text and binary data\\n•unicode for representing wide-character Unicode text\\nPython 2.X’s two string types are different ( unicode allows for the extra size of characters\\nand has extra support for encoding and decoding), but their operation sets largely\\noverlap. The str string type in 2.X is used for text that can be represented with 8-bit\\nbytes, as well as binary data that represents absolute byte values.\\nBy contrast, Python 3.X  comes with three string object types—one for textual data and\\ntwo for binary data:\\n•str for representing Unicode text (both 8-bit and wider)\\n•bytes for representing binary data\\n•bytearray, a mutable flavor of the bytes type\\nAs mentioned earlier, bytearray is also available in Python 2.6, but it’s simply a back-\\nport from 3.0 with less content-specific behavior and is generally considered a 3.0 type.\\nAll three string types in 3.0 support similar operation sets, but they have different roles.\\nThe main goal behind this change in 3.X was to merge the normal and Unicode string\\ntypes of 2.X into a single string type that supports both normal and Unicode text:\\ndevelopers wanted to remove the 2.X string dichotomy and make Unicode processing\\nmore natural. Given that ASCII and other 8-bit text is really a simple kind of Unicode,\\nthis convergence seems logically sound.\\nTo achieve this, the 3.0 str type is defined as an immutable sequence of characters (not\\nnecessarily bytes), which may be either normal text such as ASCII with one byte per\\ncharacter, or richer character set text such as UTF-8 Unicode that may include multi-\\nbyte characters. Strings processed by your script with this type are encoded per the\\nplatform default, but explicit encoding names may be provided to translate str objects\\nto and from different schemes, both in memory and when transferring to and from files.\\nWhile 3.0’s new str type does achieve the desired string/ unicode merging, many pro-\\ngrams still need to process raw binary data that is not encoded per any text format.\\nImage and audio files, as well as packed data used to interface with devices or C\\nString Basics | 899', metadata={'source': 'python.pdf', 'page': 949}),\n",
       " Document(page_content='programs you might process with Python’s struct module, fall into this category. To\\nsupport processing of truly binary data, therefore, a new type, bytes, also was\\nintroduced.\\nIn 2.X, the general str type filled this binary data role, because strings were just se-\\nquences of bytes (the separate unicode type handles wide-character strings). In 3.0, the\\nbytes type is defined as an immutable sequence of 8-bit integers  representing absolute\\nbyte values. Moreover, the 3.0 bytes type supports almost all the same operations that\\nthe str type does; this includes string methods, sequence operations, and even re mod-\\nule pattern matching, but not string formatting.\\nA 3.0 bytes object really is a sequence of small integers, each of which is in the range\\n0 through 255; indexing a bytes returns an int, slicing one returns another bytes, and\\nrunning the list built-in on one returns a list of integers, not characters. When pro-\\ncessed with operations that assume characters, though, the contents of bytes objects\\nare assumed to be ASCII-encoded bytes (e.g., the isalpha method assumes each byte\\nis an ASCII character code). Further, bytes objects are printed as character strings in-\\nstead of integers for convenience.\\nWhile they were at it, Python developers also added a bytearray type in 3.0.\\nbytearray is a variant of bytes that is mutable and so supports in-place changes. It\\nsupports the usual string operations that str and bytes do, as well as many of the same\\nin-place change operations as lists (e.g., the append and extend methods, and assignment\\nto indexes). Assuming your strings can be treated as raw bytes, bytearray finally adds\\ndirect in-place mutability for string data—something not possible without conversion\\nto a mutable type in Python 2, and not supported by Python 3.0’s str or bytes.\\nAlthough Python 2.6 and 3.0 offer much the same functionality, they package it dif-\\nferently. In fact, the mapping from 2.6 to 3.0 string types is not direct—2.6’s str equates\\nto both str and bytes in 3.0, and 3.0’s str equates to both str and unicode in 2.6.\\nMoreover, the mutability of 3.0’s bytearray is unique.\\nIn practice, though, this asymmetry is not as daunting as it might sound. It boils down\\nto the following: in 2.6, you will use str for simple text and binary data and unicode\\nfor more advanced forms of text; in 3.0, you’ll use str for any kind of text (simple and\\nUnicode) and bytes or bytearray for binary data. In practice, the choice is often made\\nfor you by the tools you use—especially in the case of file processing tools, the topic\\nof the next section.\\nText and Binary Files\\nFile I/O (input and output) has also been revamped in 3.0 to reflect the str/bytes\\ndistinction and automatically support encoding Unicode text. Python now makes a\\nsharp platform-independent distinction between text files and binary files:\\n900 | Chapter 36: \\u2002Unicode and Byte Strings', metadata={'source': 'python.pdf', 'page': 950}),\n",
       " Document(page_content='Text files\\nWhen a file is \\nopened in text mode , reading its data automatically decodes its con-\\ntent (per a platform default or a provided encoding name) and returns it as a str;\\nwriting takes a str and automatically encodes it before transferring it to the file.\\nText-mode files also support universal end-of-line translation and additional en-\\ncoding specification arguments. Depending on the encoding name, text files may\\nalso automatically process the byte order mark sequence at the start of a file (more\\non this momentarily).\\nBinary files\\nWhen a file is opened in binary mode  by adding a b (lowercase only) to the mode\\nstring argument in the built-in open call, reading its data does not decode it in any\\nway but simply returns its content raw and unchanged, as a bytes object; writing\\nsimilarly takes a bytes object and transfers it to the file unchanged. Binary-mode\\nfiles also accept a bytearray object for the content to be written to the file.\\nBecause the language sharply differentiates between str and bytes, you must decide\\nwhether your data is text or binary in nature and use either str or bytes objects to\\nrepresent its content in your script, as appropriate. Ultimately, the mode in which you\\nopen a file will dictate which type of object your script will use to represent its content:\\n• If you are processing image files, packed data created by other programs whose\\ncontent you must extract, or some device data streams, chances are good that you\\nwill want to deal with it using bytes and binary-mode files. You might also opt for\\nbytearray if you wish to update the data without making copies of it in memory.\\n• If instead you are processing something that is textual in nature, such as program\\noutput, HTML, internationalized text, or CSV or XML files, you’ll probably want\\nto use str and text-mode files.\\nNotice that the mode string  argument to built-in function open (its second argument)\\nbecomes fairly crucial in Python 3.0—its content not only specifies a file processing\\nmode, but also implies a Python object type . By adding a b to the mode string, you specify\\nbinary mode and will receive, or must provide, a bytes object to represent the file’s\\ncontent when reading or writing. Without the b, your file is processed in text mode,\\nand you’ll use str objects to represent its content in your script. For example, the modes\\nrb, wb, and rb+ imply bytes; r, w+, and rt (the default) imply str.\\nText-mode files also handle the byte order marker  (BOM) sequence that may appear at\\nthe start of files under certain encoding schemes. In the UTF-16 and UTF-32 encodings,\\nfor example, the BOM specifies big- or little-endian format (essentially, which end of\\na bitstring is most significant). A UTF-8 text file may also include a BOM to declare\\nthat it is UTF-8 in general, but this isn’t guaranteed. When reading and writing data\\nusing these encoding schemes, Python automatically skips or writes the BOM if it is\\nimplied by a general encoding name or if you provide a more specific encoding name\\nto force the issue. For example, the BOM is always processed for “utf-16,” the more\\nspecific encoding name “utf-16-le” species little-endian UTF-16 format, and the more\\nString Basics | 901', metadata={'source': 'python.pdf', 'page': 951}),\n",
       " Document(page_content='specific encoding name “utf-8-sig” forces Python to both skip and write a BOM on\\ninput and output, respectively, for UTF-8 text (the general name “utf-8” does not).\\nWe’ll learn more \\nabout BOMs and files in general in the section “Handling the BOM\\nin 3.0” on page 926. First, let’s explore the implications of Python’s new Unicode\\nstring model.\\nPython 3.0 Strings in Action\\nLet’s step through a few examples that demonstrate how the 3.0 string types are used.\\nOne note up front: the code in this section was run with and applies to 3.0 only. Still,\\nbasic string operations are generally portable across Python versions. Simple ASCII\\nstrings represented with the str type work the same in 2.6 and 3.0 (and exactly as we\\nsaw in Chapter 7  of this book). Moreover, although there is no bytes type in Python\\n2.6 (it has just the general str), it can usually run code that thinks there is—in 2.6, the\\ncall bytes(X) is present as a synonym for str(X), and the new literal form b\\'...\\' is taken\\nto be the same as the normal string literal \\'...\\'. You may still run into version skew in\\nsome isolated cases, though; the 2.6 bytes call, for instance, does not allow the second\\nargument (encoding name) required by 3.0’s bytes.\\nLiterals and Basic Properties\\nPython 3.0 string objects originate when you call a built-in function such as str or\\nbytes, process a file created by calling open (described in the next section), or code literal\\nsyntax in your script. For the latter, a new literal form, b\\'xxx\\' (and equivalently,\\nB\\'xxx\\') is used to create bytes objects in 3.0, and bytearray objects may be created by\\ncalling the bytearray function, with a variety of possible arguments.\\nMore formally, in 3.0 all the current string literal forms— \\'xxx\\', \"xxx\", and triple-quo-\\nted blocks—generate a str; adding a b or B just before any of them creates a bytes\\ninstead. This new b\\'...\\' bytes literal is similar in form to the r\\'...\\' raw string used to\\nsuppresses backslash escapes. Consider the following, run in 3.0:\\nC:\\\\misc> c:\\\\python30\\\\python\\n>>> B = b\\'spam\\'           # Make a bytes object (8-bit bytes)\\n>>> S = \\'eggs\\'            # Make a str object (Unicode characters, 8-bit or wider)\\n>>> type(B), type(S)\\n(<class \\'bytes\\'>, <class \\'str\\'>)\\n>>> B                     # Prints as a character string, really sequence of ints\\nb\\'spam\\'\\n>>> S\\n\\'eggs\\'\\n902 | Chapter 36: \\u2002Unicode and Byte Strings', metadata={'source': 'python.pdf', 'page': 952}),\n",
       " Document(page_content='The bytes object is actually a sequence of short integers, though it prints its content as\\ncharacters whenever possible:\\n>>> B[0], S[0]\\n            # Indexing returns an int for bytes, str for str\\n(115, \\'e\\')\\n>>> B[1:], S[1:]          # Slicing makes another bytes or str object\\n(b\\'pam\\', \\'ggs\\')\\n>>> list(B), list(S)\\n([115, 112, 97, 109], [\\'e\\', \\'g\\', \\'g\\', \\'s\\'])     # bytes is really ints\\nThe bytes object is immutable, just like str (though bytearray, described later, is not);\\nyou cannot assign a str, bytes, or integer to an offset of a bytes object. The bytes prefix\\nalso works for any string literal form:\\n>>> B[0] = \\'x\\'                                  # Both are immutable\\nTypeError: \\'bytes\\' object does not support item assignment\\n>>> S[0] = \\'x\\'\\nTypeError: \\'str\\' object does not support item assignment\\n>>> B = B\"\"\"              # bytes prefix works on single, double, triple quotes\\n... xxxx\\n... yyyy\\n... \"\"\"\\n>>> B\\nb\\'\\\\nxxxx\\\\nyyyy\\\\n\\'\\nAs mentioned earlier, in Python 2.6 the b\\'xxx\\' literal is present for compatibility but is\\nthe same as \\'xxx\\' and makes a str, and bytes is just a synonym for str; as you’ve seen,\\nin 3.0 both of these address the distinct bytes type. Also note that the u\\'xxx\\' and\\nU\\'xxx\\' Unicode string literal forms in 2.6 are gone in 3.0; use \\'xxx\\' instead, since all\\nstrings are Unicode, even if they contain all ASCII characters (more on writing non-\\nASCII Unicode text in the section “Coding Non-ASCII Text” on page 905).\\nConversions\\nAlthough Python 2.X allowed str and unicode type objects to be mixed freely (if the\\nstrings contained only 7-bit ASCII text), 3.0 draws a much sharper distinction—str\\nand bytes type objects never mix automatically in expressions and never are converted\\nto one another automatically when passed to functions. A function that expects an\\nargument to be a str object won’t generally accept a bytes, and vice versa.\\nBecause of this, Python 3.0 basically requires that you commit to one type or the other,\\nor perform manual, explicit conversions:\\n•str.encode() and bytes(S, encoding)  translate a string to its raw bytes form and\\ncreate a bytes from a str in the process.\\n•bytes.decode() and str(B, encoding)  translate raw bytes into its string form and\\ncreate a str from a bytes in the process.\\nPython 3.0 Strings in Action | 903', metadata={'source': 'python.pdf', 'page': 953}),\n",
       " Document(page_content='These encode and decode methods (as well as file objects, described in the next section)\\nuse either a default encoding for your platform or an explicitly passed-in encoding\\nname. For example, in 3.0:\\n>>> S = \\'eggs\\'\\n>>> S.encode()                          # str to bytes: encode text into raw bytes\\nb\\'eggs\\'\\n>>> bytes(S, encoding=\\'ascii\\')          # str to bytes, alternative\\nb\\'eggs\\'\\n>>> B = b\\'spam\\'\\n>>> B.decode()                          # bytes to str: decode raw bytes into text\\n\\'spam\\'\\n>>> str(B, encoding=\\'ascii\\')            # bytes to str, alternative\\n\\'spam\\'\\nTwo cautions here. First of all, your platform’s default encoding is available in the\\nsys module, but the encoding argument to bytes is not optional, even though it is in\\nstr.encode (and bytes.decode).\\nSecond, although calls to str do not require the encoding argument like bytes does,\\nleaving it off in str calls does not mean it defaults—instead, a str call without an\\nencoding returns the bytes object’s print string, not its str converted form (this is\\nusually not what you’ll want!). Assuming B and S are still as in the prior listing:\\n>>> import sys\\n>>> sys.platform                        # Underlying platform\\n\\'win32\\'\\n>>> sys.getdefaultencoding()            # Default encoding for str here\\n\\'utf-8\\'\\n>>> bytes(S)\\nTypeError: string argument without an encoding\\n>>> str(B)                              # str without encoding\\n\"b\\'spam\\'\"                               # A print string, not conversion!\\n>>> len(str(B))\\n7\\n>>> len(str(B, encoding=\\'ascii\\'))       # Use encoding to convert to str\\n4\\nCoding Unicode Strings\\nEncoding and decoding become more meaningful when you start dealing with actual\\nnon-ASCII Unicode text. To code arbitrary Unicode characters in your strings, some\\nof which you might not even be able to type on your keyboard, Python string literals\\nsupport both \"\\\\xNN\" hex byte value escapes and \"\\\\uNNNN\" and \"\\\\UNNNNNNNN\" Unicode\\nescapes in string literals. In Unicode escapes, the first form gives four hex digits to\\n904 | Chapter 36: \\u2002Unicode and Byte Strings', metadata={'source': 'python.pdf', 'page': 954}),\n",
       " Document(page_content=\"encode a 2-byte (16-bit) character code, and the second gives eight hex digits for a\\n4-byte (32-bit) code.\\nCoding ASCII Text\\nLet’s step through \\nsome examples that demonstrate text coding basics. As we’ve seen,\\nASCII text is a simple type of Unicode, stored as a sequence of byte values that represent\\ncharacters:\\nC:\\\\misc> c:\\\\python30\\\\python\\n>>> ord('X')             # 'X' has binary value 88 in the default encoding\\n88\\n>>> chr(88)              # 88 stands for character 'X'\\n'X'\\n>>> S = 'XYZ'            # A Unicode string of ASCII text\\n>>> S\\n'XYZ'\\n>>> len(S)               # 3 characters long\\n3\\n>>> [ord(c) for c in S]  # 3 bytes with integer ordinal values\\n[88, 89, 90]\\nNormal 7-bit ASCII text like this is represented with one character per byte under each\\nof the Unicode encoding schemes described earlier in this chapter:\\n>>> S.encode('ascii')    # Values 0..127 in 1 byte (7 bits) each\\nb'XYZ'\\n>>> S.encode('latin-1')  # Values 0..255 in 1 byte (8 bits) each\\nb'XYZ'\\n>>> S.encode('utf-8')    # Values 0..127 in 1 byte, 128..2047 in 2, others 3 or 4\\nb'XYZ'\\nIn fact, the bytes objects returned by encoding ASCII text this way is really a sequence\\nof short integers, which just happen to print as ASCII characters when possible:\\n>>> S.encode('latin-1')[0]\\n88\\n>>> list(S.encode('latin-1'))\\n[88, 89, 90]\\nCoding Non-ASCII Text\\nTo code non-ASCII characters, you may use hex or Unicode escapes in your strings;\\nhex escapes are limited to a single byte’s value, but Unicode escapes can name char-\\nacters with values two and four bytes wide. The hex values 0xCD and 0xE8, for instance,\\nare codes for two special accented characters outside the 7-bit range of ASCII, but we\\ncan embed them in 3.0 str objects because str supports Unicode today:\\nCoding Unicode Strings | 905\", metadata={'source': 'python.pdf', 'page': 955}),\n",
       " Document(page_content=\">>> chr(0xc4)            # 0xC4, 0xE8: characters outside ASCII's range\\n'Ä'\\n>>> chr(0xe8)\\n'è'\\n>>> S = '\\\\xc4\\\\xe8'       # Single byte 8-bit hex escapes\\n>>> S\\n'Äè'\\n>>> S = '\\\\u00c4\\\\u00e8'   # 16-bit Unicode escapes\\n>>> S\\n'Äè'\\n>>> len(S)               # 2 characters long (not number of bytes!)\\n2\\nEncoding and Decoding Non-ASCII text\\nNow, if we \\ntry to encode a non-ASCII string into raw bytes using as ASCII, we’ll get an\\nerror. Encoding as Latin-1 works, though, and allocates one byte per character; en-\\ncoding as UTF-8 allocates 2 bytes per character instead. If you write this string to a file,\\nthe raw bytes shown here is what is actually stored on the file for the encoding types\\ngiven:\\n>>> S = '\\\\u00c4\\\\u00e8'\\n>>> S\\n'Äè'\\n>>> len(S)\\n2\\n>>> S.encode('ascii')\\nUnicodeEncodeError: 'ascii' codec can't encode characters in position 0-1:\\nordinal not in range(128)\\n>>> S.encode('latin-1')              # One byte per character\\nb'\\\\xc4\\\\xe8'\\n>>> S.encode('utf-8')                # Two bytes per character\\nb'\\\\xc3\\\\x84\\\\xc3\\\\xa8'\\n>>> len(S.encode('latin-1'))         # 2 bytes in latin-1, 4 in utf-8\\n2\\n>>> len(S.encode('utf-8'))\\n4\\nNote that you can also go the other way, reading raw bytes from a file and decoding\\nthem back to a Unicode string. However, as we’ll see later, the encoding mode you give\\nto the open call causes this decoding to be done for you automatically on input (and\\navoids issues that may arise from reading partial character sequences when reading by\\nblocks of bytes):\\n>>> B = b'\\\\xc4\\\\xe8'\\n>>> B\\nb'\\\\xc4\\\\xe8'\\n906 | Chapter 36: \\u2002Unicode and Byte Strings\", metadata={'source': 'python.pdf', 'page': 956}),\n",
       " Document(page_content='>>> len(B)                           # 2 raw bytes, 2 characters\\n2\\n>>> B.decode(\\'latin-1\\')              # Decode to latin-1 text\\n\\'Äè\\'\\n>>> B = b\\'\\\\xc3\\\\x84\\\\xc3\\\\xa8\\'\\n>>> len(B)                           # 4 raw bytes\\n4\\n>>> B.decode(\\'utf-8\\')\\n\\'Äè\\'\\n>>> len(B.decode(\\'utf-8\\'))           # 2 Unicode characters\\n2\\nOther Unicode Coding Techniques\\nSome encodings use \\neven larger byte sequences to represent characters. When needed,\\nyou can specify both 16- and 32-bit Unicode values for characters in your strings—use\\n\"\\\\u...\" with four hex digits for the former, and \"\\\\U....\" with eight hex digits for the\\nlatter:\\n>>> S = \\'A\\\\u00c4B\\\\U000000e8C\\'\\n>>> S                                # A, B, C, and 2 non-ASCII characters\\n\\'AÄBèC\\'\\n>>> len(S)                           # 5 characters long\\n5\\n>>> S.encode(\\'latin-1\\')\\nb\\'A\\\\xc4B\\\\xe8C\\'\\n>>> len(S.encode(\\'latin-1\\'))         # 5 bytes in latin-1\\n5\\n>>> S.encode(\\'utf-8\\')\\nb\\'A\\\\xc3\\\\x84B\\\\xc3\\\\xa8C\\'\\n>>> len(S.encode(\\'utf-8\\'))           # 7 bytes in utf-8\\n7\\nInterestingly, some other encodings may use very different byte formats. The cp500 \\nEBCDIC encoding, for example, doesn’t even encode ASCII the same way as the en-\\ncodings we’ve been using so far (since Python encodes and decodes for us, we only\\ngenerally need to care about this when providing encoding names):\\n>>> S\\n\\'AÄBèC\\'\\n>>> S.encode(\\'cp500\\')                # Two other Western European encodings\\nb\\'\\\\xc1c\\\\xc2T\\\\xc3\\'\\n>>> S.encode(\\'cp850\\')                # 5 bytes each\\nb\\'A\\\\x8eB\\\\x8aC\\'\\n>>> S = \\'spam\\'                       # ASCII text is the same in most\\n>>> S.encode(\\'latin-1\\')\\nb\\'spam\\'\\n>>> S.encode(\\'utf-8\\')\\nb\\'spam\\'\\n>>> S.encode(\\'cp500\\')                # But not in cp500: IBM EBCDIC!\\nCoding Unicode Strings | 907', metadata={'source': 'python.pdf', 'page': 957}),\n",
       " Document(page_content=\"b'\\\\xa2\\\\x97\\\\x81\\\\x94'\\n>>> S.encode('cp850')\\nb'spam'\\nTechnically speaking, you \\ncan also build Unicode strings piecemeal using chr instead\\nof Unicode or hex escapes, but this might become tedious for large strings:\\n>>> S = 'A' + chr(0xC4) + 'B' + chr(0xE8) + 'C'\\n>>> S\\n'AÄBèC'\\nTwo cautions here. First, Python 3.0 allows special characters to be coded with both\\nhex and Unicode escapes in str strings, but only with hex escapes in bytes strings—\\nUnicode escape sequences are silently taken verbatim in bytes literals, not as escapes.\\nIn fact, bytes must be decoded to str strings to print their non-ASCII characters\\nproperly:\\n>>> S = 'A\\\\xC4B\\\\xE8C'                # str recognizes hex and Unicode escapes\\n>>> S\\n'AÄBèC'\\n>>> S = 'A\\\\u00C4B\\\\U000000E8C'\\n>>> S\\n'AÄBèC'\\n>>> B = b'A\\\\xC4B\\\\xE8C'               # bytes recognizes hex but not Unicode\\n>>> B\\nb'A\\\\xc4B\\\\xe8C'\\n>>> B = b'A\\\\u00C4B\\\\U000000E8C'       # Escape sequences taken literally!\\n>>> B\\nb'A\\\\\\\\u00C4B\\\\\\\\U000000E8C'\\n>>> B = b'A\\\\xC4B\\\\xE8C'               # Use hex escapes for bytes\\n>>> B                                # Prints non-ASCII as hex\\nb'A\\\\xc4B\\\\xe8C'\\n>>> print(B)\\nb'A\\\\xc4B\\\\xe8C'\\n>>> B.decode('latin-1')              # Decode as latin-1 to interpret as text\\n'AÄBèC'\\nSecond, bytes literals require characters either to be either ASCII characters or, if their\\nvalues are greater than 127, to be escaped; str stings, on the other hand, allow literals\\ncontaining any character in the source character set (which, as discussed later, defaults\\nto UTF-8 unless an encoding declaration is given in the source file):\\n>>> S = 'AÄBèC'                      # Chars from UTF-8 if no encoding declaration\\n>>> S\\n'AÄBèC'\\n>>> B = b'AÄBèC'\\nSyntaxError: bytes can only contain ASCII literal characters.\\n>>> B = b'A\\\\xC4B\\\\xE8C'               # Chars must be ASCII, or escapes\\n>>> B\\n908 | Chapter 36: \\u2002Unicode and Byte Strings\", metadata={'source': 'python.pdf', 'page': 958}),\n",
       " Document(page_content=\"b'A\\\\xc4B\\\\xe8C'\\n>>> B.decode('latin-1')\\n'AÄBèC'\\n>>> S.encode()                       # Source code encoded per UTF-8 by default\\nb'A\\\\xc3\\\\x84B\\\\xc3\\\\xa8C'               # Uses system default to encode, unless passed\\n>>> S.encode('utf-8')\\nb'A\\\\xc3\\\\x84B\\\\xc3\\\\xa8C'\\n>>> B.decode()                       # Raw bytes do not correspond to utf-8\\nUnicodeDecodeError: 'utf8' codec can't decode bytes in position 1-2: ...\\nConverting Encodings\\nSo far, we’ve \\nbeen encoding and decoding strings to inspect their structure. More gen-\\nerally, we can always convert a string to a different encoding than the source character\\nset default, but we must provide an explicit encoding name to encode to and decode\\nfrom:\\n>>> S = 'AÄBèC'\\n>>> S\\n'AÄBèC'\\n>>> S.encode()                       # Default utf-8 encoding\\nb'A\\\\xc3\\\\x84B\\\\xc3\\\\xa8C'\\n>>> T = S.encode('cp500')            # Convert to EBCDIC\\n>>> T\\nb'\\\\xc1c\\\\xc2T\\\\xc3'\\n>>> U = T.decode('cp500')            # Convert back to Unicode\\n>>> U\\n'AÄBèC'\\n>>> U.encode()                       # Default utf-8 encoding again\\nb'A\\\\xc3\\\\x84B\\\\xc3\\\\xa8C'\\nKeep in mind that the special Unicode and hex character escapes are only necessary\\nwhen you code non-ASCII Unicode strings manually. In practice, you’ll often load such\\ntext from files instead. As we’ll see later in this chapter, 3.0’s file object (created with\\nthe open built-in function) automatically decodes text strings as they are read and\\nencodes them when they are written; because of this, your script can often deal with\\nstrings generically, without having to code special characters directly.\\nLater in this chapter we’ll also see that it’s possible to convert between encodings when\\ntransferring strings to and from files, using a technique very similar to that in the last\\nexample; although you’ll still need to provide explicit encoding names when opening\\na file, the file interface does most of the conversion work for you automatically.\\nCoding Unicode Strings | 909\", metadata={'source': 'python.pdf', 'page': 959}),\n",
       " Document(page_content='Coding Unicode Strings in Python 2.6\\nNow that I’ve \\nshown you the basics of Unicode strings in 3.0, I need to explain that\\nyou can do much the same in 2.6, though the tools differ. unicode is available in Python\\n2.6, but it is a distinct data type from str, and it allows free mixing of normal and\\nUnicode strings when they are compatible. In fact, you can essentially pretend 2.6’s\\nstr is 3.0’s bytes when it comes to decoding raw bytes into a Unicode string, as long\\nas it’s in the proper form. Here is 2.6 in action (all other sections in this chapter are run\\nunder 3.0):\\nC:\\\\misc> c:\\\\python26\\\\python\\n>>> import sys\\n>>> sys.version\\n\\'2.6 (r26:66721, Oct  2 2008, 11:35:03) [MSC v.1500 32 bit (Intel)]\\'\\n>>> S = \\'A\\\\xC4B\\\\xE8C\\'                # String of 8-bit bytes\\n>>> print S                          # Some are non-ASCII\\nAÄBèC\\n>>> S.decode(\\'latin-1\\')              # Decode byte to latin-1 Unicode\\nu\\'A\\\\xc4B\\\\xe8C\\'\\n>>> S.decode(\\'utf-8\\')                # Not formatted as utf-8\\nUnicodeDecodeError: \\'utf8\\' codec can\\'t decode bytes in position 1-2: invalid data\\n>>> S.decode(\\'ascii\\')                # Outside ASCII range\\nUnicodeDecodeError: \\'ascii\\' codec can\\'t decode byte 0xc4 in position 1: ordinal\\nnot in range(128)\\nTo store arbitrarily encoded Unicode text, make a unicode object with the u\\'xxx\\' literal\\nform (this literal is no longer available in 3.0, since all strings support Unicode in 3.0):\\n>>> U = u\\'A\\\\xC4B\\\\xE8C\\'               # Make Unicode string, hex escapes\\n>>> U\\nu\\'A\\\\xc4B\\\\xe8C\\'\\n>>> print U\\nAÄBèC\\nOnce you’ve created it, you can convert Unicode text to different raw byte encodings,\\nsimilar to encoding str objects into bytes objects in 3.0:\\n>>> U.encode(\\'latin-1\\')              # Encode per latin-1: 8-bit bytes\\n\\'A\\\\xc4B\\\\xe8C\\'\\n>>> U.encode(\\'utf-8\\')                # Encode per utf-8: multibyte\\n\\'A\\\\xc3\\\\x84B\\\\xc3\\\\xa8C\\'\\nNon-ASCII characters can be coded with hex or Unicode escapes in string literals in\\n2.6, just as in 3.0. However, as with bytes in 3.0, the \"\\\\u...\" and \"\\\\U...\" escapes are\\nrecognized only for unicode strings in 2.6, not 8-bit str strings:\\nC:\\\\misc> c:\\\\python26\\\\python\\n>>> U = u\\'A\\\\xC4B\\\\xE8C\\'               # Hex escapes for non-ASCII\\n>>> U\\nu\\'A\\\\xc4B\\\\xe8C\\'\\n910 | Chapter 36: \\u2002Unicode and Byte Strings', metadata={'source': 'python.pdf', 'page': 960}),\n",
       " Document(page_content=\">>> print U\\nAÄBèC\\n>>> U = u'A\\\\u00C4B\\\\U000000E8C'       # Unicode escapes for non-ASCII\\n>>> U                                # u'' = 16 bits, U'' = 32 bits\\nu'A\\\\xc4B\\\\xe8C'\\n>>> print U\\nAÄBèC\\n>>> S = 'A\\\\xC4B\\\\xE8C'                # Hex escapes work\\n>>> S\\n'A\\\\xc4B\\\\xe8C'\\n>>> print S                          # But some print oddly, unless decoded\\nA-BFC\\n>>> print S.decode('latin-1')\\nAÄBèC\\n>>> S = 'A\\\\u00C4B\\\\U000000E8C'        # Not Unicode escapes: taken literally!\\n>>> S\\n'A\\\\\\\\u00C4B\\\\\\\\U000000E8C'\\n>>> print S\\nA\\\\u00C4B\\\\U000000E8C\\n>>> len(S)\\n19\\nLike 3.0’s str \\nand bytes, 2.6’s unicode and str share nearly identical operation sets, so\\nunless you need to convert to other encodings you can often treat unicode as though it\\nwere str. One of the primary differences between 2.6 and 3.0, though, is that\\nunicode and non-Unicode str objects can be freely mixed in expressions, and as long\\nas the str is compatible with the unicode’s encoding Python will automatically convert\\nit up to unicode (in 3.0, str and bytes never mix automatically and require manual\\nconversions):\\n>>> u'ab' + 'cd'                     # Can mix if compatible in 2.6\\nu'abcd'                              # 'ab' + b'cd' not allowed in 3.0\\nIn fact, the difference in types is often trivial to your code in 2.6. Like normal strings,\\nUnicode strings may be concatenated, indexed, sliced, matched with the re module,\\nand so on, and they cannot be changed in-place. If you ever need to convert between\\nthe two types explicitly, you can use the built-in str and unicode functions:\\n>>> str(u'spam')                     # Unicode to normal\\n'spam'\\n>>> unicode('spam')                  # Normal to Unicode\\nu'spam'\\nHowever, this liberal approach to mixing string types in 2.6 only works if the string is\\ncompatible with the unicode object’s encoding type:\\n>>> S = 'A\\\\xC4B\\\\xE8C'                # Can't mix if incompatible\\n>>> U = u'A\\\\xC4B\\\\xE8C'\\n>>> S + U\\nUnicodeDecodeError: 'ascii' codec can't decode byte 0xc4 in position 1: ordinal\\nnot in range(128)\\nCoding Unicode Strings | 911\", metadata={'source': 'python.pdf', 'page': 961}),\n",
       " Document(page_content=\">>> S.decode('latin-1') + U          # Manual conversion still required\\nu'A\\\\xc4B\\\\xe8CA\\\\xc4B\\\\xe8C'\\n>>> print S.decode('latin-1') + U\\nAÄBèCAÄBèC\\nFinally, as we’ll \\nsee in more detail later in this chapter, 2.6’s open call supports only files\\nof 8-bit bytes, returning their contents as str strings; it’s up to you to interpret the\\ncontents as text or binary data and decode if needed. To read and write Unicode files\\nand encode or decode their content automatically, use 2.6’s codecs.open call, docu-\\nmented in the 2.6 library manual. This call provides much the same functionality as\\n3.0’s open and uses 2.6 unicode objects to represent file content—reading a file translates\\nencoded bytes into decoded Unicode characters, and writing translates strings to the\\ndesired encoding specified when the file is opened.\\nSource File Character Set Encoding Declarations\\nUnicode escape codes are fine for the occasional Unicode character in string literals,\\nbut they can become tedious if you need to embed non-ASCII text in your strings\\nfrequently. For strings you code within your script files, Python uses the UTF-8 en-\\ncoding by default, but it allows you to change this to support arbitrary character sets\\nby including a comment that names your desired encoding. The comment must be of\\nthis form and must appear as either the first or second line in your script in either Python\\n2.6 or 3.0:\\n# -*- coding: latin-1 -*-\\nWhen a comment of this form is present, Python will recognize strings represented\\nnatively in the given encoding. This means you can edit your script file in a text editor\\nthat accepts and displays accented and other non-ASCII characters correctly, and Py-\\nthon will decode them correctly in your string literals. For example, notice how the\\ncomment at the top of the following file, text.py, allows Latin-1 characters to be em-\\nbedded in strings:\\n# -*- coding: latin-1 -*-\\n# Any of the following string literal forms work in latin-1.\\n# Changing the encoding above to either ascii or utf-8 fails,\\n# because the 0xc4 and 0xe8 in myStr1 are not valid in either.\\nmyStr1 = 'aÄBèC'\\nmyStr2 = 'A\\\\u00c4B\\\\U000000e8C'\\nmyStr3 = 'A' + chr(0xC4) + 'B' + chr(0xE8) + 'C'\\nimport sys\\nprint('Default encoding:', sys.getdefaultencoding())\\nfor aStr in myStr1, myStr2, myStr3:\\n912 | Chapter 36: \\u2002Unicode and Byte Strings\", metadata={'source': 'python.pdf', 'page': 962}),\n",
       " Document(page_content=\"    print('{0}, strlen={1}, '.format(aStr, len(aStr)), end='')\\n    bytes1 = aStr.encode()              # Per default utf-8: 2 bytes for non-ASCII\\n    bytes2 = aStr.encode('latin-1')     # One byte per char\\n   #bytes3 = aStr.encode('ascii')       # ASCII fails: outside 0..127 range\\n    print('byteslen1={0}, byteslen2={1}'.format(len(bytes1), len(bytes2)))\\nWhen run, this script produces the following output:\\nC:\\\\misc> c:\\\\python30\\\\python text.py\\nDefault encoding: utf-8\\naÄBèC, strlen=5, byteslen1=7, byteslen2=5\\nAÄBèC, strlen=5, byteslen1=7, byteslen2=5\\nAÄBèC, strlen=5, byteslen1=7, byteslen2=5\\nSince most programmers \\nare likely to fall back on the standard UTF-8 encoding, I’ll\\ndefer to Python’s standard manual set for more details on this option and other ad-\\nvanced Unicode support topics, such as properties and character name escapes in\\nstrings.\\nUsing 3.0 Bytes Objects\\nWe studied a wide variety of operations available for Python 3.0’s general str string\\ntype in Chapter 7 ; the basic string type works identically in 2.6 and 3.0, so we won’t\\nrehash this topic. Instead, let’s dig a bit deeper into the operation sets provided by the\\nnew bytes type in 3.0.\\nAs mentioned previously, the 3.0 bytes object is a sequence of small integers, each of\\nwhich is in the range 0 through 255, that happens to print as ASCII characters when\\ndisplayed. It supports sequence operations and most of the same methods available on\\nstr objects (and present in 2.X’s str type). However, bytes does not support the for\\nmat method or the % formatting expression, and you cannot mix and match bytes and\\nstr type objects without explicit conversions—you generally will use all str type objects\\nand text files for text data, and all bytes type objects and binary files for binary data.\\nMethod Calls\\nIf you really want to see what attributes str has that bytes doesn’t, you can always\\ncheck their dir built-in function results. The output can also tell you something about\\nthe expression operators they support (e.g., __mod__ and __rmod__ implement the %\\noperator):\\nC:\\\\misc> c:\\\\python30\\\\python\\n# Attributes unique to str\\n>>> set(dir('abc')) - set(dir(b'abc'))\\n{'isprintable', 'format', '__mod__', 'encode', 'isidentifier',\\n'_formatter_field_name_split', 'isnumeric', '__rmod__', 'isdecimal',\\nUsing 3.0 Bytes Objects | 913\", metadata={'source': 'python.pdf', 'page': 963}),\n",
       " Document(page_content=\"'_formatter_parser', 'maketrans'}\\n# Attributes unique to bytes\\n>>> set(dir(b'abc')) - set(dir('abc'))\\n{'decode', 'fromhex'}\\nAs you can \\nsee, str and bytes have almost identical functionality. Their unique at-\\ntributes are generally methods that don’t apply to the other; for instance, decode trans-\\nlates a raw bytes into its str representation, and encode translates a string into its raw\\nbytes representation. Most of the methods are the same, though bytes methods require\\nbytes arguments (again, 3.0 string types don’t mix). Also recall that bytes objects are\\nimmutable, just like str objects in both 2.6 and 3.0 (error messages here have been\\nshortened for brevity):\\n>>> B = b'spam'                    # b'...' bytes literal\\n>>> B.find(b'pa')\\n1\\n>>> B.replace(b'pa', b'XY')        # bytes methods expect bytes arguments\\nb'sXYm'\\n>>> B.split(b'pa')\\n[b's', b'm']\\n>>> B\\nb'spam'\\n>>> B[0] = 'x'\\nTypeError: 'bytes' object does not support item assignment\\nOne notable difference is that string formatting works only on str objects in 3.0, not\\non bytes objects (see Chapter 7  for more on string formatting expressions and\\nmethods):\\n>>> b'%s' % 99\\nTypeError: unsupported operand type(s) for %: 'bytes' and 'int'\\n>>> '%s' % 99\\n'99'\\n>>> b'{0}'.format(99)\\nAttributeError: 'bytes' object has no attribute 'format'\\n>>> '{0}'.format(99)\\n'99'\\nSequence Operations\\nBesides method calls, all the usual generic sequence operations you know (and possibly\\nlove) from Python 2.X strings and lists work as expected on both str and bytes in 3.0;\\nthis includes indexing, slicing, concatenation, and so on. Notice in the following that\\n914 | Chapter 36: \\u2002Unicode and Byte Strings\", metadata={'source': 'python.pdf', 'page': 964}),\n",
       " Document(page_content=\"indexing a bytes object returns an integer giving the byte’s binary value; bytes really is\\na sequence of 8-bit integers , but it prints as a string of ASCII-coded characters when\\ndisplayed as a whole for convenience. To check a given byte’s value, use the chr built-\\nin to convert it back to its character, as in the following:\\n>>> B = b'spam'                  # A sequence of small ints\\n>>> B                            # Prints as ASCII characters\\nb'spam'\\n>>> B[0]                         # Indexing yields an int\\n115\\n>>> B[-1]\\n109\\n>>> chr(B[0])                    # Show character for int\\n's'\\n>>> list(B)                      # Show all the byte's int values\\n[115, 112, 97, 109]\\n>>> B[1:], B[:-1]\\n(b'pam', b'spa')\\n>>> len(B)\\n4\\n>>> B + b'lmn'\\nb'spamlmn'\\n>>> B * 4\\nb'spamspamspamspam'\\nOther Ways to Make bytes Objects\\nSo far, we’ve been mostly making bytes objects with the b'...' literal syntax; they can\\nalso be created by calling the bytes constructor with a str and an encoding name, calling\\nthe bytes constructor with an iterable of integers representing byte values, or encoding\\na str object per the default (or passed-in) encoding. As we’ve seen, encoding takes a\\nstr and returns the raw binary byte values of the string according to the encoding\\nspecification; conversely, decoding takes a raw bytes sequence and encodes it to its\\nstring representation—a series of possibly wide characters. Both operations create new\\nstring objects:\\n>>> B = b'abc'\\n>>> B\\nb'abc'\\n>>> B = bytes('abc', 'ascii')\\n>>> B\\nb'abc'\\n>>> ord('a')\\n97\\n>>> B = bytes([97, 98, 99])\\nUsing 3.0 Bytes Objects | 915\", metadata={'source': 'python.pdf', 'page': 965}),\n",
       " Document(page_content=\">>> B\\nb'abc'\\n>>> B = 'spam'.encode()          # Or bytes()\\n>>> B\\nb'spam'\\n>>>\\n>>> S = B.decode()               # Or str()\\n>>> S\\n'spam'\\nFrom a larger \\nperspective, the last two of these operations are really tools for convert-\\ning between str and bytes, a topic introduced earlier and expanded upon in the next\\nsection.\\nMixing String Types\\nIn the replace call of the section “Method Calls” on page 913, we had to pass in two\\nbytes objects—str types won’t work there. Although Python 2.X automatically con-\\nverts str to and from unicode when possible (i.e., when the str is 7-bit ASCII text),\\nPython 3.0 requires specific string types in some contexts and expects manual conver-\\nsions if needed:\\n# Must pass expected types to function and method calls\\n>>> B = b'spam'\\n>>> B.replace('pa', 'XY')\\nTypeError: expected an object with the buffer interface\\n>>> B.replace(b'pa', b'XY')\\nb'sXYm'\\n>>> B = B'spam'\\n>>> B.replace(bytes('pa'), bytes('xy'))\\nTypeError: string argument without an encoding\\n>>> B.replace(bytes('pa', 'ascii'), bytes('xy', 'utf-8'))\\nb'sxym'\\n# Must convert manually in mixed-type expressions\\n>>> b'ab' + 'cd'\\nTypeError: can't concat bytes to str\\n>>> b'ab'.decode() + 'cd'                   # bytes to str\\n'abcd'\\n>>> b'ab' + 'cd'.encode()                   # str to bytes\\nb'abcd'\\n916 | Chapter 36: \\u2002Unicode and Byte Strings\", metadata={'source': 'python.pdf', 'page': 966}),\n",
       " Document(page_content=\">>> b'ab' + bytes('cd', 'ascii')            # str to bytes\\nb'abcd'\\nAlthough you can \\ncreate bytes objects yourself to represent packed binary data, they\\ncan also be made automatically by reading files opened in binary mode, as we’ll see in\\nmore detail later in this chapter. First, though, we should introduce bytes’s very close,\\nand mutable, cousin.\\nUsing 3.0 (and 2.6) bytearray Objects\\nSo far we’ve focused on str and bytes, since they subsume Python 2’s unicode and\\nstr. Python 3.0 has a third string type, though— bytearray, a mutable sequence of\\nintegers in the range 0 through 255, is essentially a mutable variant of bytes. As such,\\nit supports the same string methods and sequence operations as bytes, as well as many\\nof the mutable in-place-change operations supported by lists. The bytearray type is\\nalso available in Python 2.6 as a back-port from 3.0, but it does not enforce the strict\\ntext/binary distinction there that it does in 3.0.\\nLet’s take a quick tour. bytearray objects may be created by calling the bytearray built-\\nin. In Python 2.6, any string may be used to initialize:\\n# Creation in 2.6: a mutable sequence of small (0..255) ints\\n>>> S = 'spam'\\n>>> C = bytearray(S)                      # A back-port from 3.0 in 2.6\\n>>> C                                     # b'..' == '..' in 2.6 (str)\\nbytearray(b'spam')\\nIn Python 3.0, an encoding name or byte string is required, because text and binary\\nstrings do not mix, though byte strings may reflect encoded Unicode text:\\n# Creation in 3.0: text/binary do not mix\\n>>> S = 'spam'\\n>>> C = bytearray(S)\\nTypeError: string argument without an encoding\\n>>> C = bytearray(S, 'latin1')            # A content-specific type in 3.0\\n>>> C\\nbytearray(b'spam')\\n>>> B = b'spam'                           # b'..' != '..' in 3.0 (bytes/str)\\n>>> C = bytearray(B)\\n>>> C\\nbytearray(b'spam')\\nOnce created, bytearray objects are sequences of small integers like bytes and are mu-\\ntable like lists, though they require an integer for index assignments, not a string (all\\nof the following is a continuation of this session and is run under Python 3.0 unless\\notherwise noted—see comments for 2.6 usage notes):\\nUsing 3.0 (and 2.6) bytearray Objects | 917\", metadata={'source': 'python.pdf', 'page': 967}),\n",
       " Document(page_content=\"# Mutable, but must assign ints, not strings\\n>>> C[0]\\n115\\n>>> C[0] = 'x'                            # This and the next work in 2.6\\nTypeError: an integer is required\\n>>> C[0] = b'x'\\nTypeError: an integer is required\\n>>> C[0] = ord('x')\\n>>> C\\nbytearray(b'xpam')\\n>>> C[1] = b'Y'[0]\\n>>> C\\nbytearray(b'xYam')\\nProcessing bytearray objects borrows \\nfrom both strings and lists, since they are mutable\\nbyte strings. Besides named methods, the __iadd__ and __setitem__ methods in\\nbytearray implement += in-place concatenation and index assignment, respectively:\\n# Methods overlap with both str and bytes, but also has list's mutable methods\\n>>> set(dir(b'abc')) - set(dir(bytearray(b'abc')))\\n{'__getnewargs__'}\\n>>> set(dir(bytearray(b'abc'))) - set(dir(b'abc'))\\n{'insert', '__alloc__', 'reverse', 'extend', '__delitem__', 'pop', '__setitem__'\\n, '__iadd__', 'remove', 'append', '__imul__'}\\nYou can change a bytearray in-place with both index assignment, as you’ve just seen,\\nand list-like methods like those shown here (to change text in-place in 2.6, you would\\nneed to convert to and then from a list, with list(str) and ''.join(list)):\\n# Mutable method calls\\n>>> C\\nbytearray(b'xYam')\\n>>> C.append(b'LMN')                      # 2.6 requires string of size 1\\nTypeError: an integer is required\\n>>> C.append(ord('L'))\\n>>> C\\nbytearray(b'xYamL')\\n>>> C.extend(b'MNO')\\n>>> C\\nbytearray(b'xYamLMNO')\\n918 | Chapter 36: \\u2002Unicode and Byte Strings\", metadata={'source': 'python.pdf', 'page': 968}),\n",
       " Document(page_content=\"All the usual sequence operations and string methods work on bytearrays, as you would\\nexpect (notice that like bytes objects, their expressions and methods expect bytes ar-\\nguments, not str arguments):\\n# Sequence operations and string methods\\n>>> C + b'!#'\\nbytearray(b'xYamLMNO!#')\\n>>> C[0]\\n120\\n>>> C[1:]\\nbytearray(b'YamLMNO')\\n>>> len(C)\\n8\\n>>> C\\nbytearray(b'xYamLMNO')\\n>>> C.replace('xY', 'sp')                 # This works in 2.6\\nTypeError: Type str doesn't support the buffer API\\n>>> C.replace(b'xY', b'sp')\\nbytearray(b'spamLMNO')\\n>>> C\\nbytearray(b'xYamLMNO')\\n>>> C * 4\\nbytearray(b'xYamLMNOxYamLMNOxYamLMNOxYamLMNO')\\nFinally, by way of summary, the following examples demonstrate how bytes and\\nbytearray objects are sequences of ints, and str objects are sequences of characters:\\n# Binary versus text\\n>>> B                                     # B is same as S in 2.6\\nb'spam'\\n>>> list(B)\\n[115, 112, 97, 109]\\n>>> C\\nbytearray(b'xYamLMNO')\\n>>> list(C)\\n[120, 89, 97, 109, 76, 77, 78, 79]\\n>>> S\\n'spam'\\n>>> list(S)\\n['s', 'p', 'a', 'm']\\nUsing 3.0 (and 2.6) bytearray Objects | 919\", metadata={'source': 'python.pdf', 'page': 969}),\n",
       " Document(page_content='Although all three Python 3.0 string types can contain character values and support\\nmany of the same operations, again, you should always:\\n• Use str for textual data.\\n•\\nUse bytes for binary data.\\n• Use bytearray for binary data you wish to change in-place.\\nRelated tools such as files, the next section’s topic, often make the choice for you.\\nUsing Text and Binary Files\\nThis section expands on the impact of Python 3.0’s string model on the file processing\\nbasics introduced earlier in the book. As mentioned earlier, the mode in which you\\nopen a file is crucial—it determines which object type you will use to represent the file’s\\ncontent in your script. Text mode implies str objects, and binary mode implies bytes\\nobjects:\\n•Text-mode files  interpret file contents according to a Unicode encoding—either the\\ndefault for your platform, or one whose name you pass in. By passing in an encoding\\nname to open, you can force conversions for various types of Unicode files. Text-\\nmode files also perform universal line-end translations: by default, all line-end\\nforms map to the single \\'\\\\n\\' character in your script, regardless of the platform on\\nwhich you run it. As described earlier, text files also handle reading and writing\\nthe byte order mark (BOM) stored at the start-of-file in some Unicode encoding\\nschemes.\\n•Binary-mode files  instead return file content to you raw, as a sequence of integers\\nrepresenting byte values, with no encoding or decoding and no line-end\\ntranslations.\\nThe second argument to open determines whether you want text or binary processing,\\njust as it does in 2.X Python—adding a “b” to this string implies binary mode (e.g.,\\n\"rb\" to read binary data files). The default mode is \"rt\"; this is the same as \"r\", which\\nmeans text input (just as in 2.X).\\nIn 3.0, though, this mode argument to open also implies an object type  for file content\\nrepresentation, regardless of the underlying platform—text files return a str for reads\\nand expect one for writes, but binary files return a bytes for reads and expect one (or\\na bytearray) for writes.\\nText File Basics\\nTo demonstrate, let’s begin with basic file I/O. As long as you’re processing basic text\\nfiles (e.g., ASCII) and don’t care about circumventing the platform-default encoding of\\nstrings, files in 3.0 look and feel much as they do in 2.X (for that matter, so do strings\\nin general). The following, for instance, writes one line of text to a file and reads it back\\n920 | Chapter 36: \\u2002Unicode and Byte Strings', metadata={'source': 'python.pdf', 'page': 970}),\n",
       " Document(page_content='in 3.0, exactly as it would in 2.6 (note that file is no longer a built-in name in 3.0, so\\nit’s perfectly OK to use it as a variable here):\\nC:\\\\misc> c:\\\\python30\\\\python\\n# Basic text files (and strings) work the same as in 2.X\\n>>> file = open(\\'temp\\', \\'w\\')\\n>>> size = file.write(\\'abc\\\\n\\')       # Returns number of bytes written\\n>>> file.close()                     # Manual close to flush output buffer\\n>>> file = open(\\'temp\\')              # Default mode is \"r\" (== \"rt\"): text input\\n>>> text = file.read()\\n>>> text\\n\\'abc\\\\n\\'\\n>>> print(text)\\nabc\\nText and Binary Modes in 3.0\\nIn Python 2.6, there is no major distinction between text and binary files—both accept\\nand return content as str strings. The only major difference is that text files automat-\\nically map \\\\n end-of-line characters to and from \\\\r\\\\n on Windows, while binary files\\ndo not (I’m stringing operations together into one-liners here just for brevity):\\nC:\\\\misc> c:\\\\python26\\\\python\\n>>> open(\\'temp\\', \\'w\\').write(\\'abd\\\\n\\')         # Write in text mode: adds \\\\r\\n>>> open(\\'temp\\', \\'r\\').read()                 # Read in text mode: drops \\\\r\\n\\'abd\\\\n\\'\\n>>> open(\\'temp\\', \\'rb\\').read()                # Read in binary mode: verbatim\\n\\'abd\\\\r\\\\n\\'\\n>>> open(\\'temp\\', \\'wb\\').write(\\'abc\\\\n\\')        # Write in binary mode\\n>>> open(\\'temp\\', \\'r\\').read()                 # \\\\n not expanded to \\\\r\\\\n\\n\\'abc\\\\n\\'\\n>>> open(\\'temp\\', \\'rb\\').read()\\n\\'abc\\\\n\\'\\nIn Python 3.0, things are bit more complex because of the distinction between str for\\ntext data and bytes for binary data. To demonstrate, let’s write a text file and read it\\nback in both modes in 3.0. Notice that we are required to provide a str for writing, but\\nreading gives us a str or a bytes, depending on the open mode:\\nC:\\\\misc> c:\\\\python30\\\\python\\n# Write and read a text file\\n>>> open(\\'temp\\', \\'w\\').write(\\'abc\\\\n\\')         # Text mode output, provide a str\\n4\\n>>> open(\\'temp\\', \\'r\\').read()                 # Text mode input, returns a str\\n\\'abc\\\\n\\'\\nUsing Text and Binary Files | 921', metadata={'source': 'python.pdf', 'page': 971}),\n",
       " Document(page_content='>>> open(\\'temp\\', \\'rb\\').read()                # Binary mode input, returns a bytes\\nb\\'abc\\\\r\\\\n\\'\\nNotice how on \\nWindows text-mode files translate the \\\\n end-of-line character to \\\\r\\\\n\\non output; on input, text mode translates the \\\\r\\\\n back to \\\\n, but binary mode does\\nnot. This is the same in 2.6, and it’s what we want for binary data (no translations\\nshould occur), although you can control this behavior with extra open arguments in 3.0\\nif desired.\\nNow let’s do the same again, but with a binary file . We provide a bytes to write in this\\ncase, and we still get back a str or a bytes, depending on the input mode:\\n# Write and read a binary file\\n>>> open(\\'temp\\', \\'wb\\').write(b\\'abc\\\\n\\')       # Binary mode output, provide a bytes\\n4\\n>>> open(\\'temp\\', \\'r\\').read()                 # Text mode input, returns a str\\n\\'abc\\\\n\\'\\n>>> open(\\'temp\\', \\'rb\\').read()                # Binary mode input, returns a bytes\\nb\\'abc\\\\n\\'\\nNote that the \\\\n end-of-line character is not expanded to \\\\r\\\\n in binary-mode output—\\nagain, a desired result for binary data. Type requirements and file behavior are the same\\neven if the data we’re writing to the binary file is truly binary in nature. In the following,\\nfor example, the \"\\\\x00\" is a binary zero byte and not a printable character:\\n# Write and read truly binary data\\n>>> open(\\'temp\\', \\'wb\\').write(b\\'a\\\\x00c\\')      # Provide a bytes\\n3\\n>>> open(\\'temp\\', \\'r\\').read()                 # Receive a str\\n\\'a\\\\x00c\\'\\n>>> open(\\'temp\\', \\'rb\\').read()                # Receive a bytes\\nb\\'a\\\\x00c\\'\\nBinary-mode files always return contents as a bytes object, but accept either a bytes or\\nbytearray object for writing; this naturally follows, given that bytearray is basically just\\na mutable variant of bytes. In fact, most APIs in Python 3.0 that accept a bytes also\\nallow a bytearray:\\n# bytearrays work too\\n>>> BA = bytearray(b\\'\\\\x01\\\\x02\\\\x03\\')\\n>>> open(\\'temp\\', \\'wb\\').write(BA)\\n3\\n>>> open(\\'temp\\', \\'r\\').read()\\n\\'\\\\x01\\\\x02\\\\x03\\'\\n922 | Chapter 36: \\u2002Unicode and Byte Strings', metadata={'source': 'python.pdf', 'page': 972}),\n",
       " Document(page_content=\">>> open('temp', 'rb').read()\\nb'\\\\x01\\\\x02\\\\x03'\\nType and Content Mismatches\\nNotice that you \\ncannot get away with violating Python’s str/bytes type distinction\\nwhen it comes to files. As the following examples illustrate, we get errors (shortened\\nhere) if we try to write a bytes to a text file or a str to a binary file:\\n# Types are not flexible for file content\\n>>> open('temp', 'w').write('abc\\\\n')         # Text mode makes and requires str\\n4\\n>>> open('temp', 'w').write(b'abc\\\\n')\\nTypeError: can't write bytes to text stream\\n>>> open('temp', 'wb').write(b'abc\\\\n')       # Binary mode makes and requires bytes\\n4\\n>>> open('temp', 'wb').write('abc\\\\n')\\nTypeError: can't write str to binary stream\\nThis makes sense: text has no meaning in binary terms, before it is encoded. Although\\nit is often possible to convert between the types by encoding str and decoding bytes,\\nas described earlier in this chapter, you will usually want to stick to either str for text\\ndata or bytes for binary data. Because the str and bytes operation sets largely intersect,\\nthe choice won’t be much of a dilemma for most programs (see the string tools coverage\\nin the final section of this chapter for some prime examples of this).\\nIn addition to type constraints, file content  can matter in 3.0. Text-mode output files\\nrequire a str instead of a bytes for content, so there is no way in 3.0 to write truly binary\\ndata to a text-mode file. Depending on the encoding rules, bytes outside the default\\ncharacter set can sometimes be embedded in a normal string, and they can always be\\nwritten in binary mode. However, because text-mode input files in 3.0 must be able to\\ndecode content per a Unicode encoding, there is no way to read truly binary data in\\ntext mode:\\n# Can't read truly binary data in text mode\\n>>> chr(0xFF)                                   # FF is a valid char, FE is not\\n'ÿ'\\n>>> chr(0xFE)\\nUnicodeEncodeError: 'charmap' codec can't encode character '\\\\xfe' in position 1...\\n>>> open('temp', 'w').write(b'\\\\xFF\\\\xFE\\\\xFD')    # Can't use arbitrary bytes!\\nTypeError: can't write bytes to text stream\\n>>> open('temp', 'w').write('\\\\xFF\\\\xFE\\\\xFD')     # Can write if embeddable in str\\n3\\n>>> open('temp', 'wb').write(b'\\\\xFF\\\\xFE\\\\xFD')   # Can also write in binary mode\\n3\\n>>> open('temp', 'rb').read()                   # Can always read as binary bytes\\nUsing Text and Binary Files | 923\", metadata={'source': 'python.pdf', 'page': 973}),\n",
       " Document(page_content=\"b'\\\\xff\\\\xfe\\\\xfd'\\n>>> open('temp', 'r').read()                    # Can't read text unless decodable!\\nUnicodeEncodeError: 'charmap' codec can't encode characters in position 2-3: ...\\nThis last error \\nstems from the fact that all text files in 3.0 are really Unicode text files,\\nas the next section describes.\\nUsing Unicode Files\\nSo far, we’ve been reading and writing basic text and binary files, but what about pro-\\ncessing Unicode files? It turns out to be easy to read and write Unicode text stored in\\nfiles, because the 3.0 open call accepts an encoding for text files, which does the en-\\ncoding and decoding for us automatically as data is transferred. This allows us to\\nprocess Unicode text created with different encodings than the default for the platform,\\nand store in different encodings to convert.\\nReading and Writing Unicode in 3.0\\nIn fact, we can convert a string to different encodings both manually with method calls\\nand automatically on file input and output. We’ll use the following Unicode string in\\nthis section to demonstrate:\\nC:\\\\misc> c:\\\\python30\\\\python\\n>>> S = 'A\\\\xc4B\\\\xe8C'           # 5-character string, non-ASCII\\n>>> S\\n'AÄBèC'\\n>>> len(S)\\n5\\nManual encoding\\nAs we’ve already learned, we can always encode such a string to raw bytes according\\nto the target encoding name:\\n# Encode manually with methods\\n>>> L = S.encode('latin-1')     # 5 bytes when encoded as latin-1\\n>>> L\\nb'A\\\\xc4B\\\\xe8C'\\n>>> len(L)\\n5\\n>>> U = S.encode('utf-8')       # 7 bytes when encoded as utf-8\\n>>> U\\nb'A\\\\xc3\\\\x84B\\\\xc3\\\\xa8C'\\n>>> len(U)\\n7\\n924 | Chapter 36: \\u2002Unicode and Byte Strings\", metadata={'source': 'python.pdf', 'page': 974}),\n",
       " Document(page_content=\"File output encoding\\nNow, to write our string to a text file in a particular encoding, we can simply pass the\\ndesired encoding name \\nto open—although we could manually encode first and write in\\nbinary mode, there’s no need to:\\n# Encoding automatically when written\\n>>> open('latindata', 'w', encoding='latin-1').write(S)    # Write as latin-1\\n5\\n>>> open('utf8data', 'w', encoding='utf-8').write(S)       # Write as utf-8\\n5\\n>>> open('latindata', 'rb').read()                         # Read raw bytes\\nb'A\\\\xc4B\\\\xe8C'\\n>>> open('utf8data', 'rb').read()                          # Different in files\\nb'A\\\\xc3\\\\x84B\\\\xc3\\\\xa8C'\\nFile input decoding\\nSimilarly, to read arbitrary Unicode data, we simply pass in the file’s encoding type\\nname to open, and it decodes from raw bytes to strings automatically; we could read\\nraw bytes and decode manually too, but that can be tricky when reading in blocks (we\\nmight read an incomplete character), and it isn’t necessary:\\n# Decoding automatically when read\\n>>> open('latindata', 'r', encoding='latin-1').read()      # Decoded on input\\n'AÄBèC'\\n>>> open('utf8data', 'r', encoding='utf-8').read()         # Per encoding type\\n'AÄBèC'\\n>>> X = open('latindata', 'rb').read()                     # Manual decoding:\\n>>> X.decode('latin-1')                                    # Not necessary\\n'AÄBèC'\\n>>> X = open('utf8data', 'rb').read()\\n>>> X.decode()                                             # UTF-8 is default\\n'AÄBèC'\\nDecoding mismatches\\nFinally, keep in mind that this behavior of files in 3.0 limits the kind of content you can\\nload as text. As suggested in the prior section, Python 3.0 really must be able to decode\\nthe data in text files into a str string, according to either the default or a passed-in\\nUnicode encoding name. Trying to open a truly binary data file in text mode, for ex-\\nample, is unlikely to work in 3.0 even if you use the correct object types:\\n>>> file = open('python.exe', 'r')\\n>>> text = file.read()\\nUnicodeDecodeError: 'charmap' codec can't decode byte 0x90 in position 2: ...\\n>>> file = open('python.exe', 'rb')\\nUsing Unicode Files | 925\", metadata={'source': 'python.pdf', 'page': 975}),\n",
       " Document(page_content=\">>> data = file.read()\\n>>> data[:20]\\nb'MZ\\\\x90\\\\x00\\\\x03\\\\x00\\\\x00\\\\x00\\\\x04\\\\x00\\\\x00\\\\x00\\\\xff\\\\xff\\\\x00\\\\x00\\\\xb8\\\\x00\\\\x00\\\\x00'\\nThe first of \\nthese examples might not fail in Python 2.X (normal files do not decode\\ntext), even though it probably should: reading the file may return corrupted data in the\\nstring, due to automatic end-of-line translations in text mode (any embedded \\\\r\\\\n bytes\\nwill be translated to \\\\n on Windows when read). To treat file content as Unicode text\\nin 2.6, we need to use special tools instead of the general open built-in function, as we’ll\\nsee in a moment. First, though, let’s turn to a more explosive topic....\\nHandling the BOM in 3.0\\nAs described earlier in this chapter, some encoding schemes store a special byte order\\nmarker (BOM) sequence at the start of files, to specify data endianness or declare the\\nencoding type. Python both skips this marker on input and writes it on output if the\\nencoding name implies it, but we sometimes must use a specific encoding name to force\\nBOM processing explicitly.\\nFor example, when you save a text file in Windows Notepad, you can specify its en-\\ncoding type in a drop-down list—simple ASCII text, UTF-8, or little- or big-endian\\nUTF-16. If a one-line text file named spam.txt is saved in Notepad as the encoding type\\n“ANSI,” for instance, it’s written as simple ASCII text without a BOM. When this file\\nis read in binary mode in Python, we can see the actual bytes stored in the file. When\\nit’s read as text, Python performs end-of-line translation by default; we can decode it\\nas explicit UTF-8 text since ASCII is a subset of this scheme (and UTF-8 is Python 3.0’s\\ndefault encoding):\\nc:\\\\misc> C:\\\\Python30\\\\python               # File saved in Notepad\\n>>> import sys\\n>>> sys.getdefaultencoding()\\n'utf-8'\\n>>> open('spam.txt', 'rb').read()         # ASCII (UTF-8) text file\\nb'spam\\\\r\\\\nSPAM\\\\r\\\\n'\\n>>> open('spam.txt', 'r').read()          # Text mode translates line-end\\n'spam\\\\nSPAM\\\\n'\\n>>> open('spam.txt', 'r', encoding='utf-8').read()\\n'spam\\\\nSPAM\\\\n'\\nIf this file is instead saved as “UTF-8” in Notepad, it is prepended with a three-byte\\nUTF-8 BOM sequence, and we need to give a more specific encoding name\\n(“utf-8-sig”) to force Python to skip the marker:\\n>>> open('spam.txt', 'rb').read()         # UTF-8 with 3-byte BOM\\nb'\\\\xef\\\\xbb\\\\xbfspam\\\\r\\\\nSPAM\\\\r\\\\n'\\n>>> open('spam.txt', 'r').read()\\n'ï»¿spam\\\\nSPAM\\\\n'\\n>>> open('spam.txt', 'r', encoding='utf-8').read()\\n'\\\\ufeffspam\\\\nSPAM\\\\n'\\n>>> open('spam.txt', 'r', encoding='utf-8-sig').read()\\n'spam\\\\nSPAM\\\\n'\\n926 | Chapter 36: \\u2002Unicode and Byte Strings\", metadata={'source': 'python.pdf', 'page': 976}),\n",
       " Document(page_content=\"If the file is stored as “Unicode big endian” in Notepad, we get UTF-16-format data in\\nthe file, prepended \\nwith a two-byte BOM sequence—the encoding name “utf-16” in\\nPython skips the BOM because it is implied (since all UTF-16 files have a BOM), and\\n“utf-16-be” handles the big-endian format but does not skip the BOM:\\n>>> open('spam.txt', 'rb').read()\\nb'\\\\xfe\\\\xff\\\\x00s\\\\x00p\\\\x00a\\\\x00m\\\\x00\\\\r\\\\x00\\\\n\\\\x00S\\\\x00P\\\\x00A\\\\x00M\\\\x00\\\\r\\\\x00\\\\n'\\n>>> open('spam.txt', 'r').read()\\nUnicodeEncodeError: 'charmap' codec can't encode character '\\\\xfe' in position 1:...\\n>>> open('spam.txt', 'r', encoding='utf-16').read()\\n'spam\\\\nSPAM\\\\n'\\n>>> open('spam.txt', 'r', encoding='utf-16-be').read()\\n'\\\\ufeffspam\\\\nSPAM\\\\n'\\nThe same is generally true for output. When writing a Unicode file in Python code, we\\nneed a more explicit encoding name to force the BOM in UTF-8—“utf-8” does not\\nwrite (or skip) the BOM, but “utf-8-sig” does:\\n>>> open('temp.txt', 'w', encoding='utf-8').write('spam\\\\nSPAM\\\\n')\\n10\\n>>> open('temp.txt', 'rb').read()                         # No BOM\\nb'spam\\\\r\\\\nSPAM\\\\r\\\\n'\\n>>> open('temp.txt', 'w', encoding='utf-8-sig').write('spam\\\\nSPAM\\\\n')\\n10\\n>>> open('temp.txt', 'rb').read()                         # Wrote BOM\\nb'\\\\xef\\\\xbb\\\\xbfspam\\\\r\\\\nSPAM\\\\r\\\\n'\\n>>> open('temp.txt', 'r').read()\\n'ï»¿spam\\\\nSPAM\\\\n'\\n>>> open('temp.txt', 'r', encoding='utf-8').read()        # Keeps BOM\\n'\\\\ufeffspam\\\\nSPAM\\\\n'\\n>>> open('temp.txt', 'r', encoding='utf-8-sig').read()    # Skips BOM\\n'spam\\\\nSPAM\\\\n'\\nNotice that although “utf-8” does not drop the BOM, data without a BOM can be read\\nwith both “utf-8” and “utf-8-sig”—use the latter for input if you’re not sure whether a\\nBOM is present in a file (and don’t read this paragraph out loud in an airport security\\nline!):\\n>>> open('temp.txt', 'w').write('spam\\\\nSPAM\\\\n')\\n10\\n>>> open('temp.txt', 'rb').read()                         # Data without BOM\\nb'spam\\\\r\\\\nSPAM\\\\r\\\\n'\\n>>> open('temp.txt', 'r').read()                          # Any utf-8 works\\n'spam\\\\nSPAM\\\\n'\\n>>> open('temp.txt', 'r', encoding='utf-8').read()\\n'spam\\\\nSPAM\\\\n'\\n>>> open('temp.txt', 'r', encoding='utf-8-sig').read()\\n'spam\\\\nSPAM\\\\n'\\nFinally, for the encoding name “utf-16,” the BOM is handled automatically: on out-\\nput, data is written in the platform’s native endianness, and the BOM is always written;\\non input, data is decoded per the BOM, and the BOM is always stripped. More specific\\nUsing Unicode Files | 927\", metadata={'source': 'python.pdf', 'page': 977}),\n",
       " Document(page_content=\"UTF-16 encoding names can specify different endianness, though you may have to\\nmanually write and \\nskip the BOM yourself in some scenarios if it is required or present:\\n>>> sys.byteorder\\n'little'\\n>>> open('temp.txt', 'w', encoding='utf-16').write('spam\\\\nSPAM\\\\n')\\n10\\n>>> open('temp.txt', 'rb').read()\\nb'\\\\xff\\\\xfes\\\\x00p\\\\x00a\\\\x00m\\\\x00\\\\r\\\\x00\\\\n\\\\x00S\\\\x00P\\\\x00A\\\\x00M\\\\x00\\\\r\\\\x00\\\\n\\\\x00'\\n>>> open('temp.txt', 'r', encoding='utf-16').read()\\n'spam\\\\nSPAM\\\\n'\\n>>> open('temp.txt', 'w', encoding='utf-16-be').write('\\\\ufeffspam\\\\nSPAM\\\\n')\\n11\\n>>> open('spam.txt', 'rb').read()\\nb'\\\\xfe\\\\xff\\\\x00s\\\\x00p\\\\x00a\\\\x00m\\\\x00\\\\r\\\\x00\\\\n\\\\x00S\\\\x00P\\\\x00A\\\\x00M\\\\x00\\\\r\\\\x00\\\\n'\\n>>> open('temp.txt', 'r', encoding='utf-16').read()\\n'spam\\\\nSPAM\\\\n'\\n>>> open('temp.txt', 'r', encoding='utf-16-be').read()\\n'\\\\ufeffspam\\\\nSPAM\\\\n'\\nThe more specific UTF-16 encoding names work fine with BOM-less files, though\\n“utf-16” requires one on input in order to determine byte order:\\n>>> open('temp.txt', 'w', encoding='utf-16-le').write('SPAM')\\n4\\n>>> open('temp.txt', 'rb').read()             # OK if BOM not present or expected\\nb'S\\\\x00P\\\\x00A\\\\x00M\\\\x00'\\n>>> open('temp.txt', 'r', encoding='utf-16-le').read()\\n'SPAM'\\n>>> open('temp.txt', 'r', encoding='utf-16').read()\\nUnicodeError: UTF-16 stream does not start with BOM\\nExperiment with these encodings yourself or see Python’s library manuals for more\\ndetails on the BOM.\\nUnicode Files in 2.6\\nThe preceding discussion applies to Python 3.0’s string types and files. You can achieve\\nsimilar effects for Unicode files in 2.6, but the interface is different. If you replace str\\nwith unicode and open with codecs.open, the result is essentially the same in 2.6:\\nC:\\\\misc> c:\\\\python26\\\\python\\n>>> S = u'A\\\\xc4B\\\\xe8C'\\n>>> print S\\nAÄBèC\\n>>> len(S)\\n5\\n>>> S.encode('latin-1')\\n'A\\\\xc4B\\\\xe8C'\\n>>> S.encode('utf-8')\\n'A\\\\xc3\\\\x84B\\\\xc3\\\\xa8C'\\n>>> import codecs\\n928 | Chapter 36: \\u2002Unicode and Byte Strings\", metadata={'source': 'python.pdf', 'page': 978}),\n",
       " Document(page_content=\">>> codecs.open('latindata', 'w', encoding='latin-1').write(S)\\n>>> codecs.open('utfdata', 'w', encoding='utf-8').write(S)\\n>>> open('latindata', 'rb').read()\\n'A\\\\xc4B\\\\xe8C'\\n>>> open('utfdata', 'rb').read()\\n'A\\\\xc3\\\\x84B\\\\xc3\\\\xa8C'\\n>>> codecs.open('latindata', 'r', encoding='latin-1').read()\\nu'A\\\\xc4B\\\\xe8C'\\n>>> codecs.open('utfdata', 'r', encoding='utf-8').read()\\nu'A\\\\xc4B\\\\xe8C'\\nOther String Tool Changes in 3.0\\nSome of the \\nother popular string-processing tools in Python’s standard library have\\nbeen revamped for the new str/bytes type dichotomy too. We won’t cover any of these\\napplication-focused tools in much detail in this core language book, but to wrap up\\nthis chapter, here’s a quick look at four of the major tools impacted: the re pattern-\\nmatching module, the struct binary data module, the pickle object serialization mod-\\nule, and the xml package for parsing XML text.\\nThe re Pattern Matching Module\\nPython’s re pattern-matching module supports text processing that is more general\\nthan that afforded by simple string method calls such as find, split, and replace. With\\nre, strings that designate searching and splitting targets can be described by general\\npatterns, instead of absolute text. This module has been generalized to work on objects\\nof any string type in 3.0— str, bytes, and bytearray—and returns result substrings of\\nthe same type as the subject string.\\nHere it is at work in 3.0, extracting substrings from a line of text. Within pattern strings,\\n(.*) means any character ( .), zero or more times ( *), saved away as a matched substring\\n(()). Parts of the string matched by the parts of a pattern enclosed in parentheses are\\navailable after a successful match, via the group or groups method:\\nC:\\\\misc> c:\\\\python30\\\\python\\n>>> import re\\n>>> S = 'Bugger all down here on earth!'               # Line of text\\n>>> B = b'Bugger all down here on earth!'              # Usually from a file\\n>>> re.match('(.*) down (.*) on (.*)', S).groups()     # Match line to pattern\\n('Bugger all', 'here', 'earth!')                       # Matched substrings\\n>>> re.match(b'(.*) down (.*) on (.*)', B).groups()    # bytes substrings\\n(b'Bugger all', b'here', b'earth!')\\nIn Python 2.6 results are similar, but the unicode type is used for non-ASCII text, and\\nstr handles both 8-bit and binary text:\\nOther String Tool Changes in 3.0 | 929\", metadata={'source': 'python.pdf', 'page': 979}),\n",
       " Document(page_content=\"C:\\\\misc> c:\\\\python26\\\\python\\n>>> import re\\n>>> S = 'Bugger all down here on earth!'               # Simple text and binary\\n>>> U = u'Bugger all down here on earth!'              # Unicode text\\n>>> re.match('(.*) down (.*) on (.*)', S).groups()\\n('Bugger all', 'here', 'earth!')\\n>>> re.match('(.*) down (.*) on (.*)', U).groups()\\n(u'Bugger all', u'here', u'earth!')\\nSince bytes and str \\nsupport essentially the same operation sets, this type distinction is\\nlargely transparent. But note that, like in other APIs, you can’t mix str and bytes types\\nin its calls’ arguments in 3.0 (although if you don’t plan to do pattern matching on\\nbinary data, you probably don’t need to care):\\nC:\\\\misc> c:\\\\python30\\\\python\\n>>> import re\\n>>> S = 'Bugger all down here on earth!'\\n>>> B = b'Bugger all down here on earth!'\\n>>> re.match('(.*) down (.*) on (.*)', B).groups()\\nTypeError: can't use a string pattern on a bytes-like object\\n>>> re.match(b'(.*) down (.*) on (.*)', S).groups()\\nTypeError: can't use a bytes pattern on a string-like object\\n>>> re.match(b'(.*) down (.*) on (.*)', bytearray(B)).groups()\\n(bytearray(b'Bugger all'), bytearray(b'here'), bytearray(b'earth!'))\\n>>> re.match('(.*) down (.*) on (.*)', bytearray(B)).groups()\\nTypeError: can't use a string pattern on a bytes-like object\\nThe struct Binary Data Module\\nThe Python struct module, used to create and extract packed binary data from strings,\\nalso works the same in 3.0 as it does in 2.X, but packed data is represented as bytes\\nand bytearray objects only, not str objects (which makes sense, given that it’s intended\\nfor processing binary data, not arbitrarily encoded text).\\nHere are both Pythons in action, packing three objects into a string according to a binary\\ntype specification (they create a four-byte integer, a four-byte string, and a two-byte\\ninteger):\\nC:\\\\misc> c:\\\\python30\\\\python\\n>>> from struct import pack\\n>>> pack('>i4sh', 7, 'spam', 8)         # bytes in 3.0 (8-bit string)\\nb'\\\\x00\\\\x00\\\\x00\\\\x07spam\\\\x00\\\\x08'\\nC:\\\\misc> c:\\\\python26\\\\python\\n>>> from struct import pack\\n>>> pack('>i4sh', 7, 'spam', 8)         # str in 2.6 (8-bit string)\\n'\\\\x00\\\\x00\\\\x00\\\\x07spam\\\\x00\\\\x08'\\n930 | Chapter 36: \\u2002Unicode and Byte Strings\", metadata={'source': 'python.pdf', 'page': 980}),\n",
       " Document(page_content=\"Since bytes has an almost identical interface to that of str in 3.0 and 2.6, though, most\\nprogrammers probably won’t need to care—the change is irrelevant to most existing\\ncode, especially since reading from a binary file creates a bytes automatically. Although\\nthe last test in the following example fails on a type mismatch, most scripts will read\\nbinary data from a file, not create it as a string:\\nC:\\\\misc> c:\\\\python30\\\\python\\n>>> import struct\\n>>> B = struct.pack('>i4sh', 7, 'spam', 8)\\n>>> B\\nb'\\\\x00\\\\x00\\\\x00\\\\x07spam\\\\x00\\\\x08'\\n>>> vals = struct.unpack('>i4sh', B)\\n>>> vals\\n(7, b'spam', 8)\\n>>> vals = struct.unpack('>i4sh', B.decode())\\nTypeError: 'str' does not have the buffer interface\\nApart from the new syntax for bytes, creating and reading binary files works almost the\\nsame in 3.0 as it does in 2.X. Code like this is one of the main places where programmers\\nwill notice the bytes object type:\\nC:\\\\misc> c:\\\\python30\\\\python\\n# Write values to a packed binary file\\n>>> F = open('data.bin', 'wb')                  # Open binary output file\\n>>> import struct\\n>>> data = struct.pack('>i4sh', 7, 'spam', 8)   # Create packed binary data\\n>>> data                                        # bytes in 3.0, not str\\nb'\\\\x00\\\\x00\\\\x00\\\\x07spam\\\\x00\\\\x08'\\n>>> F.write(data)                               # Write to the file\\n10\\n>>> F.close()\\n# Read values from a packed binary file\\n>>> F = open('data.bin', 'rb')                  # Open binary input file\\n>>> data = F.read()                             # Read bytes\\n>>> data\\nb'\\\\x00\\\\x00\\\\x00\\\\x07spam\\\\x00\\\\x08'\\n>>> values = struct.unpack('>i4sh', data)       # Extract packed binary data\\n>>> values                                      # Back to Python objects\\n(7, b'spam', 8)\\nOnce you’ve extracted packed binary data into Python objects like this, you can dig\\neven further into the binary world if you have to—strings can be indexed and sliced to\\nget individual bytes’ values, individual bits can be extracted from integers with bitwise\\noperators, and so on (see earlier in this book for more on the operations applied here):\\n>>> values                                      # Result of struct.unpack\\n(7, b'spam', 8)\\nOther String Tool Changes in 3.0 | 931\", metadata={'source': 'python.pdf', 'page': 981}),\n",
       " Document(page_content=\"# Accesssing bits of parsed integers\\n>>> bin(values[0])                              # Can get to bits in ints\\n'0b111'\\n>>> values[0] & 0x01                            # Test first (lowest) bit in int\\n1\\n>>> values[0] | 0b1010                          # Bitwise or: turn bits on\\n15\\n>>> bin(values[0] | 0b1010)                     # 15 decimal is 1111 binary\\n'0b1111'\\n>>> bin(values[0] ^ 0b1010)                     # Bitwise xor: off if both true\\n'0b1101'\\n>>> bool(values[0] & 0b100)                     # Test if bit 3 is on\\nTrue\\n>>> bool(values[0] & 0b1000)                    # Test if bit 4 is set\\nFalse\\nSince parsed bytes  \\nstrings are sequences of small integers, we can do similar processing\\nwith their individual bytes:\\n# Accessing bytes of parsed strings and bits within them\\n>>> values[1]\\nb'spam'\\n>>> values[1][0]                          # bytes string: sequence of ints\\n115\\n>>> values[1][1:]                         # Prints as ASCII characters\\nb'pam'\\n>>> bin(values[1][0])                     # Can get to bits of bytes in strings\\n'0b1110011'\\n>>> bin(values[1][0] | 0b1100)            # Turn bits on\\n'0b1111111'\\n>>> values[1][0] | 0b1100\\n127\\nOf course, most Python programmers don’t deal with binary bits; Python has higher-\\nlevel object types, like lists and dictionaries, that are generally a better choice for\\nrepresenting information in Python scripts. However, if you must use or produce\\nlower-level data used by C programs, networking libraries, or other interfaces, Python\\nhas tools to assist.\\nThe pickle Object Serialization Module\\nWe met the pickle module briefly in Chapters 9 and 30. In Chapter 27 , we also used\\nthe shelve module, which uses pickle internally. For completeness here, keep in mind\\nthat the Python 3.0 version of the pickle module always creates a bytes object, regard-\\nless of the default or passed-in “protocol” (data format level). You can see this by using\\nthe module’s dumps call to return an object’s pickle string:\\nC:\\\\misc> C:\\\\Python30\\\\python\\n>>> import pickle                          # dumps() returns pickle string\\n>>> pickle.dumps([1, 2, 3])                # Python 3.0 default protocol=3=binary\\n932 | Chapter 36: \\u2002Unicode and Byte Strings\", metadata={'source': 'python.pdf', 'page': 982}),\n",
       " Document(page_content=\"b'\\\\x80\\\\x03]q\\\\x00(K\\\\x01K\\\\x02K\\\\x03e.'\\n>>> pickle.dumps([1, 2, 3], protocol=0)    # ASCII protocol 0, but still bytes!\\nb'(lp0\\\\nL1L\\\\naL2L\\\\naL3L\\\\na.'\\nThis implies that \\nfiles used to store pickled objects must always be opened in binary\\nmode in Python 3.0, since text files use str strings to represent data, not bytes—the\\ndump call simply attempts to write the pickle string to an open output file:\\n>>> pickle.dump([1, 2, 3], open('temp', 'w'))    # Text files fail on bytes!\\nTypeError: can't write bytes to text stream      # Despite protocol value\\n>>> pickle.dump([1, 2, 3], open('temp', 'w'), protocol=0)\\nTypeError: can't write bytes to text stream\\n>>> pickle.dump([1, 2, 3], open('temp', 'wb'))   # Always use binary in 3.0\\n>>> open('temp', 'r').read()\\nUnicodeEncodeError: 'charmap' codec can't encode character '\\\\u20ac' in ...\\nBecause pickle data is not decodable Unicode text, the same is true on input—correct\\nusage in 3.0 requires always writing and reading pickle data in binary modes:\\n>>> pickle.dump([1, 2, 3], open('temp', 'wb'))\\n>>> pickle.load(open('temp', 'rb'))\\n[1, 2, 3]\\n>>> open('temp', 'rb').read()\\nb'\\\\x80\\\\x03]q\\\\x00(K\\\\x01K\\\\x02K\\\\x03e.'\\nIn Python 2.6 (and earlier), we can get by with text-mode files for pickled data, as long\\nas the protocol is level 0 (the default in 2.6) and we use text mode consistently to convert\\nline-ends:\\nC:\\\\misc> c:\\\\python26\\\\python\\n>>> import pickle\\n>>> pickle.dumps([1, 2, 3])                      # Python 2.6 default=0=ASCII\\n'(lp0\\\\nI1\\\\naI2\\\\naI3\\\\na.'\\n>>> pickle.dumps([1, 2, 3], protocol=1)\\n']q\\\\x00(K\\\\x01K\\\\x02K\\\\x03e.'\\n>>> pickle.dump([1, 2, 3], open('temp', 'w'))    # Text mode works in 2.6\\n>>> pickle.load(open('temp'))\\n[1, 2, 3]\\n>>> open('temp').read()\\n'(lp0\\\\nI1\\\\naI2\\\\naI3\\\\na.'\\nIf you care about version neutrality, though, or don’t want to care about protocols or\\ntheir version-specific defaults, always use binary-mode files for pickled data—the fol-\\nlowing works the same in Python 3.0 and 2.6:\\n>>> import pickle\\n>>> pickle.dump([1, 2, 3], open('temp', 'wb'))     # Version neutral\\n>>> pickle.load(open('temp', 'rb'))                # And required in 3.0\\n[1, 2, 3]\\nOther String Tool Changes in 3.0 | 933\", metadata={'source': 'python.pdf', 'page': 983}),\n",
       " Document(page_content=\"Because almost all programs let Python pickle and unpickle objects automatically and\\ndo not deal \\nwith the content of pickled data itself, the requirement to always use binary\\nfile modes is the only significant incompatibility in Python 3’s new pickling model. See\\nreference books or Python’s manuals for more details on object pickling.\\nXML Parsing Tools\\nXML is a tag-based language for defining structured information, commonly used to\\ndefine documents and data shipped over the Web. Although some information can be\\nextracted from XML text with basic string methods or the re pattern module, XML’s\\nnesting of constructs and arbitrary attribute text tend to make full parsing more\\naccurate.\\nBecause XML is such a pervasive format, Python itself comes with an entire package of\\nXML parsing tools that support the SAX and DOM parsing models, as well as a package\\nknown as ElementTree—a Python-specific API for parsing and constructing XML.\\nBeyond basic parsing, the open source domain provides support for additional XML\\ntools, such as XPath, Xquery, XSLT, and more.\\nXML by definition represents text in Unicode form, to support internationalization.\\nAlthough most of Python’s XML parsing tools have always returned Unicode strings,\\nin Python 3.0 their results have mutated from the 2.X unicode type to the 3.0 general\\nstr string type—which makes sense, given that 3.0’s str string is Unicode, whether the\\nencoding is ASCII or other.\\nWe can’t go into many details here, but to sample the flavor of this domain, suppose\\nwe have a simple XML text file, mybooks.xml:\\n<books>\\n    <date>2009</date>\\n    <title>Learning Python</title>\\n    <title>Programming Python</title>\\n    <title>Python Pocket Reference</title>\\n    <publisher>O'Reilly Media</publisher>\\n</books>\\nand we want to run a script to extract and display the content of all the nested title\\ntags, as follows:\\nLearning Python\\nProgramming Python\\nPython Pocket Reference\\nThere are at least four basic ways to accomplish this (not counting more advanced tools\\nlike XPath). First, we could run basic pattern matching  on the file’s text, though this\\ntends to be inaccurate if the text is unpredictable. Where applicable, the re module we\\nmet earlier does the job—its match method looks for a match at the start of a string,\\nsearch scans ahead for a match, and the findall method used here locates all places\\nwhere the pattern matches in the string (the result comes back as a list of matched\\n934 | Chapter 36: \\u2002Unicode and Byte Strings\", metadata={'source': 'python.pdf', 'page': 984}),\n",
       " Document(page_content=\"substrings corresponding to parenthesized pattern groups, or tuples of such for mul-\\ntiple groups):\\n# File patternparse.py\\nimport re\\ntext  = open('mybooks.xml').read()\\nfound = re.findall('<title>(.*)</title>', text)\\nfor title in found: print(title)\\nSecond, to be \\nmore robust, we could perform complete XML parsing with the standard\\nlibrary’s DOM parsing  support. DOM parses XML text into a tree of objects and pro-\\nvides an interface for navigating the tree to extract tag attributes and values; the inter-\\nface is a formal specification, independent of Python:\\n# File domparse.py\\nfrom xml.dom.minidom import parse, Node\\nxmltree = parse('mybooks.xml')\\nfor node1 in xmltree.getElementsByTagName('title'):\\n    for node2 in node1.childNodes:\\n         if node2.nodeType == Node.TEXT_NODE:\\n             print(node2.data)\\nAs a third option, Python’s standard library supports SAX parsing  for XML. Under the\\nSAX model, a class’s methods receive callbacks as a parse progresses and use state\\ninformation to keep track of where they are in the document and collect its data:\\n# File saxparse.py\\nimport xml.sax.handler\\nclass BookHandler(xml.sax.handler.ContentHandler):\\n    def __init__(self):\\n        self.inTitle = False\\n    def startElement(self, name, attributes):\\n        if name == 'title':\\n            self.inTitle = True\\n    def characters(self, data):\\n        if self.inTitle:\\n            print(data)\\n    def endElement(self, name):\\n        if name == 'title':\\n            self.inTitle = False\\nimport xml.sax\\nparser = xml.sax.make_parser()\\nhandler = BookHandler()\\nparser.setContentHandler(handler)\\nparser.parse('mybooks.xml')\\nFinally, the ElementTree system available in the etree package of the standard library\\ncan often achieve the same effects as XML DOM parsers, but with less code. It’s a\\nPython-specific way to both parse and generate XML text; after a parse, its API gives\\naccess to components of the document:\\nOther String Tool Changes in 3.0 | 935\", metadata={'source': 'python.pdf', 'page': 985}),\n",
       " Document(page_content=\"# File etreeparse.py\\nfrom xml.etree.ElementTree import parse\\ntree = parse('mybooks.xml')\\nfor E in tree.findall('title'):\\n    print(E.text)\\nWhen run in either 2.6 or 3.0, all four of these scripts display the same printed result:\\nC:\\\\misc> c:\\\\python26\\\\python domparse.py\\nLearning Python\\nProgramming Python\\nPython Pocket Reference\\nC:\\\\misc> c:\\\\python30\\\\python domparse.py\\nLearning Python\\nProgramming Python\\nPython Pocket Reference\\nTechnically, though, in \\n2.6 some of these scripts produce unicode string objects, while\\nin 3.0 all produce str strings, since that type includes Unicode text (whether ASCII or\\nother):\\nC:\\\\misc> c:\\\\python30\\\\python\\n>>> from xml.dom.minidom import parse, Node\\n>>> xmltree = parse('mybooks.xml')\\n>>> for node in xmltree.getElementsByTagName('title'):\\n...     for node2 in node.childNodes:\\n...         if node2.nodeType == Node.TEXT_NODE:\\n...             node2.data\\n...\\n'Learning Python'\\n'Programming Python'\\n'Python Pocket Reference'\\nC:\\\\misc> c:\\\\python26\\\\python\\n>>> ...same code...\\n...\\nu'Learning Python'\\nu'Programming Python'\\nu'Python Pocket Reference'\\nPrograms that must deal with XML parsing results in nontrivial ways will need to ac-\\ncount for the different object type in 3.0. Again, though, because all strings have nearly\\nidentical interfaces in both 2.6 and 3.0, most scripts won’t be affected by the change;\\ntools available on unicode in 2.6 are generally available on str in 3.0.\\nRegrettably, going into further XML parsing details is beyond this book’s scope. If you\\nare interested in text or XML parsing, it is covered in more detail in the applications-\\nfocused follow-up book Programming Python . For more details on re, struct, pickle,\\nand XML tools in general, consult the Web, the aforementioned book and others, and\\nPython’s standard library manual.\\n936 | Chapter 36: \\u2002Unicode and Byte Strings\", metadata={'source': 'python.pdf', 'page': 986}),\n",
       " Document(page_content='Chapter Summary\\nThis chapter explored \\nadvanced string types available in Python 3.0 and 2.6 for pro-\\ncessing Unicode text and binary data. As we saw, many programmers use ASCII text\\nand can get by with the basic string type and its operations. For more advanced appli-\\ncations, Python’s string models fully support both wide-character Unicode text (via the\\nnormal string type in 3.0 and a special type in 2.6) and byte-oriented data (represented\\nwith a bytes type in 3.0 and normal strings in 2.6).\\nIn addition, we learned how Python’s file object has mutated in 3.0 to automatically\\nencode and decode Unicode text and deal with byte strings for binary-mode files. Fi-\\nnally, we briefly met some text and binary data tools in Python’s library, and sampled\\ntheir behavior in 3.0.\\nIn the next chapter, we’ll shift our focus to tool-builder topics, with a look at ways to\\nmanage access to object attributes by inserting automatically run code. Before we move\\non, though, here’s a set of questions to review what we’ve learned here.\\nTest Your Knowledge: Quiz\\n1. What are the names and roles of string object types in Python 3.0?\\n2.What are the names and roles of string object types in Python 2.6?\\n3.\\nWhat is the mapping between 2.6 and 3.0 string types?\\n4. How do Python 3.0’s string types differ in terms of operations?\\n5. How can you code non-ASCII Unicode characters in a string in 3.0?\\n6. What are the main differences between text- and binary-mode files in Python 3.0?\\n7. How would you read a Unicode text file that contains text in a different encoding\\nthan the default for your platform?\\n8. How can you create a Unicode text file in a specific encoding format?\\n9. Why is ASCII text considered to be a kind of Unicode text?\\n10. How large an impact does Python 3.0’s string types change have on your code?\\nTest Your Knowledge: Answers\\n1. Python 3.0 has three string types: str (for Unicode text, including ASCII), bytes\\n(for binary data with absolute byte values), and bytearray (a mutable flavor of\\nbytes). The str type usually represents content stored on a text file, and the other\\ntwo types generally represent content stored on binary files.\\nTest Your Knowledge: Answers | 937', metadata={'source': 'python.pdf', 'page': 987}),\n",
       " Document(page_content='2. Python 2.6 has two main string types: str (for 8-bit text and binary data) and\\nunicode (for wide-character text). The str type is used for both text and binary file\\ncontent; unicode is used for text file content that is generally more complex than\\n8 bits. Python 2.6 (but not earlier) also has 3.0’s bytearray type, but it’s mostly a\\nback-port and doesn’t exhibit the sharp text/binary distinction that it does in 3.0.\\n3. The mapping from 2.6 to 3.0 string types is not direct, because 2.6’s str equates\\nto both str and bytes in 3.0, and 3.0’s str equates to both str and unicode in 2.6.\\nThe mutability of bytearray in 3.0 is also unique.\\n4. Python 3.0’s string types share almost all the same operations: method calls, se-\\nquence operations, and even larger tools like pattern matching work the same way.\\nOn the other hand, only str supports string formatting operations, and\\nbytearray has an additional set of operations that perform in-place changes. The\\nstr and bytes types also have methods for encoding and decoding text,\\nrespectively.\\n5. Non-ASCII Unicode characters can be coded in a string with both hex ( \\\\xNN) and\\nUnicode (\\\\uNNNN, \\\\UNNNNNNNN) escapes. On some keyboards, some non-ASCII char-\\nacters—certain Latin-1 characters, for example—can also be typed directly.\\n6. In 3.0, text-mode files assume their file content is Unicode text (even if it’s ASCII)\\nand automatically decode when reading and encode when writing. With binary-\\nmode files, bytes are transferred to and from the file unchanged. The contents of\\ntext-mode files are usually represented as str objects in your script, and the con-\\ntents of binary files are represented as bytes (or bytearray) objects. Text-mode files\\nalso handle the BOM for certain encoding types and automatically translate end-\\nof-line sequences to and from the single \\\\n character on input and output unless\\nthis is explicitly disabled; binary-mode files do not perform either of these steps.\\n7. To read files encoded in a different encoding than the default for your platform,\\nsimply pass the name of the file’s encoding to the open built-in in 3.0\\n(codecs.open() in 2.6); data will be decoded per the specified encoding when it is\\nread from the file. You can also read in binary mode and manually decode the bytes\\nto a string by giving an encoding name, but this involves extra work and is some-\\nwhat error-prone for multibyte characters (you may accidentally read a partial\\ncharacter sequence).\\n8. To create a Unicode text file in a specific encoding format, pass the desired en-\\ncoding name to open in 3.0 ( codecs.open() in 2.6); strings will be encoded per the\\ndesired encoding when they are written to the file. You can also manually encode\\na string to bytes and write it in binary mode, but this is usually extra work.\\n9. ASCII text is considered to be a kind of Unicode text, because its 7-bit range of\\nvalues is a subset of most Unicode encodings. For example, valid ASCII text is also\\nvalid Latin-1 text (Latin-1 simply assigns the remaining possible values in an 8-bit\\nbyte to additional characters) and valid UTF-8 text (UTF-8 defines a variable-byte\\nscheme for representing more characters, but ASCII characters are still represented\\nwith the same codes, in a single byte).\\n938 | Chapter 36: \\u2002Unicode and Byte Strings', metadata={'source': 'python.pdf', 'page': 988}),\n",
       " Document(page_content='10. The impact of Python 3.0’s string types change depends upon the types of strings\\nyou use. For \\nscripts that use simple ASCII text, there is probably no impact at all:\\nthe str string type works the same in 2.6 and 3.0 in this case. Moreover, although\\nstring-related tools in the standard library such as re, struct, pickle, and xml may\\ntechnically use different types in 3.0 than in 2.6, the changes are largely irrelevant\\nto most programs because 3.0’s str and bytes and 2.6’s str support almost iden-\\ntical interfaces. If you process Unicode data, the toolset you need has simply moved\\nfrom 2.6’s unicode and codecs.open() to 3.0’s str and open. If you deal with binary\\ndata files, you’ll need to deal with content as bytes objects; since they have a similar\\ninterface to 2.6 strings, though, the impact should again be minimal.\\nTest Your Knowledge: Answers | 939', metadata={'source': 'python.pdf', 'page': 989}),\n",
       " Document(page_content='', metadata={'source': 'python.pdf', 'page': 990}),\n",
       " Document(page_content=\"CHAPTER 37\\nManaged Attributes\\nThis chapter expands on the attribute interception  techniques introduced earlier, in-\\ntroduces another, and employs them in a handful of larger examples. Like everything\\nin this part of the book, this chapter is classified as an advanced topic and optional\\nreading, because most applications programmers don’t need to care about the material\\ndiscussed here—they can fetch and set attributes on objects without concern for at-\\ntribute implementations. Especially for tools builders, though, managing attribute ac-\\ncess can be an important part of flexible APIs.\\nWhy Manage Attributes?\\nObject attributes are central to most Python programs—they are where we often store\\ninformation about the entities our scripts process. Normally, attributes are simply\\nnames for objects; a person’s name attribute, for example, might be a simple string,\\nfetched and set with basic attribute syntax:\\nperson.name                 # Fetch attribute value\\nperson.name = value         # Change attribute value\\nIn most cases, the attribute lives in the object itself, or is inherited from a class from\\nwhich it derives. That basic model suffices for most programs you will write in your\\nPython career.\\nSometimes, though, more flexibility is required. Suppose you’ve written a program to\\nuse a name attribute directly, but then your requirements change—for example, you\\ndecide that names should be validated with logic when set or mutated in some way\\nwhen fetched. It’s straightforward to code methods to manage access to the attribute’s\\nvalue (valid and transform are abstract here):\\nclass Person:\\n    def getName(self):\\n        if not valid():\\n            raise TypeError('cannot fetch name')\\n        else:\\n            return self.name.transform()\\n941\", metadata={'source': 'python.pdf', 'page': 991}),\n",
       " Document(page_content=\"    def setName(self, value):\\n         if not valid(value):\\n            raise TypeError('cannot change name')\\n        else:\\n            self.name = transform(value)\\nperson = Person()\\nperson.getName()\\nperson.setName('value')\\nHowever, this also \\nrequires changing all the places where names are used in the entire\\nprogram—a possibly nontrivial task. Moreover, this approach requires the program to\\nbe aware of how values are exported: as simple names or called methods. If you begin\\nwith a method-based interface to data, clients are immune to changes; if you do not,\\nthey can become problematic.\\nThis issue can crop up more often than you might expect. The value of a cell in a\\nspreadsheet-like program, for instance, might begin its life as a simple discrete value,\\nbut later mutate into an arbitrary calculation. Since an object’s interface should be\\nflexible enough to support such future changes without breaking existing code, switch-\\ning to methods later is less than ideal.\\nInserting Code to Run on Attribute Access\\nA better solution would allow you to run code automatically on attribute access, if\\nneeded. At various points in this book, we’ve met Python tools that allow our scripts\\nto dynamically compute attribute values when fetching them and validate or change\\nattribute values when storing them. In this chapter, were going to expand on the tools\\nalready introduced, explore other available tools, and study some larger use-case ex-\\namples in this domain. Specifically, this chapter presents:\\n• The __getattr__ and __setattr__ methods, for routing undefined attribute fetches\\nand all attribute assignments to generic handler methods.\\n• The __getattribute__ method, for routing all attribute fetches to a generic handler\\nmethod in new-style classes in 2.6 and all classes in 3.0.\\n• The property built-in, for routing specific attribute access to get and set handler\\nfunctions, known as properties.\\n• The descriptor protocol , for routing specific attribute accesses to instances of classes\\nwith arbitrary get and set handler methods.\\nThe first and third of these were briefly introduced in Part VI; the others are new topics\\nintroduced and covered here.\\nAs we’ll see, all four techniques share goals to some degree, and it’s usually possible to\\ncode a given problem using any one of them. They do differ in some important ways,\\nthough. For example, the last two techniques listed here apply to specific attributes,\\nwhereas the first two are generic enough to be used by delegation-based classes that\\n942 | Chapter 37: \\u2002Managed Attributes\", metadata={'source': 'python.pdf', 'page': 992}),\n",
       " Document(page_content='must route arbitrary attributes to wrapped objects. As we’ll see, all four schemes also\\ndiffer in both \\ncomplexity and aesthetics, in ways you must see in action to judge for\\nyourself.\\nBesides studying the specifics behind the four attribute interception techniques listed\\nin this section, this chapter also presents an opportunity to explore larger programs\\nthan we’ve seen elsewhere in this book. The CardHolder case study at the end, for ex-\\nample, should serve as a self-study example of larger classes in action. We’ll also be\\nusing some of the techniques outlined here in the next chapter to code decorators, so\\nbe sure you have at least a general understanding of these topics before you move on.\\nProperties\\nThe property protocol allows us to route a specific attribute’s get and set operations to\\nfunctions or methods we provide, enabling us to insert code to be run automatically\\non attribute access, intercept attribute deletions, and provide documentation for the\\nattributes if desired.\\nProperties are created with the property built-in and are assigned to class attributes,\\njust like method functions. As such, they are inherited by subclasses and instances, like\\nany other class attributes. Their access-interception functions are provided with the\\nself instance argument, which grants access to state information and class attributes\\navailable on the subject instance.\\nA property manages a single, specific attribute; although it can’t catch all attribute\\naccesses generically, it allows us to control both fetch and assignment accesses and\\nenables us to change an attribute from simple data to a computation freely, without\\nbreaking existing code. As we’ll see, properties are strongly related to descriptors; they\\nare essentially a restricted form of them.\\nThe Basics\\nA property is created by assigning the result of a built-in function to a class attribute:\\nattribute = property(fget, fset, fdel, doc)\\nNone of this built-in’s arguments are required, and all default to None if not passed;\\nsuch operations are not supported, and attempting them will raise an exception. When\\nusing them, we pass fget a function for intercepting attribute fetches, fset a function\\nfor assignments, and fdel a function for attribute deletions; the doc argument receives\\na documentation string for the attribute, if desired (otherwise the property copies the\\ndocstring of fget, if provided, which defaults to None). fget returns the computed at-\\ntribute value, and fset and fdel return nothing (really, None).\\nThis built-in call returns a property object, which we assign to the name of the attribute\\nto be managed in the class scope, where it will be inherited by every instance.\\nProperties | 943', metadata={'source': 'python.pdf', 'page': 993}),\n",
       " Document(page_content='A First Example\\nTo demonstrate how \\nthis translates to working code, the following class uses a property\\nto trace access to an attribute named name; the actual stored data is named _name so it\\ndoes not clash with the property:\\nclass Person:                       # Use (object) in 2.6\\n    def __init__(self, name):\\n        self._name = name\\n    def getName(self):\\n        print(\\'fetch...\\')\\n        return self._name\\n    def setName(self, value):\\n        print(\\'change...\\')\\n        self._name = value\\n    def delName(self):\\n        print(\\'remove...\\')\\n        del self._name\\n    name = property(getName, setName, delName, \"name property docs\")\\nbob = Person(\\'Bob Smith\\')           # bob has a managed attribute\\nprint(bob.name)                     # Runs getName\\nbob.name = \\'Robert Smith\\'           # Runs setName\\nprint(bob.name)\\ndel bob.name                        # Runs delName\\nprint(\\'-\\'*20)\\nsue = Person(\\'Sue Jones\\')           # sue inherits property too\\nprint(sue.name)\\nprint(Person.name.__doc__)          # Or help(Person.name)\\nProperties are available in both 2.6 and 3.0, but they require new-style object derivation\\nin 2.6 to work correctly for assignments—add object as a superclass here to run this\\nin 2.6 (you can the superclass in 3.0 too, but it’s implied and not required).\\nThis particular property doesn’t do much—it simply intercepts and traces an\\nattribute—but it serves to demonstrate the protocol. When this code is run, two in-\\nstances inherit the property, just as they would any other attribute attached to their\\nclass. However, their attribute accesses are caught:\\nfetch...\\nBob Smith\\nchange...\\nfetch...\\nRobert Smith\\nremove...\\n--------------------\\nfetch...\\nSue Jones\\nname property docs\\nLike all class attributes, properties are inherited by both instances and lower subclasses.\\nIf we change our example as follows, for example:\\n944 | Chapter 37: \\u2002Managed Attributes', metadata={'source': 'python.pdf', 'page': 994}),\n",
       " Document(page_content=\"class Super:\\n    ...the original Person class code...\\n    name = property(getName, setName, delName, 'name property docs')\\nclass Person(Super):\\n    pass                            # Properties are inherited\\nbob = Person('Bob Smith')\\n...rest unchanged...\\nthe output is \\nthe same—the Person subclass inherits the name property from Super, and\\nthe bob instance gets it from Person. In terms of inheritance, properties work the same\\nas normal methods; because they have access to the self instance argument, they can\\naccess instance state information like methods, as the next section demonstrates.\\nComputed Attributes\\nThe example in the prior section simply traces attribute accesses. Usually, though,\\nproperties do much more—computing the value of an attribute dynamically when\\nfetched, for example. The following example illustrates:\\nclass PropSquare:\\n    def __init__(self, start):\\n        self.value = start\\n    def getX(self):                         # On attr fetch\\n        return self.value ** 2\\n    def setX(self, value):                  # On attr assign\\n        self.value = value\\n    X = property(getX, setX)                # No delete or docs\\nP = PropSquare(3)       # 2 instances of class with property\\nQ = PropSquare(32)      # Each has different state information\\nprint(P.X)              # 3 ** 2\\nP.X = 4\\nprint(P.X)              # 4 ** 2\\nprint(Q.X)              # 32 ** 2\\nThis class defines an attribute X that is accessed as though it were static data, but really\\nruns code to compute its value when fetched. The effect is much like an implicit method\\ncall. When the code is run, the value is stored in the instance as state information, but\\neach time we fetch it via the managed attribute, its value is automatically squared:\\n9\\n16\\n1024\\nNotice that we’ve made two different instances—because property methods automat-\\nically receive a self argument, they have access to the state information stored in in-\\nstances. In our case, this mean the fetch computes the square of the subject instance’s\\ndata.\\nProperties | 945\", metadata={'source': 'python.pdf', 'page': 995}),\n",
       " Document(page_content='Coding Properties with Decorators\\nAlthough we’re saving \\nadditional details until the next chapter, we introduced function\\ndecorator basics earlier, in Chapter 31. Recall that the function decorator syntax:\\n@decorator\\ndef func(args): ...\\nis automatically translated to this equivalent by Python, to rebind the function name\\nto the result of the decorator callable:\\ndef func(args): ...\\nfunc = decorator(func)\\nBecause of this mapping, it turns out that the property built-in can serve as a decorator,\\nto define a function that will run automatically when an attribute is fetched:\\nclass Person:\\n    @property\\n    def name(self): ...             # Rebinds: name = property(name)\\nWhen run, the decorated method is automatically passed to the first argument of the\\nproperty built-in. This is really just alternative syntax for creating a property and re-\\nbinding the attribute name manually:\\nclass Person:\\n    def name(self): ...\\n    name = property(name)\\nAs of Python 2.6, property objects also have getter, setter, and deleter methods that\\nassign the corresponding property accessor methods and return a copy of the property\\nitself. We can use these to specify components of properties by decorating normal\\nmethods too, though the getter component is usually filled in automatically by the act\\nof creating the property itself:\\nclass Person:\\n    def __init__(self, name):\\n        self._name = name\\n    @property\\n    def name(self):                 # name = property(name)\\n        \"name property docs\"\\n        print(\\'fetch...\\')\\n        return self._name\\n    @name.setter\\n    def name(self, value):          # name = name.setter(name)\\n        print(\\'change...\\')\\n        self._name = value\\n    @name.deleter\\n    def name(self):                 # name = name.deleter(name)\\n        print(\\'remove...\\')\\n        del self._name\\n946 | Chapter 37: \\u2002Managed Attributes', metadata={'source': 'python.pdf', 'page': 996}),\n",
       " Document(page_content=\"bob = Person('Bob Smith')           # bob has a managed attribute\\nprint(bob.name)                     # Runs name getter (name 1)\\nbob.name = 'Robert Smith'           # Runs name setter (name 2)\\nprint(bob.name)\\ndel bob.name                        # Runs name deleter (name 3)\\nprint('-'*20)\\nsue = Person('Sue Jones')           # sue inherits property too\\nprint(sue.name)\\nprint(Person.name.__doc__)          # Or help(Person.name)\\nIn fact, this \\ncode is equivalent to the first example in this section—decoration is just\\nan alternative way to code properties in this case. When it’s run, the results are the same:\\nfetch...\\nBob Smith\\nchange...\\nfetch...\\nRobert Smith\\nremove...\\n--------------------\\nfetch...\\nSue Jones\\nname property docs\\nCompared to manual assignment of property results, in this case using decorators to\\ncode properties requires just three extra lines of code (a negligible difference). As is so\\noften the case with alternative tools, the choice between the two techniques is largely \\nsubjective.\\nDescriptors\\nDescriptors provide an alternative way to intercept attribute access; they are strongly\\nrelated to the properties discussed in the prior section. In fact, a property is a kind of\\ndescriptor—technically speaking, the property built-in is just a simplified way to create\\na specific type of descriptor that runs method functions on attribute accesses.\\nFunctionally speaking, the descriptor protocol allows us to route a specific attribute’s\\nget and set operations to methods of a separate class object that we provide: they pro-\\nvide a way to insert code to be run automatically on attribute access, and they allow us\\nto intercept attribute deletions and provide documentation for the attributes if desired.\\nDescriptors are created as independent classes, and they are assigned to class attributes\\njust like method functions. Like any other class attribute, they are inherited by sub-\\nclasses and instances. Their access-interception methods are provided with both a\\nself for the descriptor itself, and the instance of the client class. Because of this, they\\ncan retain and use state information of their own, as well as state information of the\\nsubject instance. For example, a descriptor may call methods available in the client\\nclass, as well as descriptor-specific methods it defines.\\nDescriptors | 947\", metadata={'source': 'python.pdf', 'page': 997}),\n",
       " Document(page_content='Like a property, a descriptor manages a single, specific attribute; although it can’t catch\\nall attribute accesses \\ngenerically, it provides control over both fetch and assignment\\naccesses and allows us to change an attribute freely from simple data to a computation\\nwithout breaking existing code. Properties really are just a convenient way to create a\\nspecific kind of descriptor, and as we shall see, they can be coded as descriptors directly.\\nWhereas properties are fairly narrow in scope, descriptors provide a more general\\nsolution. For instance, because they are coded as normal classes, descriptors have their\\nown state, may participate in descriptor inheritance hierarchies, can use composition\\nto aggregate objects, and provide a natural structure for coding internal methods and\\nattribute documentation strings.\\nThe Basics\\nAs mentioned previously, descriptors are coded as separate classes and provide spe-\\ncially named accessor methods for the attribute access operations they wish to\\nintercept—get, set, and deletion methods in the descriptor class are automatically run\\nwhen the attribute assigned to the descriptor class instance is accessed in the corre-\\nsponding way:\\nclass Descriptor:\\n    \"docstring goes here\"\\n    def __get__(self, instance, owner): ...        # Return attr value\\n    def __set__(self, instance, value): ...        # Return nothing (None)\\n    def __delete__(self, instance): ...            # Return nothing (None)\\nClasses with any of these methods are considered descriptors, and their methods are\\nspecial when one of their instances is assigned to another class’s attribute—when the\\nattribute is accessed, they are automatically invoked. If any of these methods are absent,\\nit generally means that the corresponding type of access is not supported. Unlike with\\nproperties, however, omitting a __set__ allows the name to be redefined in an instance,\\nthereby hiding the descriptor—to make an attribute read-only, you must define\\n__set__ to catch assignments and raise an exception.\\nDescriptor method arguments\\nBefore we code anything realistic, let’s take a brief look at some fundamentals. All three\\ndescriptor methods outlined in the prior section are passed both the descriptor class\\ninstance ( self) and the instance of the client class to which the descriptor instance is\\nattached (instance).\\nThe __get__ access method additionally receives an owner argument, specifying the class\\nto which the descriptor instance is attached. Its instance argument is either the instance\\nthrough which the attribute was accessed (for instance.attr), or None when the at-\\ntribute is accessed through the owner class directly (for class.attr). The former of\\nthese generally computes a value for instance access, and the latter usually returns\\nself if descriptor object access is supported.\\n948 | Chapter 37: \\u2002Managed Attributes', metadata={'source': 'python.pdf', 'page': 998}),\n",
       " Document(page_content=\"For example, in the following, when X.attr is fetched, Python automatically runs the\\n__get__ method of the Descriptor class to which the Subject.attr class attribute is\\nassigned (as with properties, in Python 2.6 we must derive from object to use descrip-\\ntors here; in 3.0 this is implied, but doesn’t hurt):\\n>>> class Descriptor(object):\\n...     def __get__(self, instance, owner):\\n...         print(self, instance, owner, sep='\\\\n')\\n...\\n>>> class Subject:\\n...     attr = Descriptor()             # Descriptor instance is class attr\\n...\\n>>> X = Subject()\\n>>> X.attr\\n<__main__.Descriptor object at 0x0281E690>\\n<__main__.Subject object at 0x028289B0>\\n<class '__main__.Subject'>\\n>>> Subject.attr\\n<__main__.Descriptor object at 0x0281E690>\\nNone\\n<class '__main__.Subject'>\\nNotice the arguments automatically passed in to the __get__ method in the first at-\\ntribute fetch—when X.attr is fetched, it’s as though the following translation occurs\\n(though the Subject.attr here doesn’t invoke __get__ again):\\nX.attr  ->  Descriptor.__get__(Subject.attr, X, Subject)\\nThe descriptor knows it is being accessed directly when its instance argument is None.\\nRead-only descriptors\\nAs mentioned earlier, unlike with properties, with descriptors simply omitting the\\n__set__ method isn’t enough to make an attribute read-only, because the descriptor\\nname can be assigned to an instance. In the following, the attribute assignment to\\nX.a stores a in the instance object X, thereby hiding the descriptor stored in class C:\\n>>> class D:\\n...     def __get__(*args): print('get')\\n...\\n>>> class C:\\n...     a = D()\\n...\\n>>> X = C()\\n>>> X.a                                 # Runs inherited descriptor __get__\\nget\\n>>> C.a\\nget\\n>>> X.a = 99                            # Stored on X, hiding C.a\\n>>> X.a\\n99\\n>>> list(X.__dict__.keys())\\nDescriptors | 949\", metadata={'source': 'python.pdf', 'page': 999}),\n",
       " ...]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "loader = PyPDFLoader('python.pdf')\n",
    "pdf_content = loader.load()\n",
    "pdf_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content=\"Python is a versatile and powerful programming language that has gained immense popularity in recent years. Known for its simplicity and readability, Python is often the first choice for beginners and experienced developers alike. Created by Guido van Rossum and first released in 1991, Python has since evolved into a robust language used in various fields such as web development, data science, artificial intelligence, and more. One of the key reasons for Python's popularity is its\", metadata={'source': 'file.txt'}),\n",
       " Document(page_content=\"science, artificial intelligence, and more. One of the key reasons for Python's popularity is its easy-to-understand syntax, which emphasizes readability and reduces the cost of program maintenance. Python's design philosophy emphasizes code readability with its notable use of significant whitespace. It provides constructs that enable clear programming on both small and large scales.\", metadata={'source': 'file.txt'}),\n",
       " Document(page_content='Python supports multiple programming paradigms, including object-oriented, imperative, functional, and procedural programming. This versatility allows developers to choose the approach that best suits their needs, making Python suitable for a wide range of applications. Additionally, Python has a comprehensive standard library that provides support for many common tasks, such as file I/O, networking, and web development. This extensive library reduces the need for developers to write code from', metadata={'source': 'file.txt'}),\n",
       " Document(page_content='and web development. This extensive library reduces the need for developers to write code from scratch, enabling them to focus on solving specific problems.', metadata={'source': 'file.txt'}),\n",
       " Document(page_content=\"Another key feature of Python is its strong community support. The Python community is known for its inclusivity and helpfulness, with a vast number of libraries and frameworks available for almost any task imaginable. These libraries and frameworks, such as Django for web development, NumPy for scientific computing, and TensorFlow for machine learning, contribute to Python's popularity in various fields.\", metadata={'source': 'file.txt'}),\n",
       " Document(page_content=\"Python's popularity in the field of data science and machine learning is particularly noteworthy. Its simplicity and readability make it an ideal choice for data analysis and visualization tasks. Libraries such as Pandas, Matplotlib, and Seaborn provide powerful tools for working with data, while libraries like TensorFlow and PyTorch offer state-of-the-art machine learning capabilities. Python's popularity in these fields has been further boosted by the rise of Jupyter notebooks, which allow\", metadata={'source': 'file.txt'}),\n",
       " Document(page_content='popularity in these fields has been further boosted by the rise of Jupyter notebooks, which allow for interactive and exploratory data analysis.', metadata={'source': 'file.txt'}),\n",
       " Document(page_content=\"In addition to its use in data science and machine learning, Python is also widely used in web development. Frameworks like Django and Flask provide developers with the tools to build scalable and secure web applications. Python's simplicity and readability make it easy to develop and maintain web applications, making it a popular choice among web developers.\", metadata={'source': 'file.txt'}),\n",
       " Document(page_content=\"Python's versatility extends beyond web development and data science. It is also used in game development, desktop applications, network programming, and more. Its ease of use and extensive library support make it a go-to language for developers working in various domains.\", metadata={'source': 'file.txt'}),\n",
       " Document(page_content=\"In conclusion, Python is a powerful and versatile programming language that has gained widespread popularity due to its simplicity, readability, and strong community support. Its versatility makes it suitable for a wide range of applications, from web development to data science and machine learning. Whether you're a beginner learning to code or an experienced developer working on complex projects, Python has something to offer for everyone.\", metadata={'source': 'file.txt'})]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)\n",
    "documents = text_splitter.split_documents(text_doc)\n",
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "embeddings = OllamaEmbeddings(model=\"mxbai-embed-large\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import Chroma\n",
    "embeddings = OllamaEmbeddings(model=\"llama2-uncensored\")\n",
    "db = Chroma.from_documents(documents[:5], embedding=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Python is a versatile and powerful programming language that has gained immense popularity in recent years. Known for its simplicity and readability, Python is often the first choice for beginners and experienced developers alike. Created by Guido van Rossum and first released in 1991, Python has since evolved into a robust language used in various fields such as web development, data science, artificial intelligence, and more. One of the key reasons for Python's popularity is its\""
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = 'Python supports multiple programming paradigms, including'\n",
    "result = db.similarity_search(query)\n",
    "result[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "embeddings = OllamaEmbeddings(model=\"llama2-uncensored\")\n",
    "db1 = FAISS.from_documents(documents[:10], embedding=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Python is a versatile and powerful programming language that has gained immense popularity in recent years. Known for its simplicity and readability, Python is often the first choice for beginners and experienced developers alike. Created by Guido van Rossum and first released in 1991, Python has since evolved into a robust language used in various fields such as web development, data science, artificial intelligence, and more. One of the key reasons for Python's popularity is its\""
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = 'Python supports multiple programming paradigms, including'\n",
    "result = db1.similarity_search(query)\n",
    "result[0].page_content"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
